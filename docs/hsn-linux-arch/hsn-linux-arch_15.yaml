- en: Using Elasticsearch, Logstash, and Kibana to Manage Logs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Elasticsearch、Logstash和Kibana管理日志
- en: Deploying **Elasticsearch**, **Logstash**, and **Kibana** (**ELK Stack**) is
    relatively straightforward, but there are several considerations that need to
    be taken into account when installing these components. While this will not be
    an in-depth guide for an Elastic Stack, the main takeaways will be the implementation
    aspects, the decisions that are made through the process, and how you, as an architect,
    should think when making these decisions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 部署Elasticsearch、Logstash和Kibana（ELK Stack）相对简单，但在安装这些组件时需要考虑几个因素。虽然这不会是Elastic
    Stack的深入指南，但主要的收获将是实施方面、在过程中做出的决策以及作为架构师在做出这些决策时应该考虑的方式。
- en: This chapter will help you, as an architect, define the aspects that are needed
    to deploy an ELK Stack, and what configurations to use when working with the components
    that make up the Elastic Stack.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将帮助您作为架构师定义部署ELK Stack所需的方面，以及在使用组成Elastic Stack的组件时要使用的配置。
- en: 'In this chapter, we will go through the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下主题：
- en: Installing and configuring Elasticsearch
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和配置Elasticsearch
- en: Installing and configuring Logstash and Kibana
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和配置Logstash和Kibana
- en: Installing and explaining Beats
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和解释Beats
- en: Configuring Kibana dashboards
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Kibana仪表板
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following tools and installations will be used in this chapter:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用以下工具和安装：
- en: '**Elasticsearch installation guide**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Elasticsearch安装指南**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/_installation.html)'
- en: '**XFS stripe size and Stripe unit "how to"**: [http://xfs.org/index.php/XFS_FAQ#Q:_How_to_calculate_the_correct_sunit.2Cswidth_values_for_optimal_performance](http://xfs.org/index.php/XFS_FAQ#Q:_How_to_calculate_the_correct_sunit.2Cswidth_values_for_optimal_performance)'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**XFS条带大小和条带单元“如何”**: [http://xfs.org/index.php/XFS_FAQ#Q:_How_to_calculate_the_correct_sunit.2Cswidth_values_for_optimal_performance](http://xfs.org/index.php/XFS_FAQ#Q:_How_to_calculate_the_correct_sunit.2Cswidth_values_for_optimal_performance)'
- en: '**XFS write barriers**: [https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/writebarrieronoff](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/writebarrieronoff)'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**XFS写屏障**: [https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/writebarrieronoff](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/writebarrieronoff)'
- en: '**Elasticsearch configuration details**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html)'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Elasticsearch配置细节**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/settings.html)'
- en: '**Avoiding a split brain in Elasticsearch**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain)'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**避免Elasticsearch中的脑裂**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain](https://www.elastic.co/guide/en/elasticsearch/reference/current/modules-node.html#split-brain)'
- en: '**Elasticsearch cluster state API**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-state.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-state.html)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Elasticsearch集群状态API**: [https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-state.html](https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-state.html)'
- en: '**Logstash installation guide**: [https://www.elastic.co/guide/en/logstash/current/installing-logstash.html](https://www.elastic.co/guide/en/logstash/current/installing-logstash.html)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Logstash安装指南**: [https://www.elastic.co/guide/en/logstash/current/installing-logstash.html](https://www.elastic.co/guide/en/logstash/current/installing-logstash.html)'
- en: '**Kibana user guide and how to install**: [https://www.elastic.co/guide/en/kibana/current/rpm.html](https://www.elastic.co/guide/en/kibana/current/rpm.html)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kibana用户指南和安装方法**: [https://www.elastic.co/guide/en/kibana/current/rpm.html](https://www.elastic.co/guide/en/kibana/current/rpm.html)'
- en: '**Logstash filter example for Beats modules**: [https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html](https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Beats模块的Logstash过滤器示例**: [https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html](https://www.elastic.co/guide/en/logstash/current/logstash-config-for-filebeat-modules.html)'
- en: '**Structure of a Logstash config file**: [https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html](https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Logstash配置文件的结构**: [https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html](https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html)'
- en: '**Filebeat installation process**: [https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Filebeat安装过程**: [https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html](https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-installation.html)'
- en: '**Metricbeat installation overview and details**: [https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-installation.html](https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-installation.html)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Metricbeat安装概述和细节**: [https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-installation.html](https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-installation.html)'
- en: Deployment overview
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署概述
- en: For this deployment, we will be using Elasticsearch version 6.5 (which is the
    latest version at the time of writing). This means that all subsequent components
    must be the same version. The base OS will be CentOS 7.6\. While this specific
    deployment will be implemented on a local **virtual machine** (**VM**) setup,
    the concepts can still be applied to the cloud.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此部署，我们将使用Elasticsearch版本6.5（这是撰写时的最新版本）。这意味着所有后续组件必须是相同的版本。基本操作系统将是CentOS
    7.6。虽然此特定部署将在本地虚拟机（VM）设置上实施，但这些概念仍然可以应用于云。
- en: Elasticsearch will be deployed using 2 nodes on 2 vCPU VMs with 4 GB of RAM
    each (in [Chapter 11](2bc754cd-e146-4fbf-b874-d2a80bf471ba.xhtml), *Designing
    an ELK Stack*, we established that the minimum RAM required is about 2.5 GB).
    The underlying storage for the VMs is **non-volatile memory express** (**NVMe**),
    so some considerations need to be taken when replicating the setup somewhere else.
    In terms of space, the Elasticsearch nodes will have 64 GB of disk space each;
    the nodes will have the 64 GB disk mounted to the `/var/lib/elasticsearch` directory.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch将使用2个节点在2个vCPU VM上部署，每个节点配备4 GB的RAM（在[第11章](2bc754cd-e146-4fbf-b874-d2a80bf471ba.xhtml)中，*设计ELK堆栈*，我们确定了所需的最小RAM约为2.5
    GB）。VM的底层存储为**非易失性内存表达**（**NVMe**），因此在其他地方复制设置时需要考虑一些因素。就空间而言，Elasticsearch节点将分别具有64
    GB的磁盘空间；节点将把64 GB磁盘挂载到`/var/lib/elasticsearch`目录。
- en: Logstash and Kibana will be deployed on the same VM using 2 vCPUs and 4 GB of
    RAM. As seen in [Chapter 11](2bc754cd-e146-4fbf-b874-d2a80bf471ba.xhtml), *Designing
    an ELK Stack*, Logstash has a requirement for persistent storage for queues. So,
    for this, we will be using a 32 GB dedicated disk. This disk will be mounted on
    the `/var/lib/logstash` directory for persistent queuing.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash和Kibana将在相同的VM上部署，使用2个vCPU和4 GB的RAM。如[第11章](2bc754cd-e146-4fbf-b874-d2a80bf471ba.xhtml)所示，*设计ELK堆栈*，Logstash需要持久存储队列。因此，我们将使用一个32
    GB的专用磁盘。该磁盘将挂载到`/var/lib/logstash`目录以进行持久排队。
- en: 'We can summarize what will be used for the deployment as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以总结部署所需的内容如下：
- en: The base OS is CentOS 7.6
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本操作系统是CentOS 7.6
- en: Elasticsearch v6.5
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch v6.5
- en: Logstash v6.5
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Logstash v6.5
- en: Kibana v6.5
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kibana v6.5
- en: Elasticsearch using 2 nodes on 2 vCPU VMs with 4 GB of RAM
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch使用2个节点在2个vCPU VM上，每个节点配备4 GB的RAM
- en: Logstash and Kibana on a single VM using 2 vCPUs with 4 GB of RAM
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在单个VM上使用2个vCPU和4 GB的RAM部署Logstash和Kibana
- en: 64 GB disks for the Elasticsearch nodes
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elasticsearch节点使用64 GB磁盘
- en: 32 GB disk for the Logstash persistent queue
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 32 GB磁盘用于Logstash持久队列
- en: 'The following diagram illustrates the entire implementation and will give you
    an idea of how things are connected:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了整个实施过程，并将让您了解事物是如何连接的：
- en: '![](img/a387ec77-f6d5-4e5f-9632-2a9751668a69.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a387ec77-f6d5-4e5f-9632-2a9751668a69.png)'
- en: Installing Elasticsearch
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Elasticsearch
- en: 'Going from nothing to a functional Elasticsearch setup requires the software
    to be installed; this can be done in several ways and on different platforms.
    Some of these installation options are as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从无到有的功能性Elasticsearch设置需要安装软件；这可以通过多种方式和不同平台完成。以下是一些安装选项：
- en: Installing from the source
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从源代码安装
- en: Installing `deb` for Debian-based Linux Distributions
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为基于Debian的Linux发行版安装`deb`
- en: Installing `rpm` for **Red Hat Enterprise Linux** (**RHEL**), CentOS, **sound
    library for embedded systems** (**SLES**), OpenSLES, and RPM-based distributions
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为**Red Hat Enterprise Linux**（**RHEL**）、CentOS、**嵌入式系统的声音库**（**SLES**）、OpenSLES和基于RPM的发行版安装`rpm`
- en: Installing `msi` for Windows
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Windows安装`msi`
- en: Deploying Docker images
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署Docker镜像
- en: For this setup, we will be using the RPM repository for consistency across versions,
    and for simplification purposes when updates are available.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对于此设置，我们将使用RPM存储库以保持版本一致，并在更新可用时简化目的。
- en: The RPM repository
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RPM存储库
- en: To install the RPM repository for RHEL and CentOS, we need to create a file
    in the `/etc/yum.repos.d` directory. Here, the name of the file doesn't matter
    but, in reality, it needs to be meaningful. The contents of the file indicate
    how `yum` will go and search for software.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装RHEL和CentOS的RPM存储库，我们需要在`/etc/yum.repos.d`目录中创建一个文件。在这里，文件的名称并不重要，但实际上，它需要有意义。文件的内容指示了`yum`将如何搜索软件。
- en: 'Create a file named `/etc/yum.repos.d/elastic.repo` with the following code
    details:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`/etc/yum.repos.d/elastic.repo`的文件，其中包含以下代码细节：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Once the repository file has been created, simply run the following command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了存储库文件后，只需运行以下命令：
- en: '[PRE1]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will refresh the metadata of all of the configured repositories. Before
    installing Elasticsearch, we need to install the OpenJDK version, `1.8.0`; for
    this, we can run the following command:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这将刷新所有配置的存储库的元数据。在安装Elasticsearch之前，我们需要安装OpenJDK版本`1.8.0`；为此，我们可以运行以下命令：
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, confirm that `java` is installed, as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，确认已安装`java`，如下所示：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, you should see something similar to the following output:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您应该看到类似以下输出：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can then proceed to install `elasticsearch`, as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以继续安装`elasticsearch`，如下所示：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Before starting Elasticsearch, some configuration needs to be done.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动Elasticsearch之前，需要进行一些配置。
- en: The Elasticsearch data directory
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Elasticsearch数据目录
- en: 'The default configuration for Elasticsearch has the data directory set to the
    `/var/lib/elasticsearch` path. This is controlled through the `path.data` configuration
    option in the `/etc/elasticsearch/elasticsearch.yml` file:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch的默认配置将数据目录设置为`/var/lib/elasticsearch`路径。这是通过`/etc/elasticsearch/elasticsearch.yml`文件中的`path.data`配置选项控制的：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this setup, a 64 GB disk will be mounted to this location.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在此设置中，将挂载一个64 GB的磁盘到此位置。
- en: When deploying in Azure, make sure that the `path.data` option is configured
    to use a data disk rather than the OS disk.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure部署时，请确保`path.data`选项配置为使用数据磁盘而不是操作系统磁盘。
- en: Partitioning the disk
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 磁盘分区
- en: Before creating a filesystem, the disk needs to be partitioned. To do this,
    we can use the `parted` utility.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建文件系统之前，需要对磁盘进行分区。为此，我们可以使用`parted`实用程序。
- en: 'First, we need to initialize the disk as `gpt`; for this, we can use the following
    command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要将磁盘初始化为`gpt`；为此，我们可以使用以下命令：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Then, we create the partition:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建分区：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Here, we're telling `parted` to create a partition from `0GB` to `64GB`, or
    from the beginning of the disk to the end. Additionally, we're using an `xfs`
    signature, since that is the filesystem that is going to be used for the data
    directory.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们告诉`parted`从`0GB`到`64GB`创建一个分区，或者从磁盘的开始到结束。此外，我们使用了`xfs`签名，因为这是将用于数据目录的文件系统。
- en: 'Finally, we verify that the partition has been successfully created with the
    correct boundaries by running the following command:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过运行以下命令验证分区是否已成功创建并具有正确的边界：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The output should be similar to the following code block:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应类似于以下代码块：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Formatting the filesystem
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 格式化文件系统
- en: To be able to store data on the newly created partition, we first need to create
    a filesystem. For this setup, we will be using the XFS filesystem.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够在新创建的分区上存储数据，我们首先需要创建一个文件系统。对于此设置，我们将使用XFS文件系统。
- en: 'To format the disk, run the `mkfs.xfs` command, as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 要格式化磁盘，请运行`mkfs.xfs`命令，如下所示：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: By default, XFS uses a 4K block size that matches the memory page size; this
    is also ideal for relatively small files.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，XFS使用与内存页大小匹配的4K块大小；这也适用于相对较小的文件。
- en: Note that the partition of the device file is specified rather than the entire
    disk. While it is possible to use the disk itself, it is recommended that you
    create filesystems on partitions. Additionally, if the filesystem is going to
    be used on a RAID setup, then changing the stripe unit and stripe size generally
    helps with performance.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，指定了设备文件的分区，而不是整个磁盘。虽然可以使用磁盘本身，但建议在分区上创建文件系统。此外，如果文件系统将用于RAID设置，则更改条带单元和条带大小通常有助于提高性能。
- en: Persistent mounting using fstab
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用fstab进行持久挂载
- en: Now that the filesystem has been created, we need to make sure that it is mounted
    after every reboot at the correct location.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在文件系统已经创建，我们需要确保它在每次重启后都能正确挂载到正确的位置。
- en: As a general rule, mounting the filesystem using the device file is not advised,
    especially in the cloud. This is because the disk order might change, causing
    the device file of the disks to be mixed up. To work around this problem, we can
    use the UUID of the disk, which is a unique identifier that will persist even
    when the disk is moved to another system.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，不建议使用设备文件挂载文件系统，特别是在云中。这是因为磁盘顺序可能会改变，导致磁盘的设备文件混乱。为了解决这个问题，我们可以使用磁盘的UUID，这是一个唯一的标识符，即使磁盘移动到另一个系统，它也会持续存在。
- en: 'To obtain the UUID of the disk, run the `blkid` command:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 获取磁盘的UUID，请运行`blkid`命令：
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In this case, `/dev/sdb1` is the 64 GB disk that we will be using for Elasticsearch.
    With the UUID, we can add it to the `/etc/fstab` file, which controls the filesystems
    that will be mounted during boot time. Simply edit the file and add the following
    entries:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，`/dev/sdb1`是我们将用于Elasticsearch的64GB磁盘。有了UUID，我们可以将其添加到控制在启动时挂载的文件系统的`/etc/fstab`文件中。只需编辑文件并添加以下条目：
- en: '[PRE13]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Here are some important details to take note of from the preceding command:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是从上述命令中需要注意的一些重要细节：
- en: '`nobarrier`: This helps with write performance as it disables the mechanism
    used by XFS to acknowledge writes once they hit persistent storage. This is usually
    used on physical storage systems where there is no form of battery backup write
    cache.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nobarrier`：这有助于写入性能，因为它禁用了XFS用于确认写入是否已经到达持久存储的机制。这通常用于物理存储系统，其中没有电池备份写缓存。'
- en: '`noatime`: This disables the recording mechanism when a file is accessed or
    modified. When `atime` is enabled, every read will result in a small set of writes,
    since the access times will need to be updated. Disabling can help with reads
    as it doesn''t generate any unnecessary writes.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`noatime`：当文件被访问或修改时，这会禁用记录机制。启用`atime`时，每次读取都会导致一小部分写入，因为访问时间需要更新。禁用可以帮助读取，因为它不会产生任何不必要的写入。'
- en: '`nofail`: This allows the system to boot normally in the event of the disk
    that is backing the mount point going missing. This is particularly helpful when
    deploying on the cloud were no access to the console exists.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nofail`：这允许系统在支持挂载点的磁盘丢失时正常启动。这在部署在云上且无法访问控制台时特别有帮助。'
- en: 'Next, verify that the disk has been mounted to the correct location before
    starting the Elasticsearch service:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在启动Elasticsearch服务之前，验证磁盘是否已挂载到正确的位置：
- en: '[PRE14]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Finally, make sure that the correct ownership of the `/var/lib/elasticsearch` directory
    is configured:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，确保正确配置了`/var/lib/elasticsearch`目录的所有权：
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Configuring Elasticsearch
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Elasticsearch
- en: Before starting the Elasticsearch service, we need to define several parameters
    that control how Elasticsearch behaves. The configuration file is in the YAML
    format and is located on `/etc/elasticsearch/elasticsearch.yml`. Let's explore
    which main parameters need to be changed.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动Elasticsearch服务之前，我们需要定义控制Elasticsearch行为的几个参数。配置文件以YAML格式存储在`/etc/elasticsearch/elasticsearch.yml`中。让我们探讨需要更改的主要参数。
- en: Elasticsearch YAML
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Elasticsearch YAML
- en: The central control for Elasticsearch is done through the `/etc/elasticsearch/elasticsearch.yml` file,
    which is in the YAML format. The default configuration file is reasonably well-documented
    and explains what each parameter controls, but there are some entries that should
    be changed as part of the configuration process.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Elasticsearch的中央控制是通过`/etc/elasticsearch/elasticsearch.yml`文件完成的，该文件以YAML格式存储。默认配置文件有相当完整的文档说明每个参数控制的内容，但作为配置过程的一部分，有一些条目应该被更改。
- en: 'The main parameters to look for are as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 要查找的主要参数如下：
- en: Cluster name
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群名称
- en: Discovery settings
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现设置
- en: Node name
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点名称
- en: Network host
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络主机
- en: Path settings
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 路径设置
- en: Cluster name
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群名称
- en: 'Elasticsearch nodes will only be able to join a cluster when they have the
    same cluster name specified in their configuration. This is handled through the
    `cluster.name` parameter; for this setup, we will use `elastic-cluster`:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 只有当Elasticsearch节点在其配置中指定了相同的集群名称时，它们才能加入集群。这是通过`cluster.name`参数处理的；对于此设置，我们将使用`elastic-cluster`：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This setting should be configured on both nodes so that they have the same value.
    Otherwise, the second node will not be able to join the cluster.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 应该在两个节点上配置此设置，以便它们具有相同的值。否则，第二个节点将无法加入集群。
- en: Discovery settings
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发现设置
- en: The discovery parameters control how Elasticsearch manages intra-node communication
    that is used for clustering and master election.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 发现参数控制Elasticsearch如何管理用于集群和主节点选举的节点内通信。
- en: The two main parameters regarding discovery are `discovery.zen.ping.unicast.hosts`
    and `discovery.zen.minimum_master_nodes`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 关于发现的两个主要参数是`discovery.zen.ping.unicast.hosts`和`discovery.zen.minimum_master_nodes`。
- en: The `discovery.zen.ping.unicast.hosts` setting controls which nodes are going
    to be used for clustering. Since two nodes will be used in our setup, the configuration
    for `node1` should have the DNS name of `node2`, while `node2` should have the
    DNS of `node1`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`discovery.zen.ping.unicast.hosts`设置控制将用于集群的节点。由于我们的设置将使用两个节点，因此`node1`的配置应具有`node2`的DNS名称，而`node2`应具有`node1`的DNS名称。'
- en: 'The `discovery.zen.minimum_master_nodes` setting controls the minimum number
    of master nodes in the cluster; this is used to avoid split-brain scenarios where
    there''s more than one master node that is active in the cluster. The number for
    this parameter can be calculated based on a simple equation, as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`discovery.zen.minimum_master_nodes`设置控制集群中主节点的最小数量；这用于避免出现多个活动主节点的分裂脑场景。可以根据简单的方程式计算此参数的数量，如下所示：'
- en: '![](img/6f0843de-eade-4bc1-ae57-eac32164ff77.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f0843de-eade-4bc1-ae57-eac32164ff77.png)'
- en: 'Here, *N* is the number of nodes in the cluster. For this setup, since only
    `2` nodes are to be configured, the setting should be `2`. Both parameters should
    be as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*N*是集群中节点的数量。对于此设置，由于只需配置`2`个节点，设置应为`2`。两个参数应如下所示：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'For `node2`, change `discovery.zen.ping.unicast.hosts: ["elastic2"]` to `discovery.zen.ping.unicast.hosts:
    ["elastic1"]`.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '对于`node2`，将`discovery.zen.ping.unicast.hosts: ["elastic2"]`更改为`discovery.zen.ping.unicast.hosts:
    ["elastic1"]`。'
- en: Node name
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点名称
- en: 'By default, Elasticsearch uses a randomly-generated UUID for its node name,
    which is not very user-friendly. This parameter is relatively simple as it controls
    the name for the specific node. For this setup, we''ll be using `elasticX`, where
    `X` is the node number; `node1` should be as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Elasticsearch使用随机生成的UUID作为其节点名称，这不太用户友好。该参数相对简单，因为它控制特定节点的名称。对于此设置，我们将使用`elasticX`，其中`X`是节点编号；`node1`应如下所示：
- en: '[PRE18]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Change `node2` to match the naming convention, so it is `elastic2`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 将`node2`更改为符合命名约定，因此它是`elastic2`。
- en: Network host
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络主机
- en: This controls which IP address Elasticsearch will bind to and listen to requests.
    By default, it binds to the loopback IP address; this setting needs to be changed
    to allow other nodes from a cluster or allow Kibana and Logstash on other servers
    to send requests. This setting also accepts special parameters, such as the network
    interface. For this setup, we'll have Elasticsearch listen to all the addresses
    by setting the `network.host` parameter to `0.0.0.0`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这控制Elasticsearch将绑定到哪个IP地址并监听请求。默认情况下，它绑定到回环IP地址；需要更改此设置以允许来自集群的其他节点或允许其他服务器上的Kibana和Logstash发送请求。此设置还接受特殊参数，例如网络接口。对于此设置，我们将通过将`network.host`参数设置为`0.0.0.0`来使Elasticsearch监听所有地址。
- en: 'On both nodes, make sure that the setting is as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在两个节点上，确保设置如下：
- en: '[PRE19]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Path settings
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路径设置
- en: Finally, the path parameters control where Elasticsearch stores its data and
    its logs.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，路径参数控制Elasticsearch存储其数据和日志的位置。
- en: 'By default, it is configured to store data under `/var/lib/elasticsearch`,
    and logs under `/var/log/elasticsearch`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，它配置为将数据存储在`/var/lib/elasticsearch`下，并将日志存储在`/var/log/elasticsearch`下：
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: One crucial aspect of this parameter is that, under the `path.data` setting,
    multiple paths can be specified. Elasticsearch will use all the paths specified
    here to store data, thus increasing the overall performance and available space.
    For this setup, we'll leave the defaults as they were in the preceding steps,
    where we mounted a data disk under the `/var/lib/elasticsearch` directory.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 该参数的一个关键方面是，在`path.data`设置下，可以指定多个路径。Elasticsearch将使用此处指定的所有路径来存储数据，从而提高整体性能和可用空间。对于此设置，我们将保留默认设置，即在前面的步骤中挂载数据磁盘到`/var/lib/elasticsearch`目录下。
- en: Starting Elasticsearch
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动Elasticsearch
- en: Now that we've configured Elasticsearch, we need to make sure that the service
    starts automatically and correctly during boot.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经配置了Elasticsearch，我们需要确保服务在启动时能够自动正确地启动。
- en: 'Start and enable the Elasticsearch service, as follows:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 启动并启用Elasticsearch服务，如下所示：
- en: '[PRE21]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then, verify that Elasticsearch started correctly by running the following
    command:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过运行以下命令验证Elasticsearch是否正确启动：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The output should be similar to the following code block:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应类似于以下代码块：
- en: '[PRE23]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Adding an Elasticsearch node
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加Elasticsearch节点
- en: At this point, we can add the second node to the Elasticsearch cluster.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以将第二个节点添加到Elasticsearch集群中。
- en: The same configuration should be applied to the previous steps, making sure
    that the settings are changed to reflect the DNS name for `node2`.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 应将相同的配置应用于先前的步骤，确保更改设置以反映`node2`的DNS名称。
- en: To add the node to the cluster, all we need to do is simply start the Elasticsearch
    service.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要将节点添加到集群，我们只需简单地启动Elasticsearch服务。
- en: 'When the service starts, messages are logged to `/var/log/elasticsearch`, which
    indicates that the node was successfully added to the cluster:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 服务启动时，消息被记录在`/var/log/elasticsearch`，这表明节点已成功添加到集群中：
- en: '[PRE24]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'You can use the following code to confirm that the cluster is up and running:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码来确认集群正在运行：
- en: '[PRE25]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The output should be similar to the following code block:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应类似于以下代码块：
- en: '[PRE26]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: For any subsequent nodes that need to be added to the cluster, the previous
    steps should be followed, making sure that the `cluster.name` parameter is set
    to the correct value.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 对于需要添加到集群的任何后续节点，应遵循先前的步骤，确保`cluster.name`参数设置为正确的值。
- en: Installing Logstash and Kibana
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Logstash和Kibana
- en: With the Elasticsearch cluster up and running, we can now go ahead and install
    Logstash and Kibana.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 有了Elasticsearch集群正在运行，我们现在可以继续安装Logstash和Kibana。
- en: The repository that was used in the previous steps is the same for the remaining
    components. So, the same process that was used before to add the repository should
    be applied to the Logstash and Kibana node.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面步骤中使用的存储库对于剩余的组件是相同的。因此，应该将之前用于添加存储库的相同过程应用于Logstash和Kibana节点。
- en: 'This is a summary, the same process has been explored before:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个总结，之前已经探讨过相同的过程：
- en: Add the repository to `/etc/yum.repos.d/elastic.repo`
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将存储库添加到`/etc/yum.repos.d/elastic.repo`
- en: Update the `yum` cache to `sudo yum makecache`
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`yum`缓存为`sudo yum makecache`
- en: Install Logstash and Kibana using `sudo yum install logstash kibana`
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sudo yum install logstash kibana`安装Logstash和Kibana
- en: Initialize the disk for `/var/lib/logstash` and `sudo parted /dev/sdX mklabel
    gpt`
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为`/var/lib/logstash`初始化磁盘和`sudo parted /dev/sdX mklabel gpt`
- en: Create the `sudo parted /dev/sdX mkpart xfs 0GB 32GB` partition (note that this
    is a 32 GB disk)
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`sudo parted /dev/sdX mkpart xfs 0GB 32GB`分区（注意这是一个32GB磁盘）
- en: Create the `sudo mkfs.xfs /dev/sdX1` filesystem
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`sudo mkfs.xfs /dev/sdX1`文件系统
- en: Update `fstab`
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新`fstab`
- en: 'Update the `sudo chown logstash: /var/lib/logstash` directory permissions'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '更新`sudo chown logstash: /var/lib/logstash`目录权限'
- en: 'The Logstash `systemd` unit is not added by default; to do so, run the script
    provided by Logstash:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash `systemd`单元默认情况下不会被添加；要这样做，运行Logstash提供的脚本：
- en: '[PRE27]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Finally, one specific component that is required is a coordinating Elasticsearch
    node. This will serve as a load balancer for the Elasticsearch cluster that is
    used by Kibana to install Elasticsearch:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一个特定的组件是必需的，那就是一个协调的Elasticsearch节点。这将作为Elasticsearch集群的负载均衡器，Kibana用于安装Elasticsearch。
- en: '[PRE28]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: More information on the coordinating node configuration is provided in the *Configuring
    Kibana* section.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 有关协调节点配置的更多信息在*配置Kibana*部分提供。
- en: Configuring Logstash
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Logstash
- en: Similar to Elasticsearch, the main configuration file for Logstash is located
    under `/etc/logstash/logstash.yml`, and some settings will need to be changed
    to achieve the desired functionality.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 与Elasticsearch类似，Logstash的主配置文件位于`/etc/logstash/logstash.yml`下，并且某些设置需要更改以实现所需的功能。
- en: Logstash YAML
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Logstash YAML
- en: First, the `node.name` parameter should be adjusted so that it identifies the
    Logstash node correctly. By default, it uses the machine's hostname as the `node.name`
    parameter. However, since we are running both Logstash and Kibana on the same
    system, it is worth changing this setting to avoid confusion.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，应调整`node.name`参数，以便正确标识Logstash节点。默认情况下，它使用机器的主机名作为`node.name`参数。然而，由于我们在同一系统上运行Logstash和Kibana，值得改变这个设置以避免混淆。
- en: Next, we need to consider the queuing settings; these control how Logstash manages
    the type of queues and where it stores queue data.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要考虑排队设置；这些控制Logstash如何管理队列类型以及它存储队列数据的位置。
- en: 'The first setting is `queue.type`, which defines the type of queue that is
    used by Logstash. For this setup, we are using persistent queuing:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个设置是`queue.type`，它定义了Logstash使用的队列类型。对于这个设置，我们使用持久队列：
- en: '[PRE29]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Since queuing is set to persistent, the events need to be stored in a temporary
    location before being sent to Elasticsearch; this is controlled by the `path.queue`
    parameter:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 由于排队设置为持久，事件需要存储在临时位置，然后再发送到Elasticsearch；这由`path.queue`参数控制：
- en: '[PRE30]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: If left by default, Logstash will use the `path.data/queue` directory to store
    events in the queue. The `path.data` directory defaults to `/var/lib/logstash`,
    which is where we configured the 32 GB disk; this is the desired configuration.
    If another location needs to be specified for queuing, this setting should be
    adjusted to match the correct path.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果保持默认设置，Logstash将使用`path.data/queue`目录来存储队列中的事件。`path.data`目录默认为`/var/lib/logstash`，这是我们配置32GB磁盘的位置；这是期望的配置。如果需要指定另一个位置用于排队，应调整此设置以匹配正确的路径。
- en: 'The last setting to be changed in the `logstash.yml` file is the `queue.max_bytes`
    setting, which controls the maximum space that is allowed for the queue. For this
    setup, since we added a dedicated 32 GB disk for only this purpose, the setting
    can be changed to 25 GB to allow for a buffer if more space is needed. The setting
    should look as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在`logstash.yml`文件中需要更改的最后一个设置是`queue.max_bytes`设置，它控制队列允许的最大空间。对于这个设置，由于我们为此目的添加了一个专用的32GB磁盘，可以将设置更改为25GB，以便在需要更多空间时提供缓冲。设置应如下所示：
- en: '[PRE31]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As an option, the `xpack.monitoring.enabled` setting can be set to true to enable
    monitoring through Kibana.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个选项，`xpack.monitoring.enabled`设置可以设置为true，以通过Kibana启用监视。
- en: Make sure that the parameters in the `yaml` file don't have a space at the beginning
    of the line or it might fail to load the configuration.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 确保`yaml`文件中的参数在行首没有空格，否则可能无法加载配置。
- en: Logstash pipelines
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Logstash管道
- en: 'Logstash outputs are controlled by the pipelines that are configured through
    files placed under `/etc/logstash/conf.d/`; these files control how Logstash ingests
    data, processes it, and then returns it as an output for Elasticsearch. A pipeline
    configuration is similar to the following code:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash输出由通过放置在`/etc/logstash/conf.d/`下的文件配置的管道控制；这些文件控制Logstash如何摄取数据，处理数据，然后将其作为Elasticsearch的输出返回。管道配置类似于以下代码：
- en: '[PRE32]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Here, the `input` section defines which data to accept and from which source;
    in this setup, we will be using `beats` as an input. The filter section controls
    how data is transformed before being sent to the output, and the output section
    defines where the data is sent. In this case, we will be sending data to the Elasticsearch
    nodes.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`input`部分定义要接受的数据以及来源；在这个设置中，我们将使用`beats`作为输入。过滤器部分控制数据在发送到输出之前的转换方式，输出部分定义数据发送到哪里。在这种情况下，我们将数据发送到Elasticsearch节点。
- en: 'Let''s create a configuration file for `syslog` messages to be filtered by
    Logstash, and then be sent to the Elasticsearch cluster. The file needs to be
    placed in `/etc/logstash/conf.d`, since the input will be from the `beats` module;
    let''s call it the `beats-syslog.conf` file:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为`syslog`消息创建一个配置文件，以便通过Logstash进行过滤，然后发送到Elasticsearch集群。该文件需要放置在`/etc/logstash/conf.d`中，因为输入将来自`beats`模块；让我们称之为`beats-syslog.conf`文件：
- en: '[PRE33]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The file''s contents is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的内容如下：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Make sure that the `output` section has the DNS names or IPs of the Elasticsearch
    nodes:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 确保`output`部分具有Elasticsearch节点的DNS名称或IP地址：
- en: '[PRE35]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: In this pipeline configuration, the `beats` module sends logs to the Logstash
    node. Then Logstash will process the data and load balance the output between
    the Elasticsearch nodes. We can now go ahead and configure Kibana.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在此管道配置中，`beats`模块将日志发送到Logstash节点。然后Logstash将处理数据并在Elasticsearch节点之间进行负载均衡输出。现在我们可以继续配置Kibana。
- en: Configuring Kibana
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Kibana
- en: The last piece of the Elastic Stack is Kibana; the configuration is handled
    by `/etc/kibana/kibana.yml` in a similar way to Elasticsearch and Logstash.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Elastic Stack的最后一部分是Kibana；配置方式与Elasticsearch和Logstash类似，由`/etc/kibana/kibana.yml`处理。
- en: Kibana YAML
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kibana YAML
- en: By default, Kibana listens on port `5601`; this is controlled by the `server.port`
    parameter, which can be changed if there's a need to access Kibana on a different
    port. For this setup, the default will be used.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kibana侦听端口`5601`；这由`server.port`参数控制，如果需要在不同端口访问Kibana，则可以更改。对于此设置，将使用默认设置。
- en: 'The `server.host` setting controls which addresses Kibana will listen to for
    requests. Since access is needed from external sources (that is, other than `localhost`),
    we can use the following setting:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`server.host`设置控制Kibana将侦听请求的地址。由于需要从外部来源（即`localhost`之外）访问，我们可以使用以下设置：'
- en: '[PRE36]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `server.name` parameter defaults to the hostname where Kibana runs, but
    since Logstash is running alongside Kibana, we can change this to identify the
    Kibana part:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`server.name`参数默认为Kibana运行的主机名，但由于Logstash与Kibana一起运行，我们可以更改此参数以标识Kibana部分：'
- en: '[PRE37]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Finally, `elasticsearch.url` specifies which Elasticsearch node Kibana will
    connect to. As we mentioned previously, we will be using an Elasticsearch coordinate
    node to act as a load balancer between the other two nodes.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`elasticsearch.url`指定了Kibana将连接到哪个Elasticsearch节点。正如我们之前提到的，我们将使用一个Elasticsearch协调节点来充当其他两个节点之间的负载均衡器。
- en: 'Here is the URL of the Elasticsearch instance to use for all your queries:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用于所有查询的Elasticsearch实例的URL：
- en: '[PRE38]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The coordinating node
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 协调节点
- en: A coordinating node is an Elasticsearch node that does not accept inputs, does
    not store data, nor does it take part in master or slave elections.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 协调节点是一个Elasticsearch节点，不接受输入，不存储数据，也不参与主节点或从节点的选举。
- en: The goal of this node is to load balance requests for Kibana between the different
    Elasticsearch nodes on the cluster. The process of installing is the same as the
    one we used before, that is making sure that Java (open JDK) is also installed.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 该节点的目标是在集群中的不同Elasticsearch节点之间负载均衡Kibana的请求。安装过程与之前使用的相同，即确保Java（open JDK）也已安装。
- en: 'The configuration will be different as we want to achieve a number of things:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 配置将不同，因为我们想要实现一些目标：
- en: Disable the master node role
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用主节点角色
- en: Disable the ingest node role
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用摄入节点角色
- en: Disable the data node role
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用数据节点角色
- en: Disable cross-cluster search
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用跨集群搜索
- en: 'To do this, we need the following settings on the `/etc/elasticsearch/elasticsearch.yml`
    file:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们需要在`/etc/elasticsearch/elasticsearch.yml`文件中设置以下设置：
- en: '[PRE39]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Starting Logstash and Kibana
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动Logstash和Kibana
- en: With all of the components already configured, we can start Logstash, Kibana,
    and the coordinating Elasticsearch node.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 所有组件已配置完成后，我们可以启动Logstash、Kibana和协调Elasticsearch节点。
- en: 'Logstash can be started first as it doesn''t require any of the other components
    to be up:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash可以首先启动，因为它不需要其他组件中的任何一个处于运行状态：
- en: '[PRE40]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Then, we can start and enable the `elasticsearch` coordinating node:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以启动和启用`elasticsearch`协调节点：
- en: '[PRE41]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Last but not least, `kibana` can go through the same procedure:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`kibana`可以通过相同的过程进行：
- en: '[PRE42]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'To verify it all started correctly, point your browser to the `kibana` address
    on port `5601` `http://kibana:5601`. Click on Monitoring, and then click on Enable
    monitoring; after a couple of seconds, you will see something similar to the following
    screenshot:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证所有内容是否正确启动，请将浏览器指向端口`5601`上的`kibana`地址`http://kibana:5601`。单击监控，然后单击启用监控；几秒钟后，您将看到类似以下屏幕截图的内容：
- en: '![](img/2668b7d3-4572-4ca6-89db-46168cb206fd.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2668b7d3-4572-4ca6-89db-46168cb206fd.png)'
- en: You should see all the components online; the **yellow** status is due to system
    indexes that are not replicated, but this is normal.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到所有组件都在线；**黄色**状态是由于未复制的系统索引，但这是正常的。
- en: With this, the cluster is up and running and ready to accept incoming data from
    logs and metrics. We will be feeding data to the cluster using Beats, which we'll
    explore in the next section.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，集群已经运行起来，准备好接受来自日志和指标的传入数据。我们将使用Beats向集群提供数据，我们将在下一节中探讨。
- en: What are Beats?
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Beats是什么？
- en: Beats are the lightweight data shippers from Elastic.co (the company behind
    Elasticsearch). Beats are designed to be easy to configure and run.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Beats是Elastic.co（Elasticsearch背后的公司）的轻量级数据发货人。Beats旨在易于配置和运行。
- en: Beats are the client part of the equation, living on the systems that are to
    be monitored. Beats capture metrics, logs, and more from servers across the environment
    and ship them to either Logstash for further processing or Elasticsearch for indexing
    and analysis.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Beats是方程式的客户端部分，驻留在要监视的系统上。Beats从环境中的服务器捕获指标、日志等，并将它们发送到Logstash进行进一步处理，或者发送到Elasticsearch进行索引和分析。
- en: There are multiple official Beats (which are developed and maintained by Elastic),
    and a multitude of open source Beats have been developed by the community.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个官方Beats（由Elastic开发和维护），社区还开发了大量的开源Beats。
- en: The main Beats that we'll be using for this setup are **Filebeat** and **Metricbeat**.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在此设置中使用的主要Beats是**Filebeat**和**Metricbeat**。
- en: Filebeat
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Filebeat
- en: The Filebeat function collects logs from sources (such as syslog, Apache, and
    Nginx), and then ships these to Elasticsearch or Logstash.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Filebeat功能从来源（如syslog、Apache和Nginx）收集日志，然后将其发送到Elasticsearch或Logstash。
- en: The Filebeat client needs to be installed in each of the servers that require
    data collection in order to be enabled. This component allows the logs to be sent
    to a centralized location for seamless search and indexing.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 需要在需要数据收集的每台服务器上安装Filebeat客户端才能启用。该组件允许将日志发送到集中位置进行无缝搜索和索引。
- en: Metricbeat
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Metricbeat
- en: Metricbeat collects metrics, such as CPU usage, memory usage, disk IO statistics,
    and network statistics, and then ships them to either Elasticsearch or Logstash.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Metricbeat收集指标，如CPU使用率、内存使用率、磁盘IO统计和网络统计，然后将其发送到Elasticsearch或Logstash。
- en: There's really no need to transform metric data further, so feeding data directly
    to Elasticsearch makes more sense.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，没有必要进一步转换度量数据，因此直接将数据馈送到Elasticsearch更有意义。
- en: Metricbeat should be installed in all systems that require monitoring of resource
    usage; having Metricbeat installed on the Elasticsearch nodes allows you to keep
    a closer control on resource usage to avoid problems.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 应在需要监视资源使用情况的所有系统中安装Metricbeat；在Elasticsearch节点上安装Metricbeat可以让您更密切地控制资源使用情况，以避免问题。
- en: 'Other Beats exist, such as the following:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他Beats，例如以下内容：
- en: '**Packetbeat**: For network traffic monitoring'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Packetbeat**：用于网络流量监控'
- en: '**Journalbeat**: For `systemd` journal logs'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Journalbeat**：用于`systemd`日志'
- en: '**Auditbeat**: For audit data such as logins'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Auditbeat**：用于审计数据，如登录'
- en: Additionally, Beats can be further adapted to suit a specific need through the
    use of modules. As an example, Metricbeat has a module to collect MySQL performance
    statistics.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Beats可以通过模块进一步适应特定需求。例如，Metricbeat具有一个模块用于收集MySQL性能统计信息。
- en: Let's not skip a beat – installing Beats
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让我们不要错过一拍-安装Beats
- en: The installation of the Beats provided by Elasticsearch can be done through
    the Elastic repository that was previously used to install Elasticsearch, Logstash,
    and Kibana.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Elasticsearch提供的Beats的安装可以通过之前用于安装Elasticsearch、Logstash和Kibana的Elastic存储库来完成。
- en: 'First, let''s install Filebeat on one of the Elasticsearch nodes:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在Elasticsearch节点中安装Filebeat：
- en: '[PRE43]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Once installed, confirm that it has completed by running the following code:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 安装后，通过运行以下代码确认已完成：
- en: '[PRE44]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The output should be similar to the following command block:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 输出应类似于以下命令块：
- en: '[PRE45]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'To install `metricbeat`, the process is the same as it lives in the same repository:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装`metricbeat`，过程与它位于同一存储库相同：
- en: '[PRE46]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: To install Beats on other clients, simply add the Elastic repository as we previously
    explained and install it through `yum`. Beats are also provided as standalone
    packages in case there is no repository available for the distribution.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 要在其他客户端上安装Beats，只需像之前解释的那样添加Elastic存储库并通过`yum`安装即可。如果分发中没有可用的存储库，Beats也可以作为独立软件包提供。
- en: Configuring Beats clients
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Beats客户端
- en: With both Filebeat and Metricbeat installed on one of the Elasticsearch nodes,
    we can go ahead and configure them to feed data to both Logstash and Elasticsearch.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在Elasticsearch节点上安装了Filebeat和Metricbeat后，我们可以继续配置它们将数据馈送到Logstash和Elasticsearch。
- en: Filebeat YAML
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Filebeat YAML
- en: Now, it is no surprise that most of the Elastic components are configured through
    YAML files. Filebeat is no exception to that norm, and its configuration is handled
    by the `/etc/filebeat/filebeat.yml` file.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，毫无疑问，大多数Elastic组件都是通过YAML文件进行配置的。Filebeat也不例外，其配置由`/etc/filebeat/filebeat.yml`文件处理。
- en: 'First, we need to tell `filebeat` where to look for the log files that are
    to be shipped to Logstash. In the `yaml` file, this is in the `filebeat.inputs`
    section; change `enabled: false` to `enabled: true`, as follows:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，我们需要告诉`filebeat`在哪里查找要发送到Logstash的日志文件。在`yaml`文件中，这在`filebeat.inputs`部分中；将`enabled:
    false`更改为`enabled: true`，如下所示：'
- en: '[PRE47]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Filebeat comes embedded with Kibana dashboards for easy visualization of the
    data that''s sent. This allows Filebeat to load the dashboards and then add the
    Kibana address to the `setup.kibana` section:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Filebeat附带了Kibana仪表板，便于可视化发送的数据。这允许Filebeat加载仪表板，然后将Kibana地址添加到`setup.kibana`部分：
- en: '[PRE48]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Load the `dashboards`, as follows:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 加载`dashboards`，如下所示：
- en: '[PRE49]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: This configuration needs to be done only once for each new Beat installation;
    there is no need to change this setting on further Filebeat installations as the
    dashboards are already loaded.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置只需要针对每个新的Beat安装执行一次；在进一步安装Filebeat时无需更改此设置，因为仪表板已经加载。
- en: 'Since we are going to be sending data to Logstash, comment out the `output.elasticsearch`
    section; then, uncomment the `output.logstash` section and add Logstash''s details:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将要将数据发送到Logstash，因此注释掉`output.elasticsearch`部分；然后取消注释`output.logstash`部分并添加Logstash的详细信息：
- en: '[PRE50]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Next, we''ll be using the system module for Filebeat to send the output to
    Logstash; to enable this, simply run the following command:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用Filebeat的系统模块将输出发送到Logstash；要启用此功能，只需运行以下命令：
- en: '[PRE51]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, load the index template into `elasticsearch`, as follows:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，加载索引模板到`elasticsearch`，如下所示：
- en: '[PRE52]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Finally, start and enable `filebeat`, as follows:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，启动并启用`filebeat`，如下所示：
- en: '[PRE53]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'To verify that data is being sent, we can use one of the provided dashboards
    to visualize `syslog` events. On Kibana, go to Dashboard and type `Syslog Dashboard` into
    the search bar; you will see something similar to the following screenshot:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证数据是否已发送，可以使用提供的仪表板之一来可视化`syslog`事件。在Kibana上，转到仪表板并在搜索栏中键入`Syslog Dashboard`；您将看到类似以下截图的内容：
- en: '![](img/9496cac8-0164-4963-aa9f-e1db2d85c59a.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9496cac8-0164-4963-aa9f-e1db2d85c59a.png)'
- en: Kibana Dashboard showing search results for Syslog Dashboard
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana仪表板显示了`Syslog Dashboard`的搜索结果
- en: Metricbeat YAML
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Metricbeat YAML
- en: Metricbeat follows a similar process to Filebeat, where the `/etc/metricbeat/metricbeat.yml`
    file needs to edited to send output to Elasticsearch, and the Kibana dashboards
    need to be loaded (that is, they need to be run once).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: Metricbeat遵循与Filebeat类似的过程，需要编辑`/etc/metricbeat/metricbeat.yml`文件以将输出发送到Elasticsearch，并加载Kibana仪表板（即，它们需要运行一次）。
- en: 'To do this, edit the `metricbeat.yml` file to allow Metricbeat to load the
    Kibana dashboards:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，编辑`metricbeat.yml`文件以允许Metricbeat加载Kibana仪表板：
- en: '[PRE54]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Next, specify the `Elasticsearch` cluster:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，指定`Elasticsearch`集群：
- en: '[PRE55]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Load the Kibana `dashboards`, as follows:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 加载Kibana `仪表板`，如下：
- en: '[PRE56]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: By default, `metricbeat` has the system module enabled, which will capture statistics
    for CPU, system load, memory, and network.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，`metricbeat`启用了系统模块，它将捕获CPU、系统负载、内存和网络的统计信息。
- en: 'Start and enable the `metricbeat` service, as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 启动并启用`metricbeat`服务，如下：
- en: '[PRE57]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'To confirm that data is being sent to the cluster, go to Discover on the kibana
    screen; then, select the metricbeat-* index pattern and verify that events are
    being sent:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 要确认数据是否被发送到集群，请转到kibana屏幕上的`Discover`，然后选择`metricbeat-*`索引模式并验证事件是否被发送：
- en: '![](img/845a23fb-4fe8-4423-a682-6e72b2404c92.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![](img/845a23fb-4fe8-4423-a682-6e72b2404c92.png)'
- en: Events filtered with the metricbeat-* index pattern
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`metricbeat-*`索引模式过滤的事件
- en: Next steps
  id: totrans-291
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 下一步
- en: At this point, the cluster is now fully functional. All that is left is to install
    Metricbeat and Filebeat onto the other nodes of the cluster to ensure full visibility
    of the cluster's health and resource usage.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，集群现在已经完全可用。剩下的就是在集群的其他节点上安装Metricbeat和Filebeat，以确保完全可见集群的健康和资源使用情况。
- en: Adding more clients to the cluster is a matter of installing the appropriate
    Beat, depending on what needs to be monitored and which logs need to be indexed.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 向集群添加更多客户端只是安装适当的Beat，具体取决于需要监视什么以及需要索引哪些日志。
- en: If load increases on the cluster, a number of options are available—either adding
    more nodes to the cluster to load balance requests or increasing the number of
    available resources for each of the nodes. In certain scenarios, simply adding
    more resources is a more cost-effective solution as it doesn't require a new node
    to be configured.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 如果集群的负载增加，可以选择多种选项——要么向集群添加更多节点以平衡负载请求，要么增加每个节点的可用资源数量。在某些情况下，简单地增加更多资源是一种更具成本效益的解决方案，因为它不需要配置新节点。
- en: An implementation such as this one can be used to monitor the performance and
    events of a Kubernetes setup (such as the one described in [Chapter 11](2bc754cd-e146-4fbf-b874-d2a80bf471ba.xhtml), *Designing
    an ELK Stack*). Some of the Beats have specific modules that are used to extract
    data from Kubernetes clusters.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的实现可以用于监视Kubernetes设置的性能和事件（例如[第11章](2bc754cd-e146-4fbf-b874-d2a80bf471ba.xhtml)中描述的设置，*设计ELK
    Stack*）。一些Beats具有特定的模块，用于从Kubernetes集群中提取数据。
- en: Finally, one enhancement that can be made to this setup to ease configuration
    and maintenance is to have the Beat clients point to the coordinating Elasticsearch
    node to act as a load balancer between the nodes; this avoids having to hardcode
    each of the Elasticsearch nodes in the output configuration for the Beats—only
    a single address is needed.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可以对此设置进行的一个增强是让Beat客户端指向协调Elasticsearch节点，以充当节点之间的负载均衡器；这样可以避免在Beats的输出配置中硬编码每个Elasticsearch节点，只需要一个单一的地址。
- en: Summary
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we went through many steps to configure an Elastic Stack, which
    is a collection of four main components—Elasticsearch, Logstash, Kibana, and Beats.
    For the setup, we used three VMs; we hosted two Elasticsearch nodes, and then,
    on a single system, we installed Logstash and Kibana, using version 6.5 for each
    of the components. We installed Elasticsearch using the RPM repository provided
    by Elastic Stack; `yum` was used to install the required packages. Elasticsearch
    configuration was done using the `elasticsearch.yml` file, which controls how
    `elasticsearch` behaves. We defined a number of settings that are required for
    a functional cluster, such as the `cluster.name` parameter and `discovery.zen.minimum_master_nodes`.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们经历了许多步骤来配置Elastic Stack，这是四个主要组件的集合——Elasticsearch、Logstash、Kibana和Beats。对于这个设置，我们使用了三个虚拟机；我们托管了两个Elasticsearch节点，然后在单个系统上安装了Logstash和Kibana，每个组件都使用了6.5版本。我们使用Elastic
    Stack提供的RPM存储库安装了Elasticsearch；使用`yum`安装了所需的软件包。Elasticsearch配置是使用`elasticsearch.yml`文件完成的，该文件控制`elasticsearch`的行为。我们定义了一些对于功能性集群是必需的设置，比如`cluster.name`参数和`discovery.zen.minimum_master_nodes`。
- en: We added a new Elasticsearch node by configuring the cluster name and the discovery
    settings, which allows the node to join the cluster automatically. Then, we moved
    onto installing Kibana and Logstash, which are provided on the same RPM repository
    that was used for Elasticsearch; configuring Logstash and Kibana was done through
    their respective `.yml` files.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 通过配置集群名称和发现设置，我们添加了一个新的Elasticsearch节点，这允许节点自动加入集群。然后，我们开始安装Kibana和Logstash，它们都在用于Elasticsearch的相同RPM存储库中提供；通过它们各自的`.yml`文件进行配置Logstash和Kibana。
- en: Once all three main components were up, and the operation was ready to accept
    incoming data, we moved onto installing Beats, which are the data shippers that
    are used by Elasticsearch and Logstash to ingest data. For logs and events, we
    used Filebeat, and for system metrics such as memory usage and CPU, we used Metricbeat.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦所有三个主要组件都启动，并且操作准备好接受传入数据，我们就开始安装Beats，这些是Elasticsearch和Logstash用来摄取数据的数据传输器。对于日志和事件，我们使用Filebeat，对于内存使用和CPU等系统指标，我们使用Metricbeat。
- en: In the next chapter, we will learn about the challenges of systems management
    and Salt's architecture.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习系统管理的挑战和Salt的架构。
- en: Questions
  id: totrans-302
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: How can Elasticsearch be installed?
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何安装Elasticsearch？
- en: How do you partition a disk?
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何分区磁盘？
- en: How can you persistently mount a filesystem?
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何持久地挂载文件系统？
- en: Which file controls Elasticsearch configuration?
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个文件控制Elasticsearch配置？
- en: What does the `cluster.name` setting do?
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`cluster.name` 设置是做什么的？'
- en: What is the recommended number of nodes in an Elasticsearch cluster?
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Elasticsearch 集群中推荐的节点数量是多少？
- en: How can an Elasticsearch node be added to an existing cluster?
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将 Elasticsearch 节点添加到现有集群中？
- en: What process is needed to install Logstash and Kibana?
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Logstash 和 Kibana 需要哪些步骤？
- en: What is persistent queuing?
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是持久性排队？
- en: What is a coordinating node?
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是协调节点？
- en: What are Beats?
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Beats 是什么？
- en: What is Filebeat used for?
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Filebeat 用于什么？
- en: Further reading
  id: totrans-315
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '***Fundamentals of Linux* by Oliver Pelz**: [https://www.packtpub.com/networking-and-servers/fundamentals-linux](https://www.packtpub.com/networking-and-servers/fundamentals-linux)'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**《Linux 基础》作者 Oliver Pelz**: [https://www.packtpub.com/networking-and-servers/fundamentals-linux](https://www.packtpub.com/networking-and-servers/fundamentals-linux)'
