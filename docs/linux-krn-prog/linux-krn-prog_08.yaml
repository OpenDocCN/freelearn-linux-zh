- en: Kernel Internals Essentials - Processes and Threads
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 内核内部基础知识-进程和线程
- en: Kernel internals, and especially those concerning memory management, are a vast
    and complex topic. In this book, we do not intend to delve deep into the gory
    details of kernel and memory internals. At the same time, I would like to provide
    sufficient, and definitely requisite,background knowledge for a budding kernel
    or device driver developer like you to successfully tackle the key topics necessary
    to understand the kernel architecture in terms of how processes, threads, and
    their stacks are managed. You'll also be able to correctly and efficiently manage
    dynamic kernel memory (with the focus on writing kernel or driver code using the
    **Loadable Kernel Module** (**LKM**) framework). As a side benefit, armed with
    this knowledge, you will find yourself becoming more proficient at *debugging* both
    user and kernel space code.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 内核内部，特别是与内存管理有关的部分，是一个广阔而复杂的主题。在本书中，我们并不打算深入研究内核和内存内部的细节。同时，我希望为像你这样的新手内核或设备驱动程序开发人员提供足够的，绝对必要的背景知识，以成功地解决理解内核架构的关键主题，包括进程、线程及其堆栈的管理。您还将能够正确高效地管理动态内核内存（重点是使用可加载内核模块（LKM）框架编写内核或驱动程序代码）。作为一个附带的好处，掌握了这些知识，你会发现自己在调试用户空间和内核空间代码方面变得更加熟练。
- en: I have divided the discussion on essential internals into two chapters, this
    one and the next. This chapter covers key aspects of the architecture of Linux
    kernel internals, especially with respect to how processes and threads are managed
    within the kernel. The following chapter will focus on memory management internals,
    another critical aspect of understanding and working with the Linux kernel. Of
    course, the reality is that all of these things do not really get covered in a
    chapter or two but are spread out across this book (for example, details on the
    CPU scheduling of processes/threads will be found in later chapters; similarly
    for memory internals, hardware interrupts, synchronization, and so on).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我将基本内部讨论分为两章，这一章和下一章。本章涵盖了Linux内核内部架构的关键方面，特别是关于内核内部如何管理进程和线程。下一章将专注于内存管理内部，这是理解和使用Linux内核的另一个关键方面。当然，事实上，所有这些事情并不真正在一两章中涵盖，而是分布在本书中（例如，有关进程/线程的CPU调度的详细信息将在后面的章节中找到；内存内部，硬件中断，同步等等也是如此）。
- en: 'Briefly, these are the topics covered in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章涵盖了以下主题：
- en: Understanding process and interrupt contexts
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解进程和中断上下文
- en: Understanding the basics of the process VAS (virtual address space)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解进程VAS的基础知识（虚拟地址空间）
- en: Organizing processes, threads, and their stacks – user and kernel space
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织进程、线程及其堆栈-用户空间和内核空间
- en: Understanding and accessing the kernel task structure
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解和访问内核任务结构
- en: Working with the task structure via current
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过当前任务结构进行工作
- en: Iterating over the kernel's task lists
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遍历内核的任务列表
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: I assume that you have gone through [Chapter 1](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml),
    *Kernel Workspace Setup*, and have appropriately prepared a guest **Virtual Machine**
    (**VM**) running Ubuntu 18.04 LTS (or a later stable release) and installed all
    the required packages. If not, I recommend you do this first.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我假设你已经阅读了[第一章](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml)，“内核工作空间设置”，并已经适当地准备了运行Ubuntu
    18.04 LTS（或更高版本）的虚拟机，并安装了所有必需的软件包。如果没有，我建议你先这样做。
- en: To get the most out of this book, I strongly recommend you first set up the
    workspace environment, including cloning this book's GitHub repository for the
    code (found here: [https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming)) and
    work on it in a hands-on fashion.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用本书，我强烈建议你首先设置好工作环境，包括克隆本书的GitHub代码库（在这里找到：[https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming)），并且动手实践。
- en: I do assume that you are familiar with basic virtual memory concepts, the user-mode
    process **Virtual Address Space** (**VAS**) layout of segments, the stack, and
    so on. Nevertheless, we do devote a few pages to explaining these basics (in the
    *Understanding the basics of the process VAS* section that soon follows).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我假设你已经熟悉基本的虚拟内存概念，用户模式进程的虚拟地址空间（VAS）布局，堆栈等。尽管如此，我们会在接下来的“理解进程VAS的基础知识”部分中花几页来解释这些基础知识。
- en: Understanding process and interrupt contexts
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解进程和中断上下文
- en: In [Chapter 4](1c494ebd-e7ec-4a78-8695-5b97bdc3d6be.xhtml), *Writing Your First
    Kernel Module – LKMs, Part 1*, we presented a brief section entitled *Kernel architecture
    I* (if you haven't read it yet, I suggest you do so before continuing).We will
    now expand on this discussion.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第四章](1c494ebd-e7ec-4a78-8695-5b97bdc3d6be.xhtml)，“编写你的第一个内核模块-LKMs，第一部分”，我们介绍了一个简短的名为“内核架构I”的部分（如果你还没有阅读，我建议你在继续之前先阅读）。我们现在将扩展这个讨论。
- en: 'It''s critical to understand that most modern OSes are **monolithic**in design.
    The word *monolithic* literally means a *single large piece of stone*. We shall
    defer a little later to how exactly this applies to our favorite OS! For now,
    we understand *monolithic *as meaning this: when a process or thread issues a
    system call, it switches to (privileged) kernel mode and executes kernel code,
    and possibly works on kernel data. Yes, there is no kernel or kernel thread executing
    code on its behalf; the process (or thread) *itself *executes kernel code. Thus,
    we say that kernel code executes within the context of a user space process or
    thread – we call this the **process context***. *Think about it, significant portions
    of the kernel execute precisely this way, including a large portion of the code
    of device drivers.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，大多数现代操作系统都是**单片式**设计。单片式字面上意味着*单一的大块石头*。我们稍后会详细讨论这如何适用于我们喜爱的操作系统！现在，我们将单片式理解为这样：当一个进程或线程发出系统调用时，它切换到（特权）内核模式并执行内核代码，并可能处理内核数据。是的，没有内核或内核线程代表它执行代码；进程（或线程）*本身*执行内核代码。因此，我们说内核代码在用户空间进程或线程的上下文中执行
    - 我们称之为**进程上下文**。想想看，内核的重要部分正是以这种方式执行的，包括设备驱动程序的大部分代码。
- en: 'Well, you may ask, now that you understand this, how else – besides process
    context – can kernel code execute? There is another way: when a hardware interrupt
    (from a peripheral device – the keyboard, a network card, a disk, and so on) fires,
    the CPU''s control unit saves the current context and immediately re-vectors the
    CPU to run the code of the interrupt handler (the **interrupt service routine**—**ISR**).
    Now this code runs in kernel (privileged) mode too – in effect, this is another,
    asynchronous, way to switch to kernel mode! The interrupt code path of many device
    drivers are executed like this; we say that the kernel code being executed in
    this manner is executing in **interrupt context***.*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，你可能会问，既然你理解了这一点，除了进程上下文之外，内核代码还可以以什么其他方式执行？还有另一种方式：当硬件中断（来自外围设备 - 键盘、网络卡、磁盘等）触发时，CPU的控制单元保存当前上下文，并立即重新定位CPU以运行中断处理程序的代码（**中断服务例程**—**ISR**）。现在，这段代码也在内核（特权）模式下运行
    - 实际上，这是另一种异步切换到内核模式的方式！许多设备驱动程序的中断代码路径就是这样执行的；我们说以这种方式执行的内核代码处于**中断上下文**中。
- en: 'So, any and every piece of kernel code is entered by and executes in one of
    two contexts:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，任何一段内核代码都是在两种上下文中的一种中进入并执行的：
- en: '**Process context**: The kernel is entered from a system call or processor *exception *(such
    as a page fault) and kernel code is executed, kernel data worked upon; it''s synchronous
    (top down).'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**进程上下文**：内核从系统调用或处理器*异常*（如页面错误）中进入，并执行内核代码，处理内核数据；这是同步的（自上而下）。'
- en: '**Interrupt context**: The is kernel entered from a peripheral chip''s hardware
    interrupt and kernel code is executed, kernel data worked upon; it''s asynchronous
    (bottom up).'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中断上下文**：内核从外围芯片的硬件中断进入，并执行内核代码，处理内核数据；这是异步的（自下而上）。'
- en: '*Figure 6.1* shows the conceptual view: user-mode processes and threads execute
    in unprivileged user context; the user mode thread can switch to privileged kernel
    mode by issuing a *system call*. The diagram also shows us that pure *kernel threads *exist
    as well within Linux; they''re very similar to user-mode threads, with the key
    difference that they only execute in kernel space; they cannot even *see* the
    user VAS. A synchronous switch to kernel mode via a system call (or processor
    exception) has the task now running kernel code in *process context.* (Kernel
    threads too run kernel code in process context.) Hardware interrupts, though,
    are a different ball game – they cause execution to asynchronously enter the kernel;
    the code they execute (typically a device driver''s interrupt handler) runs in
    the so-called *interrupt context. *'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.1*显示了概念视图：用户模式进程和线程在非特权用户上下文中执行；用户模式线程可以通过发出*系统调用*切换到特权内核模式。该图还显示了纯*内核线程*也存在于Linux中；它们与用户模式线程非常相似，关键区别在于它们只在内核空间中执行；它们甚至不能*看到*用户VAS。通过系统调用（或处理器异常）同步切换到内核模式后，任务现在在*进程上下文*中运行内核代码。（内核线程也在进程上下文中运行内核代码。）然而，硬件中断是另一回事
    - 它们导致执行异步进入内核；它们执行的代码（通常是设备驱动程序的中断处理程序）运行在所谓的*中断上下文*中。'
- en: '*Figure 6.1* shows more details – interrupt context top and bottom halves, kernel
    threads and workqueues; we request you to have some patience, we''ll cover all
    this and much more in later chapters:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.1*显示了更多细节 - 中断上下文的上半部分、下半部分、内核线程和工作队列；我们请求您耐心等待，我们将在后面的章节中涵盖所有这些内容以及更多内容：'
- en: '![](img/d1411ccc-3c39-4cc7-ba13-08780403dcc1.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d1411ccc-3c39-4cc7-ba13-08780403dcc1.png)'
- en: Figure 6.1 – Conceptual diagram showing unprivileged user-mode execution and
    privileged kernel-mode execution with both process and interrupt contexts
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 - 概念图显示了非特权用户模式执行和特权内核模式执行，同时具有进程和中断上下文
- en: Further on in the book, we shall show you how exactly you can check *in which
    context *your kernel code is currently running. Read on!
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后面，我们将向您展示如何准确检查您的内核代码当前正在运行的*上下文*。继续阅读！
- en: Understanding the basics of the process VAS
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解进程虚拟地址空间的基础
- en: 'A fundamental ''rule'' of virtual memory is this: all potentially addressable
    memory is in a box; that is, it''s *sandboxed*. We think of this ''box'' as the *process
    image *or the process VAS. Looking outside the box is disallowed.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟内存的一个基本“规则”是：所有可寻址的内存都在一个盒子里；也就是说，它是*沙盒*的。我们把这个“盒子”看作*进程镜像*或*进程*VAS。禁止看盒子外面的东西。
- en: Here, we provide only a quick overview of the process user VAS. For details,
    please refer to the *Further reading* section at the end of this chapter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们只提供了进程用户虚拟地址空间的快速概述。有关详细信息，请参阅本章末尾的*进一步阅读*部分。
- en: 'The user VAS is divided into homogeneous memory regions called *segments *or,
    more technically, *mappings.* Every Linux process has at least these mappings
    (or segments):'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 用户虚拟地址空间被划分为称为*段*或更专业的*映射*的同质内存区域。每个Linux进程至少有这些映射（或段）：
- en: '![](img/ccf55662-6096-4433-a89f-a6322988a1ee.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ccf55662-6096-4433-a89f-a6322988a1ee.png)'
- en: Figure 6.2 – Process VAS
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2 - 进程VAS
- en: 'Let''s go over a quick breakdown of these segments or mappings:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速了解一下这些段或映射的简要情况：
- en: '**Text segment***:* This is where the machine code is stored; static (mode:
    `r-x`).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本段**：这是存储机器代码的地方；静态（模式：`r-x`）。'
- en: '**Data segment(s)***:* This is where the global and static data variables are
    stored (mode: `rw-`). It is internally divided into three distinct segments:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据段**：全局和静态数据变量存储在这里（模式：`rw-`）。它内部分为三个不同的段：'
- en: '**Initialized data segment***:* Pre-initialized variables are stored here;
    static.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初始化数据段**：预初始化的变量存储在这里；静态。'
- en: '**Uninitialized data segment**: Uninitialized variables are stored here (they
    are auto-initialized to `0` at runtime; this region is sometimes called the *bss*);
    static.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未初始化数据段**：未初始化的变量存储在这里（在运行时自动初始化为`0`；这个区域有时被称为*bss*）；静态。'
- en: '**Heap segment***:* The *library APIs* for memory allocation and freeing (the
    familiar `malloc(3)` family of routines) get memory from here. That''s also not
    completely true. On modern systems, only `malloc()` instances below `MMAP_THRESHOLD`
    (128 KB by default) get their memory from the heap. Any higher and it''s allocated
    as a separate ''mapping'' in the process VAS (via the powerful `mmap(2)` system
    call). It is a dynamic segment (it can grow/shrink). The last legally reference-able
    location on the heap is referred to as the *program break.*'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**堆段**：内存分配和释放的*库API*（熟悉的`malloc(3)`系列例程）从这里获取内存。这也不完全正确。在现代系统上，只有低于`MMAP_THRESHOLD`（默认为128
    KB）的`malloc()`实例从堆中获取内存。任何更高的内存都将作为进程VAS中的一个单独的“映射”分配（通过强大的`mmap(2)`系统调用）。它是一个动态段（可以增长/缩小）。堆上的最后一个合法引用位置被称为*程序断点*。'
- en: '**Libraries (text, data)**: All shared libraries that a process dynamically
    links into are mapped (at runtime, via the loader) into the process VAS (mode:
    `r-x`/`rw-`).'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**库（文本，数据）**：所有进程动态链接的共享库都被映射到进程VAS中（在运行时，通过加载器）（模式：`r-x`/`rw-`）。'
- en: '**Stack***:* A region of memory that uses the **Last In, First Out** (**LIFO**)
    semantics; the stack is used for the purpose of *implementing a high-level language''s
    function-calling* mechanism. It includes parameter passing, local variable instantiation
    (and destruction), and return value propagation. It is a dynamic segment. On all
    modern processors (including the x86 and ARM families), *the stack ''grows'' toward
    lower addresses *(called a fully descending stack). Every time a function is called,
    a *stack frame* is allocated and initialized as required; the precise layout of
    a stack frame is very CPU dependent (you must refer to the respective CPU **Application
    Binary Interface** (**ABI**) document for this; see the *Further reading* section
    for references). The SP register (or equivalent) always points to the current
    frame, the top of the stack; as stacks grow towards lower (virtual) addresses,
    the top of the stack is actually the lowest (virtual) address! It''s non-intuitive
    but true (mode: `rw-`).'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**堆栈**：使用**后进先出**（**LIFO**）语义的内存区域；堆栈用于*实现高级语言的函数调用*机制。它包括参数传递、局部变量实例化（和销毁）以及返回值传播。它是一个动态段。在所有现代处理器上（包括x86和ARM系列），*堆栈向较低地址“增长”*（称为完全降序堆栈）。每次调用函数时，都会分配并初始化一个*堆栈帧*；堆栈帧的精确布局非常依赖于CPU（你必须参考相应的CPU**应用程序二进制接口**（**ABI**）文档；参见*进一步阅读*部分的参考资料）。SP寄存器（或等效寄存器）始终指向当前帧，堆栈的顶部；由于堆栈向较低（虚拟）地址增长，堆栈的顶部实际上是最低（虚拟）地址！这是不直观但却是真实的（模式：`rw-`）。'
- en: Of course, you will understand that processes must contain at least one *thread *of
    execution (a thread is an execution path within a process); that one thread typically
    being the `main()` function. In *Figure 6.2*, as an example, we show three threads
    of execution – `main`*,* `thrd2`, and `thrd3`*. *Also, as expected, every thread
    shares everything in the VAS *except *for the stack; as you'll know, every thread
    has its own private stack. The stack of `main` is shown at the very top of the
    process (user) VAS; the stacks of the `thrd2` and `thrd3` threads are shown as
    being between the library mappings and the stack of `main` and is illustrated
    with the two (blue) squares.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你会理解进程必须包含至少一个*执行线程*（线程是进程内的执行路径）；那个线程通常是`main()`函数。在*图6.2*中，我们举例展示了三个执行线程
    - `main`，`thrd2`和`thrd3`。*此外，如预期的那样，每个线程在VAS中共享一切*，*除了堆栈；正如你所知，每个线程都有自己的私有堆栈。`main`的堆栈显示在进程（用户）VAS的顶部；`thrd2`和`thrd3`线程的堆栈显示在库映射和`main`的堆栈之间，并用两个（蓝色）方块表示。
- en: I have designed and implemented what I feel is a pretty useful learning/teaching
    and debugging utility called ***procmap*** ([https://github.com/kaiwan/procmap](https://github.com/kaiwan/procmap))*;*
    it's a console-based process VAS visualization utility. It can actually show you
    the process VAS (in quite a bit of detail); we shall commence using it in the
    next chapter. Don't let that stop you from trying it out right away though; do
    clone it and give it a spin on your Linux system.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我设计并实现了一个我认为非常有用的学习/教学和调试实用程序，名为***procmap***（[https://github.com/kaiwan/procmap](https://github.com/kaiwan/procmap)）；它是一个基于控制台的进程VAS可视化实用程序。它实际上可以向你展示进程VAS（非常详细）；我们将在下一章开始使用它。不过，这并不妨碍你立即尝试它；在你的Linux系统上克隆它并试用一下。
- en: Now that you understand the basics of the process VAS, it's time to delve quite
    a bit deeper into the kernel internals regarding the process VAS, the user and
    kernel address spaces, and their threads and stacks.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了进程VAS的基础知识，是时候深入了解有关进程VAS、用户和内核地址空间以及它们的线程和堆栈的内核内部了。
- en: Organizing processes, threads, and their stacks – user and kernel space
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 组织进程、线程及其堆栈 - 用户和内核空间
- en: The traditional **UNIX process model** – *Everything is a process; if it's not
    a process, it's a file* – has a lot going for it. The very fact that it is still *the* model
    followed by operating systems after a span of nearly five decades amply validates
    this. Of course, nowadays, the **thread**is important; *a thread is merely an
    execution path within a process*. Threads *share all* process resources, including
    the user VAS, *except for the stack. *Every thread has its own private stack region
    (this makes perfect sense; if not, how could threads truly run in parallel, as
    it's the stack that holds execution context).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的**UNIX进程模型** - *一切都是进程；如果不是进程，就是文件* - 有很多优点。事实上，它仍然是在近五十年的时间跨度之后操作系统遵循的*模型*，这充分证明了这一点。当然，现在**线程**很重要；*线程只是进程内的执行路径*。线程*共享*所有*进程资源，包括用户VAS，*除了堆栈。*每个线程都有自己的私有堆栈区域（这是完全合理的；否则，线程如何能够真正并行运行，因为堆栈保存了执行上下文）。
- en: The other reason we focus on the *thread *and not the process is made clearer
    in [Chapter 10](5391e3c1-30ad-4c75-a106-301259064881.xhtml), *The CPU Scheduler,
    Part 1**. *For now, we shall just say this: *the thread, not the process, is the
    kernel schedulable entity* (also known as the KSE). This is actually a fallout
    of a key aspect of the Linux OS architecture. On the Linux OS, every thread –
    including kernel threads – maps to a kernel metadata structure called the **task
    structure**. The task structure (also known as the *process descriptor*) is essentially
    a large kernel data structure that the kernel uses as an attribute structure.
    For every *thread* alive, the kernel maintains a corresponding *task structure*
    (see *Figure 6.3*, and worry not, we shall cover more on the task structure in
    the coming sections).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们关注*线程*而不是进程的另一个原因在[第10章](5391e3c1-30ad-4c75-a106-301259064881.xhtml)中更清楚地阐明，*CPU调度器，第1部分**。*现在，我们只能说：*线程而不是进程是内核可调度实体*（也称为KSE）。这实际上是Linux操作系统架构的一个关键方面的结果。在Linux操作系统上，*每个线程
    - 包括内核线程 - 都映射到一个称为**任务结构**的内核元数据结构。任务结构（也称为*进程描述符*）本质上是一个大型的内核数据结构，内核将其用作属性结构。对于每个*线程*，内核维护一个相应的*任务结构*（见*图6.3*，不用担心，我们将在接下来的部分中更多地介绍任务结构）。
- en: 'The next really key point to grasp: we *require one stack per thread per privilege
    level supported by the CPU. *On modern OSes such as Linux, we support two privilege
    levels – *the unprivileged user mode (or user space) and the privileged kernel
    mode (or kernel space)*. Thus, on Linux, *every user space thread alive has two
    stacks*:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个真正关键的要点是：*每个特权级别受CPU支持的线程都需要一个堆栈。*在现代操作系统（如Linux）中，我们支持两个特权级别 - *非特权用户模式（或用户空间）和特权内核模式（或内核空间）*。因此，在Linux上，*每个用户空间线程都有两个堆栈*：
- en: '**A user space stack**: This stack is in play when the thread executes user-mode
    code paths.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户空间堆栈：当线程执行用户模式代码路径时，此堆栈处于活动状态。
- en: '**A kernel space stack**: This stack is in play when the thread switches to
    kernel mode (via a system call or processor exception) and executes kernel code
    paths (in process context).'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核空间堆栈：当线程切换到内核模式（通过系统调用或处理器异常）并执行内核代码路径（在进程上下文中）时，此堆栈处于活动状态。
- en: Of course, every good rule has an exception: *kernel threads *are threads that
    live purely within the kernel and thus have a "view" of *only *kernel (virtual)
    address space; they cannot "see" userland. Hence, as they will only ever execute
    kernel space code paths, they have **just one stack** – a kernel space stack.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，每个好的规则都有例外：*内核线程*是纯粹存在于内核中的线程，因此只能“看到”内核（虚拟）地址空间；它们无法“看到”用户空间。因此，它们只会执行内核空间代码路径，因此它们只有**一个堆栈**
    - 内核空间堆栈。
- en: '*Figure 6.3* divides up the address space into two – user space and kernel
    space. In the upper part of the diagram – user space – you can see several processes
    and their *user VASes.* In the bottom part – kernel space – you can see, corresponding
    to every user-mode thread, a kernel metadata structure (struct `task_struct`,
    which we shall cover a bit later in detail) and the kernel-mode stack of that
    thread. In addition, we see (at the very bottom) three kernel threads (labeled
    `kthrd1`*,* `kthrd2`, and `kthrdn`); as expected, they too have a `task_struct`
    metadata structure representing their innards (attributes) and a kernel-mode stack:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.3*将地址空间分为两部分 - 用户空间和内核空间。在图的上半部分 - 用户空间 - 您可以看到几个进程及其*用户VASes*。在图的底部 -
    内核空间 - 您可以看到，对于每个用户模式线程，都有一个内核元数据结构（struct `task_struct`，我们稍后将详细介绍）和该线程的内核模式堆栈。此外，我们还看到（在底部）三个内核线程（标记为`kthrd1`，`kthrd2`和`kthrdn`）；如预期的那样，它们也有一个表示其内部（属性）的`task_struct`元数据结构和一个内核模式堆栈：'
- en: '![](img/13a036df-734c-43e5-aa34-1e219544fe96.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/13a036df-734c-43e5-aa34-1e219544fe96.png)'
- en: Figure 6.3 – Processes, threads, stacks, and task structures – user and kernel
    VAS
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 - 进程、线程、堆栈和任务结构 - 用户和内核VAS
- en: 'To help make this discussion practical, let''s execute a simple Bash script
    (`ch6/countem.sh`) that counts the number of processes and threads currently alive.
    I did this on my native x86_64 Ubuntu 18.04 LTS box; see the following resulting
    output:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助使这个讨论更具实际意义，让我们执行一个简单的Bash脚本（`ch6/countem.sh`），它会计算当前存活的进程和线程的数量。我在我的本机x86_64
    Ubuntu 18.04 LTS上执行了这个操作；请参阅以下结果输出：
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: I'll leave it to you to look up the code of this simple script here: `ch6/countem.sh`. Study
    the preceding output and understand it. You will realize, of course, that this
    is a snapshot of the situation at a certain point in time. It can and does change.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我将让您查看此简单脚本的代码：`ch6/countem.sh`。研究前面的输出并理解它。当然，您会意识到这是某个时间点的*快照*。它可能会发生变化。
- en: In the following sections, we divide up the discussion into two parts (corresponding
    to the two address spaces) – that of what we see in Figure 6.3 in user space and
    what is seen in Figure 6.3 in kernel space. Let's begin with the user space components.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将讨论分成两部分（对应于两个地址空间） - 用户空间中图6.3中所见的内容和内核空间中图6.3中所见的内容。让我们从用户空间组件开始。
- en: User space organization
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用户空间组织
- en: 'With reference to the `countem.sh` Bash script that we ran in the preceding section,
    we will now break it down and discuss some key points, confining ourselves to
    the *user space portion* of the VAS for now. Please take care to read and understand
    this (the numbers we refer to in the following discussion are with reference to
    our sample run of our `countem.sh` script in the preceding section). For the sake
    of better understanding, I have placed the user space portion of the diagram here:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们在前面部分运行的`countem.sh` Bash脚本，我们现在将对其进行分解并讨论一些关键点，目前我们只限于VAS的*用户空间部分*。请注意仔细阅读和理解这一点（我们在下面的讨论中提到的数字是指我们在前面部分运行`countem.sh`脚本的示例）。为了更好地理解，我在这里放置了图表的用户空间部分：
- en: '![](img/978bed7c-1694-41d8-9acf-74d496393d10.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/978bed7c-1694-41d8-9acf-74d496393d10.png)'
- en: Figure 6.4 – User space portion of overall picture seen in Figure 6.3
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.4* - 图6.3中整体图片的用户空间部分'
- en: Here (Figure 6.4) you can see three individual processes. Every process has
    at least one thread of execution (the `main()`thread). In the preceding example,
    we show three processes `P1`*, *`P2`, and `Pn`, with one, three, and two threads
    in them respectively, including `main()`. From our preceding sample run of the
    `countem.sh` script, `Pn` would have *n*=362.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里（图6.4）你可以看到三个单独的进程。每个进程至少有一个执行线程（`main()`线程）。在前面的示例中，我们展示了三个进程`P1`，`P2`和`Pn`，分别包含一个，三个和两个线程，包括`main()`。从我们之前在`countem.sh`脚本的示例运行中，`Pn`将有*n*=362。
- en: Do note that these diagrams are purely conceptual. In reality, the 'process'
    with PID 2 is typically a single-threaded kernel thread called `kthreadd`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这些图表纯粹是概念性的。实际上，具有PID 2的“进程”通常是一个名为`kthreadd`的单线程内核线程。
- en: 'Each process consists of several segments (technically, mappings*).* Broadly,
    the user-mode segments (mappings) are as follows:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 每个进程由几个段（技术上是映射）组成。广义上，用户模式段（映射）如下：
- en: '**Text**: Code; `r-x`'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文本**：代码; `r-x`'
- en: '**Data segments**: `rw-`; consists of three distinct mappings – the initialized
    data segment, the uninitialized data segment (or `bss`), and an ''upward-growing''
    `heap`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据段**：`rw-`；包括三个不同的映射 - 初始化数据段，未初始化数据段（或`bss`），以及一个“向上增长”的`heap`'
- en: '**Library mappings**: For the text and data of each shared library the process
    dynamically links to'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**库映射**：对于进程动态链接到的每个共享库的文本和数据'
- en: '**Downward-growing stack(s)**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**向下增长的堆栈**'
- en: 'Regarding these stacks, we saw from our preceding sample run that there are
    1,053 user-mode threads currently alive on the system. This implies that there
    are 1,053 user space stacks as well, as there will exist one user mode stack for
    every user-mode thread alive. Of these user space thread stacks, we can say the
    following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些堆栈，我们从之前的示例运行中看到系统上目前有1,053个用户模式线程。这意味着也有1,053个用户空间堆栈，因为每个用户模式线程都会存在一个用户模式堆栈。关于这些用户空间线程堆栈，我们可以说以下内容：
- en: One user space stack is always present for the `main()` thread, it will be located
    close to the very top – the high end – of the user VAS; if the process is single-threaded
    (only a `main()`thread), then it will have just one user-mode stack; the `P1`
    process in *Figure 6.4* shows this case.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个用户空间堆栈始终存在于`main()`线程，它将位于用户VAS的顶部 - 高端附近; 如果进程是单线程的（只有一个`main()`线程），那么它将只有一个用户模式堆栈;
    *图6.4*中的`P1`进程显示了这种情况。
- en: 'If the process is multithreaded, it will have one user-mode thread stack per
    thread alive (including `main()`); processes `P2` and `Pn` in *Figure 6.4* illustrate
    this case. The stacks are allocated either at the time of calling `fork(2)` (for
    `main()`) or `pthread_create(3)` (for the remaining threads within the process),
    which results in this code path being executed in process context within the kernel:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果进程是多线程的，它将对每个活动的线程（包括`main()`）有一个用户模式线程堆栈；*图6.4*中的进程`P2`和`Pn`说明了这种情况。这些堆栈要么在调用`fork(2)`（对于`main()`）时分配，要么在进程内的`pthread_create(3)`（对于进程内的其他线程）时分配，这将导致内核中的进程上下文中执行这段代码路径：
- en: '[PRE1]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: FYI, the `pthread_create(3)` library API on Linux invokes the (very Linux-specific)
    `clone(2)` system call; this system call ends up calling `_do_fork()`; the `clone_flags`
    parameter passed along informs the kernel as to how exactly to create the 'custom
    process'; in other words, a thread!
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺便说一下，在Linux上，`pthread_create(3)`库API调用（非常特定于Linux）`clone(2)`系统调用；这个系统调用最终调用`_do_fork()`；传递的`clone_flags`参数告诉内核如何创建“自定义进程”；换句话说，一个线程！
- en: These user space stacks are of course dynamic; they can grow/shrink up to the
    stack size resource limit (`RLIMIT_STACK`, typically 8 MB; you can use the `prlimit(1)`
    utility to look it up).
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些用户空间堆栈当然是动态的；它们可以增长/缩小到堆栈大小资源限制（`RLIMIT_STACK`，通常为8 MB；您可以使用`prlimit(1)`实用程序查找它）。
- en: Having seen and understood the user space portion, now let's delve into the
    kernel space side of things.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到并理解了用户空间部分之后，现在让我们深入了解内核空间的情况。
- en: Kernel space organization
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内核空间组织
- en: 'Continuing our discussion with reference to the `countem.sh` Bash script that
    we ran in the previous section, we will now break it down and discuss some key
    points, confining ourselves to the *kernel space portion* of the VAS. Please take
    care to carefully read and understand this (while reading the numbers that were
    output in our preceding sample run of the `countem.sh` script). For the sake of
    better understanding I have placed the kernel space portion of the diagram here
    (Figure 6.5):'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 继续我们关于在前面部分运行的`countem.sh` Bash脚本的讨论，我们现在将对其进行分解并讨论一些关键点，目前我们只限于VAS的*内核空间部分*。请注意仔细阅读和理解这一点（在阅读我们在前面部分运行的`countem.sh`脚本时输出的数字）。为了更好地理解，我在这里放置了图表的内核空间部分（图6.5）：
- en: '![](img/f2eaae10-eb56-49f1-ad85-865bca0b20cc.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2eaae10-eb56-49f1-ad85-865bca0b20cc.png)'
- en: Figure 6.5 – Kernel space portion of overall picture seen in Figure 6.3
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.5* - 图6.3中整体图片的内核空间部分'
- en: 'Again, from our preceding sample run, you can see that there are 1,053 user-mode
    threads and 181 kernel threads currently alive on the system. This yields a total
    of 1,234 kernel space stacks. How? As mentioned earlier, every user-mode thread
    has two stacks – one user-mode stack and one kernel-mode stack. Thus, we''ll have
    1,053 kernel-mode stacks for each of the user-mode threads, plus 181 kernel-mode
    stacks for the (pure) kernel threads (recall, kernel threads have *only *a kernel-mode
    stack; they cannot ''see'' user space at all). Let''s list a few characteristics
    of kernel-mode stacks:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，从我们之前的样本运行中，您可以看到系统上目前有1,053个用户模式线程和181个内核线程。这导致了总共1,234个内核空间堆栈。为什么？如前所述，每个用户模式线程都有两个堆栈-一个用户模式堆栈和一个内核模式堆栈。因此，我们将为每个用户模式线程有1,053个内核模式堆栈，以及为（纯粹的）内核线程有181个内核模式堆栈（请记住，内核线程只有一个内核模式堆栈；它们根本无法“看到”用户空间）。让我们列出内核模式堆栈的一些特征：
- en: There will be one kernel-mode stack for each application (user-mode) thread
    alive, including `main()`.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个应用程序（用户模式）线程都将有一个内核模式堆栈，包括`main()`。
- en: '**Kernel-mode stacks are *fixed in size (static) and are quite small***. Practically
    speaking, their size is 2 pages on 32-bit and 4 pages on 64-bit OSes (with a page
    typically being 4 KB in size).'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内核模式堆栈的大小是*固定的（静态的）且非常小***。从实际角度来看，它们在32位操作系统上的大小为2页，在64位操作系统上的大小为4页（每页通常为4
    KB）。'
- en: They are allocated at thread creation time (usually boils down to `_do_fork()`).
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们在线程创建时分配（通常归结为`_do_fork()`）。
- en: 'Again, let''s be crystal clear on this: each user-mode thread has two stacks
    – a user-mode stack and a kernel-mode stack. The exception to this rule is kernel
    threads; they only have a kernel-mode stack (as they possess no user mapping and
    thus no user space ''segments''). In the lower part of *Figure 6.5*, we show three *kernel
    threads –* `kthrd1`, `kthrd2`, and `kthrdn` (in our preceding sample run, `kthrdn`
    would have *n*=181). Further, each kernel thread has a task structure and a kernel-mode
    stack allocated to it at creation time.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，让我们对此非常清楚：每个用户模式线程都有两个堆栈-一个用户模式堆栈和一个内核模式堆栈。这一规则的例外是内核线程；它们只有一个内核模式堆栈（因为它们没有用户映射，因此没有用户空间“段”）。在*图6.5*的下部，我们展示了三个内核线程-
    `kthrd1`，`kthrd2`和`kthrdn`（在我们之前的样本运行中，`kthrdn`将为*n*=181）。此外，每个内核线程在创建时都有一个任务结构和一个内核模式堆栈分配给它。
- en: A kernel-mode stack is similar in most respects to its user-mode counterpart
    – every time a function is called, a *stack frame *is set up (the frame layout
    is particular to the architecture and forms a part of the CPU ABI document; see
    the *Further reading *section for more on these details); the CPU has a register
    to track the current location of the stack (usually called a **Stack Pointer**
    (**SP**)), and the stack "grows" toward *lower* virtual addresses. But, unlike
    the dynamic user-mode stack, *the kernel-mode stack is fixed in size and small.*
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 内核模式堆栈在大多数方面与用户模式堆栈相似-每次调用函数时，都会设置一个*堆栈帧*（帧布局特定于体系结构，并且是CPU ABI文档的一部分；有关这些细节的更多信息，请参见*进一步阅读*部分）；CPU有一个寄存器来跟踪堆栈的当前位置（通常称为**堆栈指针**（**SP**）），堆栈“向*较低*虚拟地址增长”。但是，与动态用户模式堆栈不同，*内核模式堆栈的大小是固定的且较小*。
- en: An important implication of the pretty small (two-page or four-page) kernel-mode
    stack size for the kernel / driver developer – be very careful to not overflow
    your kernel stack by performing stack-intensive work (such as recursion).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于内核/驱动程序开发人员来说，非常重要的一个含义是内核模式堆栈的大小相当小（两页或四页），因此要非常小心，不要通过执行堆栈密集型工作（如递归）来溢出内核堆栈。
- en: 'There exists a kernel configurable to warn you about high (kernel) stack usage
    at compile time; here''s the text from the `lib/Kconfig.debug`file:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一个内核可配置项，可以在编译时警告您关于高（内核）堆栈使用情况；以下是来自`lib/Kconfig.debug`文件的文本：
- en: '`CONFIG_FRAME_WARN:`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`CONFIG_FRAME_WARN：`'
- en: '`Tell gcc to warn at build time for stack frames larger than this.`'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: “告诉gcc在构建时警告堆栈帧大于此值。”
- en: '`Setting this too low will cause a lot of warnings.`'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: “设置得太低会导致很多警告。”
- en: '`Setting it to 0 disables the warning.`'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: “将其设置为0会禁用警告。”
- en: '`Requires gcc 4.4`'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: “需要gcc 4.4”
- en: Summarizing the current situation
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 总结当前情况
- en: 'Okay, great, let''s now summarize our learning and findings from our preceding sample
    run of the `countem.sh` script:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在让我们总结一下我们从`countem.sh`脚本的先前样本运行中学到的内容和发现的内容：
- en: '**Task structures**:'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务结构**：'
- en: Every thread alive (user or kernel) has a corresponding task structure (`struct
    task_struct`) in the kernel; this is how the kernel tracks it and all its attributes
    are stored here (you'll learn more in the *Understanding and accessing the kernel
    task structure* section)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个活动的线程（用户或内核）在内核中都有一个相应的任务结构（`struct task_struct`）；这是内核跟踪它的方式，所有属性都存储在这里（您将在*理解和访问内核任务结构*部分中了解更多）。
- en: 'With respect to our sample run of our `ch6/countem.sh` script:'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于我们`ch6/countem.sh`脚本的样本运行：
- en: 'As there are a total of 1,234 threads (both user and kernel) alive on the system,
    this implies a total of 1,234 *task (metadata) structures* in kernel memory (in
    the code, `struct task_struct`), of which we can say the following:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于系统上有总共1,234个线程（用户和内核），这意味着内核内存中有1,234个*任务（元数据）结构*（在代码中为`struct task_struct`），我们可以说以下内容：
- en: 1,053 of these task structures represent user threads.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1,053个这些任务结构代表用户线程。
- en: The remaining 181 task structures represent kernel threads.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 剩下的181个任务结构代表内核线程。
- en: '**Stacks**:'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**堆栈**：'
- en: 'Every user space thread has two stacks:'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个用户空间线程都有两个堆栈：
- en: A user mode stack (is in play when the thread executes user-mode code paths)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当线程执行用户模式代码路径时，会有一个用户模式堆栈。
- en: A kernel mode stack (is in play when the thread executes kernel-mode code paths)
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核模式堆栈（在线程执行内核模式代码路径时发挥作用）
- en: A pure kernel thread has only one stack - a kernel mode stack
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 纯内核线程只有一个堆栈-内核模式堆栈
- en: 'With respect to our sample run of our `ch6/countem.sh` script:'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于我们`ch6/countem.sh`脚本的样本运行：
- en: 1,053 user space stacks (in user land).
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1,053个用户空间堆栈（在用户空间）。
- en: 1,053 kernel space stacks (in kernel memory).
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1,053个内核空间堆栈（在内核内存中）。
- en: 181 kernel space stacks (for the 181 kernel threads that are alive).
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 181个内核空间堆栈（对应活动的181个内核线程）。
- en: This comes together for a grand total of 1053+1053+181 = 2,287 stacks!
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这总共有 1053+1053+181 = 2,287 个堆栈！
- en: 'While discussing user and kernel-mode stacks, we should also briefly mention
    this point: many architectures (including x86 and ARM64) support a separate per-CPU
    stack for *interrupt handling. *When an external hardware interrupt occurs, the
    CPU''s control unit immediately re-vectors control to, ultimately, the interrupt
    handling code (perhaps within a device driver). A separate per-CPU interrupt stack
    is used to hold the stack frame(s) for the interrupt code path(s); this helps
    avoid putting too much pressure on the existing (small) kernel-mode stack of the
    process/thread that got interrupted.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论用户和内核模式堆栈时，我们还应该简要提到这一点：许多体系结构（包括 x86 和 ARM64）支持为*中断处理*支持单独的每CPU堆栈。当外部硬件中断发生时，CPU的控制单元立即将控制重新定向到最终的中断处理代码（可能在设备驱动程序内）。单独的每CPU中断堆栈用于保存中断代码路径的堆栈帧；这有助于避免对被中断的进程/线程的现有（小）内核模式堆栈施加太大压力。
- en: Okay, now that you understand the overall organization of the user and kernel
    spaces in terms of processes/threads and their stacks, let's move on to seeing
    how you can actually 'view' the content of both the kernel and user space stacks.
    Besides being useful for learning purposes, this knowledge can greatly aid you
    in debugging situations.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在你了解了进程/线程及其堆栈的用户空间和内核空间的整体组织，让我们继续看看你如何实际“查看”内核和用户空间堆栈的内容。除了用于学习目的外，这些知识还可以在调试情况下极大地帮助你。
- en: Viewing the user and kernel stacks
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看用户和内核堆栈
- en: The *stack *is often the key to a debug session. It is the stack, of course,
    that holds the *current execution context* of the process or thread – where it
    is now – which allows us to infer what it's doing. More importantly, being able
    to see and interpret the thread's *call stack (or call chain/backtrace)* crucially
    allows us to understand how exactly we got here. All this precious information
    resides in the stack. But wait, there are two stacks for every thread – the user
    space and the kernel space stack. How do we view them?
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '*堆栈*通常是调试会话的关键。当然，堆栈保存了进程或线程的*当前执行上下文* – 它现在在哪里 – 这使我们能够推断它在做什么。更重要的是，能够看到和解释线程的*调用堆栈（或调用链/回溯）*至关重要，这使我们能够准确理解我们是如何到达这里的。所有这些宝贵的信息都驻留在堆栈中。但等等，每个线程都有两个堆栈
    – 用户空间和内核空间堆栈。我们如何查看它们呢？'
- en: Here, we shall show two broad ways of viewing the kernel and user-mode stacks
    of a given process or thread, firstly via the 'traditional' approach, and then
    a more recent modern approach (via [e]BPF). Do read on.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将展示查看给定进程或线程的内核和用户模式堆栈的两种广泛方法，首先是通过“传统”方法，然后是更近代的方法（通过[e]BPF）。请继续阅读。
- en: Traditional approach to viewing the stacks
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看堆栈的传统方法
- en: Let's first learn to view both the kernel and user-mode stacks of a given process
    or thread using what we shall call the 'traditional' approach. Let's begin with
    the kernel-mode stack.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先学习使用我们将称之为“传统”方法来查看给定进程或线程的内核和用户模式堆栈。让我们从内核模式堆栈开始。
- en: Viewing the kernel space stack of a given thread or process
  id: totrans-117
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 查看给定线程或进程的内核空间堆栈
- en: Good news; this is really easy. The Linux kernel makes the stack visible via
    the usual mechanism to expose kernel internals to user space – the powerful `proc`filesystem
    interfaces. Just peek under `/proc/<pid>/stack`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息；这真的很容易。Linux 内核通过通常的机制使堆栈可见，以将内核内部暴露给用户空间 – 强大的 `proc` 文件系统接口。只需查看 `/proc/<pid>/stack`。
- en: 'So, okay, let''s look up the kernel-mode stack of our *Bash* process. Let''s
    say that, on our x86_64 Ubuntu guest (running the 5.4 kernel), our Bash process''
    PID is `3085`:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，好吧，让我们查看一下我们 *Bash* 进程的内核模式堆栈。假设在我们的 x86_64 Ubuntu 客户机上（运行 5.4 内核），我们的 Bash
    进程的 PID 是 `3085`：
- en: On modern kernels, to avoid *information leakage*, viewing the kernel-mode stack
    of a process or thread requires *root* access as a security requirement.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代内核上，为了避免*信息泄漏*，查看进程或线程的内核模式堆栈需要*root*访问权限作为安全要求。
- en: '[PRE2]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the preceding output, each line represents a *call frame *on the stack.
    To help decipher a kernel stack backtrace, it''s worth knowing the following points:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，每行代表堆栈上的一个*调用帧*。为了帮助解释内核堆栈回溯，了解以下几点是值得的：
- en: It should be read in a bottom-up fashion (from bottom to top).
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该以自下而上的方式阅读（从底部到顶部）。
- en: Each line of output represents a *call frame*; in effect, a function in the
    call chain.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每行输出代表一个 *调用帧*；实际上是调用链中的一个函数。
- en: A function name appearing as `??` implies that the kernel cannot reliably interpret
    the stack. Ignore it, it's the kernel saying that it's an invalid stack frame
    (a 'blip' left behind); the kernel backtrace code is usually right!
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 出现为 `??` 的函数名意味着内核无法可靠地解释堆栈。忽略它，这是内核说这是一个无效的堆栈帧（留下的“闪烁”）；内核回溯代码通常是正确的！
- en: 'On Linux, any `foo()` system call will typically become a `SyS_foo()` function
    within the kernel. Also, very often  but not always, `SyS_foo()` is a wrapper
    that invokes the ''real'' code `do_foo()`. A detail: in the kernel code, you might
    see macros of the type `SYSCALL_DEFINEn(foo, ...)`; the macro becomes the `SyS_foo()` routine;
    the number appended, `n` , is in the range [0, 6]; it''s the number of parameters
    being passed to the kernel from user space for the system call.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Linux 上，任何 `foo()` 系统调用通常会成为内核中的 `SyS_foo()` 函数。而且，很多时候但并非总是，`SyS_foo()` 是一个调用“真正”代码
    `do_foo()` 的包装器。一个细节：在内核代码中，你可能会看到 `SYSCALL_DEFINEn(foo, ...)` 这种类型的宏；这个宏会变成 `SyS_foo()`
    例程；附加的数字 `n` 在 [0, 6] 范围内；它是从用户空间传递给内核的系统调用的参数数量。
- en: 'Now look again at the preceding output; it should be quite clear: our *Bash*
    process is currently executing the `do_wait()` function; it got there via a system
    call, the `wait4()` system call! This is quite right; the shell works by forking
    off a child process and then waiting for its demise via the `wait4(2)` system
    call.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在再看一下前面的输出；应该很清楚：我们的 *Bash* 进程目前正在执行 `do_wait()` 函数；它是通过系统调用 `wait4()` 这个系统调用到达那里的！这是完全正确的；shell
    通过fork出一个子进程，然后通过 `wait4(2)` 系统调用等待其终止。
- en: Curious readers (you!) should note that the `[<0>]` in the leftmost column of
    each stack frame displayed in the preceding snippet are the placeholders for the *text
    (code) address *of that function. Again, for *security* reasons (to prevent information
    leakage), it is zeroed out on modern kernels. (Another security measure related
    to the kernel and process layout is discussed in [Chapter 7](06ee05b5-3e71-482d-93b8-235c27ce23bc.xhtml), *Memory
    Management Internals – Essentials*,in the *Randomizing the memory layout – KASLR*
    and *User-mode ASLR* sections).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 好奇的读者（您！）应该注意，在前面片段中显示的每个堆栈帧的最左列中的`[<0>]`是该函数的*文本（代码）地址*的占位符。出于*安全*原因（防止信息泄漏），它在现代内核上被清零。
    （与内核和进程布局相关的另一个安全措施在[第7章](06ee05b5-3e71-482d-93b8-235c27ce23bc.xhtml)中讨论，*内存管理内部-基本知识*，在*KASLR*和*用户模式ASLR*部分中讨论了*随机化内存布局*）。
- en: Viewing the user space stack of a given thread or process
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 查看给定线程或进程的用户空间堆栈
- en: 'Ironically, viewing the *user space stack *of a process or thread seems harder
    to do on a typical Linux distro (as opposed to viewing the kernel-mode stack,
    as we just saw in the previous section). There is a utility to do so: `gstack(1)`.
    In reality, it''s just a simple wrapper over a script that invokes `gdb(1)` in
    batch mode, getting `gdb` to invoke its `backtrace` command.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 具有讽刺意味的是，在典型的Linux发行版上查看进程或线程的*用户空间堆栈*似乎更难（与我们刚刚在前一节中看到的查看内核模式堆栈相反）。有一个实用程序可以做到这一点：`gstack(1)`。实际上，它只是一个简单的包装器，通过批处理模式调用`gdb(1)`，让`gdb`调用它的`backtrace`命令。
- en: Unfortunately, on Ubuntu (18.04 LTS at least), there seems to be an issue; the
    `gstack` program was not found in any native package. (Ubuntu does have a `pstack(1)`
    utility, but, at least on my test VM, it failed to work well.) A workaround is
    to simply use `gdb` directly (you can always `attach <PID>` and issue the `[thread
    apply all] bt` command to view the user mode stack(s)).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 很遗憾，在Ubuntu（至少是18.04 LTS）上似乎存在一个问题；在任何本地软件包中都找不到`gstack`程序。（Ubuntu确实有一个`pstack(1)`实用程序，但至少在我的测试VM上，它无法正常工作。）一个解决方法是直接使用`gdb`（您可以始终`attach
    <PID>`并发出`[thread apply all] bt`命令来查看用户模式堆栈）。
- en: 'On my x86_64 Fedora 29 guest system, though, the `gstack(1)` utility cleanly
    installs and runs well; an example is as follows (our Bash process'' PID here
    happens to be `12696`):'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我的x86_64 Fedora 29客户系统上，`gstack(1)`实用程序安装和运行良好；一个示例如下（我们的Bash进程的PID恰好是`12696`）：
- en: '[PRE3]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Again, each line represents a call frame. Read it bottom-up. Clearly, *Bash*
    executes a command and ends up invoking the `waitpid()` system call (in reality
    on modern Linux systems, `waitpid()` is just a `glibc` wrapper over the actual
    `wait4(2)` system call! Again, simply ignore any call frames labeled`??`).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，每行代表一个调用帧。从下到上阅读。显然，*Bash*执行一个命令，最终调用`waitpid()`系统调用（实际上，在现代Linux系统上，`waitpid()`只是对实际`wait4(2)`系统调用的`glibc`包装器！再次，简单地忽略任何标记为`??`的调用帧）。
- en: Being able to peek into the kernel and user space stacks (as shown in the preceding snippets),
    and using utilities including `strace(1)` and `ltrace(1)` for tracing system and
    library calls of a process/thread respectively, can be a tremendous aid when debugging!
    Don't ignore them.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 能够窥视内核和用户空间堆栈（如前面的片段所示），并使用包括`strace(1)`和`ltrace(1)`在内的实用程序分别跟踪进程/线程的系统和库调用，可以在调试时提供巨大的帮助！不要忽视它们。
- en: Now for a 'modern' approach to this question.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，对于这个问题的“现代”方法。
- en: '[e]BPF – the modern approach to viewing both stacks'
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[e]BPF-查看两个堆栈的现代方法'
- en: Now – a lot more exciting! – let's learn (the very basics) of using a powerful
    modern approach, leveraging (as of the time of writing) very recent technology
    – called the **extended Berkeley Packet Filter** (**eBPF**; or simply, BPF. We
    did mention the [e]BPF project in [Chapter 1](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml),
    *Kernel Workspace Setup*, under the *Additional useful projects* section.) The
    older BPF has been around a long time and has been used for network packet tracing;
    [e]BPF is a recent innovation, available only as of 4.x Linux kernels (which of
    course implies that you will need to be on a 4.x or more recent Linux system to
    use this approach).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在-更加令人兴奋！-让我们学习（基本知识）使用一种强大的现代方法，利用（在撰写本文时）非常新的技术-称为**扩展伯克利数据包过滤器**（**eBPF**；或简称BPF。我们在[第1章](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml)中提到过[e]BPF项目，*内核工作空间设置*，在*其他有用的项目*部分下。）旧的BPF已经存在很长时间，并且已经用于网络数据包跟踪；[e]BPF是一个最近的创新，仅在4.x
    Linux内核中可用（这当然意味着您需要在4.x或更近的Linux系统上使用这种方法）。
- en: 'Directly using the underlying kernel-level BPF bytecode technology is (extremely)
    difficult to do; thus, the good news is that there are several easy-to-use frontends
    (tools and scripts) to this technology. (A diagram showing the current BCC performance
    analysis tools can be found at [http://www.brendangregg.com/BPF/bcc_tracing_tools_early2019.png](http://www.brendangregg.com/BPF/bcc_tracing_tools_early2019.png); a
    list of the [e]BPF frontends can be found at[http://www.brendangregg.com/ebpf.html#frontends](http://www.brendangregg.com/ebpf.html#frontends)*;*
    these links are from *Brendan Gregg''s* blog.) Among the frontends, **BCC** and
    **bpftrace** are considered very useful. Here, we shall simply provide a quick
    demonstration using a BCC tool called `stackcount` (well, on Ubuntu at least it''s
    named `stackcount-bpfcc(8)`). Another advantage: using this tool allows you to
    see both the kernel and user-mode stacks at once; there''s no need for separate
    tools.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 直接使用底层内核级BPF字节码技术（极其）难以做到；因此，好消息是有几个易于使用的前端（工具和脚本）可以使用这项技术。（显示当前BCC性能分析工具的图表可以在[http://www.brendangregg.com/BPF/bcc_tracing_tools_early2019.png](http://www.brendangregg.com/BPF/bcc_tracing_tools_early2019.png)找到；[e]BPF前端的列表可以在[http://www.brendangregg.com/ebpf.html#frontends](http://www.brendangregg.com/ebpf.html#frontends)找到；这些链接来自*Brendan
    Gregg*的博客。）在前端中，**BCC**和**bpftrace**被认为非常有用。在这里，我们将简单地使用一个名为`stackcount`的BCC工具进行快速演示（至少在Ubuntu上它的名称是`stackcount-bpfcc(8)`）。另一个优势是使用这个工具可以同时看到内核和用户模式堆栈；不需要单独的工具。
- en: 'You can install the BCC tools for your *host *Linux distro by reading the installation
    instructions here: [https://github.com/iovisor/bcc/blob/master/INSTALL.md](https://github.com/iovisor/bcc/blob/master/INSTALL.md).
    Why not on our guest Linux VM? You can, *when running a distro kernel* (such as
    an Ubuntu- or Fedora-supplied kernel). The reason: the installation of the BCC
    toolset includes the installation of the `linux-headers-$(uname -r)` package;
    the latter exists only for distro kernels (and not for our custom 5.4 kernel that
    we''re running on the guest).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过阅读此处的安装说明在*主机*Linux发行版上安装BCC工具：[https://github.com/iovisor/bcc/blob/master/INSTALL.md](https://github.com/iovisor/bcc/blob/master/INSTALL.md)。为什么不能在我们的Linux虚拟机上安装？您可以在运行发行版内核（例如Ubuntu或Fedora提供的内核）时安装。原因是：BCC工具集的安装包括`linux-headers-$(uname
    -r)`包的安装；后者仅适用于发行版内核（而不适用于我们在虚拟机上运行的自定义5.4内核）。
- en: 'In the following example, we use the `stackcount` BCC tool (on my x86_64 Ubuntu
    18.04 LTS host system) to look up the stacks of our VirtualBox Fedora31 guest
    process (the virtual machine is, after all, a process on the host system!). For
    this tool, you have to specify a function (or functions) of interest (interestingly,
    you can specify either a user space or kernel space function and also use ''wildcards''
    or a regular expression when doing so!); only when those function(s) are invoked
    will the stacks be traced and reported. As an example, we select any function
    containing the name `malloc`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们使用`stackcount` BCC工具（在我的x86_64 Ubuntu 18.04 LTS主机系统上）来查找我们的VirtualBox
    Fedora31客户机进程的堆栈（毕竟，虚拟机是主机系统上的一个进程！）。对于这个工具，您必须指定一个感兴趣的函数（或函数）（有趣的是，您可以在这样做时指定用户空间或内核空间函数，并且还可以使用“通配符”或正则表达式！）；只有在调用这些函数时，堆栈才会被跟踪和报告。例如，我们选择包含名称`malloc`的任何函数：
- en: '[PRE4]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[e]BPF programs might fail due to the new *kernel lockdown* feature being merged
    into the mainline 5.4 kernel (it''s disabled by default though). It''s a **Linux
    Security Module** (**LSM**) that enables an extra ''hard'' level of security on
    Linux systems. Of course, security is a double-edged sword; having a very secure
    system implicitly means that certain things will not work as expected, and this
    includes some [e]BPF programs. Do refer to the *Further reading *section for more
    on kernel lockdown.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[e]BPF程序可能由于合并到主线5.4内核的新*内核锁定*功能而失败（尽管默认情况下已禁用）。这是一个**Linux安全模块**（**LSM**），它在Linux系统上启用了额外的“硬”安全级别。当然，安全性是一把双刃剑；拥有一个非常安全的系统意味着某些事情将无法按预期工作，其中包括一些BPF程序。有关内核锁定的更多信息，请参阅*进一步阅读*部分。'
- en: 'The `-d` option switch passed prints the delimiter `--`; it denotes the boundary
    between the kernel-mode and the user-mode stack of the process. (Unfortunately,
    as most production user-mode apps will have their symbolic information stripped,
    most user-mode stack frames simply show up as "`[unknown]`".) On this system at
    least, the kernel stack frames are very clear though; even the virtual address
    of the text (code) function in question is printed on the left. (To help you better
    understand the stack trace: firstly, read it bottom-up; next, as mentioned already,
    on Linux, any `foo()` system call will typically become the `SyS_foo()` function within
    the kernel, and often `SyS_foo()` is a wrapper around `do_foo()`, the actual worker
    function.)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 传递的`-d`选项开关打印分隔符`--`；它表示进程的内核模式和用户模式堆栈之间的边界。（不幸的是，由于大多数生产用户模式应用程序将剥离其符号信息，因此大多数用户模式堆栈帧只会显示为“`[unknown]`”。）至少在这个系统上，内核堆栈帧非常清晰；甚至打印了所讨论的文本（代码）函数的虚拟地址。
    （为了帮助您更好地理解堆栈跟踪：首先，从下到上阅读它；其次，如前所述，在Linux上，任何`foo()`系统调用通常会成为内核中的`SyS_foo()`函数，并且通常`SyS_foo()`是`do_foo()`的包装函数。）
- en: Note that the `stackcount-bpfcc` tool works only with Linux 4.6+, and requires
    root access. Do see its man page for details.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`stackcount-bpfcc`工具仅适用于Linux 4.6+，并且需要root访问权限。有关详细信息，请参阅其手册页。
- en: 'As a second simpler example, we write a simple *Hello, world* program (with
    the caveat that it''s in an infinite loop, so that we can capture the underlying
    `write(2)` system calls as they occur), build it with symbolic info enabled (that
    is, with `gcc -g ...`), and use a simple Bash script to perform the same job as
    previously: tracing the kernel and user-mode stacks as it executes. (You will
    find the code in `ch6/ebpf_stacktrace_eg/`.) A screenshot showing a sample run
    (okay, here''s an exception: I''ve run the script on an x86_64 Ubuntu *20.04*
    LTS host) looks as follows:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第二个更简单的示例，我们编写一个简单的*Hello, world*程序（有一个无限循环的警告，以便我们可以捕获发生的`write(2)`系统调用），启用符号信息构建它（也就是说，使用`gcc
    -g ...`），并使用一个简单的Bash脚本执行与以前相同的工作：跟踪内核和用户模式堆栈的执行过程。（您将在`ch6/ebpf_stacktrace_eg/`中找到代码。）显示示例运行的屏幕截图（好吧，这里有一个例外：我在x86_64
    Ubuntu *20.04* LTS主机上运行了脚本）如下：
- en: '![](img/9ed059b3-0b1e-4193-8417-f254e80a227b.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ed059b3-0b1e-4193-8417-f254e80a227b.png)'
- en: Figure 6.6 – A sample run using the stackcount-bpfcc BCC tool to trace both
    kernel and user-mode stacks for the write() of our Hello, world process
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 - 使用stackcount-bpfcc BCC工具对我们的Hello, world进程的内核和用户模式堆栈进行跟踪的示例运行
- en: We have merely scratched the surface here; [e]BPF tools such as BCC and `bpftrace`
    really are the modern, powerful approach to system, app tracing and performance
    analysis on the Linux OS. Do take the time to learn how to use these powerful
    tools! (Each BCC tool also has a dedicated man page *with examples*.) We refer
    you to the *Further reading *section for links on [e]BPF, BCC and `bpftrace`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里只是浅尝辄止；BPF工具，如BCC和`bpftrace`，确实是在Linux操作系统上进行系统、应用程序跟踪和性能分析的现代、强大方法。确实要花时间学习如何使用这些强大的工具！（每个BCC工具都有专门的手册*带有示例*。）我们建议您参考*进一步阅读*部分，了解有关BPF、BCC和`bpftrace`的链接。
- en: Let's conclude this section by zooming out and looking at an overview of what
    you have learned so far!
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过放大镜来总结本节，看看到目前为止您学到了什么！
- en: The 10,000-foot view of the process VAS
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进程VAS的一览无余
- en: Before we conclude this section, it's important to take a step back and see
    the complete VASes of each process and how it looks for the system as a whole;
    in other words, to zoom out and see the "10,000-foot view" of the complete system
    address space. This is what we attempt to do with the following rather large and
    detailed diagram (*Figure 6.7*), an extension or superset of our earlier *Figure
    6.3*.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束本节之前，重要的是退后一步，看看每个进程的完整VAS，以及它对整个系统的外观；换句话说，放大并查看完整系统地址空间的“一览无余”。这就是我们尝试用以下相当大而详细的图表（*图6.7*）来做的。
- en: For those of you reading a hard copy of the book, I'd definitely recommend you
    view the book's figures in full color from this PDF document at [https://static.packt-cdn.com/downloads/9781789953435_ColorImages.pdf](_ColorImages.pdf).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些阅读本书的纸质副本的人，我强烈建议您从此PDF文档中以全彩色查看本书的图表[https://static.packt-cdn.com/downloads/9781789953435_ColorImages.pdf](_ColorImages.pdf)。
- en: 'Besides what you have learned about and seen just now – the process user space
    segments, the (user and kernel) threads, and the kernel-mode stacks – don''t forget
    that there is a lot of other metadata within the kernel: the task structures,
    the kernel threads, the memory descriptor metadata structures, and so on. They
    all are very much a part of the *kernel VAS,* which is often called the *kernel
    segment.* There''s more to the kernel segment than tasks and stacks. It also contains
    (obviously!) the static kernel (core) code and data, in effect, all the major
    (and minor) *subsystems* of the kernel, the arch-specific code, and so on (that
    we spoke about in [Chapter 4](1c494ebd-e7ec-4a78-8695-5b97bdc3d6be.xhtml)*, Writing
    Your First Kernel Module – LKMs Part 1,* under the *Kernel space components *section).'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 除了您刚刚了解和看到的内容 - 进程用户空间段、（用户和内核）线程和内核模式堆栈 - 不要忘记内核中还有许多其他元数据：任务结构、内核线程、内存描述符元数据结构等等。它们都是*内核VAS*的一部分，通常被称为*内核段*。内核段中除了任务和堆栈之外还有更多内容。它还包含（显然！）静态内核（核心）代码和数据，实际上，内核的所有主要（和次要）*子系统*，特定于架构的代码等等（我们在[第4章](1c494ebd-e7ec-4a78-8695-5b97bdc3d6be.xhtml)*，编写您的第一个内核模块
    - LKMs第1部分*中讨论过）。
- en: 'As just mentioned, the following diagram presents an attempt to sum up and
    present all (well, much) of this information in one place:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 正如刚才提到的，以下图表试图总结并展示所有（或大部分）这些信息：
- en: '![](img/ac9dfba9-f5a1-49d8-9d43-29f4abbc5afd.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ac9dfba9-f5a1-49d8-9d43-29f4abbc5afd.png)'
- en: Figure 6.7 – The 10,000-foot view of the processes, threads, stacks, and task
    structures of the user and kernel VASes
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 - 用户和内核VAS的进程、线程、堆栈和任务结构的一览无余
- en: Whew, quite a thing, isn't it? The red box in the kernel segment of the preceding diagram
    encompasses the *core kernel code and data* – the major kernel subsystems, and
    shows the task structures and kernel-mode stacks. The rest of it is considered
    non-core stuff; this includes device drivers. (The arch-specific code can arguably
    be viewed as core code; we just show it separately here.) Also, don't let the
    preceding information overwhelm you; just focus on what we're here for right now
    – the processes, threads, their task structures, and stacks. If you're still unclear
    about it, be sure to re-read the preceding material.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，这是相当复杂的事情，不是吗？在前面图表中的红色框圈出了*核心内核代码和数据* - 主要的内核子系统，并显示了任务结构和内核模式堆栈。其余部分被认为是非核心内容；这包括设备驱动程序。（特定于架构的代码可以被认为是核心代码；我们只是在这里单独显示它。）此外，不要让前面的信息使您感到不知所措；只需专注于我们现在关注的内容
    - 进程、线程、它们的任务结构和堆栈。如果您仍然不清楚，请务必重新阅读前面的材料。
- en: Now, let's move on to actually understanding and learning how to reference the
    key or 'root' metadata structure for every single thread alive – the *task structure*.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续真正理解并学习如何引用每个活动线程的关键或“根”元数据结构 - 任务结构。
- en: Understanding and accessing the kernel task structure
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解和访问内核任务结构
- en: As you have learned by now, every single user and kernel space thread is internally
    represented within the Linux kernel by a metadata structure containing all its
    attributes – the **task structure***. *The task structure is represented in kernel
    code as `include/linux/sched.h:struct task_struct`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您现在所了解的，每个用户空间和内核空间线程在Linux内核中都由一个包含其所有属性的元数据结构表示 - 任务结构。*任务结构*在内核代码中表示为`include/linux/sched.h:struct
    task_struct`。
- en: It's often, unfortunately, referred to as the "process descriptor," causing
    no end of confusion! Thankfully, the phrase *task structure* is so much better;
    it represents a runnable task, in effect, a *thread*.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，它经常被称为“进程描述符”，导致了无尽的混乱！幸运的是，短语*任务结构*要好得多；它代表了一个可运行的任务，实际上是一个*线程*。
- en: 'So there we have it: in the Linux design, every process consists of one or
    more threads and *each thread maps to a kernel data structure called a task structure*
    (`struct task_struct`)**.**'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在Linux设计中，每个进程由一个或多个线程组成，*每个线程映射到一个称为任务结构的内核数据结构*（`struct task_struct`）。
- en: The task structure is the "root" metadata structure for the thread – it encapsulates
    all the information required by the OS for that thread. This includes information
    on its memory (segments, paging tables, usage info, and more), CPU scheduling
    details, any files it currently has open, its credentials, capability bitmasks,
    timers, locks, **Asynchronous I/O** (**AIO**) contexts, hardware context, signaling,
    IPC objects, resource limits, (optional) audit, security and profiling info, and
    many more such details.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 任务结构是线程的“根”元数据结构 - 它封装了操作系统为该线程所需的所有信息。这包括关于其内存（段、分页表、使用信息等）、CPU调度详细信息、当前打开的任何文件、凭据、能力位掩码、定时器、锁定、异步I/O（AIO）上下文、硬件上下文、信令、IPC对象、资源限制、（可选）审计、安全和分析信息等等。
- en: '*Figure 6.8* is a conceptual representation of the Linux kernel *task structure*
    and most of the information (metadata) it contains:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '*图6.8*是Linux内核*任务结构*的概念表示，以及它包含的大部分信息（元数据）。'
- en: '![](img/2f60ac23-473c-4830-9ab4-ff1d4d6444cf.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2f60ac23-473c-4830-9ab4-ff1d4d6444cf.png)'
- en: 'Figure 6.8 – Linux kernel task structure: struct task_struct'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 - Linux内核任务结构：struct task_struct
- en: 'As can be seen from *Figure 6.8*, the task structure holds a huge quantity
    of information regarding every single task (process/thread) alive on the system
    (again, I reiterate: this includes kernel threads as well). We show – in a compartmentalized
    conceptual format in Figure 6.8 – the different kinds of attributes encapsulated
    within this data structure. Also, as can be seen, certain attributes will be *inherited*
    by a child process or thread upon `fork(2)` (or `pthread_create(3)`); certain
    attributes will not be inherited and will be merely reset. (The kernel-mode stack
    for'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图6.8*可以看出，任务结构包含有关系统上每个单个任务（进程/线程）的大量信息（再次强调：这也包括内核线程）。我们以图6.8中的分隔概念格式显示了此数据结构中封装的不同类型的属性。此外，可以看到，某些属性将被*继承*给子进程或线程在`fork(2)`（或`pthread_create(3)`）时；某些属性将不会被继承，而将仅仅被重置。（内核模式堆栈为
- en: For now, at least, suffice it to say that the kernel 'understands' whether a
    task is a process or a thread. We'll later demonstrate a kernel module (`ch6/foreach/thrd_showall`) that
    reveals exactly how we can determine this (hang on, we'll get there!).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 至少目前，可以说内核“了解”任务是进程还是线程。我们稍后将演示一个内核模块（`ch6/foreach/thrd_showall`），它将准确展示我们如何确定这一点（稍等，我们会到那里的！）。
- en: Now let's start to understand in more detail some of the more important members
    of the huge task structure; read on!
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们开始更详细地了解任务结构中一些更重要的成员；继续阅读！
- en: Here, I only intend to give you a 'feel' for the kernel task structure; we do
    not delve deep into the details as it's not required for now. You will find that
    in later parts of this book, we delve into specific areas as required.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我只打算让你对内核任务结构有一个“感觉”；我们现在不需要深入细节。在本书的后面部分，我们将根据需要深入研究特定领域。
- en: Looking into the task structure
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看任务结构
- en: Firstly, recall that the task structure is essentially the 'root' data structure
    of the process or thread – it holds all attributes of the task (as we saw earlier).
    Thus, it's rather large; the powerful `crash(8)` utility (used to analyze Linux
    crash dump data or investigate a live system) reports its size on x86_64 to be
    9,088 bytes, as does the `sizeof` operator.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，回想一下任务结构本质上是进程或线程的“根”数据结构 - 它包含任务的所有属性（正如我们之前所见）。因此，它相当庞大；强大的`crash(8)`实用程序（用于分析Linux崩溃转储数据或调查活动系统）报告其在x86_64上的大小为9,088字节，`sizeof`操作符也是如此。
- en: 'The task structure is defined in the `include/linux/sched.h` kernel header (it''s
    a rather key header). In the following code, we show its definition with the caveat
    that we display only a few of its many members. (Also, the annotations in `<<
    angle brackets like this >>` are used to very briefly explain the member(s)):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 任务结构在`include/linux/sched.h`内核头文件中定义（这是一个相当关键的头文件）。在以下代码中，我们显示了它的定义，并且要注意我们只显示了其中的一些成员。（另外，像这样的`<<尖括号注释>>`用于非常简要地解释成员）：
- en: '[PRE5]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Continuing with the task structure in the following code block, see the members
    relating to memory management `(mm)`, the PID and TGID values, the credentials
    structure, open files, signal handling, and many more. Again, it''s not the intention
    to delve into (all of) them in detail; where appropriate, in later sections of
    this chapter, and possibly in other chapters of this book, we shall revisit them:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码块中继续查看任务结构，查看与内存管理`(mm)`、PID和TGID值、凭据结构、打开文件、信号处理等相关的成员。再次强调，不打算（全部）详细研究它们；在本章的后续部分以及可能在本书的其他章节中，我们将重新讨论它们：
- en: '[PRE6]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note that the `struct task_struct` members in the preceding code are shown with
    respect to the 5.4.0 kernel source; on other kernel versions, the members can
    and do change! Of course, it should go without saying, this is true of the entire
    book – all code/data is presented with regard to the 5.4.0 LTS Linux kernel (which
    will be maintained up to December 2025).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，前述代码中的`struct task_struct`成员是根据5.4.0内核源代码显示的；在其他内核版本中，成员可能会发生变化！当然，毋庸置疑，整本书都是如此
    - 所有代码/数据都是基于5.4.0 LTS Linux内核呈现的（将在2025年12月之前维护）。
- en: Okay, now that you have a better idea of the members within the task structure,
    how exactly do you access it and its various members? Read on.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在你对任务结构内的成员有了更好的了解，那么你如何访问它及其各个成员呢？继续阅读。
- en: Accessing the task structure with current
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用current访问任务结构
- en: You will recall, in our sample run of the preceding `countem.sh` script (in
    the *Organizing processes, threads, and their stacks – user and kernel space*
    section), we found that there are a total of 1,234 threads (both user and kernel)
    alive on the system. This implies that there will be a total of 1,234 task structure
    objects in the kernel memory.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你会回忆，在前述`countem.sh`脚本的示例运行中（在*组织进程、线程及其堆栈 - 用户空间和内核空间*部分），我们发现系统上有总共1,234个线程（用户和内核）是活跃的。这意味着内核内存中将有1,234个任务结构对象。
- en: 'They need to be organized in a way that the kernel can easily access them as
    and when required. Thus, all the task structure objects in kernel memory are chained
    up on a *circular doubly linked list* called the **task list***.* This kind of
    organization is required in order for various kernel code paths to iterate over
    them (commonly the `procfs` code, among others). Even so, think on this: when
    a process or thread is running kernel code (in process context), how can it find
    out which `task_struct` belongs to it among the perhaps hundreds or thousands
    that exist in kernel memory? This turns out to be a non-trivial task. The kernel
    developers have evolved a way to guarantee you can find the particular task structure
    representing the thread currently running the kernel code. It''s achieved via
    a macro called `current`. Think of it this way:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 它们需要以内核可以在需要时轻松访问它们的方式进行组织。因此，内核内存中的所有任务结构对象都被链接到一个称为**任务列表**的*循环双向链表*上。这种组织方式是为了使各种内核代码路径可以对它们进行迭代（通常是`procfs`代码等）。即使如此，请考虑这一点：当一个进程或线程在运行内核代码（在进程上下文中）时，它如何找出在内核内存中存在的数百或数千个`task_struct`中属于它的那个？这事实上是一个非平凡的任务。内核开发人员已经发展出一种方法来保证您可以找到代表当前运行内核代码的线程的特定任务结构。这是通过一个名为`current`的宏实现的。可以这样理解：
- en: Looking up `current` yields the pointer to `task_struct` of the thread that
    is running the kernel code right now, in other words, *the process context running
    right now on some particular processor core.*
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查找`current`会返回正在运行内核代码的线程的`task_struct`指针，换句话说，*当前在某个特定处理器核心上运行的进程上下文*。
- en: '`current` is analogous (but of course, not exactly) to what object-oriented
    languages call the `this` pointer.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`current`类似（但当然不完全相同）于面向对象语言中称为`this`指针的东西。'
- en: The implementation of the `current` macro is very architecture-specific. Here,
    we do not delve into the gory details. Suffice it to say that the implementation
    is carefully engineered to be fast (typically via an *O(1)* algorithm). For example,
    on some **Reduced Instruction Set Computer** (**RISC**) architectures with many
    general-purpose registers (such as the PowerPC and Aarch64 processors), a register
    is dedicated to holding the value of `current`!
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '`current`宏的实现非常特定于体系结构。在这里，我们不深入研究这些令人讨厌的细节。可以说，实现经过精心设计，以便快速（通常通过*O(1)*算法）。例如，在一些具有许多通用寄存器的**精简指令集计算机**（**RISC**）体系结构上（例如PowerPC和Aarch64处理器），有一个寄存器专门用于保存`current`的值！'
- en: I urge you to browse the kernel source tree and see the implementation details
    of `current` (under `arch/<arch>/asm/current.h`). On the ARM32, an *O(1)* calculation
    yields the result; on AArch64 and PowerPC it's stored in a register (and thus
    the lookup is blazing fast). On x86_64 architectures, the implementation uses
    a `per-cpu` *variable* to hold `current` (avoiding the use of costly locking).
    Including the `<linux/sched.h>` header is required to include the definition of `current` in
    your code.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议您浏览内核源树并查看`current`的实现细节（在`arch/<arch>/asm/current.h`下）。在ARM32上，*O(1)*计算会产生结果；在AArch64和PowerPC上，它存储在寄存器中（因此查找速度非常快）。在x86_64架构中，实现使用`per-cpu`
    *变量*来保存`current`（避免使用昂贵的锁定）。在您的代码中包含`<linux/sched.h>`头文件是必需的，以包含`current`的定义。
- en: 'We can use `current` to dereference the task structure and cull information
    from within it; for example, the process (or thread) PID and name can be looked
    up as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`current`来解引用任务结构并从中获取信息；例如，可以按以下方式查找进程（或线程）PID和名称：
- en: '[PRE7]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In the next section, you will see a full-fledged kernel module that iterates
    over the task list, printing out some details from each task structure it encounters
    along the way.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将看到一个完整的内核模块，它会遍历任务列表，并打印出它遇到的每个任务结构的一些细节。
- en: Determining the context
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定上下文
- en: 'As you now know, kernel code runs in one of two contexts:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您现在所知，内核代码在两种上下文中运行之一：
- en: Process (or task) context
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进程（或任务）上下文
- en: Interrupt (or atomic) context
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中断（或原子）上下文
- en: They are mutually exclusive – kernel code runs in either the process or atomic/interrupt
    context at any given point in time.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 它们是互斥的-内核代码在任何给定时间点都在进程或原子/中断上下文中运行。
- en: 'Often, when writing kernel or driver code, it is imperative for you to first
    figure out *what context* the code that you''re working on is running in. One
    way to learn this is by employing the following macro:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写内核或驱动程序代码时，通常需要首先弄清楚您正在处理的代码运行在*什么上下文*中。了解这一点的一种方法是使用以下宏：
- en: '[PRE8]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'It returns a Boolean: `True` if your code is running in process (or task) context,
    where it''s – usually – safe to sleep; returning `False` implies you are in some
    kind of atomic or interrupt context where it is never safe to sleep.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 它返回一个布尔值：如果您的代码在进程（或任务）上下文中运行，则返回`True`，在这种情况下通常可以安全休眠；返回`False`意味着您处于某种原子或中断上下文中，这种情况下永远不安全休眠。
- en: You might have come across the usage of the `in_interrupt()` macro; if it returns
    `True`, your code is within an interrupt context, if `False`, it isn't. However,
    the recommendation for modern code is to *not* rely on this macro (due to the
    fact that **Bottom Half** (**BH**) disabling can interfere with this). Hence,
    we recommend using `in_task()` instead.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经遇到了`in_interrupt()`宏的用法；如果它返回`True`，则您的代码在中断上下文中，如果返回`False`，则不在。然而，对于现代代码的建议是*不*依赖于这个宏（因为**Bottom
    Half**（**BH**）禁用可能会干扰这一点）。因此，我们建议使用`in_task()`代替。
- en: 'Hang on though! It can get a bit tricky: while `in_task()` returning `True`
    does imply that your code is in process context, this fact by itself does *not *guarantee
    that it''s currently *safe to sleep*. Sleeping really implies invoking the scheduler
    code and a subsequent context switch (we cover this in detail in [Chapter 10](5391e3c1-30ad-4c75-a106-301259064881.xhtml),
    *The CPU Scheduler – Part 1*, and [Chapter 11](d6e5ebd3-1f04-40e8-a240-2607c58b1299.xhtml),
    *The CPU Scheduler – Part* 2). For example, you could be in process context but
    holding a spinlock (a very common lock used within the kernel); the code between
    the lock and unlock – the so-called *critical section* – must run atomically!
    This implies that though your code may be in process (or task) context, it still
    will cause a bug if it attempts to issue any blocking (sleeping) APIs!'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 但是要注意！这可能会有点棘手：虽然`in_task()`返回`True`意味着您的代码处于进程上下文中，但这个事实本身并*不*保证当前*安全休眠*。休眠实际上意味着调用调度程序代码和随后的上下文切换（我们在[第10章](5391e3c1-30ad-4c75-a106-301259064881.xhtml)
    *CPU调度程序-第1部分*和[第11章](d6e5ebd3-1f04-40e8-a240-2607c58b1299.xhtml) *CPU调度程序-第2部分*中详细介绍了这一点）。例如，您可能处于进程上下文，但持有自旋锁（内核中非常常用的锁）；在锁定和解锁之间的代码-所谓的*临界区*
    -必须以原子方式运行！这意味着尽管您的代码可能处于进程（或任务）上下文中，但如果尝试发出任何阻塞（休眠）API，仍会导致错误！
- en: Also, be careful: `current` is only considered valid when running in *process
    context*.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意：只有在*进程上下文*中运行时，`current`才被认为是有效的。
- en: Right; by now you have learned useful background information on the task structure,
    how it can be accessed via the `current` macro, and the caveats to doing so –
    such as figuring out the context that your kernel or driver code is currently
    running in. So now, let's actually write some kernel module code to examine a
    bit of the kernel task structure.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 是的；到目前为止，您已经学到了有关任务结构的有用背景信息，以及如何通过`current`宏访问它，以及这样做的注意事项-例如弄清楚您的内核或驱动程序代码当前运行的上下文。因此，现在，让我们实际编写一些内核模块代码来检查内核任务结构的一部分。
- en: Working with the task structure via current
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过当前使用任务结构
- en: 'Here, we will write a simple kernel module to show a few members of the task
    structure and reveal the *process context *that its *init* and *cleanup* code
    paths run in. To do so, we cook up a `show_ctx()` function that uses `current`
    to access a few members of the task structure and display their values. It''s
    invoked from both the *init* as well as the *cleanup* methods, as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将编写一个简单的内核模块，以显示任务结构的一些成员，并揭示其*进程上下文*以及其*初始化*和*清理*代码路径运行的情况。为此，我们编写一个`show_ctx()`函数，它使用`current`来访问任务结构的一些成员并显示它们的值。它被从*init*和*cleanup*方法中调用，如下所示：
- en: For reasons of readability and space constraints, only key parts of the source
    code are displayed here. The entire source tree for this book is available in
    its GitHub repository; we expect you to clone and use it: `git clone https://github.com/PacktPublishing/Linux-Kernel-Programming.git`.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 出于可读性和空间限制的原因，这里只显示了源代码的关键部分。本书的整个源代码树都可以在其GitHub存储库中找到；我们希望您克隆并使用它：`git clone
    https://github.com/PacktPublishing/Linux-Kernel-Programming.git`。
- en: '[PRE9]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: As is highlighted in bold in the preceding snippet, you can see that (for some
    members) we can simply dereference the `current` pointer to gain access to various `task_struct` members
    and display them (via the kernel log buffer).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面的代码中所用粗体标出的那样，您可以看到（对于某些成员），我们可以简单地对`current`指针进行解引用，以访问各种`task_struct`成员并显示它们（通过内核日志缓冲区）。
- en: Great! The preceding code snippet does indeed show you how to gain access to
    a few `task_struct` members directly via `current`; not all members, though, can
    or should be accessed directly. Rather, the kernel provides some helper methods
    to access them; let's get into this next.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！前面的代码片段确实向您展示了如何通过`current`直接访问一些`task_struct`成员；但并非所有成员都可以或应该直接访问。相反，内核提供了一些辅助方法来访问它们；让我们接下来深入了解一下。
- en: Built-in kernel helper methods and optimizations
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内置内核辅助方法和优化
- en: In the preceding code, we made use of a few of the kernel's *built-in helper
    methods *to extract various members of the task structure. This is the recommended
    approach; for example, we use `task_pid_nr()` to peek at the PID member instead
    of directly via `current->pid`. Similarly, the process credentials within the
    task structure (such as the `EUID` members we showed in the preceding code) are
    abstracted within `struct cred` and access to them is provided via helper routines,
    just like with `from_kuid()`, which we used in the preceding code. In a similar
    fashion, there are several other helper methods; look them up in `include/linux/sched.h`
    just below the `struct task_struct` definition.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们使用了内核的一些*内置辅助方法*来提取任务结构的各个成员。这是推荐的方法；例如，我们使用`task_pid_nr()`来查看PID成员，而不是直接通过`current->pid`。同样，任务结构中的进程凭据（例如我们在前面的代码中显示的`EUID`成员）在`struct
    cred`中进行了抽象，并且通过辅助例程提供对它们的访问，就像我们在前面的代码中使用的`from_kuid()`一样。类似地，还有其他几种辅助方法；在`include/linux/sched.h`中的`struct
    task_struct`定义的下方查找它们。
- en: Why is this the case? Why not simply access task structure members directly
    via `current-><member-name>`? Well, there are various real reasons; one, perhaps
    the access requires a *lock* to be taken (we cover details on the key topic of
    locking and synchronization in the last two chapters of this book). Two, perhaps
    there's a more optimal way to access them; read on to see more on this...
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会这样？为什么不直接通过`current-><member-name>`访问任务结构成员？嗯，有各种真正的原因；也许访问需要获取*锁*（我们在本书的最后两章中详细介绍了锁定和同步的关键主题）。也许有更优化的访问方式；继续阅读以了解更多...
- en: Also, as shown in the preceding code, we can easily figure out whether the kernel
    code (of our kernel module) is running in the process or interrupt context by
    employing the `in_task()` macro – it returns `True` if in the process (or task)
    context, and `False` if otherwise.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，正如前面的代码所示，我们可以通过使用`in_task()`宏轻松地确定内核代码（我们的内核模块）是在进程还是中断上下文中运行-如果在进程（或任务）上下文中，则返回`True`，否则返回`False`。
- en: Interestingly, we also use the `likely()` macro (it becomes a compiler `__built-in_expect`
    attribute) to give a hint to the compiler's branch prediction setup and optimize
    the instruction sequence being fed into the CPU pipeline, thus keeping our code
    on the "fast path" (more on this micro-optimization with the `likely()/unlikely()`
    macros can be found in the *Further reading *section for this chapter). You will
    see kernel code often employing the `likely()/unlikely()` macros in situations
    where the developer "knows" whether the code path is likely or unlikely, respectively.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们还使用`likely()`宏（它变成了一个编译器`__built-in_expect`属性）来给编译器的分支预测设置一个提示，并优化被送入CPU流水线的指令序列，从而保持我们的代码在“快速路径”上（关于`likely()/unlikely()`宏的微优化，可以在本章的*进一步阅读*部分找到更多信息）。您会经常看到内核代码在开发者“知道”代码路径是可能还是不太可能的情况下使用`likely()/unlikely()`宏。
- en: The preceding `[un]likely()` macros are a good example of micro-optimization,
    of how the Linux kernel leverages the `gcc(1)` compiler. In fact, until recently,
    the Linux kernel could *only *be compiled with `gcc`; recently, patches are slowly
    making compilation with `clang(1)` a reality. (FYI, the modern **Android Open
    Source Project** (**AOSP**) is compiled with `clang`.)
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的`[un]likely()`宏是微优化的一个很好的例子，展示了Linux内核如何利用`gcc(1)`编译器。事实上，直到最近，Linux内核*只能*使用`gcc`进行编译；最近的补丁正在慢慢地使得使用`clang(1)`进行编译成为现实。（值得一提的是，现代的**Android开源项目**（**AOSP**）是使用`clang`进行编译的。）
- en: Okay, now that we have understood the workings of our kernel module's `show_ctx()`
    function, let's try it out.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在我们已经了解了我们的内核模块的`show_ctx()`函数的工作原理，让我们试一试。
- en: Trying out the kernel module to print process context info
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试使用内核模块打印进程上下文信息
- en: 'We build our `current_affair.ko` kernel module (we don''t show the build output
    here) and then insert it into kernel space (via `insmod(8)` as usual). Now let''s
    view the kernel log with `dmesg(1)`, then `rmmod(8)` it and use `dmesg(1)` again. The
    following screenshot shows this:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建我们的`current_affair.ko`内核模块（这里不显示构建输出），然后将其插入到内核空间（通常使用`insmod(8)`）。现在让我们使用`dmesg(1)`查看内核日志，然后使用`rmmod(8)`卸载它并再次使用`dmesg(1)`。以下截图显示了这一过程：
- en: '![](img/d6b8c619-17e7-45e1-9f14-0de34a13eb35.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d6b8c619-17e7-45e1-9f14-0de34a13eb35.png)'
- en: Figure 6.9 – The output of the current_affairs.ko kernel module
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9 - current_affairs.ko内核模块的输出
- en: 'Clearly, as can be seen from the preceding screenshot, the *process context* –
    the process (or thread) running the kernel code of `current_affairs.ko:current_affairs_init()`
    – is the `insmod` process (see the output: ''`name        : insmod`''), and the `current_affairs.ko:current_affairs_exit()` process
    context executing the cleanup code is the `rmmod` process!'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '显然，从前面的截图中可以看出，*进程上下文* - 运行`current_affairs.ko:current_affairs_init()`内核代码的进程（或线程）
    - 是`insmod`进程（查看输出：''name        : insmod''），而执行清理代码的`current_affairs.ko:current_affairs_exit()`进程上下文是`rmmod`进程！'
- en: Notice how the timestamps in the left column (`[sec.usec]`) in the preceding figure
    help us understand that `rmmod` was called close to 11 seconds after `insmod`.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意前面图中左列的时间戳（`[sec.usec]`），它们帮助我们理解`rmmod`在`insmod`后约11秒被调用。
- en: There's more to this small demo kernel module than first meets the eye. It's
    actually very helpful in understanding Linux kernel architecture. The following
    section explains how this is so.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这个小型演示内核模块的内涵远不止表面看到的那么简单。它实际上对于理解Linux内核架构非常有帮助。接下来的部分将解释为什么如此。
- en: Seeing that the Linux OS is monolithic
  id: totrans-222
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 看到Linux操作系统是单片式的
- en: 'Besides the exercise of using the `current` macro, a key point behind this
    kernel module (`ch6/current_affairs`) is to clearly show you the *monolithic nature
    of the Linux OS.* In the preceding code, we saw that when we performed the `insmod(8)` process
    on our kernel module file (`current_affairs.ko`), it got inserted into the kernel
    and its *init* code path ran; *who ran it?* Ah, that question is answered by checking
    the output: the `insmod` process itself ran it in process context, thus proving
    the monolithic nature of the Linux kernel! (Ditto with the `rmmod(8)` process
    and the *cleanup* code path; it was run by the `rmmod` process in process context.)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用`current`宏的练习之外，这个内核模块（`ch6/current_affairs`）的一个关键点是清楚地向您展示了Linux操作系统的*单片式特性*。在前面的代码中，我们看到当我们对我们的内核模块文件（`current_affairs.ko`）执行`insmod(8)`进程时，它被插入到内核中并且其*init*代码路径运行了；*谁运行了它？*
    啊，这个问题通过检查输出得到了答案：`insmod`进程本身在进程上下文中运行它，从而证明了Linux内核的单片式特性！（`rmmod(8)`进程和*cleanup*代码路径也是如此；它是由`rmmod`进程在进程上下文中运行的。）
- en: 'Note carefully and clearly: there is no "kernel" (or kernel thread) that executes
    the code of the kernel module, it''s the user space process (or thread) *itself* that,
    by issuing system calls (recall that both the `insmod(8)` and `rmmod(8)` utilities
    issue system calls), switches into kernel space and executes the code of the kernel
    module. This is how it is with a monolithic kernel.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意并清楚地注意：没有一个“内核”（或内核线程）执行内核模块的代码，而是用户空间进程（或线程）*本身*通过发出系统调用（回想一下`insmod(8)`和`rmmod(8)`工具都发出系统调用）切换到内核空间并执行内核模块的代码。这就是单片式内核的工作原理。
- en: Of course, this type of execution of kernel code is what we refer to as *running
    in process context*, as opposed to running in *interrupt context*. The Linux kernel,
    though, isn't considered to be purely monolithic; if so, it would be a single
    hard-coded piece of memory. Instead, like all modern OSes, Linux supports *modularization*
    (via the LKM framework).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这种内核代码的执行方式就是我们所说的*在进程上下文中运行*，与在*中断上下文中运行*相对。然而，Linux内核并不被认为是纯粹的单片式；如果是这样的话，它将是一个硬编码的内存块。相反，像所有现代操作系统一样，Linux支持*模块化*（通过LKM框架）。
- en: As an aside, do note that you can create and run *kernel threads* within kernel
    space; they still execute kernel code in process context when scheduled.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便提一下，您可以在内核空间内创建和运行*内核线程*；当调度时，它们仍然在进程上下文中执行内核代码。
- en: Coding for security with printk
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用printk进行安全编码
- en: 'In our previous kernel module demo (`ch6/current_affairs/current_affairs.c`),
    you noticed, I hope, the usage of `printk` with the ''special'' `%pK` format specifier.
    We repeat the relevant code snippet here:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的内核模块演示（`ch6/current_affairs/current_affairs.c`）中，你可能已经注意到了`printk`与'特殊'`%pK`格式说明符的使用。我们在这里重复相关的代码片段：
- en: '[PRE10]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Recall from our discussion in [Chapter 5](408b6f9d-42dc-4c59-ab3d-1074d595f9e2.xhtml),
    *Writing Your First Kernel Module – LKMs Part 2*, in the *Proc filesystem tunables
    affecting the system log* section, that when printing an address (firstly, you
    really shouldn't be printing addresses in production) I urged you to not use the
    usual `%p` (or `%px`) but the **`%pK`** format specifier instead. That's what
    we've done in the preceding code; *this is for security*, *to prevent a kernel
    information leak*. With a well-tuned (for security) system, `%pK` will result
    in a mere hashed value and not the actual address being displayed. To show this,
    we also display the actual kernel address via the `0x%px` format specifier just
    for contrast.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下我们在[第5章](408b6f9d-42dc-4c59-ab3d-1074d595f9e2.xhtml)中的讨论，*编写你的第一个内核模块 -
    LKMs第2部分*，在*影响系统日志的Proc文件系统可调参数*部分，当打印地址时（首先，在生产中你真的不应该打印地址），我敦促你不要使用通常的 `%p`（或
    `%px`），而是使用**`%pK`**格式说明符。这就是我们在前面的代码中所做的；*这是为了安全*，*以防止内核信息泄漏*。在一个经过良好调整（为安全）的系统中，`%pK`
    会产生一个简单的哈希值，而不是显示实际地址。为了证明这一点，我们还通过 `0x%px` 格式说明符显示实际的内核地址，以进行对比。
- en: 'Interestingly enough, `%pK` seems to have no effect on a default desktop Ubuntu
    18.04 LTS system. Both formats – the `%pK` and the `0x%px` – turn out to print
    identical values (as can be seen in Figure 6.9); this is *not* what''s expected.
    On my x86_64 Fedora 31 VM, though, it does work as expected, yielding a mere hashed
    (incorrect) value with `%pK` and the correct kernel address with `0x%px`. Here''s
    the relevant output on my Fedora 31 VM:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，`%pK` 在默认桌面版的 Ubuntu 18.04 LTS 系统上似乎没有效果。两种格式——`%pK` 和 `0x%px`——打印出来的值是相同的（如图6.9所示）；这*不是*预期的结果。然而，在我的
    x86_64 Fedora 31 VM 上，它确实按预期工作，使用 `%pK` 会产生一个简单的哈希（不正确）值，而使用 `0x%px` 会产生正确的内核地址。以下是我在
    Fedora 31 VM 上的相关输出：
- en: '[PRE11]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding output, we can clearly see the difference.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以清楚地看到区别。
- en: On production systems (embedded or otherwise) be safe: set `kernel.kptr_restrict` to `1` (or
    even better, to `2`), thus sanitizing pointers, and set `kernel.dmesg_restrict` to `1` (allowing
    only privileged users to read the kernel log).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产系统（嵌入式或其他）中要保持安全：将`kernel.kptr_restrict`设置为`1`（或者更好的是`2`），从而对指针进行清理，并将`kernel.dmesg_restrict`设置为`1`（只允许特权用户读取内核日志）。
- en: 'Now, let''s move on to something more interesting: in the following section,
    you will learn how to iterate over the Linux kernel''s *task lists*, thus in effect
    learning how to obtain kernel-level information on every single process and/or
    thread alive on the system.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们转向更有趣的事情：在接下来的部分，你将学习如何迭代 Linux 内核的*任务列表*，从而实际上学习如何获取系统中每个进程和/或线程的内核级信息。
- en: Iterating over the kernel's task lists
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迭代内核的任务列表
- en: As mentioned earlier, all the task structures are organized in kernel memory
    in a linked list called the *task list *(allowing them to be iterated over). The
    list data structure has evolved to become the very commonly used *circular doubly
    linked list. *In fact, the core kernel code to work with these lists has been
    factored out into a header called `list.h`; it's well known and expected to be
    used for any list-based work.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面提到的，所有的任务结构都以一个称为*任务列表*的链表形式组织在内核内存中（允许对它们进行迭代）。这个列表数据结构已经发展成为非常常用的*循环双向链表*。事实上，用于处理这些列表的核心内核代码已经被分解到一个名为`list.h`的头文件中；它是众所周知的，也被期望用于任何基于列表的工作。
- en: The `include/linux/types.h:list_head` data structure forms the essential doubly
    linked circular list; as expected, it consists of two pointers, one to the `prev`
    member on the list and one to the `next` member.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '`include/linux/types.h:list_head`数据结构形成了基本的双向循环链表；正如预期的那样，它由两个指针组成，一个指向列表上的`prev`成员，另一个指向`next`成员。'
- en: You can easily iterate over various lists concerned with tasks via conveniently
    provided macros in the `include/linux/sched/signal.h` header file for versions
    >= 4.11; note that for kernels 4.10 and older, the macros are in `include/linux/sched.h`.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过`include/linux/sched/signal.h`头文件中方便提供的宏来方便地迭代与任务相关的各种列表，适用于版本>= 4.11；请注意，对于4.10及更早版本的内核，这些宏在`include/linux/sched.h`中。
- en: 'Now, let''s make this discussion empirical and hands-on. In the following sections
    we will write kernel modules to iterate over the kernel task list in two ways:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们把这个讨论变得实证和实践。在接下来的几节中，我们将编写内核模块以两种方式迭代内核任务列表：
- en: '**One**: Iterate over the kernel task list and display all *processes* alive.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一**：迭代内核任务列表并显示所有*活动的进程*。'
- en: '**Two**: Iterate over the kernel task list and display all *threads* alive.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**二**：迭代内核任务列表并显示所有*活动的线程*。'
- en: We show the detailed code view for the latter case. Read on and be sure to try
    it out yourself!
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了后一种情况的详细代码视图。继续阅读，并确保自己尝试一下！
- en: Iterating over the task list I – displaying all processes
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代任务列表 I - 显示所有进程
- en: 'The kernel provides a convenient routine, the `for_each_process()` macro, which
    lets you easily iterate over every *process *in the task list:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 内核提供了一个方便的例程，即`for_each_process()`宏，它让你可以轻松地迭代任务列表中的每个*进程*：
- en: '[PRE12]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Clearly, the macro expands to a `for` loop, allowing us to loop over the circular
    list. `init_task` is a convenient 'head' or starting pointer – it points to the
    task structure of the very first user space process, traditionally `init(1)`,
    now `systemd(1)`.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这个宏扩展成一个`for`循环，允许我们在循环列表上进行循环。`init_task`是一个方便的“头”或起始指针 - 它指向第一个用户空间进程的任务结构，传统上是`init(1)`，现在是`systemd(1)`。
- en: Note that the `for_each_process()` macro is expressly designed to only iterate
    over the `main()` thread of every *process* and not the ('child' or peer) threads.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`for_each_process()`宏专门设计为只迭代每个*进程*的`main()`线程，而不是（'子'或对等）线程。
- en: 'A brief snippet of our `ch6/foreach/prcs_showall` kernel module''s output is
    shown here (when run on our x86_64 Ubuntu 18.04 LTS guest system):'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`ch6/foreach/prcs_showall`内核模块的简短片段输出如下（在我们的x86_64 Ubuntu 18.04 LTS客户机系统上运行时）：
- en: '[PRE13]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Notice how, in the preceding snippet, the TGID and PID of each process are always
    equal, 'proving' that the `for_each_process()` macro only iterates over the *main*
    thread of every process (and not every thread). We explain the details in the
    following section.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在前面的片段中，每个进程的TGID和PID始终相等，'证明'`for_each_process()`宏只迭代每个进程的*主*线程（而不是每个线程）。我们将在下一节中解释详细信息。
- en: We'll leave the studying and trying out of the sample kernel module at `ch6/foreach/prcs_showall` as
    an exercise for you.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将留给你作为练习的是，研究和尝试运行示例内核模块`ch6/foreach/prcs_showall`。
- en: Iterating over the task list II – displaying all threads
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代任务列表II-显示所有线程
- en: To iterate over each *thread* that's alive and well on the system, we could
    use the `do_each_thread() { ... } while_each_thread()` *pair* of macros; we write
    a sample kernel module to do just this (here: `ch6/foreach/thrd_showall/`).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 为了迭代系统上每个*活动正常*的*线程*，我们可以使用`do_each_thread() { ... } while_each_thread()` *宏对*；我们编写一个示例内核模块来执行此操作（这里：`ch6/foreach/thrd_showall/`）。
- en: 'Before diving into the code, let''s build it, `insmod` it (on our x86_64 Ubuntu
    18.04 LTS guest), and see the bottom part of the output it emits via `dmesg(1)`.
    As displaying the complete output isn''t really possible here – it''s far too
    large – I''ve shown only the lower part of the output in the following screenshot.
    Also, we''ve reproduced the header (Figure 6.9) so that you can make sense of
    what each column represents:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入代码之前，让我们先构建它，`insmod`它（在我们的x86_64 Ubuntu 18.04 LTS客户机上），并查看它通过`dmesg(1)`发出的输出的底部部分。由于在这里显示完整的输出并不是真正可能的-它太大了-我只显示了以下截图中输出的底部部分。此外，我们已经复制了标题（图6.9），以便您可以理解每列代表什么：
- en: '![](img/eb7e55fa-09ee-4080-87b7-0eb3815a3ae3.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb7e55fa-09ee-4080-87b7-0eb3815a3ae3.png)'
- en: Figure 6.10 – Output from our thrd_showall.ko kernel module
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10-来自我们的thrd_showall.ko内核模块的输出
- en: 'In Figure 6.9, notice how all the (kernel-mode) stack start addresses (the
    fifth column) end in zeroes:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在图6.9中，注意所有（内核模式）栈的起始地址（第五列）都以零结尾：
- en: '`0xffff .... .... .000`, implying that the stack region is *always aligned
    on a page boundary *(as `0x1000` is `4096` in decimal). This will be the case
    as kernel-mode stacks are always fixed in size and a multiple of the system page
    size (typically 4 KB).'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '`0xffff .... .... .000`，这意味着栈区域始终对齐在页面边界上（因为`0x1000`在十进制中是`4096`）。这是因为内核模式栈始终是固定大小的，并且是系统页面大小的倍数（通常为4
    KB）。'
- en: Following convention, in our kernel module, we arrange that if the thread is a
    *kernel thread*, its name shows up within square brackets.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，在我们的内核模块中，如果线程是*内核线程*，则其名称将显示在方括号内。
- en: Before continuing on to the code, we first need to examine in a bit of detail
    the TGID and PID members of the task structure.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续编码之前，我们首先需要稍微详细地检查任务结构的TGID和PID成员。
- en: Differentiating between the process and thread – the TGID and the PID
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 区分进程和线程- TGID和PID
- en: 'Think about this: as the Linux kernel uses a unique task structure (`struct
    task_struct`) to represent every thread, and as the unique member within it has
    a PID, this implies that, within the Linux kernel, *every thread has a unique
    PID*. This gives rise to an issue: how can multiple threads of the same process
    share a common PID? This violates the POSIX.1b standard (*pthreads*; indeed, for
    a while Linux was non-compliant with the standard, creating porting issues, among
    other things).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 想一想：由于Linux内核使用一个唯一的任务结构（`struct task_struct`）来表示每个线程，并且其中的唯一成员具有PID，这意味着在Linux内核中，*每个线程都有一个唯一的PID*。这带来了一个问题：同一个进程的多个线程如何共享一个公共PID？这违反了POSIX.1b标准（*pthreads*；事实上，有一段时间Linux不符合标准，造成了移植问题等）。
- en: 'To fix this annoying user space standards issue, Ingo Molnar (of Red Hat) proposed
    and mainlined a patch way back, in the 2.5 kernel series. A new member called
    the **Thread Group IDentifier** or TGID was slipped into the task structure. This
    is how it works: if the process is single-threaded, the `tgid` and `pid` values
    are equal. If it''s a multithreaded process, then the `tgid` value of the *main*
    thread is equal to its `pid` value; other threads of the process will inherit
    the *main* thread''s `tgid` value but will retain their own unique `pid` values.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个令人讨厌的用户空间标准问题，Red Hat的Ingo Molnar在2.5内核系列中提出并主线了一个补丁。任务结构中滑入了一个新成员称为**线程组标识符**或TGID。它的工作原理是：如果进程是单线程的，`tgid`和`pid`的值相等。如果是多线程进程，则*主*线程的`tgid`值等于其`pid`值；进程的其他线程将继承*主*线程的`tgid`值，但将保留自己独特的`pid`值。
- en: To understand this better, let's take an actual example from the previous screenshot.
    In Figure 6.9, notice how, if a positive integer appears in the last column on
    the right, it represents the number of threads in the multithreaded process to
    its immediate left.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，让我们从前面的截图中取一个实际的例子。在图6.9中，注意右侧最后一列出现正整数时，表示多线程进程中的线程数。
- en: 'So, check out the `VBoxService` process seen in Figure 6.9; for your convenience,
    we have duplicated that snippet as follows (note that we: eliminated the first
    column, the `dmesg` timestamp, and added the header line, for better readability):
    it has PID and TGID values of `938` representing its *main* thread (called `VBoxService`;
    for clarity, we''ve shown it in bold font), and a total of *nine threads*:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，查看图6.9中看到的`VBoxService`进程；为了方便起见，我们将该片段复制如下（注意：我们：消除了第一列，`dmesg`时间戳，并添加了标题行，以便更好地可读性）：它具有PID和TGID值为`938`，表示其*主*线程（称为`VBoxService`；为了清晰起见，我们已用粗体字显示），以及总共*九个线程*：
- en: '[PRE14]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'What are the nine threads? First, of course, the *main* thread is `VBoxService`,
    and the eight displayed below it are, by name: `RTThrdPP`, `control`, `timesync`,
    `vminfo`, `cpuhotplug`, `memballoon`, `vmstats`, and `automount`. How do we know
    this for sure? It''s easy: look carefully at the first and second columns in the
    preceding code block that represent the TGID and PID respectively: if they are
    the same, it''s the main thread of the process; *if the TGID repeats, the process
    is multithreaded* and the PID value represents the unique IDs of the ''child''
    threads.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这九个线程是什么？首先，当然，*主*线程是`VBoxService`，下面显示的八个分别是：`RTThrdPP`，`control`，`timesync`，`vminfo`，`cpuhotplug`，`memballoon`，`vmstats`和`automount`。我们怎么知道这一点呢？很简单：仔细看前面代码块中代表TGID和PID的第一列和第二列：如果它们相同，那么它就是进程的主线程；*如果TGID重复，那么进程是多线程的*，PID值代表“子”线程的唯一ID。
- en: 'As a matter of fact, it''s entirely possible to see the kernel''s TGID/PID
    representation in user space via the ubiquitous GNU `ps(1)` command, by using
    its `-LA` options (among other ways to do so):'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，完全可以通过普遍存在的GNU `ps(1)`命令在用户空间看到内核的TGID/PID表示，方法是使用它的`-LA`选项（还有其他方法）：
- en: '[PRE15]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `ps(1)` labels are as follows:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`ps(1)`的标签如下：'
- en: The first column is `PID` – this is actually representative of the `tgid` member
    of the task structure within the kernel for this task
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一列是`PID` - 这实际上代表了内核中此任务的任务结构的`tgid`成员。
- en: The second column is `LWP` (LightWeight Process or thread!) – this is actually
    representative of the `pid` member of the task structure within the kernel for
    this task.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二列是`LWP`（轻量级进程或线程！） - 这实际上代表了内核中此任务的任务结构的`pid`成员。
- en: 'Note that only with the `ps(1)` GNU  can you pass parameters (like `-LA`) and
    see the threads; this isn''t possible with a lightweight implementation of `ps` like
    that of *busybox*. It isn''t a problem though: you can always look up the same
    by looking under procfs; in this example, under `/proc/938/task`, you''ll see
    sub-folders representing the child threads. Guess what: this is actually how GNU `ps` works
    as well!'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，只有使用GNU的`ps(1)`才能传递参数（如`-LA`）并查看线程；这在像*busybox*这样的轻量级`ps`实现中是不可能的。不过这并不是问题：你总是可以通过查看procfs来查找相同的信息；在这个例子中，在`/proc/938/task`下，你会看到代表子线程的子文件夹。猜猜：GNU的`ps`实际上也是这样工作的！
- en: Okay, on to the code now...
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在进入代码部分...
- en: Iterating over the task list III – the code
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迭代任务列表III - 代码
- en: 'Now let''s see the (relevant) code of our `thrd_showall` kernel module:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看我们的`thrd_showall`内核模块的（相关）代码：
- en: '[PRE16]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'A few points to note regarding the preceding code:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 关于前面的代码，有几点需要注意：
- en: We use the `LINUX_VERSION_CODE()` macro to conditionally include a header, as
    required.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们使用`LINUX_VERSION_CODE()`宏来有条件地包含一个头文件。
- en: Please ignore the *locking* work for now – usage (or the lack thereof) of the `tasklist_lock()` and `task_[un]lock()` APIs.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在请暂时忽略*锁定*工作 - 使用（或不使用）`tasklist_lock()`和`task_[un]lock()`API。
- en: 'Don''t forget the CPU idle thread! Every CPU core has a dedicated idle thread
    (named `swapper/n`) that runs when no other thread wants to (`n` being the core
    number, starting with `0`). The `do .. while` loop we run does not start at this
    thread (nor does `ps(1)` ever show it). We include a small routine to display
    it, making use of the fact that the hard-coded task structure for the idle thread
    is available and exported at `init_task` (a detail: `init_task` always refers
    to the first CPU''s – core # `0` – idle thread).'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要忘记CPU空闲线程！每个CPU核心都有一个专用的空闲线程（名为`swapper/n`），当没有其他线程想要运行时它就运行（n是核心编号，从0开始）。我们运行的`do
    .. while`循环不从这个线程开始（`ps(1)`也从不显示它）。我们包括一个小例程来显示它，利用了空闲线程的硬编码任务结构在`init_task`处可用并导出的事实（一个细节：`init_task`总是指第一个CPU的
    - 核心#0 - 空闲线程）。
- en: 'Let''s continue: in order to iterate over every thread alive, we need to use
    a *pair* of macros, forming a loop: the `do_each_thread() { ... } while_each_thread()` pair
    of macros do precisely this, allowing us to iterate over every *thread* alive
    on the system. The following code shows this:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续：为了迭代每个活动的线程，我们需要使用一对宏形成一个循环：`do_each_thread() { ... } while_each_thread()`这一对宏正是这样做的，允许我们迭代系统上的每个*线程*。以下代码显示了这一点：
- en: '[PRE17]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Referring to the preceding code, the `do_each_thread() { ... } while_each_thread()` pair
    of macros form a loop,  allowing us to iterate over every *thread* alive on the
    system:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 参考前面的代码，`do_each_thread() { ... } while_each_thread()`这一对宏形成一个循环，允许我们迭代系统上的每个*线程*：
- en: We follow a strategy of using a temporary variable (named `tmp`) to fetch a
    data item, which we then append to a 'result' buffer, `buf`, which we print once
    on every loop iteration.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们遵循一种策略，使用一个临时变量（名为`tmp`）来获取一个数据项，然后将其附加到一个“结果”缓冲区`buf`中，我们在每次循环迭代时打印一次。
- en: Obtaining the `TGID`, `PID`, `task_struct`, and `stack` start addresses is trivial
    – here, keeping it simple, we just use `current` to dereference them (of course,
    you could use the more sophisticated kernel helper methods we saw earlier in this
    chapter to do so as well; here, we wish to keep it simple). Also notice that here
    we deliberately do *not *use the (safer) `%pK` printk format specifier but rather
    the generic `%px` specifier in order to display the *actual* kernel virtual addresses
    of the task structure and the kernel-mode stack .
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取`TGID`，`PID`，`task_struct`和`stack`的起始地址是微不足道的 - 在这里，保持简单，我们只是使用`current`来解引用它们（当然，你也可以使用我们在本章前面看到的更复杂的内核辅助方法来做到这一点；在这里，我们希望保持简单）。还要注意的是，这里我们故意*不*使用（更安全的）`%pK`
    printk格式说明符，而是使用通用的`%px`说明符来显示任务结构和内核模式堆栈的*实际*内核虚拟地址。
- en: Clean up as required before looping over (increment a counter of total threads, `memset()`
    the temporary buffers to `NULL`, and so on).
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需要进行清理（增加总线程计数器，将临时缓冲区`memset()`为`NULL`等）。
- en: On completion, we return the total number of threads we have iterated across.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成后，我们返回我们迭代过的总线程数。
- en: 'In the following code block, we cover the portion of code that was deliberately
    left out in the preceding block. We retrieve the thread''s name and print it within
    square brackets if it''s a kernel thread. We also query the number of threads
    within the process. The explanation follows the code:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码块中，我们覆盖了在前面的代码块中故意省略的代码部分。我们获取线程的名称，并在它是一个内核线程时在方括号内打印它。我们还查询进程中线程的数量。解释在代码之后。
- en: '[PRE18]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'On the preceding code, we can say the following:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们可以说以下内容：
- en: A *kernel thread *has no user space mapping. The `main()` thread's `current->mm` is
    a pointer to a structure of type `mm_struct` and represents the entire process'
    *user space* mapping; if `NULL`, it stands to reason that this is a kernel thread
    (as kernel threads have no user space mappings); we check and print the name accordingly.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*内核线程*没有用户空间映射。`main()`线程的`current->mm`是指向`mm_struct`类型结构的指针，并表示整个进程的*用户空间*映射；如果为`NULL`，那么这是一个内核线程（因为内核线程没有用户空间映射）；我们检查并相应地打印名称。'
- en: 'We print the name of the thread as well (by looking up the `comm` member of
    the task structure). You might question why we don''t use the `get_task_comm()` routine
    to obtain the task''s name here; the short reason: it causes a *deadlock*! We
    shall explore this (and how to avoid it) in detail in the later chapters on kernel
    synchronization. For now, again,  we just do it the simple way.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们也打印线程的名称（通过查找任务结构的`comm`成员）。您可能会问为什么我们不在这里使用`get_task_comm()`例程来获取任务的名称；简短的原因是：它会导致*死锁*！我们将在后面关于内核同步的章节中详细探讨这一点（以及如何避免它）。目前，我们只是用简单的方式做。
- en: We fetch the number of threads in a given process conveniently via the `get_nr_threads()` macro;
    the rest is explained clearly in the code comment above the macro in the preceding
    block.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们通过`get_nr_threads()`宏方便地获取给定进程中线程的数量；在前面的代码块中的宏上面的代码注释中已经清楚解释了其余部分。
- en: Great! With this, we complete our discussion (for now) on Linux kernel internals
    and architecture with a primary focus on processes, threads, and their stacks.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！通过这样，我们（暂时）完成了对Linux内核内部和架构的讨论，重点是进程、线程及其堆栈。
- en: Summary
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the key aspects of kernel internals that will help
    you as a kernel module or device driver author to better and more deeply understand
    the internal workings of the OS. You examined in some detail the organization
    of and relationships between the process and its threads and stacks (in both user
    and kernel space). We examined the kernel `task_struct` data structure and learned
    how to iterate over the *task list* in different ways via kernel modules.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们涵盖了内核内部的关键方面，这将帮助您作为内核模块或设备驱动程序的作者更好地理解操作系统的内部工作。您详细研究了进程及其线程和堆栈之间的组织和关系（无论是用户空间还是内核空间）。我们研究了内核的`task_struct`数据结构，并学习了如何通过内核模块以不同的方式迭代*任务列表*。
- en: Though it may not be obvious, the fact is that understanding these kernel internal
    details is a necessary and required step in your journey to becoming a seasoned
    kernel (and/or device driver) developer. The content of this chapter will help
    you debug many system programming scenarios and lays the foundation for our deeper
    exploration into the Linux kernel, particularly that of memory management.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这可能不明显，但事实是，理解这些内核内部细节是成为经验丰富的内核（和/或设备驱动程序）开发人员的必要和必需步骤。本章的内容将帮助您调试许多系统编程场景，并为我们更深入地探索Linux内核，特别是内存管理方面奠定基础。
- en: 'The next chapter and the couple that follow it are critical indeed: we''ll
    cover what you need to understand regarding the deep and complex topic of memory
    management internals. I suggest you digest the content of this chapter first,
    browse through the Further reading links of interest, work on the exercises (*Questions*
    section), and then, get to the next chapter!'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的章节以及随后的几章确实非常关键：我们将涵盖您需要了解的关于内存管理内部的深层和复杂主题。我建议您先消化本章的内容，浏览感兴趣的*进一步阅读*链接，完成练习（*问题*部分），然后继续下一章！
- en: Questions
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter''s material: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions).
    You will find some of the questions answered in the book''s GitHub repo: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn).'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这里是一些问题供您测试对本章材料的了解：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions)。您会发现一些问题的答案在书的GitHub存储库中：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn)。
- en: Further reading
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: To help you delve deeper into the subject with useful materials, we provide
    a rather detailed list of online references and links (and at times, even books)
    in a Further reading document in this book's GitHub repository. The *Further reading*
    document is available here: [https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md).
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您深入了解有用的材料，我们在本书的GitHub存储库中提供了一个相当详细的在线参考和链接列表（有时甚至包括书籍）。*进一步阅读*文档在这里可用：[https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md)。
