["```\nstruct irq_chip {\n     struct device *parent_device;\n     const char    *name;\n     unsigned int (*irq_startup)(struct irq_data *data);\n     void (*irq_shutdown)(struct irq_data *data);\n     void (*irq_enable)(struct irq_data *data);\n     void (*irq_disable)(struct irq_data *data);\n\n     void (*irq_ack)(struct irq_data *data);\n     void (*irq_mask)(struct irq_data *data);\n     void (*irq_mask_ack)(struct irq_data *data);\n     void (*irq_unmask)(struct irq_data *data);\n     void (*irq_eoi)(struct irq_data *data);\n\n     int (*irq_set_affinity)(struct irq_data *data, const struct cpumask\n                             *dest, bool force);\n\n     int (*irq_retrigger)(struct irq_data *data);    \n     int (*irq_set_type)(struct irq_data *data, unsigned int flow_type);\n     int (*irq_set_wake)(struct irq_data *data, unsigned int on);    \n     void (*irq_bus_lock)(struct irq_data *data);   \n     void (*irq_bus_sync_unlock)(struct irq_data *data);    \n     void (*irq_cpu_online)(struct irq_data *data);   \n     void (*irq_cpu_offline)(struct irq_data *data);   \n     void (*irq_suspend)(struct irq_data *data); \n     void (*irq_resume)(struct irq_data *data); \n     void (*irq_pm_shutdown)(struct irq_data *data); \n     void (*irq_calc_mask)(struct irq_data *data); \n     void (*irq_print_chip)(struct irq_data *data, struct seq_file *p);    \n     int (*irq_request_resources)(struct irq_data *data); \n     void (*irq_release_resources)(struct irq_data *data); \n     void (*irq_compose_msi_msg)(struct irq_data *data, struct msi_msg *msg);\n     void (*irq_write_msi_msg)(struct irq_data *data, struct msi_msg *msg);  \n\n     int (*irq_get_irqchip_state)(struct irq_data *data, enum  irqchip_irq_state which, bool *state);\n     int (*irq_set_irqchip_state)(struct irq_data *data, enum irqchip_irq_state which, bool state);\n\n     int (*irq_set_vcpu_affinity)(struct irq_data *data, void *vcpu_info);   \n     void (*ipi_send_single)(struct irq_data *data, unsigned int cpu);   \n     void (*ipi_send_mask)(struct irq_data *data, const struct cpumask *dest);      unsigned long flags; \n};\n```", "```\nstatic struct irq_chip ioapic_chip __read_mostly = {\n              .name             = \"IO-APIC\",\n              .irq_startup      = startup_ioapic_irq,\n              .irq_mask         = mask_ioapic_irq,\n              .irq_unmask       = unmask_ioapic_irq,\n              .irq_ack          = irq_chip_ack_parent,\n              .irq_eoi          = ioapic_ack_level,\n              .irq_set_affinity = ioapic_set_affinity,\n              .irq_retrigger    = irq_chip_retrigger_hierarchy,\n              .flags            = IRQCHIP_SKIP_SET_WAKE,\n};\n\nstatic struct irq_chip lapic_chip __read_mostly = {\n              .name            = \"local-APIC\",\n              .irq_mask        = mask_lapic_irq,\n              .irq_unmask      = unmask_lapic_irq,\n              .irq_ack         = ack_lapic_irq,\n};\n```", "```\n struct irq_desc {\n      struct irq_common_data    irq_common_data;\n      struct irq_data           irq_data;\n      unsigned int __percpu    *kstat_irqs;\n      irq_flow_handler_t        handle_irq;\n#ifdef CONFIG_IRQ_PREFLOW_FASTEOI\n      irq_preflow_handler_t     preflow_handler;\n#endif\n      struct irqaction         *action;    /* IRQ action list */\n      unsigned int             status_use_accessors;\n      unsigned int             core_internal_state__do_not_mess_with_it;\n      unsigned int             depth;    /* nested irq disables */\n      unsigned int             wake_depth;/* nested wake enables */\n      unsigned int             irq_count;/* For detecting broken IRQs */\n      unsigned long            last_unhandled;   \n      unsigned int             irqs_unhandled;\n      atomic_t                 threads_handled;\n      int                      threads_handled_last;\n      raw_spinlock_t           lock;\n      struct cpumask           *percpu_enabled;\n      const struct cpumask     *percpu_affinity;\n#ifdef CONFIG_SMP\n     const struct cpumask         *affinity_hint;\n     struct irq_affinity_notify   *affinity_notify;\n\n     ...\n     ...\n     ...\n};\n```", "```\n/**\n * struct irq_data - per irq chip data passed down to chip functions\n * @mask:          precomputed bitmask for accessing the chip registers\n * @irq:           interrupt number\n * @hwirq:         hardware interrupt number, local to the interrupt domain\n * @common:        point to data shared by all irqchips\n * @chip:          low level interrupt hardware access\n * @domain:        Interrupt translation domain; responsible for mapping\n *                 between hwirq number and linux irq number.\n * @parent_data:   pointer to parent struct irq_data to support hierarchy\n *                 irq_domain\n * @chip_data:     platform-specific per-chip private data for the chip\n *                 methods, to allow shared chip implementations\n */\n\nstruct irq_data { \n       u32 mask;    \n       unsigned int irq;    \n       unsigned long hwirq;    \n       struct irq_common_data *common;    \n       struct irq_chip *chip;    \n       struct irq_domain *domain; \n#ifdef CONFIG_IRQ_DOMAIN_HIERARCHY    \n       struct irq_data *parent_data; \n#endif    \n       void *chip_data; \n};\n```", "```\n/**\n * struct irqaction - per interrupt action descriptor\n * @handler: interrupt handler function\n * @name: name of the device\n * @dev_id: cookie to identify the device\n * @percpu_dev_id: cookie to identify the device\n * @next: pointer to the next irqaction for shared interrupts\n * @irq: interrupt number\n * @flags: flags \n * @thread_fn: interrupt handler function for threaded interrupts\n * @thread: thread pointer for threaded interrupts\n * @secondary: pointer to secondary irqaction (force threading)\n * @thread_flags: flags related to @thread\n * @thread_mask: bitmask for keeping track of @thread activity\n * @dir: pointer to the proc/irq/NN/name entry\n */\nstruct irqaction {\n       irq_handler_t handler;\n       void * dev_id;\n       void __percpu * percpu_dev_id;\n       struct irqaction * next;\n       irq_handler_t thread_fn;\n       struct task_struct * thread;\n       struct irqaction * secondary;\n       unsigned int irq;\n       unsigned int flags;\n       unsigned long thread_flags;\n       unsigned long thread_mask;\n       const char * name;\n       struct proc_dir_entry * dir;\n};  \n```", "```\ntypedef irqreturn_t (*irq_handler_t)(int, void *);\n\n/**\n * request_irq - allocate an interrupt line\n * @irq: Interrupt line to allocate\n * @handler: Function to be called when the IRQ occurs.\n * @irqflags: Interrupt type flags\n * @devname: An ascii name for the claiming device\n * @dev_id: A cookie passed back to the handler function\n */\n int request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,\n                 const char *name, void *dev);\n```", "```\nirqreturn_t handler(int irq, void *dev_id);\n```", "```\nenum irqreturn {\n        IRQ_NONE         = (0 << 0),\n        IRQ_HANDLED              = (1 << 0),\n        IRQ_WAKE_THREAD          = (1 << 1),\n};\n\ntypedef enum irqreturn irqreturn_t;\n```", "```\n/**\n * free_irq - free an interrupt allocated with request_irq\n * @irq: Interrupt line to free\n * @dev_id: Device identity to free\n *\n * Remove an interrupt handler. The handler is removed and if the\n * interrupt line is no longer in use by any driver it is disabled.\n * On a shared IRQ the caller must ensure the interrupt is disabled\n * on the card it drives before calling this function. The function\n * does not return until any executing interrupts for this IRQ\n * have completed.\n * Returns the devname argument passed to request_irq.\n */\nconst void *free_irq(unsigned int irq, void *dev_id);\n```", "```\n/**\n * request_threaded_irq - allocate an interrupt line\n * @irq: Interrupt line to allocate\n * @handler: Function to be called when the IRQ occurs.\n * Primary handler for threaded interrupts\n * If NULL and thread_fn != NULL the default\n * primary handler is installed\n * @thread_fn: Function called from the irq handler thread\n * If NULL, no irq thread is created\n * @irqflags: Interrupt type flags\n * @devname: An ascii name for the claiming device\n * @dev_id: A cookie passed back to the handler function\n */\n   int request_threaded_irq(unsigned int irq, irq_handler_t handler,\n                            irq_handler_t thread_fn, unsigned long irqflags,\n                            const char *devname, void *dev_id);\n```", "```\nstatic inline int __must_check\nrequest_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,\n            const char *name, void *dev)\n{\n        return request_threaded_irq(irq, handler, NULL, flags, name, dev);\n}\n```", "```\n/**\n * request_any_context_irq - allocate an interrupt line\n * @irq: Interrupt line to allocate\n * @handler: Function to be called when the IRQ occurs.\n * Threaded handler for threaded interrupts.\n * @flags: Interrupt type flags\n * @name: An ascii name for the claiming device\n * @dev_id: A cookie passed back to the handler function\n *\n * This call allocates interrupt resources and enables the\n * interrupt line and IRQ handling. It selects either a\n * hardirq or threaded handling method depending on the\n * context.\n * On failure, it returns a negative value. On success,\n * it returns either IRQC_IS_HARDIRQ or IRQC_IS_NESTED..\n */\nint request_any_context_irq(unsigned int irq,irq_handler_t handler, \n                            unsigned long flags,const char *name,void *dev_id)\n\n```", "```\nvoid disable_irq(unsigned int irq);\n```", "```\nvoid disable_irq_nosync(unsigned int irq);\n```", "```\nvoid enable_irq(unsigned int irq);\n```", "```\n/*\n * per-CPU IRQ handling stacks\n */\nstruct irq_stack {\n        u32                     stack[THREAD_SIZE/sizeof(u32)];\n} __aligned(THREAD_SIZE);\n\nDECLARE_PER_CPU(struct irq_stack *, hardirq_stack);\nDECLARE_PER_CPU(struct irq_stack *, softirq_stack);\n```", "```\nstruct softirq_action\n{\n        void (*action)(struct softirq_action *);\n};\n```", "```\nenum\n{\n        HI_SOFTIRQ=0,\n        TIMER_SOFTIRQ,\n        NET_TX_SOFTIRQ,\n        NET_RX_SOFTIRQ,\n        BLOCK_SOFTIRQ,\n        IRQ_POLL_SOFTIRQ,\n        TASKLET_SOFTIRQ,\n        SCHED_SOFTIRQ,\n        HRTIMER_SOFTIRQ, /* Unused, but kept as tools rely on the\n                            numbering. Sigh! */\n        RCU_SOFTIRQ, /* Preferable RCU should always be the last softirq */\n\n        NR_SOFTIRQS\n};\n```", "```\nstatic struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp;\n\n/* string constants for naming each softirq */\nconst char * const softirq_to_name[NR_SOFTIRQS] = {\n        \"HI\", \"TIMER\", \"NET_TX\", \"NET_RX\", \"BLOCK\", \"IRQ_POLL\",\n        \"TASKLET\", \"SCHED\", \"HRTIMER\", \"RCU\"\n};\n```", "```\nvoid open_softirq(int nr, void (*action)(struct softirq_action *))\n{\n        softirq_vec[nr].action = action;\n}\n\n```", "```\n/*kernel/time/timer.c*/\nopen_softirq(TIMER_SOFTIRQ, run_timer_softirq);\n```", "```\nvoid raise_softirq(unsigned int nr)\n{\n        unsigned long flags;\n\n        local_irq_save(flags);\n        raise_softirq_irqoff(nr);\n        local_irq_restore(flags);\n} \n```", "```\nvoid run_local_timers(void)\n{\n        struct timer_base *base = this_cpu_ptr(&amp;timer_bases[BASE_STD]);\n\n        hrtimer_run_queues();\n        /* Raise the softirq only if required. */\n        if (time_before(jiffies, base->clk)) {\n                if (!IS_ENABLED(CONFIG_NO_HZ_COMMON) || !base->nohz_active)\n                        return;\n                /* CPU is awake, so check the deferrable base. */\n                base++;\n                if (time_before(jiffies, base->clk))\n                        return;\n        }\n        raise_softirq(TIMER_SOFTIRQ);\n}\n```", "```\nstruct tasklet_struct\n{\n        struct tasklet_struct *next;\n        unsigned long state;\n        atomic_t count;\n        void (*func)(unsigned long);\n        unsigned long data;\n};\n```", "```\n#define DECLARE_TASKLET(name, func, data) \\\nstruct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }\n\n#define DECLARE_TASKLET_DISABLED(name, func, data) \\\nstruct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }\n```", "```\nvoid tasklet_init(struct tasklet_struct *t,\n                  void (*func)(unsigned long), unsigned long data)\n{\n        t->next = NULL;\n        t->state = 0;\n        atomic_set(&t->count, 0);\n        t->func = func;\n        t->data = data;\n}\n```", "```\n/*\n * Tasklets\n */\nstruct tasklet_head {\n        struct tasklet_struct *head;\n        struct tasklet_struct **tail;\n};\n\nstatic DEFINE_PER_CPU(struct tasklet_head, tasklet_vec);\nstatic DEFINE_PER_CPU(struct tasklet_head, tasklet_hi_vec);\n\n```", "```\nextern void __tasklet_schedule(struct tasklet_struct *t);\n\nstatic inline void tasklet_schedule(struct tasklet_struct *t)\n{\n        if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))\n                __tasklet_schedule(t);\n}\n```", "```\nvoid __tasklet_schedule(struct tasklet_struct *t)\n{\n        unsigned long flags;\n\n        local_irq_save(flags);\n        t->next = NULL;\n *__this_cpu_read(tasklet_vec.tail) = t;\n __this_cpu_write(tasklet_vec.tail, &(t->next));\n        raise_softirq_irqoff(TASKLET_SOFTIRQ);\n        local_irq_restore(flags);\n}\n```", "```\nextern void __tasklet_hi_schedule(struct tasklet_struct *t);\n\nstatic inline void tasklet_hi_schedule(struct tasklet_struct *t)\n{\n        if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))\n                __tasklet_hi_schedule(t);\n}\n```", "```\nvoid __tasklet_hi_schedule(struct tasklet_struct *t)\n{\n        unsigned long flags;\n\n        local_irq_save(flags);\n        t->next = NULL;\n *__this_cpu_read(tasklet_hi_vec.tail) = t;\n __this_cpu_write(tasklet_hi_vec.tail, &(t->next));\n raise_softirq_irqoff(HI_SOFTIRQ);\n        local_irq_restore(flags);\n}\n```", "```\nextern void __tasklet_hi_schedule_first(struct tasklet_struct *t);\n\n */\nstatic inline void tasklet_hi_schedule_first(struct tasklet_struct *t)\n{\n        if (!test_and_set_bit(TASKLET_STATE_SCHED, &t->state))\n                __tasklet_hi_schedule_first(t);\n}\n\n/*kernel/softirq.c */\nvoid __tasklet_hi_schedule_first(struct tasklet_struct *t)\n{\n        BUG_ON(!irqs_disabled());\n        t->next = __this_cpu_read(tasklet_hi_vec.head);\n __this_cpu_write(tasklet_hi_vec.head, t);\n        __raise_softirq_irqoff(HI_SOFTIRQ);\n}\n\n```", "```\nvoid tasklet_disable(struct tasklet_struct *t);\n```", "```\nvoid tasklet_enable(struct tasklet_struct *t);\n```", "```\nvoid tasklet_kill(struct tasklet_struct *t);\n```", "```\nvoid tasklet_kill_immediate(struct tasklet_struct *t, unsigned int cpu);\n```", "```\nstruct work_struct {\n        atomic_long_t data;\n        struct list_head entry;\n        work_func_t func;\n#ifdef CONFIG_LOCKDEP\n        struct lockdep_map lockdep_map;\n#endif\n};\n```", "```\n#define DECLARE_WORK(n, f) \\\n struct work_struct n = __WORK_INITIALIZER(n, f)\n```", "```\nbool schedule_work(struct work_struct *work);\n```", "```\nbool schedule_work_on(int cpu, struct work_struct *work);\n```", "```\nschedule_work_on(smp_processor_id(), &t_work);\n```", "```\nstruct delayed_work {\n        struct work_struct work;\n        struct timer_list timer;\n\n        /* target workqueue and CPU ->timer uses to queue ->work */\n        struct workqueue_struct *wq;\n        int cpu;\n};\n```", "```\n#define DECLARE_DELAYED_WORK(n, f) \\\n        struct delayed_work n = __DELAYED_WORK_INITIALIZER(n, f, 0)\n```", "```\nbool schedule_delayed_work(struct delayed_work *dwork,unsigned long delay);\nbool schedule_delayed_work_on(int cpu, struct delayed_work *dwork,\n                                                       unsigned long delay);\n```", "```\n   struct workqueue_struct *wq;\n   ...\n   wq = alloc_workqueue(\"nfsiod\", WQ_MEM_RECLAIM, 0);\n```", "```\nbool queue_work(struct workqueue_struct *wq, struct work_struct *work);\n```", "```\nbool queue_work_on(int cpu,struct workqueue_struct *wq,struct work_struct\n                                                                 *work);                                         \n```", "```\nbool queue_delayed_work_on(int cpu, struct workqueue_struct *wq, struct                                                                                                                                                        delayed_work *dwork,unsigned long delay);\n\nbool queue_delayed_work(struct workqueue_struct *wq, struct delayed_work                             *dwork, unsigned long delay\n```"]