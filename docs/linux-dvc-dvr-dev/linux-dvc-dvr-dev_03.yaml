- en: Kernel Facilities and Helper Functions
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核设施和辅助函数
- en: The kernel is a standalone piece of software, as you'll see in this chapter,
    that does not make use of any C library. It implements any mechanism you may encounter
    in modern libraries, and even more, such as compression, string functions, and
    so on. We will walk step by step through the most important aspects of such capabilities.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 内核是一个独立的软件，正如您将在本章中看到的，它不使用任何C库。它实现了您可能在现代库中遇到的任何机制，甚至更多，例如压缩、字符串函数等。我们将逐步介绍这些功能的最重要方面。
- en: 'In this chapter, we will cover the following topic:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing the kernel container data structure
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引入内核容器数据结构
- en: Dealing with the kernel sleeping mechanism
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理内核睡眠机制
- en: Using timers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用定时器
- en: Delving into the kernel locking mechanism (mutex, spnlock)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入了解内核锁定机制（互斥锁、自旋锁）
- en: Deferring work using a kernel dedicated API
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内核专用API推迟工作
- en: Using IRQs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用IRQs
- en: Understanding container_of macro
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解container_of宏
- en: 'When it comes to managing several data structures in the code, you''ll almost
    always need to embed one structure into another and retrieve them at any moment
    without being asked questions about memory offset or boundaries. Let''s say you
    have a `struct person` , as defined here:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到在代码中管理多个数据结构时，您几乎总是需要将一个结构嵌入到另一个结构中，并在任何时刻检索它们，而不需要询问有关内存偏移或边界的问题。假设您有一个`struct
    person`，如此定义：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'By only having a pointer on `age` or `name` , one can retrieve the whole structure
    wrapping (containing) that pointer. As the name says, `container_of` macro is
    used to find the container of the given field of a structure. The macro is defined
    in `include/linux/kernel.h` and looks like:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 只需拥有`age`或`name`的指针，就可以检索包含该指针的整个结构。正如其名称所示，`container_of`宏用于查找结构的给定字段的容器。该宏在`include/linux/kernel.h`中定义，如下所示：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Don''t be afraid by the pointers; just see it as:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 不要害怕指针；只需将其视为：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here are the elements of the preceding code fragment:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面代码片段的元素：
- en: '`pointer` : This is the pointer to the field in the structure'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pointer`：这是结构中字段的指针'
- en: '`container_type` : This is the type of structure wrapping (containing) the
    pointer'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`container_type`：这是包装（包含）指针的结构的类型'
- en: '`container_field` : This is the name of the field to which `pointer` points
    inside the structure'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`container_field`：这是指针在结构内指向的字段的名称'
- en: 'Let us consider the following container:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑以下容器：
- en: '[PRE3]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now let us consider one of its instance, along with a pointer to the `name`
    member:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑它的一个实例，以及指向`name`成员的指针：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Along with a pointer to the `name` member (`the_name_ptr` ), you can use the
    `container_of` macro in order to get a pointer to the whole structure (container)
    that wraps this member by using the following:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 以及指向`name`成员的指针（`the_name_ptr`），您可以使用`container_of`宏来获取包含此成员的整个结构（容器）的指针，方法如下：
- en: '[PRE5]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`container_of` takes the offset of `name` at the beginning of the struct into
    account to get the correct pointer location. If you subtract the offset of the
    field `name` from the pointer `the_name_ptr` , you will get the correct location.
    It is what the macro''s last line does:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`container_of`考虑了`name`在结构的开头的偏移量，以获取正确的指针位置。如果您从指针`the_name_ptr`中减去字段`name`的偏移量，您将得到正确的位置。这就是宏的最后一行所做的事情：'
- en: '[PRE6]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Applying this to a real example, it gives the following:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 将其应用于一个真实的例子，得到以下结果：
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'It''s all you need to know about the `container_of` macro, and believe me,
    it is enough. In real drivers that we''ll develop further in the book, it looks
    like the following:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是您需要了解的关于`container_of`宏的全部内容，相信我，这已经足够了。在我们将在本书中进一步开发的真实驱动程序中，它看起来像这样：
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '`controller_of` macro is mainly used in generic containers in the kernel. In
    some examples in this book (starting from [Chapter 5](text00146.html) , *Platform
    Device Drivers* ), you will encounter the `container_of` macro.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`controller_of`宏主要用于内核中的通用容器。在本书的一些示例中（从[第5章](text00146.html)开始，*平台设备驱动程序*），您将遇到`container_of`宏。'
- en: Linked lists
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 链表
- en: 'Imagine you have a driver that manages more than one device, let''s say five
    devices. You may need to keep a track of each of them in your driver. What you
    need here is a linked list. Two types of linked list actually exist:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，您有一个管理多个设备的驱动程序，比如说五个设备。您可能需要在驱动程序中跟踪每个设备。您需要的是一个链表。实际上存在两种类型的链表：
- en: Simply linked list
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单链表
- en: Doubly linked list
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 双向链表
- en: 'Therefore, kernel developers only implement circular doubly linked lists because
    this structure allows you to implement FIFO and LIFO, and kernel developers take
    care to maintain a minimal set of code. The header to be added in the code in
    order to support lists is `<linux/list.h>` . The data structure at the core of
    list implementation in the kernel is `struct list_head` structure, defined as
    the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，内核开发人员只实现循环双向链表，因为这种结构允许您实现FIFO和LIFO，并且内核开发人员会努力维护一组最小的代码。要支持列表，需要在代码中添加的标头是`<linux/list.h>`。内核中列表实现的核心数据结构是`struct
    list_head`结构，定义如下：
- en: '[PRE9]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `struct list_head` is used in both the head of the list and each node.
    In the world of the kernel, before a data structure can be represented as a linked
    list, that structure must embed a `struct list_head` field. For example, let''s
    create a list of cars:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`struct list_head`在列表的头部和每个节点中都使用。在内核世界中，要将数据结构表示为链表，该结构必须嵌入一个`struct list_head`字段。例如，让我们创建一个汽车列表：'
- en: '[PRE10]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Before we can create a list for the car, we must change its structure in order
    to embed a `struct list_head` field. The structure becomes:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以为汽车创建一个列表之前，我们必须改变其结构以嵌入一个`struct list_head`字段。结构变为：
- en: '[PRE11]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'First, we need to create a `struct list_head` variable that will always point
    to the head (first element) of our list. This instance of `list_head` is not associated
    to any car and is special:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建一个`struct list_head`变量，它将始终指向我们列表的头部（第一个元素）。这个`list_head`的实例不与任何汽车相关联，它是特殊的：
- en: '[PRE12]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now we can create cars and add them to our list—`carlist` :'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建汽车并将它们添加到我们的列表`carlist`：
- en: '[PRE13]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: It is as simple as that. Now, `carlist` contains two elements. Let us get deeper
    into the linked list API.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这么简单。现在，`carlist` 包含两个元素。让我们深入了解链表API。
- en: Creating and initializing the list
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和初始化列表
- en: 'There are two ways to create and initialize the list:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以创建和初始化列表：
- en: Dynamic method
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态方法
- en: 'The dynamic method consists of a `struct list_head` and initializes it with
    the `INIT_LIST_HEAD` macro:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 动态方法包括一个 `struct list_head` 并使用 `INIT_LIST_HEAD` 宏进行初始化：
- en: '[PRE14]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following is the expansion of `INIT_LIST_HEAD` :'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `INIT_LIST_HEAD` 的展开：
- en: '[PRE15]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Static method
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态方法
- en: 'Static allocation is done through the `LIST_HEAD` macro:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `LIST_HEAD` 宏进行静态分配：
- en: '[PRE16]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '`LIST_HEAD` s definition is defined as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`LIST_HEAD` 的定义如下：'
- en: '[PRE17]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following is its expansion:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是它的展开：
- en: '[PRE18]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This assigns each pointer (`prev` and `next` ) inside the `name` field to point
    to `name` itself (just like `INIT_LIST_HEAD` does).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这将把 `name` 字段内的每个指针（`prev` 和 `next`）都指向 `name` 本身（就像 `INIT_LIST_HEAD` 做的那样）。
- en: Creating a list node
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建列表节点
- en: 'To create new nodes, just create our data struct instance, and initialize their
    embedded `list_head` field. Using the car example, it will give the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建新节点，只需创建我们的数据结构实例，并初始化它们的嵌入式 `list_head` 字段。使用汽车示例，将得到以下内容：
- en: '[PRE19]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As said earlier, use `INIT_LIST_HEAD,` which is a dynamically allocated list
    and usually part of another structure.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，使用 `INIT_LIST_HEAD`，这是一个动态分配的列表，通常是另一个结构的一部分。
- en: Adding a list node
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加列表节点
- en: 'The kernel provides `list_add` to add a new entry to the list, which is a wrapper
    around the internal function `__list_add` :'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 内核提供了 `list_add` 来将新条目添加到列表中，它是对内部函数 `__list_add` 的封装：
- en: '[PRE20]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '`__list_add` will take two known entries as a parameter, and inserts your elements
    between them. Its implementation in the kernel is quite easy:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`__list_add` 将接受两个已知的条目作为参数，并在它们之间插入您的元素。它在内核中的实现非常简单：'
- en: '[PRE21]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following is an example of adding two cars in our list:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们列表中添加两辆车的示例：
- en: '[PRE22]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This mode can be used to implement a stack. The other function to add an entry
    into the list is:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式可以用来实现栈。另一个将条目添加到列表中的函数是：
- en: '[PRE23]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'This inserts the given new entry at the end of the list. Given our previous
    example, we can use the following:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这将给定的新条目插入到列表的末尾。根据我们之前的示例，我们可以使用以下内容：
- en: '[PRE24]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This mode can be used to implement a queue.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式可以用来实现队列。
- en: Deleting a node from the list
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从列表中删除节点
- en: 'List handling is an easy task in kernel code. Deleting a node is straightforward:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在内核代码中处理列表是一项简单的任务。删除节点很简单：
- en: '[PRE25]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Following the preceding example, let us delete the red car:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 按照前面的示例，让我们删除红色的车：
- en: '[PRE26]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`list_del` disconnects the `prev` and `next` pointers of the given entry, resulting
    in an entry removal. The memory allocated for the node is not freed yet; you need
    to do that manually with `kfree` .'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`list_del` 断开给定条目的 `prev` 和 `next` 指针，导致条目被移除。节点分配的内存尚未被释放；您需要使用 `kfree` 手动释放。'
- en: Linked list traversal
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 链表遍历
- en: We have the macro `list_for_each_entry(pos, head, member)` for list traversal.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有宏 `list_for_each_entry(pos, head, member)` 用于列表遍历。
- en: '`head` is the list''s head node.'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`head` 是列表的头节点。'
- en: '`member` is the name of the list `struct list_head` within our data struct
    (in our case, it is `list` ).'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`member` 是我们数据结构中 `struct list_head` 的列表名称（在我们的例子中是 `list`）。'
- en: '`pos` is used for iteration. It is a loop cursor (just like `i` in `for(i=0;
    i<foo; i++)` ). `head` could be the head node of the linked list, or any entry,
    and we don''t care since we are dealing with a doubly linked list:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pos` 用于迭代。它是一个循环游标（就像 `for(i=0; i<foo; i++)` 中的 `i`）。`head` 可能是链表的头节点，也可能是任何条目，我们不关心，因为我们处理的是双向链表。'
- en: '[PRE27]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Why do we need the name of the `list_head` type field in our data structure?
    Look at the `list_for_each_entry` definition:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们需要在数据结构中的 `list_head` 类型字段的名称？看看 `list_for_each_entry` 的定义：
- en: '[PRE28]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Given this, we can understand that it is all about `container_of` 's power.
    Also bear in mind `list_for_each_entry_safe(pos, n, head, member)` .
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个，我们可以理解这一切都是关于 `container_of` 的力量。还要记住 `list_for_each_entry_safe(pos, n,
    head, member)`。
- en: Kernel sleeping mechanism
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核睡眠机制
- en: Sleeping is the mechanism by which a process relaxes a processor, with the possibility
    of handling another process. The reason why a processor can sleep could be for
    sensing data availability, or waiting for a resource to be free.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 睡眠是一个进程使处理器放松的机制，有可能处理另一个进程。处理器可以进入睡眠状态的原因可能是为了感知数据的可用性，或者等待资源空闲。
- en: The kernel scheduler manages a list of tasks to run, known as a run queue. Sleeping
    processes are not scheduled anymore, since they are removed from that run queue.
    Unless its state changes (that is, it wakes up), a sleeping process will never
    be executed. You may relax a processor as soon as one is waiting for something
    (resource or anything else), and make sure a condition or someone else will wake
    it up. That said, the Linux kernel eases the implementation of the sleeping mechanism
    by providing a set of functions and data structures.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 内核调度程序管理要运行的任务列表，称为运行队列。睡眠进程不再被调度，因为它们已从运行队列中移除。除非其状态发生变化（即它被唤醒），否则睡眠进程永远不会被执行。只要有一个进程在等待某些东西（资源或其他任何东西），您就可以放松处理器，并确保某个条件或其他人会唤醒它。也就是说，Linux内核通过提供一组函数和数据结构来简化睡眠机制的实现。
- en: Wait queue
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 等待队列
- en: 'Wait queues are essentially used to process blocked I/O, to wait for particular
    conditions to be true, and to sense data or resource availability. To understand
    how it works, let''s have a look at its structure in `include/linux/wait.h` :'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 等待队列主要用于处理阻塞的I/O，等待特定条件成立，并感知数据或资源的可用性。为了理解它的工作原理，让我们来看看 `include/linux/wait.h`
    中的结构：
- en: '[PRE29]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Let's pay attention to the `task_list` field. As you can see, it is a list.
    Every process you want to put to sleep is queued in that list (hence the name
    *wait queue* ) and put into a sleep state until a condition becomes true. The
    wait queue can be seen as nothing but a simple list of processes and a lock.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注`task_list`字段。如您所见，它是一个列表。您想要让进程进入睡眠状态的每个进程都排队在该列表中（因此称为*等待队列*），并进入睡眠状态，直到条件成为真。等待队列可以被视为一系列进程和一个锁。
- en: 'The functions you will always face when dealing with wait queues are:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 处理等待队列时您将经常遇到的函数是：
- en: 'Static declaration:'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态声明：
- en: '[PRE30]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Dynamic declaration:'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态声明：
- en: '[PRE31]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Blocking:'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻塞：
- en: '[PRE32]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Unblocking:'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解除阻塞：
- en: '[PRE33]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`wait_event_interruptible` does not continuously poll, but simply evaluates
    the condition when it is called. If the condition is false, the process is put
    into a `TASK_INTERRUPTIBLE` state and removed from the run queue. The condition
    is then only rechecked each time you call `wake_up_interruptible` in the wait
    queue. If the condition is true when `wake_up_interruptible` runs, a process in
    the wait queue will be awakened, and its state set to `TASK_RUNNING` . Processes
    are awakened in the order they are put to sleep. To awaken all processes waiting
    in the queue, you should use `wake_up_interruptible_all` .'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '`wait_event_interruptible`不会持续轮询，而只是在调用时评估条件。如果条件为假，则将进程置于`TASK_INTERRUPTIBLE`状态并从运行队列中移除。然后在等待队列中每次调用`wake_up_interruptible`时重新检查条件。如果在`wake_up_interruptible`运行时条件为真，则等待队列中的进程将被唤醒，并且其状态设置为`TASK_RUNNING`。进程按照它们进入睡眠的顺序被唤醒。要唤醒等待队列中的所有进程，您应该使用`wake_up_interruptible_all`。'
- en: In fact, the main functions are `wait_event` , `wake_up` , and `wake_up_all`
    . They are used with processes in the queue in an exclusive (uninterruptible)
    wait, since they can't be interrupted by the signal. They should be used only
    for critical tasks. Interruptible functions are just optional (but recommended).
    Since they can be interrupted by signals, you should check their return value.
    A nonzero value means your sleep has been interrupted by some sort of signal,
    and the driver should return `ERESTARTSYS` .
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，主要功能是`wait_event`，`wake_up`和`wake_up_all`。它们与队列中的进程一起使用，处于独占（不可中断）等待状态，因为它们不能被信号中断。它们应该仅用于关键任务。可中断函数只是可选的（但建议使用）。由于它们可以被信号中断，您应该检查它们的返回值。非零值意味着您的睡眠已被某种信号中断，驱动程序应返回`ERESTARTSYS`。
- en: 'If someone has called `wake_up` or `wake_up_interruptible` and the condition
    is still `FALSE` , then nothing will happen. Without `wake_up` (or `wake_up_interuptible`
    ), process(es) will never be awakened. Here is an example of a wait queue:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人调用了`wake_up`或`wake_up_interruptible`，并且条件仍然为`FALSE`，那么什么也不会发生。没有`wake_up`（或`wake_up_interuptible`），进程将永远不会被唤醒。以下是等待队列的一个示例：
- en: '[PRE34]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'In the preceding example, the current process (actually `insmod` ) will be
    put into sleep in the wait queue for 5 seconds and woken up by the work handler.
    The `dmesg` output is as follows:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，当前进程（实际上是`insmod`）将被放入等待队列中，等待5秒钟后由工作处理程序唤醒。`dmesg`输出如下：
- en: '[PRE35]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Delay and timer management
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 延迟和定时器管理
- en: 'Time is one of the most used resources, right after memory. It is used to do
    almost everything: defer work, sleep, scheduling, timeout, and many other tasks.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 时间是最常用的资源之一，仅次于内存。它用于几乎所有事情：延迟工作，睡眠，调度，超时和许多其他任务。
- en: There are the two categories of time. The kernel uses absolute time to know
    what time it is, that is, the date and time of the day, whereas relative time
    is used by, for example, the kernel scheduler. For absolute time, there is a hardware
    chip called **real-time clock** (**RTC** ). We will deal with such devices later
    in the book in [Chapter 18](text00398.html) , *RTC Drivers.* On the other side,
    to handle relative time, the kernel relies on a CPU feature (peripheral), called
    a timer, which, from the kernel's point of view, is called a *kernel timer* .
    Kernel timers are what we will talk about in this section.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 时间有两个类别。内核使用绝对时间来知道现在是什么时间，也就是说，日期和时间，而相对时间则由内核调度程序等使用。对于绝对时间，有一个名为**实时时钟**（**RTC**）的硬件芯片。我们将在本书的[第18章](text00398.html)中处理这些设备，*RTC驱动程序*。另一方面，为了处理相对时间，内核依赖于一个称为定时器的CPU特性（外围设备），从内核的角度来看，它被称为*内核定时器*。内核定时器是我们将在本节中讨论的内容。
- en: 'Kernel timers are classified into two different parts:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 内核定时器分为两个不同的部分：
- en: Standard timers, or system timers
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标准定时器，或系统定时器
- en: High-resolution timers
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高分辨率定时器
- en: Standard timers
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准定时器
- en: Standard timers are kernel timers operating on the granularity of jiffies.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 标准定时器是以jiffies为粒度运行的内核定时器。
- en: Jiffies and HZ
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jiffies和HZ
- en: A jiffy is a kernel unit of time declared in `<linux/jiffies.h>` . To understand
    jiffies, we need to introduce a new constant HZ, which is the number of times
    `jiffies` is incremented in one second. Each increment is called a *tick* . In
    other words, HZ represents the size of a jiffy. HZ depends on the hardware and
    on the kernel version, and also determines how frequently the clock interrupt
    fires. This is configurable on some architecture, fixed on other ones.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: jiffy是在`<linux/jiffies.h>`中声明的内核时间单位。要理解jiffies，我们需要介绍一个新的常数HZ，它是在一秒钟内递增`jiffies`的次数。每次递增称为*tick*。换句话说，HZ表示jiffy的大小。HZ取决于硬件和内核版本，并且还确定时钟中断的频率。这在某些架构上是可配置的，在其他架构上是固定的。
- en: What it means is that `jiffies` is incremented HZ times every second. If HZ
    = 1,000, then it is incremented 1,000 times (that is, one tick every 1/1,000 seconds).
    Once defined, the **programmable interrupt timer** (**PIT** ), which is a hardware
    component, is programmed with that value in order to increment jiffies when the
    PIT interrupt comes in.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着`jiffies`每秒递增HZ次。如果HZ = 1,000，则递增1,000次（也就是说，每1/1,000秒递增一次）。一旦定义了**可编程中断定时器**（**PIT**），它是一个硬件组件，就会使用该值来对PIT进行编程，以便在PIT中断时递增jiffies。
- en: 'Depending on the platform, jiffies can lead to overflow. On a 32-bit system,
    HZ = 1,000 will result in about 50 days duration only, whereas the duration is
    about 600 million years on a 64-bit system. By storing jiffies in a 64-bit variable,
    the problem is solved. A second variable has then been introduced and defined
    in `<linux/jiffies.h>` :'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 根据平台的不同，jiffies可能会导致溢出。在32位系统上，HZ = 1,000将导致大约50天的持续时间，而在64位系统上，持续时间约为6亿年。通过将jiffies存储在64位变量中，问题得到解决。然后引入了第二个变量，并在`<linux/jiffies.h>`中定义：
- en: '[PRE36]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In this manner on 32-bit systems, `jiffies` will point to low-order 32-bits,
    and `jiffies_64` will point to high-order bits. On 64-bit platforms, `jiffies
    = jiffies_64` .
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在32位系统上，`jiffies`将指向低位32位，而`jiffies_64`将指向高位位。在64位平台上，`jiffies = jiffies_64`。
- en: Timers API
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定时器API
- en: 'A timer is represented in the kernel as an instance of `timer_list` :'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 定时器在内核中表示为`timer_list`的实例：
- en: '[PRE37]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '`expires` is an absolute value in jiffies. `entry` is a doubly linked list,
    and `data` is optional, and passed to the callback function.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`expires`是jiffies中的绝对值。`entry`是一个双向链表，`data`是可选的，并传递给回调函数。'
- en: Timer setup initialization
  id: totrans-134
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定时器设置初始化
- en: 'The following are steps to initialize timers:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是初始化定时器的步骤：
- en: '**Setting up the timer:** Set up the timer, feeding the user-defined callback
    and data:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置定时器**：设置定时器，提供用户定义的回调和数据：'
- en: '[PRE38]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'One can also use this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以使用以下方法：
- en: '[PRE39]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '`setup_timer` is a wrapper around `init_timer` .'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`setup_timer`是`init_timer`的包装器。'
- en: '**Setting the expiration time:** When the timer is initialized, we need to
    set its expiration before the callback gets fired:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**设置到期时间**：当初始化定时器时，需要在回调触发之前设置其到期时间：'
- en: '[PRE40]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '**Releasing the timer:** When you are done with the timer, it needs to be released:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**释放定时器**：当您完成定时器时，需要释放它：'
- en: '[PRE41]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '`del_timer` returns `void` whether it has deactivated a pending timer or not.
    Its return value is `0` on an inactive timer, or `1` on an active one. The last,
    `del_timer_sync` , waits for the handler to finish its execution, even those that
    may happen on another CPU. You should not hold a lock preventing the handler''s
    completion, otherwise it will result in a dead lock. You should release the timer
    in the module cleanup routine. You can independently check whether the timer is
    running or not:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '`del_timer`返回`void`，无论它是否已停用挂起的定时器。其返回值为0表示未激活的定时器，1表示激活的定时器。最后，`del_timer_sync`等待处理程序完成执行，即使可能发生在另一个CPU上的处理程序。您不应持有阻止处理程序完成的锁，否则将导致死锁。您应在模块清理例程中释放定时器。您可以独立检查定时器是否正在运行：'
- en: '[PRE42]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This function checks whether there are any fired timer callbacks pending.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 此函数检查是否有任何已触发的定时器回调待处理。
- en: Standard timer example
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标准定时器示例
- en: '[PRE43]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: High resolution timers (HRTs)
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高分辨率定时器（HRTs）
- en: Standard timers are less accurate and do not suit real-time applications. High-resolution
    timers, introduced in kernel v2.6.16 (and enabled by the `CONFIG_HIGH_RES_TIMERS`
    option in the kernel configuration) have a resolution of microseconds (up to nanoseconds,
    depending on the platform), compared to milliseconds on standard timers. The standard
    timer depends on HZ (since they rely on jiffies), whereas HRT implementation is
    based on `ktime` .
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 标准定时器精度较低，不适用于实时应用。高分辨率定时器在内核v2.6.16中引入（并通过内核配置中的`CONFIG_HIGH_RES_TIMERS`选项启用）具有微秒级（取决于平台，可达纳秒级）的分辨率，而标准定时器依赖于HZ（因为它们依赖于jiffies），而HRT实现基于`ktime`。
- en: Kernel and hardware must support an HRT before being used on your system. In
    other words, there must be an arch-dependent code implemented to access your hardware
    HRTs.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的系统上使用HRT之前，内核和硬件必须支持HRT。换句话说，必须实现与体系结构相关的代码以访问您的硬件HRT。
- en: HRT API
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HRT API
- en: 'The required headers are:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的头文件是：
- en: '[PRE44]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'An HRT is represented in the kernel as an instance of `hrtimer` :'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: HRT在内核中表示为`hrtimer`的实例：
- en: '[PRE45]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: HRT setup initialization
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HRT设置初始化
- en: '**Initializing the hrtimer** : Before hrtimer initialization, you need to set
    up a `ktime` , which represents time duration. We will see how to achieve that
    in the following example:'
  id: totrans-159
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化hrtimer**：在hrtimer初始化之前，您需要设置一个代表时间持续的`ktime`。我们将在以下示例中看到如何实现：'
- en: '[PRE46]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '**Starting hrtimer** : hrtimer can be started as shown in the following example:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**启动hrtimer**：hrtimer可以如以下示例所示启动：'
- en: '[PRE47]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '`mode` represents the expiry mode. It should be `HRTIMER_MODE_ABS` for an absolute
    time value, or `HRTIMER_MODE_REL` for a time value relative to now.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`mode`表示到期模式。对于绝对时间值，它应为`HRTIMER_MODE_ABS`，对于相对于现在的时间值，它应为`HRTIMER_MODE_REL`。'
- en: '**hrtimer cancellation** : You can either cancel the timer or see whether it
    is possible to cancel it or not:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**hrtimer取消**：您可以取消定时器，或者查看是否可能取消它：'
- en: '[PRE48]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Both return `0` when the timer is not active and `1` when the timer is active.
    The difference between these two functions is that `hrtimer_try_to_cancel` fails
    if the timer is active or its callback is running, returning `-1` , whereas `hrtimer_cancel`
    will wait until the callback finishes.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当定时器未激活时，两者返回`0`，当定时器激活时返回`1`。这两个函数之间的区别在于，如果定时器处于活动状态或其回调正在运行，`hrtimer_try_to_cancel`将失败，返回`-1`，而`hrtimer_cancel`将等待回调完成。
- en: 'We can independently check whether the hrtimer''s callback is still running
    with the following:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以独立检查hrtimer的回调是否仍在运行，如下所示：
- en: '[PRE49]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Remember, `hrtimer_try_to_cancel` internally calls `hrtimer_callback_running`
    .
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，`hrtimer_try_to_cancel`内部调用`hrtimer_callback_running`。
- en: In order to prevent the timer from automatically restarting, the hrtimer callback
    function must return `HRTIMER_NORESTART` .
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止定时器自动重新启动，hrtimer回调函数必须返回`HRTIMER_NORESTART`。
- en: 'You can check whether HRTs are available on your system by doing the following:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过以下方式检查系统是否支持HRT：
- en: 'By looking in the kernel config file, which should contain something like `CONFIG_HIGH_RES_TIMERS=y:
    zcat /proc/configs.gz | grep CONFIG_HIGH_RES_TIMERS` .'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过查看内核配置文件，其中应包含类似`CONFIG_HIGH_RES_TIMERS=y`的内容：`zcat /proc/configs.gz | grep
    CONFIG_HIGH_RES_TIMERS`。
- en: By looking at the `cat /proc/timer_list` or `cat /proc/timer_list | grep resolution`
    result. The `.resolution` entry must show 1 nsecs and the event_handler must show
    `hrtimer_interrupts` .
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过查看`cat /proc/timer_list`或`cat /proc/timer_list | grep resolution`的结果。`.resolution`条目必须显示1纳秒，事件处理程序必须显示`hrtimer_interrupts`。
- en: By using the `clock_getres` system call.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过使用`clock_getres`系统调用。
- en: From within the kernel code, by using `#ifdef CONFIG_HIGH_RES_TIMERS` .
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从内核代码中，通过使用`#ifdef CONFIG_HIGH_RES_TIMERS`。
- en: With HRTs enabled on your system, the accuracy of sleep and timer system calls
    do not depend on jiffies anymore, but they are still as accurate as HRTs are.
    It is the reason why some systems do not support `nanosleep()` , for example.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在系统上启用HRT后，睡眠和定时器系统调用的准确性不再取决于jiffies，但它们仍然与HRT一样准确。这就是为什么有些系统不支持`nanosleep()`的原因，例如。
- en: Dynamic tick/tickless kernel
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态滴答/无滴答内核
- en: With previous HZ options, the kernel is interrupted HZ times per second in order
    to reschedule tasks, even in an idle state. If HZ is set to 1,000, there will
    be 1,000 kernel interruptions per second, preventing the CPU from being idle for
    a long time, thus affecting CPU power consumption.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 使用先前的HZ选项，内核每秒被中断HZ次以重新安排任务，即使在空闲状态下也是如此。如果HZ设置为1,000，则每秒将有1,000次内核中断，防止CPU长时间处于空闲状态，从而影响CPU功耗。
- en: Now let's look at a kernel with no fixed or predefined ticks, where the ticks
    are disabled until some task needs to be performed. We call such a kernel a **tickless
    kernel** . In fact, tick activation is scheduled, based on the next action. The
    right name should be **dynamic tick kernel** . The kernel is responsible for task
    scheduling, and maintains a list of runnable tasks (the run queue) in the system.
    When there is no task to schedule, the scheduler switches to the idle thread,
    which enables dynamic tick by disabling the periodic tick until the next timer
    expires (a new task is queued for processing).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看一个没有固定或预定义滴答声的内核，其中滴答声被禁用，直到需要执行某些任务。我们称这样的内核为**无滴答内核**。实际上，滴答激活是根据下一个动作安排的。正确的名称应该是**动态滴答内核**。内核负责任务调度，并在系统中维护可运行任务的列表（运行队列）。当没有任务需要调度时，调度程序切换到空闲线程，通过禁用周期性滴答声来启用动态滴答，直到下一个定时器到期（新任务排队等待处理）。
- en: Under the hood, the kernel also maintains a list of the tasks timeouts (it then
    knows when and how long it has to sleep). In an idle state, if the next tick is
    further away than the lowest timeout in the tasks list timeout, the kernel programs
    the timer with that timeout value. When the timer expires, the kernel re-enables
    the periodic ticks back and invokes the scheduler, which then schedules the task
    associated with the timeout. This is how the tickless kernel removes the periodic
    tick and saves power when idle.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，内核还维护任务超时的列表（然后知道何时以及需要睡眠多长时间）。在空闲状态下，如果下一个滴答声比任务列表超时中的最低超时时间更长，则内核将使用该超时值对定时器进行编程。当定时器到期时，内核重新启用周期性滴答声并调用调度程序，然后调度与超时相关的任务。这就是无滴答内核在空闲时如何移除周期性滴答声并节省电源的方式。
- en: Delays and sleep in the kernel
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核中的延迟和睡眠
- en: 'Without going deep into the details, there are two types of delays, depending
    on the context your code runs in: atomic or nonatomic. The mandatory header to
    handle delays in the kernel is `#include <linux/delay>.`'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 不深入细节，根据代码运行的上下文，有两种类型的延迟：原子或非原子。内核中处理延迟的强制头文件是`#include <linux/delay>`。
- en: Atomic context
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 原子上下文
- en: 'Tasks in the atomic context (such as ISR) can''t sleep, and can''t be scheduled;
    it is the reason why busy-wait loops are used for delaying purposes in an atomic
    context. The kernel exposes the `Xdelay` family of functions that will spend time
    in a busy loop, long (based on jiffies) enough to achieve the desired delay:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在原子上下文中的任务（例如ISR）无法睡眠，也无法被调度；这就是为什么在原子上下文中用于延迟目的的忙等待循环。内核公开了`Xdelay`函数系列，这些函数将在忙循环中花费时间，足够长（基于jiffies）以实现所需的延迟：
- en: '`ndelay(unsigned long nsecs)`'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ndelay(unsigned long nsecs)`'
- en: '`udelay(unsigned long usecs)`'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`udelay(unsigned long usecs)`'
- en: '`mdelay(unsigned long msecs)`'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mdelay(unsigned long msecs)`'
- en: You should always use `udelay()` since `ndelay()` precision depends on how accurate
    your hardware timer is (not always the case on an embedded SOC). Use of `mdelay()`
    is also discouraged.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该始终使用`udelay()`，因为`ndelay()`的精度取决于您的硬件定时器的准确性（在嵌入式SOC上并非总是如此）。还不鼓励使用`mdelay()`。
- en: Timer handlers (callbacks) are executed in an atomic context, meaning that sleeping
    is not allowed at all. By *sleeping* , I mean any function that may result in
    sending the caller to sleep, such as allocating memory, locking a mutex, an explicit
    call to `sleep()` function, and so on.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 定时器处理程序（回调）在原子上下文中执行，这意味着根本不允许睡眠。通过*睡眠*，我的意思是可能导致调用者进入睡眠状态的任何函数，例如分配内存，锁定互斥锁，显式调用`sleep()`函数等。
- en: Nonatomic context
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非原子上下文
- en: 'In a nonatomic context, the kernel provides the `sleep[_range]` family of functions
    and which function to use depends on how long you need to delay by:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在非原子上下文中，内核提供了`sleep[_range]`函数系列，使用哪个函数取决于您需要延迟多长时间：
- en: '`udelay(unsigned long usecs)` : Busy-wait loop based. You should use this function
    if you need to sleep for a few µsecs ( < ~10 us ).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`udelay(unsigned long usecs)`：基于忙等待循环。如果您需要睡眠几微秒（<〜10微秒），则应使用此函数。'
- en: '`usleep_range(unsigned long min, unsigned long max)` : Relies on hrtimers,
    and it is recommended to let this sleep for few ~µsecs or small msecs (10 us -
    20 ms), avoiding the busy-wait loop of `udelay()` .'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`usleep_range(unsigned long min, unsigned long max)`：依赖于hrtimers，并建议让此睡眠几个~微秒或小毫秒（10微秒-20毫秒），避免`udelay()`的忙等待循环。'
- en: '`msleep(unsigned long msecs)` : Backed by jiffies/legacy_timers. You should
    use this for larger, msecs sleep (10 ms+).'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`msleep(unsigned long msecs)`：由jiffies/legacy_timers支持。您应该用于更大的毫秒睡眠（10毫秒以上）。'
- en: Sleep and delay topics are well explained in *Documentation/timers/timers-howto.txt*
    in the kernel source.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 内核源代码中的*Documentation/timers/timers-howto.txt*中很好地解释了睡眠和延迟主题。
- en: Kernel locking mechanism
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核锁定机制
- en: 'Locking is a mechanism that helps shares resources between different threads
    or processes. A shared resource is a data or a device that can be accessed by
    at least two user, simultaneously or no. Locking mechanisms prevent abusive access,
    for example, a process writing data when another one is reading in the same place,
    or two processes accessing the same device (the same GPIO for example). The kernel
    provides several locking mechanisms. The most important are:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 锁定是一种帮助在不同线程或进程之间共享资源的机制。共享资源是可以由至少两个用户同时访问的数据或设备，或者不可以。锁定机制可以防止滥用访问，例如，一个进程在另一个进程读取相同位置时写入数据，或者两个进程访问相同的设备（例如相同的GPIO）。内核提供了几种锁定机制。最重要的是：
- en: Mutex
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互斥锁
- en: Semaphore
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信号量
- en: Spinlock
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自旋锁
- en: We will only learn about mutexes and spinlock, since they are widely used in
    device drivers.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只会学习互斥锁和自旋锁，因为它们在设备驱动程序中被广泛使用。
- en: Mutex
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁
- en: '**Mutual exclusion** (**mutex** ) is the de facto most used locking mechanism.
    To understand how it works, let''s see what its structure looks like in `include/linux/mutex.h`
    :'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**互斥排他**（**mutex**）是事实上最常用的锁定机制。要了解它的工作原理，让我们看看在`include/linux/mutex.h`中它的结构是什么样的：'
- en: '[PRE50]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'As we have seen in the section *wait queue* , there is also a `list` type field
    in the structure: `wait_list` . The principle of sleeping is the same.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*等待队列*部分中所看到的，结构中还有一个`list`类型的字段：`wait_list`。睡眠的原理是相同的。
- en: Contenders are removed from the scheduler run queue and put onto the wait list
    (`wait_list` ) in a sleep state. The kernel then schedules and executes other
    tasks. When the lock is released, a waiter in the wait queue is woken, moved off
    the `wait_list` , and scheduled back.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 竞争者从调度程序运行队列中移除，并放入等待列表（`wait_list`）中的睡眠状态。然后内核调度和执行其他任务。当锁被释放时，等待队列中的等待者被唤醒，移出`wait_list`，并重新调度。
- en: Mutex API
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁API
- en: 'Using mutex requires only a few basic functions:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 使用互斥锁只需要几个基本函数：
- en: Declare
  id: totrans-209
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 声明
- en: 'Statically:'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态地：
- en: '[PRE51]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Dynamically:'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态地：
- en: '[PRE52]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Acquire and release
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取和释放
- en: 'Lock:'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁：
- en: '[PRE53]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Unlock:'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解锁：
- en: '[PRE54]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Sometimes, you may only need to check whether a mutex is locked or not. For
    that purpose, you can use the `int mutex_is_locked(struct mutex *lock)` function.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，您可能只需要检查互斥锁是否被锁定。为此，您可以使用`int mutex_is_locked(struct mutex *lock)`函数。
- en: '[PRE55]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'What this function does is just check whether the mutex''s owner is empty (`NULL`
    ) or not. There is also `mutex_trylock` , that acquires the mutex if it is not
    already locked, and returns `1` ; otherwise, it returns `0` :'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数的作用只是检查互斥锁的所有者是否为空（`NULL`）或不为空。还有`mutex_trylock`，如果互斥锁尚未被锁定，则会获取互斥锁，并返回`1`；否则返回`0`：
- en: '[PRE56]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: As with the wait queue's interruptible family function, `mutex_lock_interruptible()`
    , which is recommended, will result in the driver being able to be interrupted
    by any signal, whereas with `mutex_lock_killable()` , only signals killing the
    process can interrupt the driver.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 与等待队列的可中断系列函数一样，`mutex_lock_interruptible()`是推荐的，将导致驱动程序能够被任何信号中断，而`mutex_lock_killable()`只有杀死进程的信号才能中断驱动程序。
- en: You should be very careful with `mutex_lock()` , and use it when you can guarantee
    that the mutex will be released, whatever happens. In the user context, it is
    recommended you always use `mutex_lock_interruptible()` to acquire the mutex,
    since `mutex_lock()` will not return if a signal is received (even a c*trl + c*
    ).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`mutex_lock()`时，应非常小心，并且只有在可以保证无论发生什么都会释放互斥锁时才使用它。在用户上下文中，建议始终使用`mutex_lock_interruptible()`来获取互斥锁，因为如果收到信号（甚至是c*trl
    + c*），`mutex_lock()`将不会返回。
- en: 'Here is an example of a mutex implementation:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是互斥锁实现的示例：
- en: '[PRE57]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Please have a look at `include/linux/mutex.h` in the kernel source to see the
    strict rules you must respect with mutexes. Here are some of them:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看内核源码中的`include/linux/mutex.h`，以了解您必须遵守的互斥锁的严格规则。以下是其中一些规则：
- en: Only one task can hold the mutex at a time; this is actually not a rule, but
    a fact
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一次只有一个任务可以持有互斥锁；这实际上不是一条规则，而是一个事实
- en: Multiple unlocks are not permitted
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不允许多次解锁
- en: They must be initialized through the API
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们必须通过API进行初始化
- en: A task holding the mutex may not exit, since the mutex will remain locked, and
    possible contenders will wait (will sleep) forever
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持有互斥锁的任务可能不会退出，因为互斥锁将保持锁定，并且可能的竞争者将永远等待（将永远睡眠）
- en: Memory areas where held locks reside must not be freed
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存锁定的内存区域不得被释放
- en: Held mutexes must not be reinitialized
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持有的互斥锁不得被重新初始化
- en: Since they involve rescheduling, mutexes may not be used in atomic contexts,
    such as tasklets and timers
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于它们涉及重新调度，因此在原子上下文中可能无法使用互斥锁，例如任务和定时器
- en: As with `wait_queue` , there is no polling mechanism with mutexes. Every time
    that `mutex_unlock` is called on a mutex, the kernel checks for waiters in `wait_list`
    . If any, one (and only one) of them is awakened and scheduled; they are woken
    in the same order in which they were put to sleep.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 与`wait_queue`一样，互斥锁没有轮询机制。每次在互斥锁上调用`mutex_unlock`时，内核都会检查`wait_list`中是否有等待者。如果有，其中一个（仅一个）会被唤醒并调度；它们被唤醒的顺序与它们入睡的顺序相同。
- en: Spinlock
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自旋锁
- en: 'Like mutex, spinlock is a mutual exclusion mechanism; it only has two states:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 与互斥锁类似，自旋锁是一种互斥排他机制；它只有两种状态：
- en: locked (aquired)
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已锁定（已获取）
- en: unlocked (released)
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未锁定（已释放）
- en: Any thread that needs to acquire the spinlock will active loop until the lock
    is acquired, which breaks out of the loop. This is the point where mutex and spinlock
    differ. Since spinlock heavily consumes the CPU while looping, it should be used
    for very quick acquires, especially when time to hold the spinlock is less than
    time to reschedule. Spinlock should be released as soon as the critical task is
    done.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 需要获取自旋锁的任何线程都将主动循环，直到获取锁为止，然后才会跳出循环。这是互斥锁和自旋锁的区别所在。由于自旋锁在循环时会大量消耗CPU，因此应该在非常快速获取锁的情况下使用，特别是当持有自旋锁的时间小于重新调度的时间时。自旋锁应该在关键任务完成后尽快释放。
- en: In order to avoid wasting CPU time by scheduling a thread that may probably
    spin, trying to acquire a lock held by another thread moved off the run queue,
    the kernel disables preemption whenever a code holding a spinlock is running.
    With preemption disabled, we prevent the spinlock holder from being moved off
    the run queue, which could lead waiting processes to spin for a long time and
    consume CPU.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免通过调度可能旋转的线程来浪费CPU时间，尝试获取由另一个线程持有的锁，内核在运行持有自旋锁的代码时禁用了抢占。通过禁用抢占，我们防止自旋锁持有者被移出运行队列，这可能导致等待进程长时间旋转并消耗CPU。
- en: As long as one holds a spinlock, other tasks may be spinning while waiting on
    it. By using spinlock, you asserts and guarantee that it will not be held for
    a long time. You can say it is better to spin in a loop, wasting CPU time, than
    the cost of sleeping your thread, context-shifting to another thread or process,
    and being woken up afterward. Spinning on a processor means no other task can
    run on that processor; it then makes no sense to use spinlock on a single core
    machine. In the best case, you will slow down the system; in the worst case, you
    will deadlock, as with mutexes. For this reason, the kernel just disables preemption
    in response to the `spin_lock(spinlock_t *lock)` function on single processor.
    On a single processor (core) system, you should use `spin_lock_irqsave()` and
    `spin_unlock_irqrestore()` , which will respectively disable the interrupts on
    the CPU, preventing interrupt concurrency.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 只要持有自旋锁，其他任务可能会在等待它时旋转。通过使用自旋锁，你断言并保证它不会被长时间持有。你可以说在循环中旋转，浪费CPU时间，比睡眠线程、上下文切换到另一个线程或进程的成本，然后被唤醒要好。在处理器上旋转意味着没有其他任务可以在该处理器上运行；因此，在单核机器上使用自旋锁是没有意义的。在最好的情况下，你会减慢系统的速度；在最坏的情况下，你会死锁，就像互斥体一样。因此，内核只会在单处理器上对`spin_lock(spinlock_t
    *lock)`函数做出响应时禁用抢占。在单处理器（核心）系统上，你应该使用`spin_lock_irqsave()`和`spin_unlock_irqrestore()`，分别禁用CPU上的中断，防止中断并发。
- en: 'Since you do not know in advance what system you will write the driver for,
    it is recommended you acquire a spinlock using `spin_lock_irqsave(spinlock_t *lock,
    unsigned long flags)` , which disables interrupts on the current processor (the
    processor where it is called) before taking the spinlock. `spin_lock_irqsave`
    internally calls `local_irq_save(flags);` , an architecture-dependent function
    to save the IRQ status, and `preempt_disable()` to disable preemption on the relevant
    CPU. You should then release the lock with `spin_unlock_irqrestore()` , which
    does the reverse operations that we previously enumerated. This is a code that
    does lock acquire and release. It is an IRQ handler, but let''s just focus on
    the lock aspect. We will discuss more about IRQ handlers in the next section:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你事先不知道要为哪个系统编写驱动程序，建议你使用`spin_lock_irqsave(spinlock_t *lock, unsigned long
    flags)`来获取自旋锁，它会在获取自旋锁之前禁用当前处理器（调用它的处理器）上的中断。`spin_lock_irqsave`内部调用`local_irq_save(flags);`，一个依赖于体系结构的函数来保存IRQ状态，并调用`preempt_disable()`来禁用相关CPU上的抢占。然后你应该使用`spin_unlock_irqrestore()`释放锁，它会执行我们之前列举的相反操作。这是一个执行锁获取和释放的代码。这是一个IRQ处理程序，但让我们只关注锁方面。我们将在下一节讨论更多关于IRQ处理程序的内容。
- en: '[PRE58]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Spinlock versus mutexes
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自旋锁与互斥体
- en: 'Used for concurrency in the kernel, spinlocks and mutexes each have their own
    objectives:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在内核中用于并发的自旋锁和互斥体各自有各自的目标：
- en: Mutexes protect the process's critical resource, whereas spinlock protects the
    IRQ handler's critical sections
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互斥体保护进程的关键资源，而自旋锁保护IRQ处理程序的关键部分
- en: Mutexes put contenders to sleep until the lock is acquired, whereas spinlocks
    infinitely spin in a loop (consuming CPU) until the lock is acquired
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互斥体将竞争者置于睡眠状态，直到获得锁，而自旋锁会无限循环旋转（消耗CPU），直到获得锁
- en: Because of the previous point, you can't hold spinlock for a long time, since
    waiters will waste CPU time waiting for the lock, whereas a mutex can be held
    as long as the resource needs to be protected, since contenders are put to sleep
    in a wait queue
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于前面的观点，你不能长时间持有自旋锁，因为等待者会浪费CPU时间等待锁，而互斥体可以持有资源需要受保护的时间，因为竞争者被放置在等待队列中睡眠
- en: When dealing with spinlocks, please keep in mind that preemption is disabled
    only for threads holding spinlocks, not for spinning waiters.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理自旋锁时，请记住抢占仅对持有自旋锁的线程禁用，而不是对自旋等待者禁用。
- en: Work deferring mechanism
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作延迟机制
- en: 'Deferring is a method by which you schedule a piece of work to be executed
    in the future. It''s a way to report an action later. Obviously, the kernel provides
    facilities to implement such a mechanism; it allows you to defer functions, whatever
    their type, to be called and executed later. There are three of them in the kernel:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 延迟是一种安排将来执行的工作的方法。这是一种以后报告动作的方式。显然，内核提供了实现这种机制的设施；它允许你推迟函数，无论它们的类型，以便以后调用和执行。内核中有三种：
- en: '**SoftIRQs** : Executed in an atomic context'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SoftIRQs**：在原子上下文中执行'
- en: '**Tasklets** : Executed in an atomic context'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tasklets**：在原子上下文中执行'
- en: '**Workqueues** : Executed in a process context'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Workqueues**：在进程上下文中执行'
- en: Softirqs and ksoftirqd
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Softirqs和ksoftirqd
- en: '**Software IRQ** ( **softirq** ) , or software interrupt is a deferring mechanism
    used only for very fast processing, since it runs with a disabled scheduler (in
    an interrupt context). You''ll rarely (almost never) want to deal with softirq
    directly. There are only networks and block device subsystems using softirq. Tasklets
    are an instantiation of softirqs, and will be sufficient in almost every case
    that you feel the need to use softirqs.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 软件中断（softirq），或软件中断是一种延迟机制，仅用于非常快速的处理，因为它在禁用调度程序的情况下运行（在中断上下文中）。你几乎不会直接处理softirq。只有网络和块设备子系统使用softirq。Tasklets是softirq的一个实例，在几乎所有需要使用softirq的情况下都足够了。
- en: ksoftirqd
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ksoftirqd
- en: 'In most cases, softirqs are scheduled in hardware interrupts, which may arrive
    very quickly, faster than they can be serviced. They are then queued by the kernel
    in order to be processed later. **Ksoftirqds** are responsible for late execution
    (process context this time). A ksoftirqd is a per-CPU kernel thread raised to
    handle unserviced software interrupts:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，softirqs在硬件中断中调度，这可能会非常快，比它们能够被服务的速度更快。然后它们被内核排队以便稍后处理。**Ksoftirqds**负责延迟执行（这次是在进程上下文中）。ksoftirqd是每个CPU的内核线程，用于处理未服务的软中断：
- en: '![](img/Image00009.jpg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Image00009.jpg)'
- en: In the preceding `top` sample from my personal computer, you can see `ksoftirqd/n`
    entries, where `n` is the CPU number that the ksoftirqd runs on. CPU-consuming
    ksoftirqd may indicate an overloaded system or a system under **interrupts storm**
    , which is never good. You can have a look at `kernel/softirq.c` to see how ksoftirqds
    are designed.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在我个人电脑的前面的`top`示例中，您可以看到`ksoftirqd/n`条目，其中`n`是ksoftirqd运行的CPU编号。消耗CPU的ksoftirqd可能表明系统负载过重或处于**中断风暴**下，这是不好的。您可以查看`kernel/softirq.c`，了解ksoftirqd的设计方式。
- en: Tasklets
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tasklets
- en: 'Tasklets are a bottom-half (we will see what this means later) mechanism built
    on top of softirqs. They are represented in the kernel as instances of struct
    `tasklet_struct` :'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: Tasklet是建立在softirqs之上的一种底半部（稍后我们将看到这意味着什么）机制。它们在内核中表示为`tasklet_struct`的实例：
- en: '[PRE59]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Tasklets are not re-entrant by nature. A code is called reentrant if it can
    be interrupted anywhere in the middle of its execution, and then be safely called
    again. Tasklets are designed such that a tasklet can run on one and only one CPU
    simultaneously (even on an SMP system), which is the CPU it was scheduled on,
    but different tasklets may be run simultaneously on different CPUs. The tasklet
    API is quite basic and intuitive.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: tasklet本质上不是可重入的。如果代码在执行过程中可以在任何地方被中断，然后可以安全地再次调用，则称为可重入代码。tasklet被设计成只能在一个CPU上同时运行（即使在SMP系统上也是如此），这是它被计划的CPU，但不同的tasklet可以在不同的CPU上同时运行。tasklet
    API非常基本和直观。
- en: Declaring a tasklet
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 声明一个tasklet
- en: 'Dynamically:'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态地：
- en: '[PRE60]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Statically:'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态地：
- en: '[PRE61]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'There is one difference between the two functions; the former creates a tasklet
    already enabled and ready to be scheduled without any other function call, done
    by setting the `count` field to `0` , whereas the latter creates a tasklet disabled
    (done by setting `count` to `1` ), on which one has to call `tasklet_enable()`
    before the tasklet can be schedulable:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个函数之间有一个区别；前者创建一个已经启用并准备好在没有任何其他函数调用的情况下进行调度的tasklet，通过将`count`字段设置为`0`，而后者创建一个已禁用的tasklet（通过将`count`设置为`1`），在这种情况下，必须调用`tasklet_enable()`才能使tasklet可调度：
- en: '[PRE62]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: Globally, setting the `count` field to `0` means that the tasklet is disabled
    and cannot be executed, whereas a nonzero value means the opposite.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 全局地，将`count`字段设置为`0`意味着tasklet被禁用，不能执行，而非零值意味着相反。
- en: Enabling and disabling a tasklet
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用和禁用tasklet
- en: 'There is one function to enable a tasklet:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个函数可以启用tasklet：
- en: '[PRE63]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '`tasklet_enable` simply enables the tasklet. In older kernel versions, you
    may find void `tasklet_hi_enable(struct tasklet_struct *)` is used, but those
    two functions do exactly the same thing. To disable a tasklet, call:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '`tasklet_enable`简单地启用tasklet。在旧的内核版本中，可能会发现使用`void tasklet_hi_enable(struct
    tasklet_struct *)`，但这两个函数实际上是一样的。要禁用tasklet，调用：'
- en: '[PRE64]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'You can also call:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以调用：
- en: '[PRE65]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '`tasklet_disable` will disable the tasklet and return only when the tasklet
    has terminated its execution (if it was running), whereas `tasklet_disable_nosync`
    returns immediately, even if the termination has not occurred.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '`tasklet_disable`将禁用tasklet，并且只有在tasklet终止执行后才会返回（如果它正在运行），而`tasklet_disable_nosync`会立即返回，即使终止尚未发生。'
- en: Tasklet scheduling
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tasklet调度
- en: 'There are two scheduling functions for tasklet, depending on whether your tasklet
    has normal or higher priority:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个用于tasklet的调度函数，取决于您的tasklet是具有正常优先级还是较高优先级的：
- en: '[PRE66]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'The kernel maintains normal priority and high priority tasklets in two different
    lists. `tasklet_schedule` adds the tasklet into the normal priority list, scheduling
    the associated softirq with a `TASKLET_SOFTIRQ` flag. With `tasklet_hi_schedule`
    , the tasklet is added into the high priority list, scheduling the associated
    softirq with a `HI_SOFTIRQ` flag. High priority tasklets are meant to be used
    for soft interrupt handlers with low latency requirements. There are some properties
    associated with tasklets you should know:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 内核在两个不同的列表中维护正常优先级和高优先级的tasklet。`tasklet_schedule`将tasklet添加到正常优先级列表中，并使用`TASKLET_SOFTIRQ`标志调度相关的softirq。使用`tasklet_hi_schedule`，tasklet将添加到高优先级列表中，并使用`HI_SOFTIRQ`标志调度相关的softirq。高优先级tasklet用于具有低延迟要求的软中断处理程序。有一些与tasklet相关的属性您应该知道：
- en: Calling `tasklet_schedule` on a tasklet already scheduled, but whose execution
    has not started, will do nothing, resulting in the tasklet being executed only
    once.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对已经计划的tasklet调用`tasklet_schedule`，但其执行尚未开始，将不会产生任何效果，导致tasklet只执行一次。
- en: '`tasklet_schedule` can be called in a tasklet, meaning that a tasklet can reschedule
    itself.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tasklet_schedule`可以在tasklet中调用，这意味着tasklet可以重新安排自己。'
- en: High priority tasklets are always executed before normal ones. Abusive use of
    high priority tasks will increase the system latency. Only use them for really
    quick stuff.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高优先级的tasklet始终在正常优先级的tasklet之前执行。滥用高优先级任务会增加系统的延迟。只能用于非常快速的任务。
- en: 'You can stop a tasklet using the `tasklet_kill` function that will prevent
    the tasklet from running again or wait for its completion before killing it if
    the tasklet is currently scheduled to run:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`tasklet_kill`函数停止tasklet，这将阻止tasklet再次运行，或者在当前计划运行时等待其完成后再杀死它：
- en: '[PRE67]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Let us check. Look at the following example:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看。看下面的例子：
- en: '[PRE68]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: Work queues
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作队列
- en: Added since Linux kernel 2.6, the most used and simple deferring mechanism is
    the work queue. It is the last one we will talk about in this chapter. As a deferring
    mechanism, it takes an opposite approach to the others we've seen, running only
    in a preemptible context. It is the only choice when you need to sleep in your
    bottom half (I will explain what a bottom half is later in the next section).
    By sleep, I mean process I/O data, hold mutexes, delay, and all the other tasks
    that may lead to sleep or move the task off the run queue.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 自Linux内核2.6以来，最常用和简单的推迟机制是工作队列。这是我们将在本章中讨论的最后一个。作为一个推迟机制，它采用了与我们所见其他机制相反的方法，仅在可抢占的上下文中运行。当您需要在底半部分休眠时，它是唯一的选择（我将在下一节中解释什么是底半部分）。通过休眠，我指的是处理I/O数据，持有互斥锁，延迟和所有可能导致休眠或将任务移出运行队列的其他任务。
- en: Keep in mind that work queues are built on top of kernel threads, and this is
    the reason why I decided not to talk about the kernel thread as a deferring mechanism
    at all. However, there are two ways to deal with work queues in the kernel. First,
    there is a default shared work queue, handled by a set of kernel threads, each
    running on a CPU. Once you have work to schedule, you queue that work into the
    global work queue, which will be executed at the appropriate moment. The other
    method is to run the work queue in a dedicated kernel thread. It means whenever
    your work queue handler needs to be executed, your kernel thread is woken up to
    handle it, instead of one of the default predefined threads.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，工作队列是建立在内核线程之上的，这就是为什么我决定根本不谈论内核线程作为推迟机制的原因。但是，在内核中处理工作队列有两种方法。首先，有一个默认的共享工作队列，由一组内核线程处理，每个线程在一个CPU上运行。一旦有要安排的工作，您就将该工作排入全局工作队列，该工作将在适当的时刻执行。另一种方法是在专用内核线程中运行工作队列。这意味着每当需要执行工作队列处理程序时，将唤醒您的内核线程来处理它，而不是默认的预定义线程之一。
- en: Structures and functions to call are different, depending on whether you chose
    a shared work queue or dedicated ones.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您选择的是共享工作队列还是专用工作队列，要调用的结构和函数是不同的。
- en: Kernel-global workqueue – the shared queue
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核全局工作队列-共享队列
- en: Unless you have no choice, or you need critical performance, or you need to
    control everything from the work queue initialization to the work scheduling,
    and if you only submit tasks occasionally, you should use the shared work queue
    provided by the kernel. With that queue being shared over the system, you should
    be nice, and should not monopolize the queue for a long time.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 除非您别无选择，或者需要关键性能，或者需要从工作队列初始化到工作调度的所有控制，并且只偶尔提交任务，否则应该使用内核提供的共享工作队列。由于该队列在整个系统中共享，因此您应该友好，并且不应该长时间垄断队列。
- en: Since the execution of the pending task on the queue is serialized on each CPU,
    you should not sleep for a long time because no other task on the queue will run
    until you wake up. You won't even know who you share the work queue with, so don't
    be surprised if your task takes longer to get the CPU. Work in the shared work
    queues is executed in a per-CPU thread called events/n, created by the kernel.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在每个CPU上对队列中的挂起任务的执行是串行化的，因此您不应该长时间休眠，因为在您醒来之前，队列中的其他任务将不会运行。您甚至不知道与您共享工作队列的是谁，因此如果您的任务需要更长时间才能获得CPU，也不要感到惊讶。共享工作队列中的工作在由内核创建的每个CPU线程中执行。
- en: 'In this case, the work must also be initialized with the `INIT_WORK` macro.
    Since we are going to use the shared work queue, there is no need to create a
    work queue structure. We only need the `work_struct` structure that will be passed
    as an argument. There are three functions to schedule work on the shared work
    queue:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，工作还必须使用`INIT_WORK`宏进行初始化。由于我们将使用共享工作队列，因此无需创建工作队列结构。我们只需要作为参数传递的`work_struct`结构。有三个函数可以在共享工作队列上安排工作：
- en: 'The version that ties the work on the current CPU:'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将工作绑定到当前CPU的版本：
- en: '[PRE69]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The same but delayed function:'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相同但带有延迟功能：
- en: '[PRE70]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The function that actually schedules the work on a given CPU:'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际在给定CPU上安排工作的函数：
- en: '[PRE71]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'The same as shown previously, but with a delay:'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与之前显示的相同，但带有延迟：
- en: '[PRE72]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'All of these functions schedule the work given as an argument on to the system''s
    shared work queue `system_wq` , defined in `kernel/workqueue.c` :'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些函数都将作为参数安排到系统的共享工作队列`system_wq`中，该队列在`kernel/workqueue.c`中定义：
- en: '[PRE73]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'A work already submitted to the shared queue can be cancelled with the `cancel_delayed_work`
    function. You can flush the shared workqueue with:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 已经提交到共享队列的工作可以使用`cancel_delayed_work`函数取消。您可以使用以下方法刷新共享工作队列：
- en: '[PRE74]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'Since the queue is shared over the system, one can''t really know how long
    `flush_scheduled_work()` may last before it returns:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 由于队列在整个系统中共享，因此在`flush_scheduled_work()`返回之前，人们无法真正知道它可能持续多长时间：
- en: '[PRE75]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: In order to pass data to my work queue handler, you may have noticed that in
    both examples, I've embedded my `work_struct` structure inside my custom data
    structure, and used `container_of` to retrieve it. It is the common way to pass
    data to the work queue handler.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将数据传递给我的工作队列处理程序，您可能已经注意到在这两个示例中，我将我的`work_struct`结构嵌入到自定义数据结构中，并使用`container_of`来检索它。这是将数据传递给工作队列处理程序的常用方法。
- en: Dedicated work queue
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专用工作队列
- en: 'Here, the work queue is represented as an instance of `struct workqueue_struct`
    . The work to be queued into the work queue is represented as an instance of `struct
    work_struct` . There are four steps involved prior to scheduling your work in
    your own kernel thread:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，工作队列表示为`struct workqueue_struct`的一个实例。要排入工作队列的工作表示为`struct work_struct`的一个实例。在将您的工作安排到自己的内核线程之前，有四个步骤：
- en: Declare/initialize a `struct workqueue_struct` .
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 声明/初始化一个`struct workqueue_struct`。
- en: Create your work function.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建您的工作函数。
- en: Create a `struct work_struct` so that your work function will be embedded into
    it.
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`struct work_struct`，以便将您的工作函数嵌入其中。
- en: Embed your work function in the `work_struct` .
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的工作函数嵌入`work_struct`。
- en: Programming syntax
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编程语法
- en: 'The following functions are defined in `include/linux/workqueue.h` :'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 以下函数在`include/linux/workqueue.h`中定义：
- en: 'Declare work and work queue:'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 声明工作和工作队列：
- en: '[PRE76]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Define the worker function (the handler):'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义工作函数（处理程序）：
- en: '[PRE77]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Initialize our work queue and embed our work into:'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化我们的工作队列并嵌入我们的工作：
- en: '[PRE78]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: We could have also created our work queues through a macro called `create_workqueue`
    . The difference between `create_workqueue` and `create_singlethread_workqueue`
    is that the former will create a work queue that in turn will create a separate
    kernel thread on each and every processor available.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以通过一个名为 `create_workqueue` 的宏创建我们的工作队列。`create_workqueue` 和 `create_singlethread_workqueue`
    之间的区别在于前者将创建一个工作队列，该工作队列将为每个可用的处理器创建一个单独的内核线程。
- en: 'Scheduling work:'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调度工作：
- en: '[PRE79]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Queue after the given delay to the given worker thread:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定的延迟时间后排队到给定的工作线程：
- en: '[PRE80]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: These functions return `false` if the work was already on a queue and `true`
    if otherwise. `delay` represents the number of jiffies to wait before queueing.
    You may use the helper function `msecs_to_jiffies` in order to convert the standard
    ms delay into jiffies. For example, to queue a work after 5 ms, you can use `queue_delayed_work(myqueue,
    &thework, msecs_to_jiffies(5));` .
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果工作已经在队列中，则这些函数返回 `false`，如果不在队列中则返回 `true`。`delay` 表示排队前等待的 jiffies 数。您可以使用辅助函数
    `msecs_to_jiffies` 将标准毫秒延迟转换为 jiffies。例如，要在 5 毫秒后排队工作，可以使用 `queue_delayed_work(myqueue,
    &thework, msecs_to_jiffies(5));`。
- en: 'Wait on all pending work on the given work queue:'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待给定工作队列上的所有待处理工作：
- en: '[PRE81]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '`flush_workqueue` sleeps until all queued work has finished their execution.
    New incoming (enqueued) work does not affect the sleep. One may typically use
    this in driver shutdown handlers.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '`flush_workqueue` 等待直到所有排队的工作都完成执行。新进入的（排队的）工作不会影响等待。通常可以在驱动程序关闭处理程序中使用这个函数。'
- en: 'Cleanup:'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清理：
- en: 'Use `cancel_work_sync()` or `cancel_delayed_work_sync` for synchronous cancellation,
    which will cancel the work if it is not already running, or block until the work
    has completed. The work will be cancelled even if it requeues itself. You must
    also ensure that the work queue on which the work was last queued can''t be destroyed
    before the handler returns. These functions are to be used respectively for nondelayed
    or delayed work:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `cancel_work_sync()` 或 `cancel_delayed_work_sync` 进行同步取消，如果工作尚未运行，将取消工作，或者阻塞直到工作完成。即使工作重新排队，也将被取消。您还必须确保在处理程序返回之前，最后排队的工作队列不会被销毁。这些函数分别用于非延迟或延迟工作：
- en: '[PRE82]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'Since Linux kernel v4.8, it is possible to use `cancel_work` or `cancel_delayed_work`
    , which are asynchronous forms of cancellation. One must check whether the function
    returns true or no, and makes sure the work does not requeue itself. You must
    then explicitly flush the work queue:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 自 Linux 内核 v4.8 起，可以使用 `cancel_work` 或 `cancel_delayed_work`，这是取消的异步形式。必须检查函数是否返回
    true 或 false，并确保工作不会重新排队。然后必须显式刷新工作队列：
- en: '[PRE83]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'The other is a different version of the same method and will create only a
    single thread for all the processors. In case you need a delay before the work
    is enqueued, feel free to use the following work initialization macro:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个是相同方法的不同版本，将为所有处理器创建一个线程。如果需要在工作排队之前延迟，请随时使用以下工作初始化宏：
- en: '[PRE84]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Using the preceding macros would imply that you should use the following functions
    to queue or schedule the work in the work queue:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述宏意味着您应该使用以下函数在工作队列中排队或调度工作：
- en: '[PRE85]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: '`queue_work` ties the work to the current CPU. You can specify the CPU on which
    the handler should run using the `queue_work_on` function:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '`queue_work` 将工作绑定到当前 CPU。您可以使用 `queue_work_on` 函数指定处理程序应在哪个 CPU 上运行：'
- en: '[PRE86]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'For delayed work, you can use:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 对于延迟工作，您可以使用：
- en: '[PRE87]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The following is an example of using dedicated work queue:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用专用工作队列的示例：
- en: '[PRE88]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Predefined (shared) workqueue and standard workqueue functions
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预定义（共享）工作队列和标准工作队列函数
- en: 'The predefined work queue is defined in `kernel/workqueue.c` as follows:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 预定义的工作队列在 `kernel/workqueue.c` 中定义如下：
- en: '[PRE89]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: It is nothing more than a standard work for which the kernel provides a custom
    API that simply wraps around the standard one.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 它只是一个标准工作，内核为其提供了一个简单包装标准工作的自定义 API。
- en: 'Comparisons between kernel predefined work queue functions and standard work
    queue functions are mentioned as follows:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 内核预定义的工作队列函数与标准工作队列函数的比较如下：
- en: '| **Predefined work queue function** | **Equivalent standard work queue function**
    |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
  zh: '| **预定义工作队列函数** | **等效标准工作队列函数** |'
- en: '| `schedule_work(w)` | `queue_work(keventd_wq,w)` |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
  zh: '| `schedule_work(w)` | `queue_work(keventd_wq,w)` |'
- en: '| `schedule_delayed_work(w,d)` | `queue_delayed_work(keventd_wq,w,d)` (on any
    CPU) |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| `schedule_delayed_work(w,d)` | `queue_delayed_work(keventd_wq,w,d)`（在任何 CPU
    上） |'
- en: '| `schedule_delayed_work_on(cpu,w,d)` | `queue_delayed_work(keventd_wq,w,d)`
    (on a given CPU) |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| `schedule_delayed_work_on(cpu,w,d)` | `queue_delayed_work(keventd_wq,w,d)`（在给定的
    CPU 上） |'
- en: '| `flush_scheduled_work()` | `flush_workqueue(keventd_wq)` |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| `flush_scheduled_work()` | `flush_workqueue(keventd_wq)` |'
- en: Kernel threads
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核线程
- en: Work queues run on top of kernel threads. You already use kernel threads when
    you use work queues. It is the reason why I have decided not to talk about the
    kernel thread API.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 工作队列运行在内核线程之上。当您使用工作队列时，已经在使用内核线程。这就是为什么我决定不谈论内核线程 API 的原因。
- en: Kernel interruption mechanism
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核中断机制
- en: An interrupt is the way a device halts the kernel, telling it that something
    interesting or important has happened. These are called IRQs on Linux systems.
    The main advantage interrupts offer is to avoid devices polling. It is up to the
    device to tell if there is a change in its state; it is not up to us to poll it.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 中断是设备停止内核的方式，告诉内核发生了有趣或重要的事情。在 Linux 系统上称为 IRQ。中断提供的主要优势是避免设备轮询。由设备告知其状态是否发生变化；不是由我们轮询它。
- en: In order to get notified when an interrupt occurs, you need to register to that
    IRQ, providing a function called interrupt handler that will be called every time
    that interrupt is raised.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在中断发生时得到通知，您需要注册到该 IRQ，提供一个称为中断处理程序的函数，每次引发该中断时都会调用它。
- en: Registering an interrupt handler
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册中断处理程序
- en: 'You can register a callback to be run when the interruption (or interrupt line)
    you are interested in gets fired. You can achieve that with the function `request_irq()`
    , declared in `<linux/interrupt.h>` :'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以注册一个回调函数，在您感兴趣的中断（或中断线）被触发时运行。您可以使用`<linux/interrupt.h>`中声明的`request_irq()`函数来实现这一点。
- en: '[PRE90]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: '`request_irq()` may fail, and return `0` on success. Other elements of the
    preceding code are outlined in detail as follows:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '`request_irq()`可能会失败，并在成功时返回`0`。前面代码的其他元素如下所述：'
- en: '`flags` : These should be a bitmask of the masks defined in `<linux/interrupt.h>`
    . The most used are:'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flags`：这些应该是`<linux/interrupt.h>`中定义的掩码的位掩码。最常用的是：'
- en: '`IRQF_TIMER:` Informs the kernel that this handler is originated by a system
    timer interrupt.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRQF_TIMER:` 通知内核，此处理程序由系统定时器中断发起。'
- en: '`IRQF_SHARED:` Used for interrupt lines that can be shared by two or more devices.
    Each device sharing the same line must have this flag set. If omitted, only one
    handler can be registered for the specified IRQ line.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRQF_SHARED:` 用于可以被两个或更多设备共享的中断线。共享同一线的每个设备都必须设置此标志。如果省略，只能为指定的IRQ线注册一个处理程序。'
- en: '`IRQF_ONESHOT:` Used essentially in the threaded IRQ. It instructs the kernel
    not to re-enable the interrupt when the hardirq handler has finished. It will
    remain disabled until the threaded handler has been run.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRQF_ONESHOT:` 主要用于线程化的IRQ。它指示内核在硬中断处理程序完成后不要重新启用中断。它将保持禁用状态，直到线程处理程序运行。'
- en: In older kernel versions (until v2.6.35), there were `IRQF_DISABLED` flags,
    which asked the kernel to disable all interrupts when the handler is running.
    This flag is no longer used.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在旧的内核版本（直到v2.6.35），有`IRQF_DISABLED`标志，它要求内核在处理程序运行时禁用所有中断。现在不再使用这个标志。
- en: '`name` : This is used by the kernel to identify your driver in `/proc/interrupts`
    and `/proc/irq` *.*'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：这由内核用于在`/proc/interrupts`和`/proc/irq`中标识您的驱动程序。'
- en: '`dev` : Its primary goal is to pass as argument to the handler. This should
    be unique to each registered handler, since it is used to identify the device.
    It can be `NULL` for nonshared IRQs, but not for shared ones. The common way of
    using it is to provide a `device` structure, since it is both unique and may potentially
    be useful to the handler. That said, a pointer to any per-device data structure
    is sufficient:'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dev`：其主要目标是作为处理程序的参数传递。这应该对每个注册的处理程序都是唯一的，因为它用于标识设备。对于非共享的IRQ，它可以是`NULL`，但对于共享的IRQ则不行。通常的使用方式是提供一个`device`结构，因为它既是唯一的，也可能对处理程序有用。也就是说，任何与设备相关的数据结构的指针都是足够的：'
- en: '[PRE91]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: '`handler` : This is the callback function that will run when the interrupt
    is fired. An interrupt handler''s structure looks like:'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`handler`：这是当中断触发时将运行的回调函数。中断处理程序的结构如下：'
- en: '[PRE92]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'This contains the following code elements:'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这包含以下代码元素：
- en: '`irq` : The numeric value of the IRQ (the same used in `request_irq` ).'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`irq`：IRQ的数值（与`request_irq`中使用的相同）。'
- en: '`dev` : The same as used in `request_irq` .'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dev`：与`request_irq`中使用的相同。'
- en: 'Both parameters are given to your handler by the kernel. There are only two
    values the handler can return, depending on whether your device originated the
    IRQ or not:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个参数由内核传递给您的处理程序。处理程序只能返回两个值，取决于您的设备是否引起了IRQ：
- en: '`IRQ_NONE` : Your device is not the originator of that interrupt (it especially
    happens on shared IRQ lines)'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRQ_NONE`：您的设备不是该中断的发起者（这在共享的IRQ线上经常发生）'
- en: '`IRQ_HANDLED` : Your device caused the interrupt'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRQ_HANDLED`：您的设备引起了中断'
- en: Depending on the processing, one may use the `IRQ_RETVAL(val)` macro, which
    will return `IRQ_HANDLED` if the value is nonzero, or `IRQ_NONE` otherwise.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 根据处理情况，可以使用`IRQ_RETVAL(val)`宏，如果值非零，则返回`IRQ_HANDLED`，否则返回`IRQ_NONE`。
- en: When writing the interrupt handler, you don't have to worry about reentrancy,
    since the IRQ line serviced is disabled on all processors by the kernel in order
    to avoid recursive interrupt.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 在编写中断处理程序时，您不必担心重入性，因为内核会在所有处理器上禁用服务的IRQ线，以避免递归中断。
- en: 'The associated function to free the previously registered handler is:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 释放先前注册的处理程序的相关函数是：
- en: '[PRE93]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: If the specified IRQ is not shared, `free_irq` will not only remove the handler,
    but will also disable the line. If it is shared, only the handler identified through
    `dev` (which should be the same as that used in `request_irq` ) is removed, but
    the interrupt line still remains, and will be disabled only when the last handler
    is removed. `free_irq` will block until any executing interrupts for the specified
    IRQ have completed. You must then avoid both `request_irq` and `free_irq` in the
    interrupt context.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 如果指定的IRQ不是共享的，`free_irq`不仅会删除处理程序，还会禁用该线路。如果是共享的，只有通过`dev`（应该与`request_irq`中使用的相同）标识的处理程序被删除，但中断线路仍然存在，只有在最后一个处理程序被删除时才会被禁用。`free_irq`将阻塞，直到指定IRQ的所有执行中断完成。然后，您必须避免在中断上下文中同时使用`request_irq`和`free_irq`。
- en: Interrupt handler and lock
  id: totrans-394
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 中断处理程序和锁
- en: 'It goes without saying that you are in an atomic context and must only use
    spinlock for concurrency. Whenever there is global data accessible by both user
    code (the user task; that is, the system call) and interrupt code, this shared
    data should be protected by `spin_lock_irqsave()` in the user code. Let''s see
    why we can''t just use `spin_lock.` An interrupt handler will always have priority
    on the user task, even if that task is holding a spinlock. Simply disabling IRQ
    is not sufficient. An interrupt may happen on another CPU. It would be a disaster
    if a user task updating the data gets interrupted by an interrupt handler trying
    to access the same data. Using `spin_lock_irqsave()` will disable all interrupts
    on the local CPU, preventing the system call from being interrupted by any kind
    of interrupt:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 不用说，您处于原子上下文中，只能使用自旋锁进行并发。每当全局数据可被用户代码（用户任务；即系统调用）和中断代码访问时，这些共享数据应该在用户代码中由`spin_lock_irqsave()`保护。让我们看看为什么我们不能只使用`spin_lock`。中断处理程序将始终优先于用户任务，即使该任务持有自旋锁。简单地禁用IRQ是不够的。中断可能发生在另一个CPU上。如果用户任务更新数据时被中断处理程序尝试访问相同的数据，那将是一场灾难。使用`spin_lock_irqsave()`将在本地CPU上禁用所有中断，防止系统调用被任何类型的中断中断：
- en: '[PRE94]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: When sharing data between different interrupt handlers (that is, the same driver
    managing two or more devices, each having its own IRQ line), one should also protect
    that data with `spin_lock_irqsave()` in those handlers, in order to prevent the
    other IRQs from being triggered and uselessly spinning.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同的中断处理程序之间共享数据（即，同一驱动程序管理两个或多个设备，每个设备都有自己的IRQ线），应该在这些处理程序中使用`spin_lock_irqsave()`来保护数据，以防止其他IRQ被触发并且无用地旋转。
- en: Concept of bottom halves
  id: totrans-398
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 底半部分的概念
- en: Bottom halves are mechanisms by which you split interrupt handlers into two
    part. This introduces another term, which is top half. Before discussing each
    of them, let us talk about their origin, and what problem they solve.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 底半部分是一种将中断处理程序分成两部分的机制。这引入了另一个术语，即顶半部分。在讨论它们各自之前，让我们谈谈它们的起源以及它们解决了什么问题。
- en: The problem – interrupt handler design limitations
  id: totrans-400
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题-中断处理程序设计的限制
- en: Whether an interrupt handler holds a spinlock or not, preemption is disabled
    on the CPU running that handler. The more one wastes time in the handler, the
    less CPU is granted to the other task, which may considerably increase latency
    of other interrupts and so increase the latency of the whole system. The challenge
    is to acknowledge the device that raised the interrupt as quickly as possible
    in order to keep the system responsive.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 无论中断处理程序是否持有自旋锁，都会在运行该处理程序的CPU上禁用抢占。在处理程序中浪费的时间越多，分配给其他任务的CPU就越少，这可能会显着增加其他中断的延迟，从而增加整个系统的延迟。挑战在于尽快确认引发中断的设备，以保持系统的响应性。
- en: On Linux systems (actually on all OS, by hardware design), any interrupt handler
    runs with its current interrupt line disabled on all processors, and sometimes
    you may need to disable all interrupts on the CPU actually running the handler,
    but you definitely don't want to miss an interrupt. To meet this need, the concept
    of *halves* has been introduced.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux系统（实际上在所有操作系统上，根据硬件设计），任何中断处理程序都会在所有处理器上禁用其当前中断线，并且有时您可能需要在实际运行处理程序的CPU上禁用所有中断，但绝对不想错过中断。为了满足这个需求，引入了*halves*的概念。
- en: The solution – bottom halves
  id: totrans-403
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案-底半部分
- en: 'This idea consists of splitting the handler into two parts:'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是将处理程序分成两部分：
- en: The first part, called the top half or hard-IRQ, which is the registered function
    using `request_irq()` that will eventually mask/hide interrupts (on the current
    CPU, except the one being serviced since it is already disabled by the kernel
    before running the handler) depending on the needs, performs quick and fast operations
    (essentially time-sensitive tasks, read/write hardware registers, and fast processing
    of this data), schedules the second and next part, and then acknowledges the line.
    All interrupts that are disabled must have been re-enabled just before exiting
    the bottom half.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一部分称为顶半部分或硬中断，它是使用`request_irq()`注册的函数，最终会掩盖/隐藏中断（在当前CPU上，除了正在服务的CPU，因为内核在运行处理程序之前已经禁用了它），根据需要执行快速操作（基本上是时间敏感的任务，读/写硬件寄存器以及对这些数据的快速处理），安排第二部分和下一个部分，然后确认该线路。所有被禁用的中断必须在退出底半部分之前重新启用。
- en: The second part, called the bottom half, will process time-consuming stuff,
    and run with interrupt re-enabled. This way, you have the chance not to miss an
    interrupt.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二部分，称为底半部分，将处理耗时的任务，并在重新启用中断时运行。这样，您就有机会不会错过中断。
- en: 'Bottom halves are designed using a work-deferring mechanism, which we have
    seen previously. Depending on which one you choose, it may run in a (software)
    interrupt context, or in a process context. Bottom halves'' mechanisms are:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 底半部分是使用工作推迟机制设计的，我们之前已经看到了。根据您选择的是哪一个，它可能在（软件）中断上下文中运行，或者在进程上下文中运行。底半部分的机制有：
- en: Softirqs
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软中断
- en: Tasklets
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务let
- en: Workqueues
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作队列
- en: Threaded IRQs
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程中断
- en: Softirqs and tasklets execute in a (software) interrupt context (meaning that
    preemption is disabled), Workqueues and threaded IRQs are executed in a process
    (or simply task) context, and can be preempted, but nothing prevents us from changing
    their real-time properties to fit your needs and change their preemption behavior
    (see `CONFIG_PREEMPT` or `CONFIG_PREEMPT_VOLUNTARY.` This also impacts the whole
    system). Bottom halves are not always possible. But when it is possible, it is
    certainly the best thing to do.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 软中断和任务let在（软件）中断上下文中执行（意味着抢占被禁用），工作队列和线程中断在进程（或简单任务）上下文中执行，并且可以被抢占，但没有什么可以阻止我们改变它们的实时属性以适应您的需求并改变它们的抢占行为（参见`CONFIG_PREEMPT`或`CONFIG_PREEMPT_VOLUNTARY`。这也会影响整个系统）。底半部分并不总是可能的。但当可能时，这绝对是最好的选择。
- en: Tasklets as bottom halves
  id: totrans-413
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 任务let作为底半部分
- en: 'The tasklet deferring mechanism is most used in DMA, network, and block device
    drivers. Just try the following command in the kernel source:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 任务延迟机制在DMA、网络和块设备驱动程序中最常用。只需在内核源代码中尝试以下命令：
- en: '[PRE95]'
  id: totrans-415
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'Now let''s see how to implement such a mechanism in our interrupt handler:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何在我们的中断处理程序中实现这样的机制：
- en: '[PRE96]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: In the preceding sample, our tasklet will execute the function `my_tasklet_work()`
    .
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，我们的tasklet将执行函数`my_tasklet_work()`。
- en: Workqueue as bottom halves
  id: totrans-419
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作队列作为底半部分。
- en: 'Let''s just start with a sample:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个示例开始：
- en: '[PRE97]'
  id: totrans-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: In the preceding sample, we used either a wait queue or a work queue in order
    to wake up a possibly sleeping process waiting for us, or schedule a work depending
    on the value of a register. We have no shared data or resource, so there is no
    need to disable all other IRQs (`spin_lock_irq_disable` ).
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，我们使用等待队列或工作队列来唤醒可能正在等待我们的进程，或者根据寄存器的值安排工作。我们没有共享的数据或资源，因此不需要禁用所有其他IRQs（`spin_lock_irq_disable`）。
- en: Softirqs as bottom half
  id: totrans-423
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Softirqs作为底半部分
- en: As said in the beginning of this chapter, we will not discuss softirq. Tasklets
    will be enough everywhere you feel the need to use softirqs. Anyway, let's talk
    about their defaults.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章开头所说，我们不会讨论softirq。在你感觉需要使用softirqs的任何地方，tasklets都足够了。无论如何，让我们谈谈它们的默认值。
- en: Softirqs run in a software interrupt context, with preemption disabled, holding
    the CPU until they complete. Softirq should be fast; otherwise they may slow the
    system down. When, for any reason, a softirq prevents the kernel from scheduling
    other tasks, any new incoming softirq will be handled by **ksoftirqd** threads,
    running in a process context.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: Softirq在软件中断上下文中运行，禁用了抢占，保持CPU直到它们完成。Softirq应该很快；否则它们可能会减慢系统。当由于任何原因softirq阻止内核调度其他任务时，任何新进入的softirq将由**ksoftirqd**线程处理，运行在进程上下文中。
- en: Threaded IRQs
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程化的IRQs
- en: 'The main goal of threaded IRQs is reducing the time spent with interrupts disabled
    to a bare minimum. With threaded IRQs, the way you register an interrupt handler
    is a bit simplified. You does not even have to schedule the bottom half yourself.
    The core does that for us. The bottom half is then executed in a dedicated kernel
    thread. We do not use `request_irq()` anymore, but `request_threaded_irq()` :'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 线程化的IRQs的主要目标是将中断禁用的时间减少到最低限度。使用线程化的IRQs，注册中断处理程序的方式有些简化。你甚至不需要自己安排底半部分。核心会为我们做这件事。然后底半部分将在一个专用的内核线程中执行。我们不再使用`request_irq()`，而是使用`request_threaded_irq()`：
- en: '[PRE98]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'The `request_threaded_irq()` function accepts two functions in its parameters:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '`request_threaded_irq()`函数在其参数中接受两个函数：'
- en: '**@handler function** : This is the same function as the one registered with
    `request_irq()` . It represents the top-half function, which runs in an atomic
    context (or hard-IRQ). If it can process the interrupt faster so that you can
    get rid of the bottom half at all, it should return `IRQ_HANDLED` . But, if the
    interrupt processing needs more than 100 µs, as discussed previously, you should
    use the bottom half. In this case, it should return `IRQ_WAKE_THREAD` , which
    will result in scheduling the `thread_fn` function that must have been provided.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**@handler函数**：这与使用`request_irq()`注册的函数相同。它代表顶半部分函数，运行在原子上下文（或硬中断）中。如果它可以更快地处理中断，以至于你可以完全摆脱底半部分，它应该返回`IRQ_HANDLED`。但是，如果中断处理需要超过100微秒，如前面讨论的那样，你应该使用底半部分。在这种情况下，它应该返回`IRQ_WAKE_THREAD`，这将导致调度必须已经提供的`thread_fn`函数。'
- en: '**@thread_fn function** : This represents the bottom half, as you would have
    scheduled in your top half. When the hard-IRQ handler (handler function) function
    returns `IRQ_WAKE_THREAD` , the kthread associated with this bottom half will
    be scheduled, invoking the `thread_fn` function when it comes to run the ktread.
    The `thread_fn` function must return `IRQ_HANDLED` when complete. After being
    executed, the kthread will not be rescheduled again until the IRQ is triggered
    again and the hard-IRQ returns `IRQ_WAKE_THREAD` .'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**@thread_fn函数**：这代表了底半部分，就像你在顶半部分中安排的那样。当硬中断处理程序（处理函数）返回`IRQ_WAKE_THREAD`时，与该底半部分相关联的kthread将被调度，在运行ktread时调用`thread_fn`函数。`thread_fn`函数在完成时必须返回`IRQ_HANDLED`。执行完毕后，kthread将不会再次被调度，直到再次触发IRQ并且硬中断返回`IRQ_WAKE_THREAD`。'
- en: 'Everywhere that you would have used the work queue to schedule the bottom half,
    threaded IRQs can be used. `handler` and `thread_fn` must be defined in order
    to have a proper threaded IRQ. A default hard-IRQ handler will be installed by
    the kernel if `handler` is `NULL` and `thread_fn != NULL` (see the following),
    which will simply return `IRQ_WAKE_THREAD` to schedule the bottom half. `handler`
    is always called in an interrupt context, whether it has been provided by yourself
    or by the kernel by default:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何你会使用工作队列来安排底半部分的地方，都可以使用线程化的IRQs。必须定义`handler`和`thread_fn`以正确使用线程化的IRQ。如果`handler`为`NULL`且`thread_fn
    != NULL`（见下文），内核将安装默认的硬中断处理程序，它将简单地返回`IRQ_WAKE_THREAD`以安排底半部分。`handler`总是在中断上下文中调用，无论是由你自己提供还是默认情况下由内核提供的。
- en: '[PRE99]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: With threaded IRQs, the handler definition does not change, but the way it is
    registered changes a little bit.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程化的IRQs，处理程序的定义不会改变，但它的注册方式会有一点变化。
- en: '[PRE100]'
  id: totrans-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: Threaded bottom half
  id: totrans-436
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线程化的底半部分
- en: 'The simple following excerpt is a demonstration of how you can implement the
    threaded bottom half mechanism:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 以下简单的摘录演示了如何实现线程化的底半部分机制：
- en: '[PRE101]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: When an interrupt handler is executed, the serviced IRQ is always disabled on
    all CPUs, and re-enabled when the hard-IRQ (top-half) finishes. But if for any
    reason you need the IRQ line not to be re-enabled after the top half, and to remain
    disabled until the threaded handler has been run, you should request the threaded
    IRQ with the flag `IRQF_ONESHOT` enabled (by just doing an OR operation as shown
    previously). The IRQ line will then be re-enabled after the bottom half has finished.
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 当中断处理程序被执行时，所有 CPU 上的服务 IRQ 始终被禁用，并在硬件 IRQ（顶半部）完成时重新启用。但是，如果出于任何原因，您需要在顶半部完成后不重新启用
    IRQ 线，并且保持禁用直到线程处理程序运行完毕，您应该使用启用了 `IRQF_ONESHOT` 标志的线程 IRQ（只需像之前显示的那样执行 OR 操作）。然后
    IRQ 线将在底半部完成后重新启用。
- en: Invoking user-space applications from the kernel
  id: totrans-440
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从内核调用用户空间应用程序
- en: 'User-space applications are most of the time called from within the user space
    by other applications. Without going deep into the details, let''s see an example:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 用户空间应用程序大多数情况下是由其他应用程序从用户空间调用的。不深入细节，让我们看一个例子：
- en: '[PRE102]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: In the preceding example, the API used (`call_usermodehelper` ) is a part of
    the Usermode-helper API, with all functions defined in `kernel/kmod.c` . Its use
    is quite simple; just a look inside `kmod.c` will give you an idea. You may be
    wondering what this API was defined for. It is used by the kernel, for example,
    for module (un)loading and cgroups management.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，使用的 API（`call_usermodehelper`）是 Usermode-helper API 的一部分，所有函数都在 `kernel/kmod.c`
    中定义。它的使用非常简单；只需查看 `kmod.c` 就能给你一个想法。您可能想知道这个 API 是为什么定义的。例如，内核使用它进行模块（卸载）和 cgroups
    管理。
- en: Summary
  id: totrans-444
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed about the fundamental elements to start driver
    development, presenting every mechanism frequently used in drivers. This chapter
    is very important, since it discusses topics other chapters in this book rely
    on. The next chapter for example, dealing with character devices, will use some
    of elements discussed in this chapter.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了开始驱动程序开发的基本元素，介绍了驱动程序中经常使用的每种机制。本章非常重要，因为它涉及到本书其他章节依赖的主题。例如，下一章将处理字符设备，将使用本章讨论的一些元素。
