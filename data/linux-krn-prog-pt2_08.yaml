- en: Kernel Synchronization - Part 1
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 内核同步 - 第1部分
- en: As any developer familiar with programming in a multithreaded environment (or
    even a single-threaded one where multiple processes work on shared memory, or
    where interrupts are a possibility) is well aware, there is a need for **synchronization**
    whenever two or more threads (code paths in general) may race; that is, their
    outcome cannot be predicted. Pure code itself is never an issue as its permissions
    are read/execute (`r-x`); reading and executing code simultaneously on multiple CPU
    cores is not only perfectly fine and safe, but it's encouraged (it results in
    better throughput and is why multithreading is a good idea). However, the moment
    you're working on shared writeable data is the moment you need to start being
    very careful!
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 任何熟悉在多线程环境中编程的开发人员（甚至在多个进程共享内存或中断可能发生的单线程环境中）都知道，当两个或更多个线程（一般的代码路径）可能会竞争时，需要**同步**；也就是说，它们的结果是无法预测的。纯代码本身从来不是问题，因为它的权限是读/执行（`r-x`）；在多个CPU核心上同时读取和执行代码不仅完全正常和安全，而且是受鼓励的（它会提高吞吐量，这就是为什么多线程是一个好主意）。然而，当你开始处理共享可写数据时，你就需要开始非常小心了！
- en: The discussions around concurrency and its control – synchronization – are varied,
    especially in the context of a complex piece of software such as a Linux kernel
    (its subsystems and related regions, such as device drivers), which is what we're
    dealing with in this book. Thus, for convenience, we will split this large topic
    into two chapters, this one and the next.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 围绕并发性及其控制 - 同步 - 的讨论是多种多样的，特别是在像Linux内核这样的复杂软件环境中（其子系统和相关区域，如设备驱动程序），这也是我们在本书中要处理的。因此，为了方便起见，我们将把这个大主题分成两章，本章和下一章。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Critical sections, exclusive execution, and atomicity
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键部分、独占执行和原子性
- en: Concurrency concerns within the Linux kernel
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux内核中的并发性问题
- en: Mutex or spinlock? Which to use when
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互斥锁还是自旋锁？在什么情况下使用
- en: Using the mutex lock
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用互斥锁
- en: Using the spinlock
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用自旋锁
- en: Locking and interrupts
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁定和中断
- en: Let's get started!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Critical sections, exclusive execution, and atomicity
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关键部分、独占执行和原子性
- en: 'Imagine you''re writing software for a multicore system (well, nowadays, it''s
    typical that you will work on multicore systems, even on most embedded projects).
    As we mentioned in the introduction, running multiple code paths in parallel is
    not only safe, it''s desirable (why spend those dollars otherwise, right?). On
    the other hand, concurrent (parallel and simultaneous) code paths within which
    **shared writeable data** (also known as **shared state**) **is accessed** in
    any manner is where you are required to guarantee that, at any given point in
    time, only one thread can work on that data at a time! This is really key; why?
    Think about it: if you allow multiple concurrent code paths to work in parallel
    on shared writeable data, you''re literally asking for trouble: **data corruption**
    (a "race") can occur as a result.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你正在为一个多核系统编写软件（嗯，现在，通常情况下，你会在多核系统上工作，即使是在大多数嵌入式项目中）。正如我们在介绍中提到的，同时运行多个代码路径不仅是安全的，而且是可取的（否则，为什么要花那些钱呢，对吧？）。另一方面，在其中**共享可写数据**（也称为**共享状态**）**被访问**的并发（并行和同时）代码路径是需要你保证，在任何给定的时间点，只有一个线程可以同时处理该数据！这真的很关键；为什么？想想看：如果你允许多个并发代码路径在共享可写数据上并行工作，你实际上是在自找麻烦：**数据损坏**（"竞争"）可能会发生。
- en: What is a critical section?
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是关键部分？
- en: A code path that can execute in parallel and that works on (reads and/or writes)
    shared writeable data (shared state) is called a critical section. They require
    protection from parallelism. Identifying and protecting critical sections from
    simultaneous execution is an implicit requirement for correct software that you
    – the designer/architect/developer – must handle.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可以并行执行并且可以处理（读取和/或写入）共享可写数据（共享状态）的代码路径被称为关键部分。它们需要保护免受并行性的影响。识别和保护关键部分免受同时执行是你
    - 设计师/架构师/开发人员 - 必须处理的隐含要求，以确保正确的软件。
- en: A critical section is a piece of code that must run either exclusively; that
    is, alone (serialized), or atomically; that is, indivisibly, to completion, without
    interruption.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 关键部分是必须要么独占地运行；也就是说，单独运行（串行化），要么是原子地；也就是说，不可分割地，一直运行到完成，没有中断。
- en: By exclusively, we're implying that at any given point in time, one thread is
    running the code of the critical section; this is obviously required for data
    safety reasons.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通过“独占”，我们暗示在任何给定的时间点，一个线程正在运行关键部分的代码；这显然是出于数据安全的原因而需要的。
- en: 'This notion also brings up the important concept of *atomicity*: a single atomic
    operation is one that is indivisible. On any modern processor, two operations
    are considered to always be **atomic**; that is, they cannot be interrupted and
    will run to completion:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个概念也提出了*原子性*的重要概念：单个原子操作是不可分割的。在任何现代处理器上，两个操作被认为总是**原子的**；也就是说，它们不能被中断，并且会一直运行到完成：
- en: The execution of a single machine language instruction.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个机器语言指令的执行。
- en: Reads or writes to an aligned primitive data type that is within the processor's
    word size (typically 32 or 64 bits); for example, reading or writing a 64-bit integer
    on a 64-bit system is guaranteed to be atomic. Threads reading that variable will
    never see an in-between, torn, or dirty result; they will either see the old or
    the new value.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对齐的原始数据类型的读取或写入，它在处理器的字长（通常为32位或64位）内；例如，在64位系统上读取或写入64位整数是有保证的。读取该变量的线程永远不会看到中间、撕裂或脏的结果；它们要么看到旧值，要么看到新值。
- en: So, if you have some lines of code that work upon shared (global or static)
    writeable data, it cannot – in the absence of any explicit synchronization mechanism
    – be guaranteed to run exclusively. Note that at times, running the critical section's
    code *atomically, *as well as exclusively, is required, but not all the time.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果您有一些代码行处理共享（全局或静态）可写数据，那么在没有任何显式同步机制的情况下，不能保证其独占运行。请注意，有时需要以原子方式运行临界区的代码，以及独占运行，但并非始终如此。
- en: When the code of the critical section is running in a safe-to-sleep process
    context (such as typical file operations on a driver via a user app (open, read,
    write, ioctl, mmap, and so on), or the execution path of a kernel thread or workqueue),
    it might well be acceptable to not have the critical section being truly atomic.
    However, when its code is running in a non-blocking atomic context (such as a
    hardirq, tasklet, or softirq), *it must run atomically as well as exclusively*
    (we shall cover these points in more detail in the *Mutex or spinlock? Which to
    use when* section).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当临界区的代码在安全睡眠的进程上下文中运行时（例如通过用户应用程序对驱动程序进行典型文件操作（打开，读取，写入，ioctl，mmap等），或者内核线程或工作队列的执行路径），也许可以接受临界区不是真正原子的。但是，当其代码在非阻塞原子上下文中运行时（例如硬中断，tasklet或softirq），*它必须以原子方式运行以及独占运行*（我们将在*互斥锁还是自旋锁？何时使用*部分中更详细地讨论这些问题）。
- en: 'A conceptual example will help clarify things. Let''s say that three threads
    (from user space app(s)) attempt to open and read from your driver more or less
    simultaneously on a multicore system. Without any intervention, they may well
    end up running the critical section''s code in parallel, thus working on the shared
    writable data in parallel, thus very likely corrupting it! For now, let''s look
    at a conceptual diagram to see how non-exclusive execution within a critical section''s
    code path is wrong (we won''t even talk about atomicity here):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个概念性的例子将有助于澄清事情。假设三个线程（来自用户空间应用程序）在多核系统上几乎同时尝试打开并从您的驱动程序读取。在没有任何干预的情况下，它们可能会并行运行临界区的代码，从而并行地处理共享可写数据，从而很可能损坏它！现在，让我们看一个概念图示，看看临界区代码路径内的非独占执行是错误的（我们甚至不会在这里谈论原子性）：
- en: '![](img/4daabc10-0ddf-4879-96c2-49eeb6aa96e3.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4daabc10-0ddf-4879-96c2-49eeb6aa96e3.png)'
- en: Figure 6.1 – A conceptual diagram showing how a critical section code path is
    violated by having >1 thread running within it simultaneously
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.1 - 一个概念图示，显示了临界区代码路径如何被同时运行的多个线程违反
- en: 'As shown in the preceding diagram, in your device driver, within its (say)
    read method, you''re having it run some code in order to perform its job (reading
    some data from the hardware). Let''s take a more in-depth look at this diagram *in
    terms of data accesses being made* at different points in time:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，在您的设备驱动程序中，在其（比如）读取方法中，您正在运行一些代码以执行其工作（从硬件中读取一些数据）。让我们更深入地看一下这个图示*在不同时间点进行的数据访问*：
- en: 'From time `t0` to `t1`: None or only local variable data is accessed. This
    is concurrent-safe, with no protection required, and can run in parallel (since
    each thread has its own private stack).'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从时间`t0`到`t1`：没有或只有本地变量数据被访问。这是并发安全的，不需要保护，并且可以并行运行（因为每个线程都有自己的私有堆栈）。
- en: 'From time `t1` to `t2`: Global/static shared writeable data is accessed. This
    is *not *concurrent-safe; it''s **a critical section** and thus must be **protected**
    from concurrent access. It should only contain code that runs exclusively (alone,
    exactly one thread at a time, serialized) and, perhaps, atomically.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从时间`t1`到`t2`：访问全局/静态共享可写数据。这是*不*并发安全的；它是**临界区**，因此必须受到**保护**，以免并发访问。它应该只包含以独占方式运行的代码（独自，每次只有一个线程，串行），也许还是原子的。
- en: 'From time `t2` to `t3`: None or only local variable data is accessed. This
    is concurrent-safe, with no protection required, and can run in parallel (since
    each thread has its own private stack).'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从时间`t2`到`t3`：没有或只有本地变量数据被访问。这是并发安全的，不需要保护，并且可以并行运行（因为每个线程都有自己的私有堆栈）。
- en: In this book, we assume that you are already aware of the need to synchronize
    critical sections; we will not discuss this particular topic any further. Those
    of you who are interested may refer to my earlier book, *Hands-On System Programming
    with Linux (Packt, October 2018)*, which covers these points in detail (especially
    *Chapter 15*, *Multithreading with Pthreads Part II – Synchronization*).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们假设您已经意识到需要同步临界区；我们将不再讨论这个特定的主题。有兴趣的人可以参考我早期的书，*Linux系统编程实战（Packt，2018年10月）*，其中详细介绍了这些问题（特别是*第15章*，*使用Pthreads进行多线程编程第二部分-同步*）。
- en: 'So, knowing this, we can now restate the notion of a critical section while
    also mentioning when the situation arises (shown in square brackets and italics
    in the bullet points). A critical section is code that must run as follows:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，了解这一点，我们现在可以重新阐述临界区的概念，同时提到情况何时出现（在项目符号和斜体中显示在项目符号中）。临界区是必须按以下方式运行的代码：
- en: '**(Always) Exclusively**: Alone (serialized)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （始终）*独占地*：独自（串行）
- en: '**(When in an atomic context) Atomically**: Indivisibly, to completion, without
    interruption'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （在原子上下文中）*原子地*：不可分割地，完整地，没有中断
- en: In the next section, we'll look at a classic scenario – the increment of a global
    integer.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将看一个经典的场景 - 全局整数的增量。
- en: A classic case – the global i ++
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个经典的例子 - 全局i ++
- en: 'Think of this classic example: a global `i` integer is being incremented within
    a concurrent code path, one within which multiple threads of execution can simultaneously
    execute. A naive understanding of computer hardware and software will lead you
    to believe that this operation is obviously atomic. However, the reality is that
    modern hardware and software (the compiler and OS) are much more sophisticated
    than you may imagine, thus causing all kinds of invisible (to the app developer)
    performance-driven optimizations.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下这个经典的例子：在并发代码路径中递增一个全局整数`i`，其中多个执行线程可以同时执行。对计算机硬件和软件的天真理解会让您相信这个操作显然是原子的。然而，现实是，现代硬件和软件（编译器和操作系统）要比您想象的复杂得多，因此会引起各种看不见的（对应用程序开发人员来说）性能驱动的优化。
- en: 'We won''t attempt to delve into too much detail here, but the reality is that
    modern processors are extremely complex: among the many technologies they employ
    toward better performance, a few are superscalar and super-pipelined execution
    in order to execute multiple independent instructions and several parts of various
    instructions in parallel (respectively), performing on-the-fly instruction and/or
    memory reordering, caching memory in complex hierarchical on-CPU caches, false
    sharing, and so on! We will delve into some of these details in [Chapter 7](14cf1232-dfd5-428a-9c0b-30bcd84651b9.xhtml),
    *Kernel Synchronization – Part 2*, in the *Cache effects – false sharing* and
    *Memory barriers* sections.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会在这里深入讨论太多细节，但现实是，现代处理器非常复杂：它们采用许多技术来提高性能，其中一些是超标量和超流水线执行，以便并行执行多个独立指令和各种指令的几个部分（分别），进行即时指令和/或内存重排序，在复杂的CPU缓存中缓存内存，虚假共享等等！我们将在[第7章](14cf1232-dfd5-428a-9c0b-30bcd84651b9.xhtml)中的*内核同步-第2部分*中的*缓存效应-虚假共享*和*内存屏障*部分中深入探讨其中的一些细节。
- en: The paper *What every systems programmer should know about concurrency* by *Matt
    Kline, April 2020*, ([https://assets.bitbashing.io/papers/concurrency-primer.pdf](https://assets.bitbashing.io/papers/concurrency-primer.pdf))
    is superb and a must-read on this subject; do read it!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Matt Kline于2020年4月撰写的论文*《每个系统程序员都应该了解的并发知识》*（[https://assets.bitbashing.io/papers/concurrency-primer.pdf](https://assets.bitbashing.io/papers/concurrency-primer.pdf)）非常出色，是这个主题上的必读之作；一定要阅读！
- en: 'All of this makes for a situation that''s more complex than it appears to be
    at first glance. Let''s continue with the classic `i ++`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些使得情况比起初看起来更加复杂。让我们继续讨论经典的`i ++`：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Is this increment safe by itself? The short answer is no, you must protect
    it. Why? It''s a critical section – we''re accessing shared writeable data for
    a read and/or write operation. The longer answer is that it really depends on
    whether the increment operation is truly atomic (indivisible); if it is, then
    `i ++` poses no danger in the presence of parallelism – if not, it does! So, how
    do we know whether `i ++` is truly atomic or not? Two things determine this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个递增本身安全吗？简短的答案是否定的，您必须保护它。为什么？这是一个关键部分——我们正在访问共享的可写数据进行读取和/或写入操作。更长的答案是，这实际上取决于递增操作是否真正是原子的（不可分割的）；如果是，那么`i
    ++`在并行性的情况下不会造成危险——如果不是，就会有危险！那么，我们如何知道`i ++`是否真正是原子的呢？有两件事决定了这一点：
- en: The processor's **Instruction Set Architecture** (**ISA**), which determines
    (among several things related to the processor at a low level) the machine instructions
    that execute at runtime.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理器的**指令集架构**（ISA），它决定了（与处理器低级相关的几件事情之一）在运行时执行的机器指令。
- en: The compiler.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编译器。
- en: If the ISA has the facility to employ a single machine instruction to perform
    an integer increment, *and* the compiler has the intelligence to use it, *then *it's
    truly atomic – it's safe and doesn't require locking. Otherwise, it's not safe
    and requires locking!
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果ISA具有使用单个机器指令执行整数递增的功能，并且编译器具有使用它的智能，那么它就是真正原子的——它是安全的，不需要锁定。否则，它是不安全的，需要锁定！
- en: '**Try this out**: Navigate your browser to this wonderful compiler explorer
    website: [https://godbolt.org/](https://godbolt.org/). Select C as the programming
    language and then, in the left pane, declare the global `i` integer and increment
    within a function. Compile in the right pane with an appropriate compiler and
    compiler options. You''ll see the actual machine code generated for the C high-level `i
    ++;` statement. If it''s indeed a single machine instruction, then it will be
    safe; if not, you will require locking. By and large, you will find that you can''t
    really tell: in effect, you *cannot *afford to assume things – you will have to
    assume it''s unsafe by default and protect it! This can be seen in the following
    screenshot:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试一下：将浏览器导航到这个精彩的编译器探索网站：[https://godbolt.org/](https://godbolt.org/)。选择C作为编程语言，然后在左侧窗格中声明全局整数`i`并在函数内递增。在右侧窗格中使用适当的编译器和编译器选项进行编译。您将看到为C高级`i
    ++;`语句生成的实际机器代码。如果确实是单个机器指令，那么它将是安全的；如果不是，您将需要锁定。总的来说，您会发现您实际上无法判断：实际上，您*不能*假设事情——您将不得不默认假设它是不安全的并加以保护！这可以在以下截图中看到：
- en: '![](img/a6f1659c-346b-40c8-b5e0-f0e4033381ef.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a6f1659c-346b-40c8-b5e0-f0e4033381ef.png)'
- en: Figure 6.2 – Even with the latest stable gcc version but no optimization, the
    x86_64 gcc produces multiple instructions for the i ++
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.2——即使是最新的稳定gcc版本，但没有优化，x86_64 gcc为i ++生成了多个指令
- en: 'The preceding screenshot clearly shows this: the yellow background regions
    in the left- and right-hand panes is the C source and the corresponding assembly
    generated by the compiler, respectively (based on the x86_64 ISA and the compiler''s
    optimization level). By default, with no optimization, `i ++` becomes three machine
    instructions. This is exactly what we expect: it corresponds to the *fetch* (memory
    to register), the *increment*, and the *store* (register to memory)! Now, this
    is *not *atomic; it''s entirely possible that, after one of the machine instructions
    executes, the control unit interferes and switches the instruction stream to a
    different point. This could even result in another process or thread being context
    switched in!'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的截图清楚地显示了这一点：左右两个窗格中的黄色背景区域分别是C源代码和编译器生成的相应汇编代码（基于x86_64 ISA和编译器的优化级别）。默认情况下，没有优化，`i
    ++`变成了三条机器指令。这正是我们所期望的：它对应于*获取*（内存到寄存器）、*增量*和*存储*（寄存器到内存）！现在，这*不是*原子的；完全有可能，在其中一条机器指令执行后，控制单元干扰并将指令流切换到不同的位置。这甚至可能导致另一个进程或线程被上下文切换！
- en: The good news is that with a quick `-O2` in the `Compiler options...` window,
    `i ++` becomes just one machine instruction – truly atomic! However, we can't
    predict these things in advance; one day, your code may execute on a fairly low-end
    ARM (RISC) system, increasing the chance that multiple machine instructions are
    required for `i ++`. (Worry not – we shall cover an optimized locking technology
    specifically for integers in the *Using the atomic integer operators* section).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，通过在`编译器选项...`窗口中快速加上`-O2`，`i ++`就变成了一条机器指令 - 真正的原子操作！然而，我们无法预测这些事情；有一天，你的代码可能会在一个相当低端的ARM（RISC）系统上执行，增加了`i
    ++`需要多条机器指令的可能性。（不用担心 - 我们将在*使用原子整数操作符*部分专门介绍针对整数的优化锁技术）。
- en: Modern languages provide native atomic operators; for C/C++, it's fairly recent
    (from 2011); the ISO C++11 and the ISO C11 standards provide ready-made and built-in
    atomic variables for this. A little googling will quickly reveal them to you.
    Modern glibc also makes use of them. As an example, if you've worked with signaling
    in user space, you will know to use the `volatile sig_atomic_t` data type to safely access
    and/or update an atomic integer within signal handlers. What about the kernel?
    In the next chapter, you'll learn about the Linux kernel's solution to this key
    issue. We'll cover this in the *Using the atomic integer operators* and *Using
    the atomic bit operators* sections.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现代语言提供了本地原子操作符；对于C/C++来说，这是相当近期的（从2011年起）；ISO C++11和ISO C11标准提供了现成的和内置的原子变量。稍微搜索一下就可以快速找到它们。现代的glibc也在使用它们。举个例子，如果你在用户空间使用信号，你会知道要使用`volatile
    sig_atomic_t`数据类型来安全地访问和/或更新信号处理程序中的原子整数。那么内核呢？在下一章中，你将了解Linux内核对这个关键问题的解决方案。我们将在*使用原子整数操作符*和*使用原子位操作符*部分进行介绍。
- en: 'The Linux kernel is, of course, a concurrent environment: multiple threads
    of execution run in parallel on multiple CPU cores. Not only that, but even on uni-processor
    (UP/single CPU) systems, the presence of hardware interrupts, traps, faults, exceptions,
    and software signals can cause data integrity issues. Needless to say, protecting
    against concurrency at required points in the code path is easier said than done;
    identifying and protecting critical sections using technologies such as locking
    – as well as other synchronization primitives and technologies – is absolutely
    essential, which is why this is the core subject matter of this chapter and the
    next.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核当然是一个并发环境：多个执行线程在多个CPU核心上并行运行。不仅如此，即使在单处理器（UP/单CPU）系统上，硬件中断、陷阱、故障、异常和软件信号的存在也可能导致数据完整性问题。毋庸置疑，保护代码路径中必要的并发性是易说难做的；识别和保护关键部分使用诸如锁等技术的同步原语和技术是绝对必要的，这也是为什么这是本章和下一章的核心主题。
- en: Concepts – the lock
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概念 - 锁
- en: We require synchronization because of the fact that, without any intervention,
    threads can concurrently execute critical sections where shared writeable data
    (shared state)is being worked upon. To defeat concurrency, we need to get rid
    of parallelism, and we need to *serialize *code that's within the critical section
    – the place where the shared data is being worked upon (for reading and/or writing).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要同步是因为，没有任何干预，线程可以同时执行关键部分，其中共享可写数据（共享状态）正在被处理。为了打败并发性，我们需要摆脱并行性，我们需要*串行化*关键部分内的代码
    - 共享数据正在被处理的地方（用于读取和/或写入）。
- en: 'To force a code path to become serialized, a common technique is to use a **lock**.
    Essentially, a lock works by guaranteeing that precisely one thread of execution
    can "take" or own the lock at any given point in time. Thus, using a lock to protect
    a critical section in your code will give you what we''re after – running the
    critical section''s code exclusively (and perhaps atomically; more on this to
    come):'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了强制一个代码路径变成串行化，一个常见的技术是使用**锁**。基本上，锁通过保证在任何给定时间点上只有一个执行线程可以“获取”或拥有锁来工作。因此，在代码中使用锁来保护关键部分将给我们想要的东西
    - 专门运行关键部分的代码（也许是原子的；更多内容即将到来）：
- en: '![](img/5ccf6307-e970-4b7f-bcaa-566fb4acfb80.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ccf6307-e970-4b7f-bcaa-566fb4acfb80.png)'
- en: Figure 6.3 – A conceptual diagram showing how a critical section code path is
    honored, given exclusivity, by using a lock
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.3 - 一个概念图示，展示了如何使用锁来保证关键部分代码路径的独占性
- en: 'The preceding diagram shows one way to fix the situation mentioned previously:
    using a lock to protect the critical section! How does the lock (and unlock) work,
    conceptually?'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图示展示了解决前面提到的情况的一种方法：使用锁来保护关键部分！锁（和解锁）在概念上是如何工作的呢？
- en: The basic premise of a lock is that whenever there is contention for it – that
    is, when multiple competing threads (say, `n` threads) attempt to acquire the
    lock (the `LOCK` operation) – exactly one thread will succeed. This is called
    the "winner" or the "owner" of the lock. It sees the *lock* API as a non-blocking
    call and thus continues to run happily – and exclusively – while executing the
    code of the critical section (the critical section is effectively the code between
    the *lock* and the *unlock* operations!). What happens to the `n-1` "loser" threads?
    They (perhaps) see the lock API as a blocking call; they, to all practical effect,
    wait. Wait upon what? The *unlock* operation, of course, which is performed by
    the owner of the lock (the "winner" thread)! Once unlocked, the remaining `n-1`
    threads now compete for the next "winner" slot; of course, exactly one of them
    will "win" and proceed forward; in the interim, the `n-2` losers will now wait
    upon the (new) winner's *unlock*; this repeats until all `n` threads (finally
    and sequentially) acquire the lock.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 锁的基本前提是，每当有争用时（即多个竞争线程（比如`n`个线程）尝试获取锁（`LOCK`操作）时），只有一个线程会成功。这被称为锁的“赢家”或“所有者”。它将*lock*
    API视为非阻塞调用，因此在执行关键部分的代码时会继续运行 - 并且是独占的（关键部分实际上是*lock*和*unlock*操作之间的代码！）。那么剩下的`n-1`个“失败者”线程会发生什么呢？它们（也许）会将锁API视为阻塞调用；它们实际上会等待。等待什么？当然是锁的*unlock*操作，这是由锁的所有者（“赢家”线程）执行的！一旦解锁，剩下的`n-1`个线程现在会竞争下一个“赢家”位置；当然，它们中的一个会“赢”并继续前进；在此期间，`n-2`个失败者现在会等待（新的）赢家的*unlock*；这种情况会重复，直到所有`n`个线程（最终和顺序地）获取锁。
- en: 'Now, locking works of course, but – and this should be quite intuitive – it results
    in (pretty steep!) **overhead, as it defeats parallelism and serializes** the
    execution flow! To help you visualize this situation, think of a funnel, with
    the narrow stem being the critical section where only one thread can fit at a
    time. All other threads get choked; locking creates bottlenecks:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，锁定是有效的，但 - 这应该是相当直观的 - 它会导致（相当大的！）**开销，因为它破坏了并行性并串行化了**执行流！为了帮助您可视化这种情况，想象一个漏斗，狭窄的部分是只有一个线程可以一次进入的关键部分。所有其他线程都会被堵住；锁定会创建瓶颈：
- en: '![](img/4f476235-4b35-4d76-8d49-694b0095c1be.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4f476235-4b35-4d76-8d49-694b0095c1be.png)'
- en: Figure 6.4 – A lock creates a bottleneck, analogous to a physical funnel
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.4 - 锁创建了一个瓶颈，类似于一个物理漏斗
- en: Another oft-mentioned physical analog is a highway with several lanes merging
    into one very busy – and choked with traffic – lane (a poorly designed toll booth,
    perhaps). Again, parallelism – cars (threads) driving in parallel with other cars
    in different lanes (CPUs) – is lost, and serialized behavior is required – cars
    are forced to queue one behind the other.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个经常提到的物理类比是一条高速公路，有几条车道汇入一条非常繁忙 - 交通拥挤 - 的车道（也许是一个设计不佳的收费站）。同样，并行性 - 车辆（线程）在不同车道上与其他车辆并行行驶（CPU）
    - 丢失，并且需要串行行为 - 车辆被迫排队排队。
- en: Thus, it is imperative that we, as software architects, try and design our products/projects
    so that locking is minimally required. While completely eliminating global variables
    is not practically possible in most real-world projects, optimizing and minimizing
    their usage is required. We shall cover more regarding this, including some very
    interesting lockless programming techniques, later.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，作为软件架构师，我们必须努力设计我们的产品/项目，以尽量减少对锁的需求。虽然在大多数实际项目中完全消除全局变量是不可行的，但优化和最小化它们的使用是必需的。我们将在以后更详细地介绍这一点，包括一些非常有趣的无锁编程技术。
- en: Another really key point is that a newbie programmer might naively assume that
    performing reads on a shared writeable data object is perfectly safe and thus
    requires no explicit protection (with the exception of an aligned primitive data
    type that is within the size of the processor's bus); this is untrue. This situation
    can lead to what's called **dirty or torn reads**, a situation where possibly
    stale data can be read as another writer thread is simultaneously writing while
    you are – incorrectly, without locking – reading the very same data item.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常关键的点是，新手程序员可能天真地认为在共享可写数据对象上执行读取是完全安全的，因此不需要显式保护（除了在处理器总线大小范围内的对齐原始数据类型的情况下）；这是不正确的。这种情况可能导致所谓的**脏读或破碎读**，即在另一个写入线程同时写入时可能读取到过时的数据，而你在没有锁定的情况下错误地读取了相同的数据项。
- en: Since we're on the topic of atomicity, as we just learned, on a typical modern
    microprocessor, the only things guaranteed to be atomic are a single machine language
    instruction or a read/write to an aligned primitive data type within the processor
    bus's width. So, how can we mark a few lines of "C" code so that they're truly
    atomic? In user space, this isn't even possible (we can come close, but cannot
    guarantee atomicity).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们谈到了原子性，正如我们刚刚了解的那样，在典型的现代微处理器上，唯一保证原子性的是单个机器语言指令或者在处理器总线宽度内对齐的原始数据类型的读/写。那么，我们如何标记几行“C”代码，使其真正原子化呢？在用户空间中，这甚至是不可能的（我们可以接近，但无法保证原子性）。
- en: How do you "come close" to atomicity in user space apps? You can always construct
    a user thread to employ a `SCHED_FIFO` policy and a real-time priority of `99`.
    This way, when it wants to run, pretty much nothing besides hardware interrupts/exceptions
    can preempt it. (The old audio subsystem implementation heavily relied on this.)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户空间应用程序中如何“接近”原子性？您可以始终构建一个用户线程来使用`SCHED_FIFO`策略和实时优先级为`99`。这样，当它想要运行时，除了硬件中断/异常之外，几乎没有其他东西可以抢占它。（旧的音频子系统实现在很大程度上依赖于此。）
- en: In kernel space, we can write code that's truly atomic. How, exactly? The short
    answer is that we can use spinlocks! We'll learn about spinlocks in more detail
    shortly.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在内核空间中，我们可以编写真正原子的代码。怎么做呢？简短的答案是，我们可以使用自旋锁！我们很快将更详细地了解自旋锁。
- en: A summary of key points
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 关键点总结
- en: 'Let''s summarize some key points regarding critical sections. It''s really
    important to go over these carefully, keep these handy, and ensure you use them
    in practice:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们总结一些关于临界区的关键点。仔细审查这些内容非常重要，保持这些内容方便，并确保在实践中使用它们：
- en: A **critical section** is a code path that can execute in parallel and that
    works upon (reads and/or writes) shared writeable data (also known as "shared
    state").
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**临界区**是一个可以并行执行并且可以操作（读和/或写）共享可写数据（也称为“共享状态”）的代码路径。'
- en: 'Because it works on shared writable data, the critical section requires protection
    from the following:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于它处理共享可写数据，临界区需要保护免受以下影响：
- en: Parallelism (that is, it must run alone/serialized/in a mutually exclusive fashion)
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并行性（也就是说，它必须单独运行/串行运行/以互斥的方式运行）
- en: When running in an atomic (interrupt) non-blocking context – atomically: indivisibly,
    to completion, without interruption. Once protected, you can safely access your
    shared state until you "unlock".
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在原子（中断）非阻塞上下文中运行 - 原子地：不可分割地，完全地，没有中断。一旦受保护，你可以安全地访问你的共享状态，直到“解锁”。
- en: 'Every critical section in the code base must be identified and protected:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代码库中的每个临界区都必须被识别和保护：
- en: Identifying critical sections is critical! Carefully review your code and make
    sure you don't miss them.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别临界区至关重要！仔细审查你的代码，确保你没有漏掉它们。
- en: Protecting them can be achieved via various technologies; one very common technique
    is *locking* (there's also lock-free programming, which we'll look at in the next
    chapter).
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过各种技术来保护它们；一个非常常见的技术是*锁定*（还有无锁编程，我们将在下一章中看到）。
- en: A common mistake is only protecting critical sections that *write* to global writeable
    data; you must also protect critical sections that *read* global writeable data;
    otherwise, you risk a **torn or dirty read! **To help make this key point clear,
    visualize an unsigned 64-bit data item being read and written on a 32-bit system;
    in such a case, the operation can't be atomic (two load/store operations are required).
    Thus, what if, while you're reading the value of the data item in one thread,
    it's being simultaneously written to by another thread!? The writer thread takes
    a "lock" of some sort but because you thought reading is safe, the lock isn't
    taken by the reader thread; due to an unfortunate timing coincidence, you can
    end up performing a partial/torn/dirty read! We will learn how to overcome these
    issues by using various techniques in the coming sections and the next chapter.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个常见的错误是只保护对全局可写数据的*写*的临界区；你还必须保护对全局可写数据的*读*的临界区；否则，你会面临**破碎或脏读！**为了帮助澄清这一关键点，想象一下在32位系统上读取和写入无符号64位数据项；在这种情况下，操作不能是原子的（需要两次加载/存储操作）。因此，如果在一个线程中读取数据项的值的同时，另一个线程正在同时写入它，会怎么样！？写入线程以某种方式“锁定”，但因为你认为读取是安全的，读取线程没有获取锁；由于不幸的时间巧合，你最终可能会执行部分/破碎/脏读！我们将在接下来的章节和下一章中学习如何通过使用各种技术来克服这些问题。
- en: Another deadly mistake is not using the same lock to protect a given data item.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个致命的错误是不使用相同的锁来保护给定的数据项。
- en: Failing to protect critical sections leads to a **data race**, a situation where
    the outcome – the actual value of the data being read/written – is "racy", which
    means it varies, depending on runtime circumstances and timing. This is known
    as a bug. (A bug that, once in "the field", is extremely difficult to see, reproduce,
    determine its root cause, and fix. We will cover some very powerful stuff to help
    you with this in the next chapter, in the *Lock debugging within the kernel *section;
    be sure to read it!)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 未保护临界区会导致**数据竞争**，即实际值的结果 - 被读/写的数据的实际值 - 是“竞争的”，这意味着它会根据运行时环境和时间而变化。这被称为一个bug。（一旦在“现场”中，这是极其难以看到、重现、确定其根本原因和修复的bug。我们将在下一章中涵盖一些非常强大的内容，以帮助你解决这个问题，在*内核中的锁调试*部分；一定要阅读！）
- en: '**Exceptions**: You are safe (implicitly, without explicit protection) in the
    following situations:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**例外**：在以下情况下，你是安全的（隐式地，没有显式保护）：'
- en: When you are working on local variables. They're allocated on the private stack
    of the thread (or, in the interrupt context, on the local IRQ stack) and are thus,
    by definition, safe.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你在处理局部变量时。它们分配在线程的私有堆栈上（或者，在中断上下文中，分配在本地IRQ堆栈上），因此，根据定义，是安全的。
- en: When you are working on shared writeable data in code that cannot possibly run
    in another context; that is, it's serialized by nature. In our context, the *init *and *cleanup *methods
    of an LKM qualify (they run exactly once, serially, on `insmod` and `rmmod` only).
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你在代码中处理共享可写数据时，这段代码不可能在另一个上下文中运行；也就是说，它是串行化的。在我们的情况下，LKM的*init*和*cleanup*方法符合条件（它们仅在`insmod`和`rmmod`上一次串行运行）。
- en: When you are working on shared data that is truly constant and read-only (don't
    let C's `const` keyword fool you, though!).
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你在处理真正常量和只读的共享数据时（不要让C的`const`关键字误导你）。
- en: Locking is inherently complex; you must carefully think, design, and implement
    this to avoid *deadlocks. *We'll cover this in more detail in the *Locking guidelines
    and deadlocks* section.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁定本质上是复杂的；你必须仔细思考、设计和实现，以避免*死锁*。我们将在*锁定指南和死锁*部分中更详细地介绍这一点。
- en: Concurrency concerns within the Linux kernel
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Linux内核中的并发性问题
- en: 'Recognizing critical sections within a piece of kernel code is of critical
    importance; how can you protect it if you can''t even see it? The following are
    a few guidelines to help you, as a budding kernel/driver developer, recognize
    where concurrency concerns – and thus critical sections – may arise:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在内核代码中识别临界区至关重要；如果你甚至看不到它，你怎么保护它呢？以下是一些建议，可以帮助你作为一个新手内核/驱动程序开发人员，识别并发性问题的地方
    - 因此可能出现临界区的地方：
- en: The presence of **Symmetric Multi-Processor** (**SMP**) systems (`CONFIG_SMP`)
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对称多处理器**（**SMP**）系统的存在（`CONFIG_SMP`）'
- en: The presence of a preemptible kernel
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可抢占内核的存在
- en: Blocking I/O
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻塞I/O
- en: Hardware interrupts (on either SMP or UP systems)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件中断（在SMP或UP系统上）
- en: These are critical points to understand, and we will discuss each in this section.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是需要理解的关键点，我们将在本节中讨论每一个。
- en: Multicore SMP systems and data races
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多核SMP系统和数据竞争
- en: 'The first point is pretty obvious; take a look at the pseudocode shown in the
    following screenshot:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个点是非常明显的；看一下以下截图中显示的伪代码：
- en: '![](img/79357d73-c814-478c-b463-1951621f15e2.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79357d73-c814-478c-b463-1951621f15e2.png)'
- en: Figure 6.5 – Pseudocode – a critical section within a (fictional) driver's read
    method; it's wrong as there's no locking
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.5 - 伪代码 - 在（虚构的）驱动程序读取方法中的一个关键部分；由于没有锁定，这是错误的
- en: It's a similar situation to what we showed in *Figures 6.1* and 6*.3*; it's
    just that here, we're showing the concurrency in terms of pseudocode. Clearly, from
    time `t2` to time `t3`, the driver is working on some global shared writeable
    data, thus making this a critical section.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们在*图6.1*和*6.3*中展示的情况类似；只是这里，我们用伪代码来展示并发。显然，从时间`t2`到时间`t3`，驱动程序正在处理一些全局共享的可写数据，因此这是一个关键部分。
- en: Now, visualize a system with, say, four CPU cores (an SMP system); two user
    space processes, P1 (running on, say, CPU 0) and P2 (running on, say, CPU 2),
    can concurrently open the device file and simultaneously issue a `read(2)` system
    call. Now, both processes will be concurrently executing the driver read "method",
    thus simultaneously working on shared writeable data! This (the code between `t2`
    and `t3`) is a critical section, and since we are in violation of the fundamental
    exclusivity rule – critical sections must be executed by only a single thread
    at any point in time – we can very well end up corrupting the data, the application,
    or worse.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，想象一个具有四个CPU核心（SMP系统）的系统；两个用户空间进程，P1（运行在CPU 0上）和P2（运行在CPU 2上），可以同时打开设备文件并同时发出`read(2)`系统调用。现在，两个进程将同时执行驱动程序的读取“方法”，因此同时处理共享的可写数据！这（在`t2`和`t3`之间的代码）是一个关键部分，由于我们违反了基本的排他性规则
    - 关键部分必须由单个线程在任何时间点执行 - 我们很可能会破坏数据、应用程序，甚至更糟。
- en: In other words, this is now a **data race**; depending on delicate timing coincidences,
    we may or may not generate an error (a bug). This very uncertainty – the delicate
    timing coincidence – is what makes finding and fixing errors like this extremely difficult
    (it can escape your testing effort).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，这现在是一个**数据竞争**；取决于微妙的时间巧合，我们可能会或可能不会产生错误（bug）。这种不确定性 - 微妙的时间巧合 - 正是使得像这样找到和修复错误变得极其困难的原因（它可能逃脱了您的测试努力）。
- en: 'This aphorism is all too unfortunately true: *Testing can detect the presence
    of errors, not their absence. *Adding to this, you''re worse off if your testing
    fails to catch races (and bugs), allowing them free rein in the field.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这句格言太不幸地是真的：*测试可以检测到错误的存在，但不能检测到它们的缺失。*更糟糕的是，如果您的测试未能捕捉到竞争（和错误），那么它们将在现场自由发挥。
- en: 'You might feel that since your product is a small embedded system running on one
    CPU core (UP), this discussion regarding controlling concurrency (often, via locking)
    does not apply to you. We beg to differ: pretty much all modern products, if they
    haven''t already, will move to multicore (in their next-generation phases, perhaps).
    More importantly, even UP systems have concurrency concerns, as we shall explore.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会觉得，由于您的产品是运行在单个CPU核心（UP）上的小型嵌入式系统，因此关于控制并发性（通常通过锁定）的讨论对您不适用。我们不这么认为：几乎所有现代产品，如果尚未，都将转向多核（也许是在它们的下一代阶段）。更重要的是，即使是UP系统也存在并发性问题，我们将在接下来的部分中探讨。
- en: Preemptible kernels, blocking I/O, and data races
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可抢占内核，阻塞I/O和数据竞争
- en: Imagine you're running your kernel module or driver on a Linux kernel that's
    been configured to be preemptible (that is, `CONFIG_PREEMPT` is on; we covered
    this topic in the companion guide *Linux Kernel Programming,* *Chapter 10*, *The
    CPU Scheduler – Part 1*). Consider that a process, P1, is running the driver's
    read method code in the process context, working on the global array. Now, while
    it's within the critical section (between time `t2` and `t3`), what if the kernel *preempts*
    process P1 and context switches to another process, P2, which is just waiting
    to execute this very code path? It's dangerous, and again, a data race. This could
    well happen on even a UP system!
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，您正在运行配置为可抢占的Linux内核的内核模块或驱动程序（即`CONFIG_PREEMPT`已打开；我们在配套指南*Linux内核编程*的*第10章*
    *CPU调度器-第1部分*中涵盖了这个主题）。考虑一个进程P1，在进程上下文中运行驱动程序的读取方法代码，正在处理全局数组。现在，在关键部分内（在时间`t2`和`t3`之间），如果内核*抢占*了进程P1并上下文切换到另一个进程P2，后者正好在等待执行这个代码路径？这是危险的，同样是数据竞争。这甚至可能发生在UP系统上！
- en: 'Another scenario that''s somewhat similar (and again, could occur on either
    a single core (UP) or multicore system): process P1 is running through the critical
    section of the driver method (between time `t2` and `t3;` again, see *Figure 6.5*).
    This time, what if, within the critical section, it hits a blocking call?'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个有些类似的情景（同样，可能发生在单核（UP）或多核系统上）：进程P1正在通过驱动程序方法的关键部分运行（在时间`t2`和`t3`之间；再次参见*图6.5*）。这一次，如果在关键部分中遇到了阻塞调用呢？
- en: A **blocking call** is a function that causes the calling process context to
    be put to sleep, waiting upon an event; when that event occurs, the kernel will
    "wake up" the task, and it will resume execution from where it left off. This
    is also known as blocking on I/O and is very common; many APIs (including several
    user space library and system calls, as well as several kernel APIs, are blocking
    by nature). In such a case, process P1 is effectively context switches off the
    CPU and goes to sleep, which means that the code of `schedule()` runs and enqueues
    it onto a wait queue.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**阻塞调用**是一个导致调用进程上下文进入休眠状态，等待事件发生的函数；当事件发生时，内核将“唤醒”任务，并从上次中断的地方恢复执行。这也被称为I/O阻塞，非常常见；许多API（包括几个用户空间库和系统调用，以及几个内核API）天生就是阻塞的。在这种情况下，进程P1实际上是从CPU上上下文切换并进入休眠状态，这意味着`schedule()`的代码运行并将其排队到等待队列。'
- en: In the interim, before P1 gets switched back, what if another process, P2, is
    scheduled to run? What if that process is also running this particular code path?
    Think about it – by the time P1 is back, the shared data could have changed "underneath
    it", causing all kinds of errors; again, a data race, a bug!
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在P1被切换回来之前，如果另一个进程P2被调度运行怎么办？如果该进程也在运行这个特定的代码路径怎么办？想一想-当P1回来时，共享数据可能已经在“它下面”发生了变化，导致各种错误；再次，数据竞争，一个错误！
- en: Hardware interrupts and data races
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件中断和数据竞争
- en: 'Finally, envision this scenario: process P1 is, again, innocently running the
    driver''s read method code; it enters the critical section (between time `t2`
    and `t3`; again, see *Figure 6.5*). It makes some progress but then, alas, a hardware
    interrupt triggers (on the same CPU)! On the Linux OS, hardware (peripheral) interrupts
    have the highest priority; they preempt any code (including kernel code) by default.
    Thus, process (or thread) P1 will be at least temporarily shelved, thus losing
    the processor; the interrupt handling code will preempt it and run.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，设想这种情况：进程P1再次无辜地运行驱动程序的读取方法代码；它进入了临界区（在时间`t2`和`t3`之间；再次参见*图6.5*）。它取得了一些进展，但然后，哎呀，硬件中断触发了（在同一个CPU上）！在Linux操作系统上，硬件（外围）中断具有最高优先级；它们默认情况下会抢占任何代码（包括内核代码）。因此，进程（或线程）P1将至少暂时被搁置，从而失去处理器；中断处理代码将抢占它并运行。
- en: 'Well, you might be wondering, so what? Indeed, this is a completely commonplace
    occurrence! Hardware interrupts fire very frequently on modern systems, effectively
    (and literally) interrupting all kinds of task contexts (do a quick `vmstat 3` on
    your shell; the column under `system` labeled `in` shows the number of hardware
    interrupts that fired on your system in the last 1 second!). The key question
    to ask is this: is the interrupt handling code (either the hardirq top half or
    the so-called tasklet or softirq bottom half, whichever occurred), *sharing and
    working upon the same shared writable data of the process context that it just
    interrupted?*'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，那又怎样呢？确实，这是一个非常普遍的情况！在现代系统上，硬件中断非常频繁地触发，有效地（字面上）中断了各种任务上下文（在你的shell上快速执行`vmstat
    3`；`system`标签下的列显示了你的系统在过去1秒内触发的硬件中断的数量！）。要问的关键问题是：中断处理代码（无论是硬中断的顶半部分还是所谓的任务let或软中断的底半部分，无论哪个发生了），*是否共享并处理了它刚刚中断的进程上下文的相同共享可写数据？*
- en: If this is true, then, *Houston, we have a problem* – a data race! If not, then
    your interrupted code is not a critical section with respect to the interrupt
    code path, and that's fine. The fact is that the majority of device drivers do
    handle interrupt(s); thus, it is the driver author's (your!) responsibility to
    ensure that no global or static data – in effect, no critical sections – are shared between
    the process context and interrupt code paths. If they are (which does happen),
    you must somehow protect that data from data races and possible corruption.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是真的，那么，*休斯顿，我们有一个问题*-数据竞争！如果不是，那么你中断的代码对于中断代码路径来说不是一个临界区，那就没问题。事实上，大多数设备驱动程序确实处理中断；因此，驱动程序作者（你！）有责任确保没有全局或静态数据-实际上，没有临界区-在进程上下文和中断代码路径之间共享。如果有（这确实会发生），你必须以某种方式保护这些数据，以防数据竞争和可能的损坏。
- en: These scenarios might leave you feeling that protecting against these concurrency
    concerns is a really tall order; how exactly can you accomplish data safety in the
    face of critical sections existing, along with various possible concurrency concerns? Interestingly,
    the actual APIs are not hard to learn to use; again, we emphasize that **recognizing critical
    sections** is the key thing to do.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些情景可能会让你觉得，在面对这些并发问题时保护数据安全是一个非常艰巨的任务；你究竟如何在存在临界区的情况下确保数据安全，以及各种可能的并发问题？有趣的是，实际的API并不难学习使用；我们再次强调**识别临界区**是关键。
- en: Again, the basics regarding how a lock (conceptually) works, locking guidelines
    (very important; we'll recap on them shortly), and the types of and how to prevent
    deadlocks, are all dealt with in my earlier book, *Hands-On System Programming
    with Linux (Packt, Oct 2018)*. This books covers these points in detail in *Chapter
    15*, *Multithreading with Pthreads Part II – Synchronization*.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 关于锁（概念上）的工作原理，锁定指南（非常重要；我们很快会对它们进行总结），以及死锁的类型和如何预防死锁，都在我早期的书籍《Linux系统编程实践（Packt，2018年10月）》中有所涉及。这本书在第15章“使用Pthreads进行多线程编程第二部分-同步”中详细介绍了这些要点。
- en: Without further ado, let's dive into the primary synchronization technology
    that will serve to protect our critical sections – locking.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 话不多说，让我们深入探讨主要的同步技术，以保护我们的临界区-锁定。
- en: Locking guidelines and deadlocks
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 锁定指南和死锁
- en: 'Locking, by its very nature, is a complex beast; it tends to give rise to complex
    interlocking scenarios. Not understanding it well enough can lead to both performance
    headaches and bugs – deadlocks, circular dependencies, interrupt-unsafe locking,
    and more. The following locking guidelines are key to ensuring correctly written
    code when using locking:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 锁定本质上是一个复杂的问题；它往往会引发复杂的交叉锁定场景。不充分理解它可能会导致性能问题和错误-死锁、循环依赖、中断不安全的锁定等。以下锁定指南对确保使用锁定时编写正确的代码至关重要：
- en: '**Locking granularity**: The ''distance'' between the lock and the unlock (in
    effect, the length of the critical section) should not be coarse (too long a critical section)
    it should be ''fine enough''; what does this mean? The points below explain this:'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**锁定粒度**：锁定和解锁之间的“距离”（实际上是临界区的长度）不应该是粗粒度的（临界区太长），它应该是“足够细”; 这是什么意思？下面的要点解释了这一点：'
- en: You need to be careful here. When you're working on large projects, keeping
    too few locks is a problem, as is keeping too many! Too few locks can lead to
    performance issues (as the same locks are repeatedly used and thus tend to be
    highly contended).
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里你需要小心。在处理大型项目时，保持过少的锁是一个问题，保持过多的锁也是一个问题！过少的锁可能会导致性能问题（因为相同的锁被重复使用，因此很容易受到高度争用）。
- en: 'Having a lot of locks is actually good for performance, but not good for complexity
    control. This also leads to another key point to understand: with many locks in
    the code base, you should be very clear on which lock protects which shared data
    object. It''s completely meaningless if you use, say, `lockA` to protect `mystructX`,
    but in a code path far away (perhaps an interrupt handler) you forget this and
    try and use some other lock, `lockB`, for protection when working on the same
    structure! Right now, these things might sound obvious, but (as experienced developers
    know), under sufficient pressure, even the obvious isn''t always obvious!'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有大量锁实际上对性能有好处，但对复杂性控制不利。这也导致另一个关键点的理解：在代码库中有许多锁时，您应该非常清楚哪个锁保护哪个共享数据对象。如果您在代码路径中使用，例如`lockA`来保护`mystructX`，但在远处的代码路径（也许是中断处理程序）中忘记了这一点，并尝试在相同的结构上使用其他锁，`lockB`来保护！现在这些事情可能听起来很明显，但（有经验的开发人员知道），在足够的压力下，即使明显的事情也不总是明显的！
- en: Try and balance things out. In large projects, using one lock to protect one
    global (shared) data structure is typical. (*Naming* the lock variable well can
    become a big problem in itself! This is why we place the lock that protects a
    data structure within it as a member.)
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试平衡事物。在大型项目中，使用一个锁来保护一个全局（共享）数据结构是典型的。(*命名*好锁变量本身可能成为一个大问题！这就是为什么我们将保护数据结构的锁放在其中作为成员。)
- en: '**Lock ordering** is critical; **locks must be taken in the same order throughout**,
    and their order should be documented and followed by all the developers working
    on the project (annotating locks is useful too; more on this in the section on
    *lockdep* in the next chapter). Incorrect lock ordering often leads to deadlocks.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**锁定顺序**至关重要；**锁必须以相同的顺序获取**，并且其顺序应该由所有参与项目开发的开发人员记录和遵循（注释锁也很有用；在下一章节关于*lockdep*的部分中会更多介绍）。不正确的锁定顺序经常导致死锁。'
- en: Avoid recursive locking as much as possible.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽量避免递归锁定。
- en: Take care to prevent starvation; verify that a lock, once taken, is indeed released "quickly
    enough".
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意防止饥饿；验证一旦获取锁，确实会“足够快”释放。
- en: '**Simplicity is key**: Try to avoid complexity or over-design, especially with
    regard to complex scenarios involving locks.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单是关键**：尽量避免复杂性或过度设计，特别是涉及锁的复杂情况。'
- en: 'On the topic of locking, the (dangerous) issue of deadlocks arises. A **deadlock**
    is the inability to make any progress; in other words, the app and/or kernel component(s)
    appear to hang indefinitely. While we don''t intend to delve into the gory details
    of deadlocks here, I will quickly mention some of the more common types of deadlock
    scenarios that can occur:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在锁定的话题上，（危险的）死锁问题出现了。**死锁**是无法取得任何进展；换句话说，应用程序和/或内核组件似乎无限期地挂起。虽然我们不打算在这里深入研究死锁的可怕细节，但我会快速提到一些可能发生的常见死锁情况类型：
- en: 'Simple case, single lock, process context:'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单情况，单个锁，进程上下文：
- en: We attempt to acquire the same lock twice; this results in a **self-deadlock**.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们尝试两次获取相同的锁；这会导致**自死锁**。
- en: 'Simple case, multiple (two or more) locks, process context – an example:'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单情况，多个（两个或更多）锁，进程上下文 - 一个例子：
- en: On CPU `0`, thread A acquires lock A and then wants lock B.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在CPU `0`上，线程A获取锁A，然后想要获取锁B。
- en: Concurrently, on CPU `1`, thread B acquires lock B and then wants lock A.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时，在CPU `1`上，线程B获取锁B，然后想要获取锁A。
- en: The result is a deadlock, often called the **AB-BA** **deadlock**.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结果是死锁，通常称为**AB-BA** **死锁**。
- en: It can be extended; for example, the AB-BC-CA **circular dependency** (A-B-C lock
    chain) results in a deadlock.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以被扩展；例如，AB-BC-CA **循环依赖**（A-B-C锁链）会导致死锁。
- en: 'Complex case, single lock, and process and interrupt contexts:'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 复杂情况，单个锁，进程和中断上下文：
- en: Lock A takes in an interrupt context.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁A在中断上下文中获取。
- en: What if an interrupt occurs (on another core) and the handler attempts to take
    lock A? Deadlock is the result! Thus, locks acquired in the interrupt context
    must always be used with interrupts disabled. (How? We will look at this in more
    detail when we cover spinlocks.)
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果发生中断（在另一个核心上），并且处理程序试图获取锁A，会发生死锁！因此，在中断上下文中获取的锁必须始终与中断禁用一起使用。（如何？当我们涵盖自旋锁时，我们将更详细地讨论这个问题。）
- en: More complex cases, multiple locks, and process and interrupt (hardirq and softirq) contexts
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更复杂的情况，多个锁，进程和中断（硬中断和软中断）上下文
- en: 'In simpler cases, always following the *lock ordering guideline* is sufficient:
    always obtain and release locks in a well-documented order (we will provide an
    example of this in kernel code in the *Using the mutex lock* section). However,
    this can get very complex; complex deadlock scenarios can trip up even experienced
    developers. Luckily for us, ***lockdep*** – the Linux kernel''s runtime lock dependency
    validator – can catch every single deadlock case! (Don''t worry – we shall get
    there: we''ll cover lockdep in detail in the next chapter). When we cover spinlocks
    (the *Using the spinlock* section), we''ll come across process and/or interrupt
    context scenarios similar to the ones mentioned previously; the type of spinlock
    to use is made clear there.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在更简单的情况下，始终遵循*锁定顺序指南*就足够了：始终以有记录的顺序获取和释放锁（我们将在内核代码中的*使用互斥锁*部分提供一个示例）。然而，这可能变得非常复杂；复杂的死锁情况甚至会让经验丰富的开发人员感到困惑。幸运的是，***lockdep***
    - Linux内核的运行时锁依赖验证器 - 可以捕捉每一个死锁情况！（不用担心 - 我们会到那里的：我们将在下一章节详细介绍lockdep）。当我们涵盖自旋锁（*使用自旋锁*部分）时，我们将遇到类似于先前提到的进程和/或中断上下文情况；在那里明确了要使用的自旋锁类型。
- en: With regard to deadlocks, a pretty detailed presentation on lockdep was given
    by Steve Rostedt at a Linux Plumber's Conference (back in 2011); the relevant
    slides are informative and explore both simple and complex deadlock scenarios,
    as well as how lockdep can detect them ([https://blog.linuxplumbersconf.org/2011/ocw/sessions/153](https://blog.linuxplumbersconf.org/2011/ocw/sessions/153)).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 关于死锁，Steve Rostedt在2011年的Linux Plumber's Conference上对lockdep进行了非常详细的介绍；相关幻灯片内容丰富，探讨了简单和复杂的死锁场景，以及lockdep如何检测它们（[https://blog.linuxplumbersconf.org/2011/ocw/sessions/153](https://blog.linuxplumbersconf.org/2011/ocw/sessions/153)）。
- en: Also, the reality is that not just deadlock, but even **livelock** situations,
    can be just as deadly! Livelock is essentially a situation similar to deadlock;
    it's just that the state of the participating task is running and not waiting. An
    example, an interrupt "storm" can cause a livelock; modern network drivers mitigate
    this effect by switching off interrupts (under interrupt load) and resorting to
    a polling technique called **New API; Switching Interrupts** (**NAPI**) (switching interrupts
    back on when appropriate; well, it's more complex than that, but we leave it at
    that here).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，现实情况是，不仅是死锁，甚至**活锁**情况也可能同样致命！活锁本质上是一种类似于死锁的情况；只是参与任务的状态是运行而不是等待。例如，中断“风暴”可能导致活锁；现代网络驱动程序通过关闭中断（在中断负载下）并采用一种称为**新API；切换中断**（**NAPI**）的轮询技术来减轻这种效应（在适当时重新打开中断；好吧，实际情况比这更复杂，但我们就到此为止）。
- en: 'For those of you who''ve been living under a rock, you will know that the Linux
    kernel has two primary types of locks: the mutex lock and the spinlock. Actually,
    there are several more types, including other synchronization (and "lockless"
    programming) technology, all of which will be covered in the course of this chapter
    and the next.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些生活在石头下的人，你会知道Linux内核有两种主要类型的锁：互斥锁和自旋锁。实际上，还有几种类型，包括其他同步（和“无锁”编程）技术，所有这些都将在本章和下一章中涵盖。
- en: Mutex or spinlock? Which to use when
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁还是自旋锁？在何时使用
- en: The exact semantics of learning to use the mutex lock and the spinlock are quite simple
    (with appropriate abstraction within the kernel API set, making it even easier
    for the typical driver developer or module author). The critical question in this
    situation is a conceptual one: what really is the difference between the two locks?
    More to the point, under which circumstances should you use which lock? You will
    learn the answers to these questions in this section.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 学习使用互斥锁和自旋锁的确切语义非常简单（在内核API集中有适当的抽象，使得对于典型的驱动程序开发人员或模块作者来说更容易）。在这种情况下的关键问题是一个概念性的问题：两种锁之间的真正区别是什么？更重要的是，在什么情况下应该使用哪种锁？你将在本节中找到这些问题的答案。
- en: 'Taking our previous driver read method''s pseudocode (*Figure 6.5*) as a base
    example, let''s say that three threads – **tA**, **tB**, and **tC** – are running
    in parallel (on an SMP system) through this code. We shall solve this concurrency
    issue, while avoiding any data races, by taking or acquiring a lock prior to the
    start of the critical section (time **t2**), and release the lock (unlock) just
    after the end of the critical section code path (time **t3**). Let''s take a look
    at the pseudocode once more, this time with locking to ensure it''s correct:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以前的驱动程序读取方法的伪代码（*图6.5*）作为基本示例，假设三个线程 - **tA**，**tB**和**tC** - 在并行运行（在SMP系统上）通过这段代码。我们将通过在关键部分开始之前获取锁或获取锁来解决这个并发问题，同时避免任何数据竞争，并在关键部分代码路径结束后释放锁（解锁）（时间**t3**）。让我们再次看一下伪代码，这次使用锁定以确保它是正确的：
- en: '![](img/a0db53d6-0c64-4377-90a2-bdb95a2fab16.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a0db53d6-0c64-4377-90a2-bdb95a2fab16.png)'
- en: Figure 6.6 – Pseudocode – a critical section within a (fictional) driver's read
    method; correct, with locking
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.6 - 伪代码 - 驱动程序读取方法中的关键部分；正确，带锁
- en: 'When the three threads attempt to simultaneously acquire the lock, the system
    guarantees that only exactly one of them will get it. Let''s say that **tB** (thread
    B) gets the lock: it''s now the "winner" or "owner" thread. This means that threads
    **tA** and **tC** are the "losers"; what do they do? They wait upon the unlock!
    The moment the "winner" (**tB**) completes the critical section and unlocks the
    lock, the battle resumes between the previous losers; one of them will be the
    next winner and the process repeats.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 当三个线程尝试同时获取锁时，系统保证只有一个线程会获得它。假设**tB**（线程B）获得了锁：现在它是“获胜者”或“所有者”线程。这意味着线程**tA**和**tC**是“失败者”；他们会等待解锁！一旦“获胜者”（**tB**）完成关键部分并解锁锁，之前的失败者之间的战斗就会重新开始；其中一个将成为下一个获胜者，进程重复。
- en: The key difference between the two lock types – the mutex and the spinlock –
    is based on how the losers wait upon the unlock. With the mutex lock, the loser
    threads are put to sleep; that is, they wait by sleeping. The moment the winner
    performs the unlock, the kernel awakens the losers (all of them) and they run,
    again competing for the lock. (In fact, mutexes and semaphores are sometimes referred
    to as sleeplocks.)
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 两种锁类型之间的关键区别 - 互斥锁和自旋锁 - 基于失败者等待解锁的方式。使用互斥锁，失败者线程会进入睡眠；也就是说，它们通过睡眠等待。一旦获胜者执行解锁，内核就会唤醒失败者（所有失败者）并重新运行，再次竞争锁。（事实上，互斥锁和信号量有时被称为睡眠锁。）
- en: 'With the **spinlock**, however, there is no question of sleeping; the losers
    wait by spinning upon the lock until it is unlocked. Conceptually, this looks
    as follows:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用**自旋锁**，没有睡眠的问题；失败者会在锁上自旋等待，直到它被解锁。从概念上看，情况如下：
- en: '[PRE1]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that this is *only conceptual*. Think about it a moment – this is actually
    polling. However, as a good programmer, you will understand, that polling is usually
    considered a bad idea. Why, then, does the spinlock work this way? Well, it doesn't;
    it has only been presented in this manner for conceptual purposes. As you will
    soon understand, spinlocks only really have meaning on multicore (SMP) systems.
    On such systems, while the winner thread is away and running the critical section
    code, the losers wait by spinning on other CPU cores! In reality, at the implementation
    level, the code that's used to implement the modern spinlock is highly optimized (and
    arch-specific) and does not work by trivially "spinning" (for example, many spinlock implementations
    for ARM use the **wait for event** (**WFE**) machine language instruction, which
    has the CPU optimally wait in a low power state; see the *Further reading *section
    for several resources on the internal implementation of spinlocks).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这仅仅是*概念性的*。想一想——这实际上是轮询。然而，作为一个优秀的程序员，你会明白，轮询通常被认为是一个不好的主意。那么，自旋锁为什么会这样工作呢？嗯，它并不是这样的；它只是以这种方式呈现出来是为了概念上的目的。正如你很快会明白的，自旋锁只在多核（SMP）系统上才有意义。在这样的系统上，当获胜的线程离开并运行关键部分的代码时，失败者会在其他CPU核上旋转等待！实际上，在实现层面，用于实现现代自旋锁的代码是高度优化的（并且特定于体系结构），并不是通过简单地“自旋”来工作（例如，许多ARM的自旋锁实现使用**等待事件**（**WFE**）机器语言指令，这使得CPU在低功耗状态下等待；请参阅*进一步阅读*部分，了解有关自旋锁内部实现的几个资源）。
- en: Determining which lock to use – in theory
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在理论上确定使用哪种锁
- en: 'How the spinlock is implemented is really not our concern here; the fact that
    the spinlock has a lower overhead than the mutex lock is of interest to us. How
    so? It''s simple, really: for the mutex lock to work, the loser thread has to
    go to sleep. To do so, internally, the `schedule()` function gets called, which
    means the loser sees the mutex lock API as a blocking call! A call to the scheduler
    will ultimately result in the processer being context-switched off. Conversely,
    when the owner thread unlocks the lock, the loser thread(s) must be woken up;
    again, it will be context-switched back onto the processor. Thus, the minimal
    "cost" of the mutex lock/unlock operation is the time it takes to perform two
    context switches on the given machine. (See the *Information Box* in the next
    section.) By relooking at the preceding screenshot once more, we can determine
    a few things, including the time spent in the critical section (the "locked" code
    path); that is, `t_locked = t3 - t2`.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 自旋锁的实现方式实际上并不是我们关心的重点；自旋锁的开销比互斥锁更低对我们来说是有兴趣的。为什么呢？实际上很简单：为了使互斥锁工作，失败者线程必须休眠。为了做到这一点，内部调用了`schedule()`函数，这意味着失败者将互斥锁API视为一个阻塞调用！对调度程序的调用最终将导致处理器被上下文切换。相反，当所有者线程解锁锁时，失败者线程必须被唤醒；同样，它将被上下文切换回处理器。因此，互斥锁/解锁操作的最小“成本”是在给定机器上执行两次上下文切换所需的时间。（请参阅下一节中的*信息框*。）通过再次查看前面的屏幕截图，我们可以确定一些事情，包括在关键部分中花费的时间（“锁定”代码路径）；即，`t_locked
    = t3 - t2`。
- en: 'Let''s say that `t_ctxsw` represents the time to context switch. As we''ve
    learned, the minimal cost of the mutex lock/unlock operation is `2 * t_ctxsw`.
    Now, let''s say that the following expression is true:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 假设`t_ctxsw`代表上下文切换的时间。正如我们所了解的，互斥锁/解锁操作的最小成本是`2 * t_ctxsw`。现在，假设以下表达式为真：
- en: '[PRE2]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In other words, what if the time spent within the critical section is less than
    the time taken for two context switches? In this case, using the mutex lock is
    just wrong as this is far too much overhead; more time is being spent performing
    metawork than actual work – a phenomenon known as **thrashing**. It's this precise
    use case – the presence of very short critical sections – that's often the case
    on modern OSes such as Linux. So, in conclusion, for short non-blocking critical
    sections, using a spinlock is (far) superior to using a mutex lock.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，如果在关键部分内花费的时间少于两次上下文切换所需的时间，那么使用互斥锁就是错误的，因为这会带来太多的开销；执行元工作的时间比实际工作的时间更多——这种现象被称为**抖动**。这种精确的用例——非常短的关键部分的存在——在现代操作系统（如Linux）中经常出现。因此，总的来说，对于短的非阻塞关键部分，使用自旋锁（远远）优于使用互斥锁。
- en: Determining which lock to use – in practice
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在实践中确定使用哪种锁
- en: 'So, operating under the `t_locked < 2 * t_ctxsw` "rule" might be great in theory,
    but hang on: are you really expected to precisely measure the context switch time
    and the time spent in the critical section of each and every case where one (critical
    section) exists? No, of course not – that''s pretty unrealistic and pedantic.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在“`t_locked < 2 * t_ctxsw`”的“规则”下运行在理论上可能很好，但是等等：你真的期望精确地测量每种情况下关键部分的上下文切换时间和花费的时间吗？当然不是——那是相当不现实和迂腐的。
- en: 'Practically speaking, think about it this way: the mutex lock works by having
    the loser threads sleep upon the unlock; the spinlock does not (the losers "spin").
    Let''s recall one of our golden rules of the Linux kernel: a kernel cannot sleep
    (call `schedule()`) in any kind of atomic context. Thus, we can never use the
    mutex lock in an interrupt context, or indeed in any context where it isn''t safe
    to sleep; using the spinlock, however, would be fine. (Remember, a blocking API
    is one that puts the calling context to sleep by calling `schedule()`.) Let''s
    summarize this:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 从实际角度来看，可以这样理解：互斥锁通过在解锁时使失败者线程休眠来工作；自旋锁不会（失败者“自旋”）。让我们回顾一下Linux内核的一个黄金规则：内核不能在任何类型的原子上下文中休眠（调用`schedule()`）。因此，我们永远不能在中断上下文中使用互斥锁，或者在任何不安全休眠的上下文中使用；然而，使用自旋锁是可以的。让我们总结一下：
- en: '**Is the critical section running in an atomic (interrupt) context, or, in
    a process context, where it cannot sleep?** Use the spinlock.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键部分是在原子（中断）上下文中运行，还是在进程上下文中运行，无法休眠？** 使用自旋锁。'
- en: '**Is the critical section running in a process context and sleep in the critical
    section is necessary?** Use the mutex lock.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键部分是在进程上下文中运行，且在关键部分中需要休眠？** 使用互斥锁。'
- en: Of course, using the spinlock is considered lower overhead than using the mutex;
    thus, you can even use the spinlock in the process context (such as our fictional
    driver's read method), as long as the critical section does not block (sleep).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，使用自旋锁的开销比使用互斥锁的开销要低；因此，您甚至可以在进程上下文中使用自旋锁（例如我们虚构的驱动程序的读取方法），只要关键部分不会阻塞（休眠）。
- en: '**[1]** The time taken for a context switch is varied; it largely depends on the
    hardware and the OS quality. Recent (September 2018) measurements show that context
    switching time is in the region of 1.2 to 1.5 **us** (**microseconds**) on a pinned-down
    CPU, and around 2.2 us without pinning ([https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/](https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/)).'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**[1]** 上下文切换所需的时间是不同的；这在很大程度上取决于硬件和操作系统的质量。最近（2018年9月）的测量结果显示，在固定的CPU上，上下文切换时间在1.2到1.5**us**（**微秒**）左右，在没有固定的情况下大约为2.2微秒（[https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/](https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/)）。'
- en: Both hardware and the Linux OS have improved tremendously, and because of that,
    so has the average context switching time. An old (December 1998) Linux Journal
    article determined that on an x86 class system, the average context switch time
    was 19 us (microseconds), and that the worst-case time was 30 us.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件和Linux操作系统都有了巨大的改进，因此平均上下文切换时间也有所改善。一篇旧的（1998年12月）Linux Journal文章确定，在x86类系统上，平均上下文切换时间为19微秒（微秒），最坏情况下为30微秒。
- en: 'This brings up the question, how do we know if the code is currently running
    in a process or interrupt context? Easy: our `PRINT_CTX()` macro (within our `convenient.h`
    header) shows us this:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这带来了一个问题，我们如何知道代码当前是在进程上下文还是中断上下文中运行？很简单：我们的`PRINT_CTX()`宏（在我们的`convenient.h`头文件中）可以显示这一点：
- en: '[PRE3]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that you understand which one – mutex or spinlock – to use and when, let's
    get into the actual usage. We'll begin with how to use the mutex lock!
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您了解了何时使用互斥锁或自旋锁，让我们进入实际用法。我们将从如何使用互斥锁开始！
- en: Using the mutex lock
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用互斥锁
- en: Mutexes are also called sleepable or blocking mutual exclusion locks. As you
    have learned, they are used in the process context if the critical section can
    sleep (block). They must not be used within any kind of atomic or interrupt context
    (top halves, bottom halves such as tasklets or softirqs, and so on), kernel timers,
    or even the process context where blocking is not allowed.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果关键部分可以休眠（阻塞），则互斥锁也称为可休眠或阻塞互斥排他锁。它们必须不在任何类型的原子或中断上下文（顶半部，底半部，如tasklets或softirqs等），内核定时器，甚至不允许阻塞的进程上下文中使用。
- en: Initializing the mutex lock
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 初始化互斥锁
- en: 'A mutex lock "object" is represented in the kernel as a `struct mutex` data
    structure. Consider the following code:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 互斥锁“对象”在内核中表示为`struct mutex`数据结构。考虑以下代码：
- en: '[PRE4]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To use a mutex lock, it *must* be explicitly initialized to the unlocked state. Initialization
    can be performed statically (declare and initialize the object) with the `DEFINE_MUTEX()` macro,
    or dynamically via the `mutex_init()` function (this is actually a macro wrapper
    over the `__mutex_init()` function).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用互斥锁，*必须*将其显式初始化为未锁定状态。可以使用`DEFINE_MUTEX()`宏静态地（声明并初始化对象）进行初始化，也可以通过`mutex_init()`函数动态进行初始化（这实际上是对`__mutex_init()`函数的宏包装）。
- en: For example, to declare and initialize a mutex object called `mymtx`, we can
    use `DEFINE_MUTEX(mymtx);`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要声明并初始化名为`mymtx`的互斥锁对象，我们可以使用`DEFINE_MUTEX(mymtx);`。
- en: 'We can also do this dynamically. Why dynamically? Often, the mutex lock is
    a member of the (global) data structure that it protects (clever!). For example,
    let''s say we have the following global context structure in our driver code (note
    that this code is fictional):'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以动态地执行此操作。为什么要动态执行？通常，互斥锁是它所保护的（全局）数据结构的成员（聪明！）。例如，假设我们在驱动程序代码中有以下全局上下文结构（请注意，此代码是虚构的）：
- en: '[PRE5]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, in your driver''s (or LKM''s) `init` method, do the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在您的驱动程序（或LKM）的`init`方法中，执行以下操作：
- en: '[PRE6]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Keeping the lock variable as a member of the (parent) data structure it protects
    is a common (and clever) pattern that's used within Linux; this approach has the
    added benefit of avoiding namespace pollution and is unambiguous about which mutex
    protects which shared data item (a bigger problem than it might appear to be at
    first, especially in enormous projects such as the Linux kernel!).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 将锁变量作为（父）数据结构的成员保护是Linux中常用的（聪明）模式；这种方法还有一个额外的好处，即避免命名空间污染，并且清楚地说明哪个互斥锁保护哪个共享数据项（这可能是一个比起初看起来更大的问题，尤其是在像Linux内核这样的庞大项目中！）。
- en: Keep the lock protecting a global or shared data structure as a member within
    that data structure.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 将保护全局或共享数据结构的锁作为该数据结构的成员。
- en: Correctly using the mutex lock
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正确使用互斥锁
- en: 'Typically, you can find very insightful comments within the kernel source tree.
    Here''s a great one that neatly summarizes the rules you must follow to correctly
    use a mutex lock; please read this carefully:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您可以在内核源树中找到非常有见地的注释。这里有一个很好的总结了您必须遵循的规则以正确使用互斥锁的注释；请仔细阅读：
- en: '[PRE7]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As a kernel developer, you must understand the following:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 作为内核开发人员，您必须了解以下内容：
- en: A critical section causes the code path *to be serialized, defeating parallelism*.
    Due to this, it's imperative that you keep the critical section as short as possible.
    A corollary to this is **lock data, not code**.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关键部分导致代码路径*被串行化，破坏了并行性*。因此，至关重要的是尽量保持关键部分的时间尽可能短。与此相关的是**锁定数据，而不是代码**。
- en: Attempting to reacquire an already acquired (locked) mutex lock – which is effectively recursive locking
    – is *not* supported and will lead to a self-deadlock.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试重新获取已经获取（锁定）的互斥锁 - 这实际上是递归锁定 - 是*不*支持的，并且会导致自死锁。
- en: '**Lock ordering**: This is a very important rule of thumb for preventing dangerous
    deadlock situations. In the presence of multiple threads and multiple locks, it
    is critical that *the order in which locks are taken is documented and strictly
    followed by all the developers working on the project.* The actual lock ordering
    itself isn''t sacrosanct, but the fact that once it''s been decided on it must
    be followed, is. While browsing through the kernel source tree, you will come
    across many places where the kernel developers ensure this is done, and they (usually)
    write a comment regarding this for other developers to see and follow. Here''s
    a sample comment from the slab allocator code (`mm/slub.c`):'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**锁定顺序**：这是防止危险死锁情况的一个非常重要的经验法则。在存在多个线程和多个锁的情况下，关键的是*记录锁被获取的顺序，并且所有参与项目开发的开发人员都严格遵循*。实际的锁定顺序本身并不是不可侵犯的，但一旦决定了，就必须遵循。在浏览内核源代码时，您会发现许多地方，内核开发人员确保这样做，并且（通常）为其他开发人员编写注释以便查看和遵循。这是来自slab分配器代码（`mm/slub.c`）的一个示例注释：'
- en: '[PRE8]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now that we understand how mutexes work from a conceptual standpoint (and we
    understand their initialization), let's learn how to make use of the lock/unlock
    APIs.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们从概念上理解了互斥锁的工作原理（并且了解了它们的初始化），让我们学习如何使用锁定/解锁API。
- en: Mutex lock and unlock APIs and their usage
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 互斥锁定和解锁API及其用法
- en: 'The actual locking and unlocking APIs for the mutex lock are as follows. The
    following code shows how to lock and unlock a mutex, respectively:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 互斥锁的实际锁定和解锁API如下。以下代码分别显示了如何锁定和解锁互斥锁：
- en: '[PRE9]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: (Ignore `__sched` here; it's just a compiler attribute that has this function
    disappear in the `WCHAN` output, which shows up in procfs and with certain option
    switches to `ps(1)` (such as `-l`)).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: （这里忽略`__sched`；这只是一个编译器属性，使得这个函数在`WCHAN`输出中消失，在procfs中显示，并且在`ps(1)`的某些选项开关（如`-l`）中显示）。
- en: 'Again, the comments within the source code in `kernel/locking/mutex.c` are
    very detailed and descriptive; I encourage you to take a look at this file in
    more detail. We''ve only shown some of its code here, which has been taken directly
    from the 5.4 Linux kernel source tree:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在`kernel/locking/mutex.c`中的源代码中的注释非常详细和描述性；我鼓励您更详细地查看这个文件。我们在这里只显示了其中的一些代码，这些代码直接来自5.4
    Linux内核源代码树：
- en: '[PRE10]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`might_sleep()` is a macro with an interesting debug property; it catches code
    that''s supposed to execute in an atomic context but doesn''t! So, think about
    it: `might_sleep()`, which is the first line of code in `mutex_lock()`, implies
    that this code path should not be executed by anything that''s in an atomic context
    since it might sleep. This means that you should only use the mutex in the process
    context when it''s safe to sleep!'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`might_sleep()`是一个具有有趣调试属性的宏；它捕捉到了本应在原子上下文中执行但实际上没有执行的代码！所以，请思考一下：`might_sleep()`是`mutex_lock()`中的第一行代码，这意味着这段代码路径不应该被任何处于原子上下文中的东西执行，因为它可能会睡眠。这意味着只有在安全睡眠时才应该在进程上下文中使用互斥锁！'
- en: '**A quick and important reminder**: The Linux kernel can be configured with
    a large number of debug options; in this context, the `CONFIG_DEBUG_MUTEXES` config
    option will help you catch possible mutex-related bugs, including deadlocks. Similarly,
    under the Kernel Hackingmenu, you will find a large number of debug-related kernel
    config options. We discussed this in the companion guide *Linux Kernel Programming
    -* *Chapter 5*, *Writing Your First Kernel Module – LKMs Part 2*. There are several
    very useful kernel configs with regard to lock debugging; we shall cover these
    in the next chapter, in the *Lock debugging within the kernel* section.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**一个快速而重要的提醒**：Linux内核可以配置大量的调试选项；在这种情况下，`CONFIG_DEBUG_MUTEXES`配置选项将帮助您捕捉可能的与互斥锁相关的错误，包括死锁。同样，在Kernel
    Hacking菜单下，您将找到大量与调试相关的内核配置选项。我们在配套指南*Linux Kernel Programming - Chapter 5*，*Writing
    Your First Kernel Module – LKMs Part 2*中讨论了这一点。关于锁调试，有几个非常有用的内核配置，我们将在下一章中介绍，在*内核中的锁调试*部分。'
- en: Mutex lock – via [un]interruptible sleep?
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 互斥锁 - 通过[不]可中断的睡眠？
- en: As usual, there's more to the mutex than what we've seen so far. You already
    know that a Linux process (or thread) cycles through various states of a state
    machine. On Linux, sleeping has two discrete states – an interruptible sleep and
    an uninterruptible sleep. A process (or thread) in an interruptible sleep is sensitive,
    which means it will respond to user space signals, whereas a task in an uninterruptible sleep
    is not sensitive to user signals.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 和往常一样，互斥锁比我们迄今所见到的更复杂。您已经知道Linux进程（或线程）在状态机的各种状态之间循环。在Linux上，睡眠有两种离散状态 - 可中断睡眠和不可中断睡眠。处于可中断睡眠状态的进程（或线程）是敏感的，这意味着它将响应用户空间信号，而处于不可中断睡眠状态的任务对用户信号不敏感。
- en: 'In a human-interactive application with an underlying driver, as a general
    rule of thumb, you should typically put a process into an interruptible sleep
    (while it''s blocking upon the lock), thus leaving it up to the end user as to whether
    to abort the application by pressing *Ctrl* + *C* (or some such mechanism involving signals).
    There is a design rule that''s often followed on Unix-like systems: **provide
    mechanism, not policy**. Having said this, on non-interactive code paths, it''s
    often the case that you must wait on the lock to wait indefinitely, with the semantic
    that a signal that''s been delivered to the task should not abort the blocking
    wait. On Linux, the uninterruptible case turns out to be the most common one.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在具有底层驱动程序的人机交互应用程序中，通常的经验法则是，您应该将一个进程放入可中断的睡眠状态（当它在锁上阻塞时），这样就由最终用户决定是否通过按下*Ctrl*
    + *C*（或某种涉及信号的机制）来中止应用程序。在类Unix系统上通常遵循的设计规则是：**提供机制，而不是策略**。话虽如此，在非交互式代码路径上，通常情况下，您必须等待锁来无限期地等待，语义上，已传递给任务的信号不应中止阻塞等待。在Linux上，不可中断的情况是最常见的情况。
- en: 'So, here''s the thing: the `mutex_lock()` API always puts the calling task
    into an uninterruptible sleep. If this is not what you want, use the `mutex_lock_interruptible()`
    API to put the calling task into an interruptible sleep. There is one difference
    syntax-wise; the latter returns an integer value of `0` on success and `-EINTR`
    (remember the `0`/`-E` return convention) on failure (due to signal interruption).'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这里的问题是：`mutex_lock()` API总是将调用任务置于不可中断的睡眠状态。如果这不是你想要的，使用`mutex_lock_interruptible()`
    API将调用任务置于可中断的睡眠状态。在语法上有一个不同之处；后者在成功时返回整数值`0`，在失败时返回`-EINTR`（记住`0`/`-E`返回约定）（由于信号中断）。
- en: In general, using `mutex_lock()` is faster than using `mutex_lock_interruptible()`; use
    it when the critical section is short (thus pretty much guaranteeing that the
    lock is held for a short while, which is a very desirable characteristic).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，使用`mutex_lock()`比使用`mutex_lock_interruptible()`更快；当临界区很短时使用它（因此几乎可以保证锁定时间很短，这是一个非常理想的特性）。
- en: The 5.4.0 kernel contains over 18,500 and just over 800 instances of calling
    the `mutex_lock()` and `mutex_lock_interruptible()` APIs, respectively; you can
    check this out via the powerful `cscope(1)` utility on the kernel source tree.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 5.4.0内核包含超过18,500个`mutex_lock()`和800多个`mutex_lock_interruptible()` API的调用实例；你可以通过内核源树上强大的`cscope(1)`实用程序来检查这一点。
- en: 'In theory, the kernel provides a `mutex_destroy()` API as well. This is the
    opposite of `mutex_init()`; its job is to mark the mutex as being unusable. It
    must only be invoked once the mutex is in the unlocked state, and once invoked,
    the mutex cannot be used. This is a bit theoretical because, on regular systems,
    it just reduces to an empty function; only on a kernel with `CONFIG_DEBUG_MUTEXES`
    enabled does it become actual (simple) code. Thus, we should use this pattern
    when working with the mutex, as shown in the following pseudocode:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，内核提供了`mutex_destroy()` API。这是`mutex_init()`的相反操作；它的工作是将互斥锁标记为不可用。只有在互斥锁处于未锁定状态时才能调用它，一旦调用，互斥锁就不能再使用。这有点理论性，因为在常规系统上，它只是一个空函数；只有在启用了`CONFIG_DEBUG_MUTEXES`的内核上，它才变成实际的（简单的）代码。因此，当使用互斥锁时，我们应该使用这种模式，如下面的伪代码所示：
- en: '[PRE11]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now that you have learned how to use the mutex lock APIs, let's put this knowledge
    to use. In the next section, we will build on top of one of our earlier (poorly
    written – no protection!) "misc" drivers by employing the mutex object to lock
    critical sections as required.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何使用互斥锁API，让我们把这些知识付诸实践。在下一节中，我们将在之前的一个（编写不好 - 没有保护！）“misc”驱动程序的基础上，通过使用互斥对象来锁定必要的临界区来构建。
- en: Mutex locking – an example driver
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 互斥锁定 - 一个示例驱动程序
- en: We have created a simple device driver code example in *Chapter 1* - *Writing
    a Simple misc Character Device Driver*; that is, `ch1/miscdrv_rdwr`. There, we
    wrote a simple `misc` class character device driver and used a user space utility
    program (`ch12/miscdrv_rdwr/rdwr_drv_secret.c`) to read and write a (so-called)
    secret from and to the device driver's memory.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*第1章* - *编写一个简单的misc字符设备驱动程序*中创建了一个简单的设备驱动程序示例，即`ch1/miscdrv_rdwr`。在那里，我们编写了一个简单的`misc`类字符设备驱动程序，并使用了一个用户空间实用程序（`ch12/miscdrv_rdwr/rdwr_drv_secret.c`）来从设备驱动程序的内存中读取和写入一个（所谓的）秘密。
- en: 'However, what we glaringly (egregiously is the right word here!) failed to
    do in that code is protect shared (global) writeable data! This will cost us dearly
    in the real world. I urge you to take some time to think about this: it isn''t
    viable that two (or three or more) user mode processes open the device file of
    this driver, and then concurrently issue various I/O reads and writes. Here, the
    global shared writable data (in this particular case, two global integers and
    the driver context data structure) could easily get corrupted.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在那段代码中，我们明显（egregiously是正确的词！）未能保护共享（全局）可写数据！这在现实世界中会让我们付出昂贵的代价。我敦促你花些时间考虑一下：两个（或三个或更多）用户模式进程打开该驱动程序的设备文件，然后同时发出各种I/O读写是不可行的。在这里，全局共享可写数据（在这种特殊情况下，两个全局整数和驱动程序上下文数据结构）很容易被破坏。
- en: 'So, let''s learn from and correct our mistakes by making a copy of this driver
    (we will now call it `ch12/1_miscdrv_rdwr_mutexlock/1_miscdrv_rdwr_mutexlock.c`)
    and rewriting some portions of it. The key point is that we must use mutex locks
    to protect all critical sections. Instead of displaying the code here (it''s in
    this book''s GitHub repository at [https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming),
    after all, please do `git clone` it!), let''s do something interesting: let''s
    look at a "diff" (the differences – the delta generated by `diff(1)`) between
    the older unprotected version and the newer protected code version. The output
    here has been truncated:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们从错误中吸取教训，并通过复制这个驱动程序（我们现在将其称为`ch12/1_miscdrv_rdwr_mutexlock/1_miscdrv_rdwr_mutexlock.c`）并重写其中的一些部分来纠正错误。关键点是我们必须使用互斥锁来保护所有关键部分。而不是在这里显示代码（毕竟，它在这本书的GitHub存储库中[https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming)，请使用`git
    clone`！），让我们做一些有趣的事情：让我们看一下旧的未受保护版本和新的受保护代码版本之间的“diff”（`diff(1)`生成的差异 - ）的输出在这里已经被截断：
- en: '[PRE12]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here, we can see that in the newer safe version of the driver, we have declared
    and initialized a mutex variable called `lock1`; we shall use it to protect the
    (just for demonstration purposes) two global integers, `ga` and `gb`, within our
    driver. Next, importantly, we declared a mutex lock named `lock` within the "driver
    context" data structure; that is, `drv_ctx`. This will be used to protect any
    and all access to members of that data structure. It is initialized within the `init` code:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到在驱动程序的更新的安全版本中，我们声明并初始化了一个名为`lock1`的互斥变量；我们将用它来保护（仅用于演示目的）驱动程序中的两个全局整数`ga`和`gb`。接下来，重要的是，在“驱动程序上下文”数据结构`drv_ctx`中声明了一个名为`lock`的互斥锁；这将用于保护对该数据结构成员的任何访问。它在`init`代码中初始化：
- en: '[PRE13]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This detailed comment clearly explains why we don''t need to lock/unlock around
    `strscpy()`. Again, this should be obvious, but local variables are implicitly
    private to each process context (as they reside in that process or thread''s kernel
    mode stack) and therefore require no protection (each thread/process has a separate
    *instance* of the variable, so no one steps on anyone''s toes!). Before we forget,
    the *cleanup* code path (which is invoked via the `rmmod(8)` process context),
    must destroy the mutexes:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这个详细的注释清楚地解释了为什么我们不需要在`strscpy()`周围进行锁定/解锁。再次强调，这应该是显而易见的，但是局部变量隐式地对每个进程上下文都是私有的（因为它们驻留在该进程或线程的内核模式堆栈中），因此不需要保护（每个线程/进程都有一个变量的单独*实例*，所以没有人会干涉别人的工作！）。在我们忘记之前，*清理*代码路径（通过`rmmod(8)`进程上下文调用）必须销毁互斥锁：
- en: '[PRE14]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, let''s look at the diff of the driver''s open method:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下驱动程序的打开方法的差异：
- en: '[PRE15]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This is where we manipulated the global integers, *making this a critical section*;
    unlike the previous version of this program, here, we *do protect this critical section*
    with the `lock1` mutex. So, there it is: the critical section here is the code `ga++;
    gb--;`: the code between the (mutex) lock and unlock operations.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们操纵全局整数的地方，*使其成为关键部分*；与程序的先前版本不同，在这里，我们使用`lock1`互斥锁*保护这个关键部分*。所以，关键部分就是这里的代码`ga++;
    gb--;`：在（互斥）锁定和解锁操作之间的代码。
- en: 'But (there''s always a but, isn''t there?), all is not well! Take a look at
    the `printk` function (`dev_info()`) following the `mutex_unlock()` line of code:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 但是（总是有一个但是，不是吗？），一切并不顺利！看一下`mutex_unlock()`代码行后面的`printk`函数（`dev_info()`）：
- en: '[PRE16]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Does this look okay to you? No, look carefully: we are *reading* the value
    of the global integers, `ga` and `gb`. Recall the fundamentals: in the presence
    of concurrency (which is certainly a possibility here in this driver''s *open*
    method), *even reading shared writeable data without the lock is potentially unsafe*.
    If this doesn''t make sense to you, please think: what if, while one thread is
    reading the integers, another is simultaneously updating (writing) them; what
    then? This kind of situation is called a **dirty read** (or a **torn read)**;
    we might end up reading stale data and must be protected against. (The fact is
    that this isn''t really a great example of a dirty read as, on most processors,
    reading and writing single integer items does tend to be an atomic operation.
    However, we must not assume such things – we must simply do our job and protect
    it.)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 这对你来说看起来还好吗？不，仔细看：我们正在*读取*全局整数`ga`和`gb`的值。回想一下基本原理：在并发存在的情况下（在这个驱动程序的*打开*方法中肯定是可能的），*即使没有锁定，读取共享可写数据也可能是不安全的*。如果这对你来说没有意义，请想一想：如果一个线程正在读取整数，同时另一个线程正在更新（写入）它们；那么呢？这种情况被称为**脏读**（或**断裂读**）；我们可能会读取过时的数据，必须加以保护。（事实上，这并不是一个真正的脏读的很好的例子，因为在大多数处理器上，读取和写入单个整数项目确实
    tend to be an atomic operation。然而，我们不应该假设这样的事情 - 我们只需要做好我们的工作并保护它。）
- en: 'In fact, there''s another similar bug-in-waiting: we have read data from the
    open file structure (the `filp` pointer) without bothering to protect it (indeed,
    the open file structure has a lock; we''re supposed to use it! We shall do so
    later).'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，还有另一个类似的潜在错误：我们从打开文件结构（`filp`指针）中读取数据而没有进行保护（的确，打开文件结构有一个锁；我们应该使用它！我们以后会这样做）。
- en: 'The precise semantics of how and when things such as *dirty reads* occur does
    tend to be very arch (machine)-dependent; nevertheless, our job as module or driver
    authors is clear: we must ensure that we protect all critical sections. This includes
    reads upon shared writable data.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如*脏读*之类的事情发生的具体语义通常非常依赖于体系结构（机器），然而，我们作为模块或驱动程序的作者的工作是清楚的：我们必须确保保护所有关键部分。这包括对共享可写数据的读取。
- en: 'For now, we shall just flag these as potential errors (bugs). We will take
    care of this in the *Using the atomic integer operators* section, in a more performance-friendly
    manner. Looking at the diff of the driver''s read method reveals something interesting
    (ignore the line numbers shown here; they might change):'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们将把这些标记为潜在的错误（bug）。我们将在*使用原子整数操作符*部分以更加性能友好的方式处理这个问题。查看驱动程序的读取方法的差异会发现一些有趣的东西（忽略这里显示的行号；它们可能会改变）：
- en: '![](img/ad26b085-7d4a-4090-96b8-44aef98664ce.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ad26b085-7d4a-4090-96b8-44aef98664ce.png)'
- en: Figure 6.7 – The diff of the driver's read() method; see the usage of the mutex
    lock in the newer version
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.7 - 驱动程序的read()方法的差异；查看新版本中互斥锁的使用
- en: We have now used the driver context structure's mutex lock to protect the critical
    sections. The same goes for both the *write* and *close* (release) methods of
    the device driver (generate the patch for yourself and take a look).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在使用驱动程序上下文结构的互斥锁来保护关键部分。对于设备驱动程序的*写*和*关闭*（释放）方法也是一样的（生成补丁并查看）。
- en: Note that the user mode app remains unchanged, which means for us to test the
    new safer version, we must continue using the user mode app at `ch12/miscdrv_rdwr/rdwr_drv_secret.c`. Running
    and testing code such as this driver code on a debug kernel, which contains various locking
    errors and deadlock detection capabilities, is crucial (we'll return to these
    "debug" capabilities in the next chapter, in the *Lock debugging within the kernel* section).
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意用户模式应用程序保持不变，这意味着为了测试新的更安全的版本，我们必须继续使用用户模式应用程序`ch12/miscdrv_rdwr/rdwr_drv_secret.c`。在调试内核上运行和测试此驱动程序代码，其中包含各种锁定错误和死锁检测功能，这是至关重要的（我们将在下一章中返回到这些“调试”功能，在*内核中的锁调试*部分）。
- en: In the preceding code, we took the mutex lock just before the `copy_to_user()`
    routine; that's fine. However, we only release it after `dev_info()`. Why not
    release it before this `printk`, thus shortening the critical section?
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们在`copy_to_user()`例程之前获取了互斥锁；这很好。然而，我们只在`dev_info()`之后释放它。为什么不在这个`printk`之前释放它，从而缩短关键部分的时间？
- en: 'A closer look at `dev_info()` reveals why it''s *within* the critical section.
    We are printing the values of three variables here: the number of bytes read by `secret_len` and
    the number of bytes that are "transmitted" and "received" by `ctx->tx` and `ctx->rx`,
    respectively. `secret_len` is a local variable and does not require protection,
    but the other two variables are within the global driver context structure and
    thus do require protection, even from (possibly dirty) reads.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细观察`dev_info()`，可以看出为什么它*在*关键部分。我们在这里打印了三个变量的值：`secret_len`读取的字节数，以及`ctx->tx`和`ctx->rx`分别“传输”和“接收”的字节数。`secret_len`是一个局部变量，不需要保护，但另外两个变量在全局驱动程序上下文结构中，因此需要保护，即使是（可能是脏的）读取也需要。
- en: The mutex lock – a few remaining points
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 互斥锁 - 一些剩余的要点
- en: In this section, we will cover a few additional points regarding mutexes.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将涵盖有关互斥锁的一些其他要点。
- en: Mutex lock API variants
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 互斥锁API变体
- en: First, let's take a look at a few variants of the mutex lock API; besides the
    interruptible variant (described in the *Mutex lock – via [un]interruptible sleep?* section),
    we have the *trylock, killable*, and *io* variants.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下互斥锁API的几个变体；除了可中断变体（在*互斥锁 - 通过[不]可中断睡眠？*部分中描述），我们还有*trylock，可杀死*和*io*变体。
- en: The mutex trylock variant
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 互斥trylock变体
- en: 'What if you would like to implement a **busy-wait** semantic; that is, test
    for the availability of the (mutex) lock and, if available (meaning it''s currently
    unlocked), acquire/lock it and continue with the critical section code path? If
    this is not available (it''s currently in the locked state), do not wait for the
    lock; instead, perform some other work and retry. In effect, this is a non-blocking
    mutex lock variant and is called the trylock; the following flowchart shows how
    it works:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想实现一个**忙等待**语义；也就是说，测试（互斥）锁的可用性，如果可用（意味着当前未锁定），则获取/锁定它并继续关键部分代码路径？如果不可用（当前处于锁定状态），则不等待锁；而是执行其他工作并重试。实际上，这是一个非阻塞的互斥锁变体，称为trylock；以下流程图显示了它的工作原理：
- en: '![](img/421daaad-97a1-4acc-8cfc-e4d33751eb84.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/421daaad-97a1-4acc-8cfc-e4d33751eb84.png)'
- en: Figure 6.8 – The "busy wait" semantic, a non-blocking trylock operation
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.8 - “忙等待”语义，一个非阻塞的trylock操作
- en: 'The API for this trylock variant of the mutex lock is as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这个互斥锁的trylock变体的API如下：
- en: '[PRE17]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This API''s return value signifies what transpired at runtime:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API的返回值表示了运行时发生了什么：
- en: A return value of `1` indicates that the lock has been successfully acquired.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回值`1`表示成功获取了锁。
- en: A return value of `0` indicates that the lock is currently contended (locked).
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回值`0`表示当前争用（已锁定）。
- en: Though it might sound tempting to, do *not* attempt to use the `mutex_trylock()`
    API to figure out if a mutex lock is in a locked or unlocked state; this is inherently
    "racy". Next, note that using this trylock variant in a highly contended lock
    path may well reduce your chances of acquiring the lock. The trylock variant has
    been traditionally used in deadlock prevention code that might need to back out
    of a certain lock order sequence and be retried via another sequence (ordering).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管尝试使用`mutex_trylock()` API来确定互斥锁是处于锁定还是未锁定状态可能听起来很诱人，但*不要*尝试这样做，因为这本质上是“竞争的”。另外，要注意，在高度竞争的锁路径中使用这个trylock变体可能会降低你获取锁的机会。trylock变体传统上用于死锁预防代码，可能需要退出某个锁定顺序序列并通过另一个序列（顺序）重试。
- en: Also, with respect to the trylock variant, even though the literature uses the
    term *try and acquire the mutex atomically*, it does not work in an atomic or
    interrupt context – it *only* works in the process context (as with any type of
    mutex lock). As usual, the lock must be released by `mutex_unlock()` being invoked
    by the owner context.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，关于trylock变体，尽管文献中使用了术语*尝试原子地获取互斥锁*，但它不适用于原子或中断上下文——它*只*适用于进程上下文（与任何类型的互斥锁一样）。通常情况下，锁必须由拥有者上下文调用的`mutex_unlock()`来释放。
- en: I suggest that you try working on the trylock mutex variant as an exercise.
    See the *Questions *section at the end of this chapter for an assignment!
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议你尝试作为练习使用trylock互斥锁变体。请参阅本章末尾的*问题*部分进行作业！
- en: The mutex interruptible and killable variants
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 互斥可中断和可杀死变体
- en: 'As you have already learned, the `mutex_lock_interruptible()` API is used when
    the driver (or module) is willing to acknowledge any (user space) signal interrupting
    it (and returns `-ERESTARTSYS` to tell the kernel VFS layer to perform signal
    handling; the user space system call will fail with `errno` set to `EINTR`). An
    example can be found in the module handling code in the kernel, within the `delete_module(2)`
    system call (which `rmmod(8)` invokes):'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你已经学到的，当驱动程序（或模块）愿意接受任何（用户空间）信号中断时，会使用`mutex_lock_interruptible()` API（并返回`-ERESTARTSYS`告诉内核VFS层执行信号处理；用户空间系统调用将以`errno`设置为`EINTR`失败）。一个例子可以在内核中的模块处理代码中找到，在`delete_module(2)`系统调用中（由`rmmod(8)`调用）：
- en: '[PRE18]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Notice how the API returns `-EINTR` on failure. (The `SYSCALL_DEFINEn()` macro
    becomes a system call signature; `n` signifies the number of parameters this particular
    system call accepts. Also, notice the capability check – unless you are running
    as root or have the `CAP_SYS_MODULE` capability (or module loading is completely
    disabled), the system call just returns a failure (`-EPERM`).)
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 注意API在失败时返回`-EINTR`。（`SYSCALL_DEFINEn()`宏成为系统调用签名；`n`表示这个特定系统调用接受的参数数量。还要注意权限检查——除非你以root身份运行或具有`CAP_SYS_MODULE`权限（或者模块加载完全被禁用），否则系统调用将返回失败（`-EPERM`）。）
- en: If, however, your driver is only willing to be interrupted by fatal signals
    (those that *will kill* the user space context), then use the `mutex_lock_killable()`
    API (the signature is identical to that of the interruptible variant).
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你的驱动程序只愿意被致命信号（那些*将杀死*用户空间上下文的信号）中断，那么使用`mutex_lock_killable()` API（签名与可中断变体相同）。
- en: The mutex io variant
  id: totrans-248
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 互斥io变体
- en: The `mutex_lock_io()` API is identical in syntax to the `mutex_lock()` API;
    the only difference is that the kernel thinks that the wait time of the loser
    thread(s) is the same as waiting for I/O (the code comment in `kernel/locking/mutex.c:mutex_lock_io()`
    clearly documents this; take a look). This can matter accounting-wise.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '`mutex_lock_io()` API在语法上与`mutex_lock()` API相同；唯一的区别是内核认为失败线程的等待时间与等待I/O相同（`kernel/locking/mutex.c:mutex_lock_io()`中的代码注释清楚地记录了这一点；看一下）。这在会计方面很重要。'
- en: You can find fairly exotic APIs such as `mutex_lock[_interruptible]_nested()`
    within the kernel, with the emphasis here being on the `nested` suffix. However,
    note that the Linux kernel does not prefer developers to use nested (or recursive)
    locking (as we mentioned in the *Correctly using the mutex lock* section). Also, these
    APIs only get compiled in the presence of the `CONFIG_DEBUG_LOCK_ALLOC` config
    option; in effect, the nested APIs were added to support the kernel lock validator
    mechanism. They should only be used in special circumstances (where a nesting
    level must be incorporated between instances of the same lock type).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在内核中找到相当奇特的API，比如`mutex_lock[_interruptible]_nested()`，这里重点是`nested`后缀。但是，请注意，Linux内核不希望开发人员使用嵌套（或递归）锁定（正如我们在*正确使用互斥锁*一节中提到的）。此外，这些API只在存在`CONFIG_DEBUG_LOCK_ALLOC`配置选项时才会被编译；实际上，嵌套API是为了支持内核锁验证器机制而添加的。它们只应在特殊情况下使用（在同一类型的锁实例之间必须包含嵌套级别的情况下）。
- en: 'In the next section, we will answer a typical FAQ: what''s the difference between
    the mutex and semaphore objects? Does Linux even have a semaphore object? Read
    on to find out!'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将回答一个典型的常见问题：互斥锁和信号量对象有什么区别？Linux是否有信号量对象？继续阅读以了解更多！
- en: The semaphore and the mutex
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 信号量和互斥锁
- en: 'The Linux kernel does provide a semaphore object, along with the usual operations
    you can perform on a (binary) semaphore:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核确实提供了一个信号量对象，以及您可以对（二进制）信号量执行的常规操作：
- en: A semaphore lock acquire via the `down[_interruptible]()` (and variations) APIs
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`down[_interruptible]()`（和变体）API获取信号量锁
- en: A semaphore unlock via the `up()` API.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`up()` API解锁信号量。
- en: In general, the semaphore is an older implementation, so it's advised that you
    use the mutex lock in place of it.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，信号量是一种较旧的实现，因此建议您使用互斥锁来代替它。
- en: 'An FAQ worth looking at, though, is this: *what is the difference between a
    mutex and a semaphore?* They appear to be conceptually similar, but are actually
    quite different:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一看的常见问题是：*互斥锁和信号量之间有什么区别？*它们在概念上看起来相似，但实际上是非常不同的。
- en: A semaphore is a more generalized form of a mutex; a mutex lock can be acquired
    (and subsequently released or unlocked) exactly once, while a semaphore can be
    acquired (and subsequently released) multiple times.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信号量是互斥锁的一种更一般化的形式；互斥锁可以被获取（然后释放或解锁）一次，而信号量可以被获取（然后释放）多次。
- en: A mutex is used to protect a critical section from simultaneous access, while
    a semaphore should be used as a mechanism to signal another waiting task that
    a certain milestone has been reached (typically, a producer task posts a signal
    via the semaphore object, which a consumer task is waiting to receive, in order
    to continue with further work).
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互斥锁用于保护临界区免受同时访问，而信号量应该被用作一种机制，用于向另一个等待任务发出信号，表明已经达到了某个里程碑（通常，生产者任务通过信号量对象发布信号，等待接收的消费者任务可以继续进行进一步的工作）。
- en: A mutex has the notion of ownership of the lock and only the owner context can perform
    the unlock; there is no ownership for a binary semaphore.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互斥锁具有锁的所有权概念，只有所有者上下文才能执行解锁；二进制信号量没有所有权。
- en: Priority inversion and the RT-mutex
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优先级反转和RT-互斥锁
- en: A word of caution when using any kind of locking is that you should carefully
    design and code to prevent the dreaded *deadlock* scenarios that could arise (more
    on this in the next chapter in the *The lock validator lockdep – catch locking
    issues early* section).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用任何类型的锁定时需要注意的一点是，您应该仔细设计和编码，以防止可能出现的可怕的*死锁*情况（在*锁验证器lockdep - 及早捕捉锁定问题*一节中将更多地讨论这一点）。
- en: 'Aside from deadlocks, there is another risky scenario that arises when using
    the mutex: that of priority inversion (again, we will not delve into the details
    in this book). Suffice it to say that the unbounded **priority inversion** case
    can be a deadly one; the end result is that the product''s high(est) priority
    thread is kept off the CPU for too long.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 除了死锁之外，使用互斥锁时还会出现另一种风险情况：优先级反转（在本书中我们不会深入讨论细节）。可以说，无界**优先级反转**情况可能是致命的；最终结果是产品的高（最高）优先级线程被长时间挡在CPU之外。
- en: As I covered in some detail in my earlier book, *Hands-on System Programming
    with Linux, *it's precisely this priority inversion issue that struck NASA's Mars
    Pathfinder robot, on the Martian surface no less, back in July 1997! See the *Further
    reading* section of this chapter for interesting resources about this, something
    that every software developer should be aware of!
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在早期的书籍*使用Linux进行系统编程*中详细介绍的那样，正是这种优先级反转问题在1997年7月击中了NASA的火星探路者机器人，而且还是在火星表面！请参阅本章的*进一步阅读*部分，了解有关这一问题的有趣资源，这是每个软件开发人员都应该知道的内容！
- en: The userspace Pthreads mutex implementation certainly has **priority inheritance**
    (**PI**) semantics available. But what about within the Linux kernel? For this,
    Ingo Molnar provided the PI-futex-based RT-mutex (a real-time mutex; in effect,
    a mutex extended to have PI capabilities. `futex(2)` is a sophisticated system
    call that provides a fast userspace mutex). These become available when the `CONFIG_RT_MUTEXES` config
    option is enabled. Quite similar to the "regular" mutex semantics, RT-mutex APIs
    are provided to initialize, (un)lock, and destroy the RT-mutex object. (This code
    has been merged into the mainline kernel from Ingo Molnar's `-rt` tree). As far
    as actual usage is concerned, the RT-mutex is used for internally implementing
    the PI futex (the `futex(2)` system call itself internally implements the userspace
    Pthreads mutex). Besides this, the kernel locking self-test code and the I2C subsystem
    uses the RT-mutex directly.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 用户空间Pthreads互斥锁实现当然具有**优先级继承**（**PI**）语义。但在Linux内核中呢？对此，Ingo Molnar提供了基于PI-futex的RT互斥锁（实时互斥锁；实际上是扩展为具有PI功能的互斥锁。`futex(2)`是一个提供快速用户空间互斥锁的复杂系统调用）。当启用`CONFIG_RT_MUTEXES`配置选项时，这些就可用了。与“常规”互斥锁语义非常相似，RT互斥锁API用于初始化、（解）锁定和销毁RT互斥锁对象。（此代码已从Ingo
    Molnar的`-rt`树合并到主线内核）。就实际使用而言，RT互斥锁用于在内部实现PI futex（`futex(2)`系统调用本身在内部实现了用户空间Pthreads互斥锁）。除此之外，内核锁定自测代码和I2C子系统直接使用RT互斥锁。
- en: Thus, for a typical module (or driver) author, these APIs are not going to be
    used very frequently. The kernel does provide some documentation on the internal
    design of the RT-mutex at [https://www.kernel.org/doc/Documentation/locking/rt-mutex-design.rst](https://www.kernel.org/doc/Documentation/locking/rt-mutex-design.rst) (covering
    priority inversion, priority inheritance, and more).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于典型的模块（或驱动程序）作者来说，这些API并不经常使用。内核确实提供了一些关于RT互斥锁内部设计的文档（涵盖了优先级反转、优先级继承等）。
- en: Internal design
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内部设计
- en: 'A word on the reality of the internal implementation of the mutex lock deep
    within the kernel fabric: Linux tries to implement a *fast path* approach when
    possible.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 关于互斥锁在内核结构深处的内部实现的现实：Linux在可能的情况下尝试实现*快速路径*方法。
- en: A **fast path** is the most optimized high-performance type of code path; for example,
    one with no locks and no blocking. The intent is to have code follow this fast
    path as far as possible. Only when it really isn't possible does the kernel fall
    back to a (possible) "mid path", and then a "slow path", approach; it still works
    but is slow(er).
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速路径**是最优化的高性能代码路径；例如，没有锁和阻塞。目的是让代码尽可能地遵循这条快速路径。只有在真的不可能的情况下，内核才会退回到“中间路径”，然后是“慢路径”；它仍然可以工作，但速度较慢。'
- en: This fast path is taken in the absence of contention for the lock (that is,
    the lock is in an unlocked state to begin with). So, the lock is locked with no
    fuss, pretty much immediately. If, however, the mutex is already locked, then
    the kernel typically uses a mid path optimistic spinning implementation, making
    it more of a hybrid (mutex/spinlock) lock type. If even this isn't possible, the
    "slow path" is followed – the process context attempting to get the lock may well
    enter the sleep state. If you're interested in its internal implementation, more
    details can be found within the official kernel documentation: [https://www.kernel.org/doc/Documentation/locking/mutex-design.rst](https://www.kernel.org/doc/Documentation/locking/mutex-design.rst).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有锁争用的情况下（即，锁最初处于未锁定状态），会采用这条快速路径。因此，锁会立即被锁定，没有麻烦。然而，如果互斥锁已经被锁定，那么内核通常会使用中间路径的乐观自旋实现，使其更像是混合（互斥锁/自旋锁）锁类型。如果甚至这也不可能，就会遵循“慢路径”
    – 尝试获取锁的进程上下文可能会进入睡眠状态。如果您对其内部实现感兴趣，可以在官方内核文档中找到更多详细信息。
- en: '*LDV (Linux Driver Verification) project:* in the companion guide *Linux Kernel
    Programming -* *Chapter 1*, *Kernel Workspace Setup*, in the section *The LDV
    – Linux Driver Verification – project*, we mentioned that this project has useful
    "rules" with respect to various programming aspects of Linux modules (drivers,
    mostly) as well as the core kernel.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '*LDV（Linux驱动程序验证）项目：*在伴随指南*Linux内核编程 - 第1章*，*内核工作空间设置*的*LDV – Linux驱动程序验证 –
    项目*部分中，我们提到该项目对Linux模块（主要是驱动程序）以及核心内核的各种编程方面有有用的“规则”。'
- en: 'With regard to our current topic, here''s one of the rules: *Locking a mutex
    twice or unlocking without prior locking* ([http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0032](http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0032)).
    It mentions the kind of things you cannot do with the mutex lock (we have already
    covered this in the *Correctly using the mutex lock* section). The interesting
    thing here: you can see an actual example of a bug – a mutex lock double-acquire
    attempt, leading to (self) deadlock – in a kernel driver (as well as the subsequent
    fix).'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们当前的主题，这里有一个规则：*两次锁定互斥锁或在先前未锁定的情况下解锁*。它提到了您不能使用互斥锁做的事情（我们已经在*正确使用互斥锁*部分中涵盖了这一点）。有趣的是：您可以看到一个实际的bug示例
    – 一个互斥锁双重获取尝试，导致（自身）死锁 – 在内核驱动程序中（以及随后的修复）。
- en: Now that you've understood how to use the mutex lock, let's move on and look
    at the other very common lock within the kernel – the spinlock.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了如何使用互斥锁，让我们继续看看内核中另一个非常常见的锁 – 自旋锁。
- en: Using the spinlock
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自旋锁
- en: 'In the *Mutex or spinlock? Which to use when* section, you learned when to
    use the spinlock instead of the mutex lock and vice versa. For convenience, we
    have reproduced the key statements we provided previously here:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在*互斥锁还是自旋锁？何时使用*部分，您学会了何时使用自旋锁而不是互斥锁，反之亦然。为了方便起见，我们在此重复了我们之前提供的关键声明。
- en: '**Is the critical section running in an atomic (interrupt) context or in a
    process context where it cannot sleep?** Use the spinlock.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键部分是在原子（中断）上下文中运行还是在不能睡眠的进程上下文中运行？**使用自旋锁。'
- en: '**Is the critical section running in a process context and sleep in the critical section
    is necessary?** Use the mutex lock.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关键部分是在进程上下文中运行并且在关键部分中睡眠是必要的吗？**使用互斥锁。'
- en: In this section, we shall consider that you've now decided to use the spinlock.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们假设您现在决定使用自旋锁。
- en: Spinlock – simple usage
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自旋锁 - 简单用法
- en: For all the spinlock APIs, you must include the relevant header file; that is, `include
    <linux/spinlock.h>`.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有自旋锁API，您必须包括相关的头文件；即`include <linux/spinlock.h>`。
- en: 'Similar to the mutex lock, you *must* declare and initialize the spinlock to
    the unlocked state before use. The spinlock is an "object" that''s declared via
    the `typedef` data type named `spinlock_t` (internally, it''s a structure defined
    in `include/linux/spinlock_types.h`). It can be initialized dynamically via the
    `spin_lock_init()` macro:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 与互斥锁类似，您*必须*在使用之前声明和初始化自旋锁为未锁定状态。自旋锁是通过`typedef`数据类型`spinlock_t`（在内部，它是在`include/linux/spinlock_types.h`中定义的结构）声明的“对象”。它可以通过`spin_lock_init()`宏动态初始化：
- en: '[PRE19]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Alternatively, this can be performed statically (declared and initialized) with `DEFINE_SPINLOCK(lock);`.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，这可以通过`DEFINE_SPINLOCK(lock);`静态执行（声明和初始化）。
- en: 'As with the mutex, declaring a spinlock within the (global/static) data structure
    is meant to protect against concurrent access, and is typically a very good idea.
    As we mentioned earlier, this very idea is made use of within the kernel often;
    as an example, the data structure representing an open file on the Linux kernel
    is called `struct file`:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 与互斥锁一样，在（全局/静态）数据结构中声明自旋锁是为了防止并发访问，并且通常是一个非常好的主意。正如我们之前提到的，这个想法在内核中经常被使用；例如，表示Linux内核上打开文件的数据结构被称为`struct
    file`：
- en: '[PRE20]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Check it out: for the `file` structure, the spinlock variable named `f_lock` is
    the spinlock that protects the `f_ep_links` and `f_flags` members of the `file`
    data structure (it also has a mutex lock to protect another member; that is, the
    file''s current seek position – `f_pos`).'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下：对于`file`结构，名为`f_lock`的自旋锁变量是保护`file`数据结构的`f_ep_links`和`f_flags`成员的自旋锁（它还有一个互斥锁来保护另一个成员；即文件的当前寻位位置
    - `f_pos`）。
- en: 'How do you actually lock and unlock the spinlock? There are quite a few variations
    on the API that are exposed by the kernel to us module/driver authors; the simplest
    form of the spin(un)lock APIs are as folows:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何实际上锁定和解锁自旋锁？内核向我们模块/驱动程序作者公开了许多API的变体；自旋锁API的最简单形式如下：
- en: '[PRE21]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Note that there is no spinlock equivalent of the `mutex_destroy()` API.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`mutex_destroy()`API没有自旋锁的等效API。
- en: Now, let's see the spinlock APIs in action!
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看自旋锁API的实际应用！
- en: Spinlock – an example driver
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自旋锁 - 一个示例驱动程序
- en: 'Similar to what we did with our mutex locking sample driver (the *Mutex locking
    – an example driver* section), to illustrate the simple usage of a spinlock, we
    shall make a copy of our earlier `ch12/1_miscdrv_rdwr_mutexlock` driver as a starting template
    and then place it in a new kernel driver; that is, `ch12/2_miscdrv_rdwr_spinlock`.
    Again, here, we''ll only show small parts of the diff (the differences, the delta
    generated by `diff(1)`) between that program and this one (we won''t show every
    line of the diff, only the relevant portions):'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们的互斥锁示例驱动程序（*互斥锁 - 一个示例驱动程序*部分）所做的类似，为了说明自旋锁的简单用法，我们将复制我们之前的`ch12/1_miscdrv_rdwr_mutexlock`驱动程序作为起始模板，然后将其放置在一个新的内核驱动程序中；也就是`ch12/2_miscdrv_rdwr_spinlock`。同样，在这里，我们只会显示差异的小部分（`diff(1)`生成的差异，我们不会显示每一行差异，只显示相关部分）。
- en: '[PRE22]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This time, to protect the members of our `drv_ctx` global data structure, we
    have both the original mutex lock and a new spinlock. This is quite common; the
    mutex lock protects member usage in a critical section where blocking can occur,
    while the spinlock is used to protect members in critical sections where blocking
    (sleeping – recall that it might sleep) cannot occur.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次，为了保护我们的`drv_ctx`全局数据结构的成员，我们既有原始的互斥锁，又有一个新的自旋锁。这是相当常见的；互斥锁用于保护关键部分中可能发生阻塞的成员使用，而自旋锁用于保护关键部分中不会发生阻塞（睡眠
    - 请记住它可能会睡眠）的成员。
- en: 'Of course, we must ensure that we initialize all the locks so that they''re
    in the unlocked state. We can do this in the driver''s `init` code (continuing
    with the patch output):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们必须确保初始化所有锁，使它们处于未锁定状态。我们可以在驱动程序的`init`代码中执行这个操作（继续使用补丁输出）：
- en: '[PRE23]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'In the driver''s `open` method, we replace the mutex lock with the spinlock
    to protect the increments and decrements of the global integers:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在驱动程序的`open`方法中，我们用自旋锁替换互斥锁来保护全局整数的增量和减量：
- en: '[PRE24]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, within the driver''s `read` method, we use the spinlock instead of the
    mutex to protect some critical sections:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在驱动程序的`read`方法中，我们使用自旋锁而不是互斥锁来保护一些关键部分：
- en: '[PRE25]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'However, that''s not all! Continuing with the driver''s `read` method, carefully
    take a look at the following code and comment:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这还不是全部！继续使用驱动程序的`read`方法，仔细看一下以下代码和注释：
- en: '[PRE26]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: When protecting data where the critical section has possibly blocking APIs – such
    as in `copy_to_user()` – we *must* only use a mutex lock! (Due to lack of space,
    we haven't displayed more of the code diff here; we expect you to read through the
    spinlock sample driver code and try it out for yourself.)
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在保护关键部分可能有阻塞API的数据时 - 例如在`copy_to_user()`中 - 我们*必须*只使用互斥锁！（由于空间不足，我们没有在这里显示更多的代码差异；我们希望您阅读自旋锁示例驱动程序代码并自行尝试。）
- en: Test – sleep in an atomic context
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试 - 在原子上下文中睡眠
- en: You have already learned that the one thing we should *not do is sleep (block)
    in any kind of atomic or interrupt context*. Let's put this to the test. As always,
    the empirical approach – where you test things for yourself rather than relying
    on other's experiences – is key!
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学会了我们*不应该在任何类型的原子或中断上下文中睡眠（阻塞）*。让我们来测试一下。一如既往，经验主义方法 - 在测试自己的东西而不是依赖他人的经验时
    - 是关键！
- en: 'How exactly can we test this? Easy: we shall use a simple integer module parameter, `buggy`, that,
    when set to `1` (the default value being `0`), executes a code path within our
    spinlock''s critical section that violates this rule. We shall invoke the `schedule_timeout()`
    API (which, as you learned in [Chapter 5](c7d2d826-9d8a-439f-b843-06fa72db36b9.xhtml), *Working
    with Kernel Timers, Threads, and Workqueues*, in the *Understanding how to use
    the *sleep() blocking APIs* section) internally invokes `schedule()`; it''s how
    we go to sleep in the kernel space). Here''s the relevant code:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们究竟如何测试这个？很简单：我们将使用一个简单的整数模块参数`buggy`，当设置为`1`（默认值为`0`）时，会执行违反此规则的自旋锁临界区内的代码路径。我们将调用`schedule_timeout()`
    API（正如您在[第5章](c7d2d826-9d8a-439f-b843-06fa72db36b9.xhtml)中学到的，*使用内核定时器、线程和工作队列*，在*理解如何使用*sleep()阻塞API*部分中）内部调用`schedule()`；这是我们在内核空间中进入睡眠的方式）。以下是相关代码：
- en: '[PRE27]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, for the interesting part: let''s test this (buggy) code path in two kernels:
    first, in our custom 5.4 "debug" kernel (the kernel where we have enabled several
    kernel debug configuration options (mostly from the `Kernel Hacking` menu in `make
    menuconfig`), as explained in the companion guide *Linux Kernel Programming -* *Chapter
    5*, *Writing Your First Kernel Module – LKMs Part 2*), and second, on a generic
    distro (we usually run on Ubuntu) 5.4 kernel without any relevant kernel debug
    options enabled.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有趣的部分：让我们在两个内核中测试这个（错误的）代码路径：首先是在我们的自定义5.4“调试”内核中（我们在这个内核中启用了几个内核调试配置选项（主要是从`make
    menuconfig`中的`Kernel Hacking`菜单中），如伴随指南*Linux内核编程*-*第5章*，*编写您的第一个内核模块-LKMs第2部分*中所解释的），其次是在一个没有启用任何相关内核调试选项的通用发行版（我们通常在Ubuntu上运行）5.4内核上。
- en: Testing on a 5.4 debug kernel
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在5.4调试内核上进行测试
- en: 'First of all, ensure you''ve built the custom 5.4 kernel and that all the required
    kernel debug config options enabled (again, look back to the companion guide *Linux
    Kernel Programming -* *Chapter 5*, *Writing Your First Kernel Module – LKMs Part
    2*, the *Configuring a debug kernel* section if you need to). Then, boot off your
    debug kernel (here, it''s named `5.4.0-llkd-dbg`). Now, build the driver (in `ch12/2_miscdrv_rdwr_spinlock/`)
    against this debug kernel (the usual `make` within the driver''s directory should
    do this; you might find that, on the debug kernel, the build is noticeably slower!):'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 首先确保您已经构建了自定义的5.4内核，并且所有必需的内核调试配置选项都已启用（再次回到伴随指南*Linux内核编程*-*第5章*，*编写您的第一个内核模块-LKMs第2部分*，*配置调试内核*部分，如果需要的话）。然后，从调试内核启动（这里命名为`5.4.0-llkd-dbg`）。现在，在这个调试内核中构建驱动程序（在`ch12/2_miscdrv_rdwr_spinlock/`中）（在驱动程序目录中通常使用`make`命令即可完成；您可能会发现，在调试内核上，构建速度明显较慢！）：
- en: '[PRE28]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As you can see, we're running our custom 5.4.0 "debug" kernel on our x86_64
    Ubuntu 20.04 guest VM.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们在我们的x86_64 Ubuntu 20.04客户VM上运行我们的自定义5.4.0“调试”内核。
- en: How do you know whether you're running on a **virtual machine** (**VM**) or
    on the "bare metal" (native) system? `virt-what(1)` is a useful little script
    that shows this (you can install it on Ubuntu with `sudo apt install virt-what`).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 您如何知道自己是在**虚拟机**（VM）上运行还是在“裸机”（本机）系统上运行？`virt-what(1)`是一个有用的小脚本，可以显示这一点（您可以在Ubuntu上使用`sudo
    apt install virt-what`进行安装）。
- en: 'To run our test case, insert the driver into the kernel and set the `buggy` module
    parameter to `1`. Invoking the driver''s `read` method (via our user space app;
    that is, `ch12/miscdrv_rdwr/rdwr_test_secret`) isn''t an issue, as shown here:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行我们的测试用例，将驱动程序插入内核并将`buggy`模块参数设置为`1`。调用驱动程序的`read`方法（通过我们的用户空间应用程序；也就是`ch12/miscdrv_rdwr/rdwr_test_secret`）不是问题，如下所示：
- en: '[PRE29]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Next, we issue a `write(2)` to the driver via the user mode app; this time,
    our buggy code path gets executed. As you saw, we issued a `schedule_timeout()`
    within a spinlock critical section (that is, between the lock and unlock). The
    debug kernel detects this as a bug and spawns (impressively large) debug diagnostics
    into the kernel log (note that bugs like this can quite possibly hang your system,
    so test this on a VM first):'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们通过用户模式应用程序向驱动程序发出`write(2)`；这次，我们的错误代码路径被执行。正如您所看到的，我们在自旋锁的临界区内发出了`schedule_timeout()`（也就是在锁定和解锁之间）。调试内核将此检测为错误，并在内核日志中生成（令人印象深刻的大量）调试诊断（请注意，这样的错误很可能会使您的系统挂起，因此请先在虚拟机上进行测试）：
- en: '![](img/3c6f7129-6f1c-4a04-9f5c-df29e28b0420.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c6f7129-6f1c-4a04-9f5c-df29e28b0420.png)'
- en: Figure 6.9 – Kernel diagnostics being triggered by the "scheduling in atomic
    context" bug we've deliberately hit here
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.9-由我们故意触发的“在原子上下文中调度”错误触发的内核诊断
- en: 'The preceding screenshot shows part of what transpired (follow along while
    viewing the driver code in `ch12/2_miscdrv_rdwr_spinlock/2_miscdrv_rdwr_spinlock.c`):'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的屏幕截图显示了发生的部分情况（在查看`ch12/2_miscdrv_rdwr_spinlock/2_miscdrv_rdwr_spinlock.c`中的驱动程序代码时，请跟随一起）：
- en: 'First, we have our user mode app''s process context (`rdwr_test_secre`; notice
    how the name is truncated to the first 16 characters, including the `NULL` byte),
    which enters the driver''s write method; that is, `write_miscdrv_rdwr()`. This
    can be seen in the output of our useful `PRINT_CTX()` macro (we''ve reproduced
    this line here):'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们有我们的用户模式应用程序的进程上下文（`rdwr_test_secre`；请注意名称被截断为前16个字符，包括`NULL`字节），它进入驱动程序的写入方法；也就是`write_miscdrv_rdwr()`。这可以在我们有用的`PRINT_CTX()`宏的输出中看到（我们在这里重现了这一行）：
- en: '[PRE30]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: It copies in the new 'secret' from the user space writer process and writes
    it, for 24 bytes.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它从用户空间写入进程中复制新的“秘密”并将其写入，共24个字节。
- en: It then "takes" the spinlock, enters the critical section, and copies this data
    to the `oursecret` member of our driver's context structure.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，“获取”自旋锁，进入临界区，并将这些数据复制到我们驱动程序上下文结构的`oursecret`成员中。
- en: After this, `if (1 == buggy) {` evaluates to true.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，`if (1 == buggy) {`评估为true。
- en: 'Then, it calls `schedule_timeout()`, which is a blocking API (as it internally
    calls `schedule()`), triggering the bug, which is helpfully highlighted in red:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，它调用`schedule_timeout()`，这是一个阻塞API（因为它内部调用`schedule()`），触发了错误，这在红色中得到了很好的突出显示：
- en: '[PRE31]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The kernel now dumps a good deal of the diagnostic output. Among the first things
    to be dumped is the **call stack**.
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内核现在会输出大量的诊断输出。首先要输出的是**调用堆栈**。
- en: The call stack or stack backtrace (or "call trace") of the kernel mode stack
    of the process – here, it's our user space app, `rdwr_drv_secret`, which is running
    our (buggy) driver's code in the process context – can be clearly seen in *Figure
    6.9*. Each line after the `Call Trace:` header is essentially a call frame on
    the kernel stack.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 进程的内核模式堆栈或堆栈回溯（或“调用跟踪”）- 在这里，它是我们的用户空间应用程序`rdwr_drv_secret`，它正在运行我们（有缺陷的）驱动程序的代码在进程上下文中-
    可以在*图6.9*中清楚地看到。`Call Trace:`标题之后的每一行本质上都是内核堆栈上的一个调用帧。
- en: 'As a tip, ignore the stack frames that begin with the `?` symbol; they are
    literally questionable call frames, in all likelihood "leftovers" from previous
    stack usage in the same memory region. It''s worth taking a small memory-related
    diversion here: this is how stack allocation really works; stack memory isn''t
    allocated and freed on a per-call frame basis as that would be frightfully expensive.
    Only when a stack memory page is exhausted is a new one automatically *faulted
    in*! (Recall our discussions in the companion guide *Linux Kernel Programming
    -* *Chapter 9*, *Kernel Memory Allocation for Module Authors – Part 2*, in the *A
    brief note on memory allocations and demand paging* section.) So, the reality
    is that, as code calls and returns from functions, the same stack memory page(s)
    tend to keep getting reused.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提示，忽略以`?`符号开头的堆栈帧；它们很可能是同一内存区域中以前堆栈使用的“剩余物”。在这里值得进行一次与内存相关的小的偏离：这就是堆栈分配的真正工作原理；堆栈内存不是按照每个调用帧的基础分配和释放的，因为那将是非常昂贵的。只有在堆栈内存页耗尽时，才会自动*故障*新的内存页！（回想一下我们在伴随指南*Linux内核编程-第9章*，*模块作者的内核内存分配-第2部分*中的讨论，在*内存分配和需求分页的简短说明*部分。）因此，现实情况是，当代码调用和从函数返回时，相同的堆栈内存页往往会不断被重用。
- en: Not only that, but for performance reasons, the memory isn't wiped each time,
    leading to leftovers from previous frames often appearing. (They can literally
    "spoil" the picture. However, fortunately, the modern stack call frame tracing
    algorithms are usually able to do a superb job in figuring out the correct stack
    trace.)
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，出于性能原因，内存并不是每次都被擦除，这导致以前的帧留下的情况经常出现。（它们可以真正“破坏”图像。然而，幸运的是，现代堆栈调用帧跟踪算法通常能够出色地找出正确的堆栈跟踪。）
- en: 'Following the stack trace bottom-up (*always read it bottom-up*), we can see
    that, as expected, our user space `write(2)` system call (it often shows up as
    (something like) `SyS_write` or, on the x86, as `__x64_sys_write`, though not
    visible in *Figure 6.9*) invokes the kernel''s VFS layer code (you can see `vfs_write()` here,
    which calls `__vfs_write()`), which further invokes our driver''s write method;
    that is, `write_miscdrv_rdwr()`! This code, as we well know, invokes the buggy
    code path where we call `schedule_timeout()`, which, in turn, invokes `schedule()`
    (and `__schedule()`), causing the whole **`BUG: scheduling while atomic`** bug
    to trigger.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 从下到上（*总是从下到上阅读*）跟踪堆栈，我们可以看到，如预期的那样，我们的用户空间`write(2)`系统调用（它经常显示为（类似于）`SyS_write`或在x86上显示为`__x64_sys_write`，尽管在*图6.9*中看不到）调用了内核的VFS层代码（您可以在这里看到`vfs_write()`，它调用了`__vfs_write()`），进一步调用了我们驱动程序的写方法；也就是`write_miscdrv_rdwr()`！正如我们所知，这段代码调用了有缺陷的代码路径，我们在其中调用了`schedule_timeout()`，这又调用了`schedule()`（和`__schedule()`），导致整个**`BUG：scheduling
    while atomic`**错误触发。
- en: 'The format of the `scheduling while atomic` code path is retrieved from the
    following line of code, which can be found in `kernel/sched/core.c`:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '`scheduling while atomic`代码路径的格式是从以下代码行中检索的，该代码行可以在`kernel/sched/core.c`中找到：'
- en: '[PRE32]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Interesting! Here, you can see that it printed the following string:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣！在这里，您可以看到它打印了以下字符串：
- en: '[PRE33]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: After `atomic:`, it prints the process name – the PID – and then invokes the
    `preempt_count()` inline function, which prints the *preempt depth*; the preempt
    depth is a counter that's incremented every time a lock is taken and decremented
    on every unlock. So, if it's positive, this implies that the code is within a
    critical or atomic section; here, it shows as the value `2`.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在`atomic:`之后，它打印进程名称-PID-，然后调用`preempt_count()`内联函数，该函数打印*抢占深度*；抢占深度是一个计数器，每次获取锁时递增，每次解锁时递减。因此，如果它是正数，这意味着代码在关键或原子部分内；在这里，它显示为值`2`。
- en: 'Note that this bug gets neatly served up during this test run precisely because the `CONFIG_DEBUG_ATOMIC_SLEEP` debug
    kernel config option is turned on. It''s on because we''re running a custom "debug
    kernel" (kernel version 5.4.0)! The config option details (you can interactively
    find and set this option in `make menuconfig`, under the `Kernel Hacking` menu) are
    as follows:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个错误在这次测试运行中得到了很好的解决，因为`CONFIG_DEBUG_ATOMIC_SLEEP`调试内核配置选项已经打开。这是因为我们正在运行一个自定义的“调试内核”（内核版本5.4.0）！配置选项的详细信息（您可以在`make
    menuconfig`中交互地找到并设置此选项，在`Kernel Hacking`菜单下）如下：
- en: '[PRE34]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Testing on a 5.4 non-debug distro kernel
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在5.4非调试distro内核上进行测试
- en: As a contrasting test, we will now perform the very same thing on our Ubuntu
    20.04 LTS VM, which we'll boot via its default generic 'distro' 5.4 Linux kernel
    that is typically *not configured as a 'debug' kernel* (here, the `CONFIG_DEBUG_ATOMIC_SLEEP`
    kernel config option hasn't been set).
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 作为对比测试，我们现在将在我们的Ubuntu 20.04 LTS VM上执行完全相同的操作，我们将通过其默认的通用“distro” 5.4 Linux内核引导，通常*未配置为“调试”内核*（这里，`CONFIG_DEBUG_ATOMIC_SLEEP`内核配置选项尚未设置）。
- en: 'First, we insert our (buggy) driver. Then, when we run our `rdwr_drv_secret`
    process in order to write the new secret to the driver, the buggy code path gets
    executed. However, this time, the kernel *does not crash, nor does it report any
    issues at all* (looking at the `dmesg(1)` output validates this):'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们插入我们的（有缺陷的）驱动程序。然后，当我们运行我们的`rdwr_drv_secret`进程以向驱动程序写入新的秘密时，有缺陷的代码路径被执行。然而，这一次，内核*既不崩溃，也不报告任何问题*（查看`dmesg(1)`输出验证了这一点）：
- en: '[PRE35]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We know that our write method has a deadly bug, yet it doesn't seem to fail
    in any manner! This is really bad; it's this kind of thing that can erroneously
    lead you to conclude that your code is just fine when there's actually a nasty
    bug silently lying in wait to pounce one fine day!
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们的写入方法有一个致命的错误，但它似乎并没有以任何方式失败！这真的很糟糕；这种事情可能会误导你错误地认为你的代码很好，而实际上一个难以察觉的致命错误悄悄地等待着某一天突然袭击！
- en: 'To help us investigate what exactly is going on under the hood, let''s run
    our test app (the `rdwr_drv_secret` process) once more, but this time via the
    powerful `trace-cmd(1)` tool (a very useful wrapper over the Ftrace kernel infrastructure;
    the following is its truncated output:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们调查底层到底发生了什么，让我们再次运行我们的测试应用程序（`rdwr_drv_secret`进程），但这次通过强大的`trace-cmd（1）`工具（一个非常有用的包装器，覆盖了Ftrace内核基础设施；以下是它的截断输出：
- en: 'The Linux kernel''s **Ftrace** infrastructure is the kernel''s primary tracing infrastructure;
    it provides a detailed trace of pretty much every function that''s been executed
    in the kernel space. Here, we are leveraging Ftrace via a convenient frontend:
    the `trace-cmd(1)` utility. These are indeed very powerful and useful debug tools;
    we''ve mentioned several others in the companion guide *Linux Kernel Programming
    -* *Chapter 1*, *Kernel Workspace Setup*, but unfortunately, the details are beyond
    the scope of this book. Check out the man pages to learn more.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核的**Ftrace**基础设施是内核的主要跟踪基础设施；它提供了内核空间中几乎每个执行的函数的详细跟踪。在这里，我们通过一个方便的前端利用Ftrace：`trace-cmd（1）`实用程序。这些确实是非常强大和有用的调试工具；我们在伴随指南*
    Linux内核编程 - 第1章* *内核工作空间设置*中提到了其他几个，但不幸的是，这些细节超出了本书的范围。查看手册以了解更多。
- en: '[PRE36]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The output can be seen in the following screenshot:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 输出可以在以下截图中看到：
- en: '![](img/63b163f7-5ce7-45f1-907e-b10a06909ef3.png)'
  id: totrans-348
  prefs: []
  type: TYPE_IMG
  zh: '![](img/63b163f7-5ce7-45f1-907e-b10a06909ef3.png)'
- en: Figure 6.10 – A partial screenshot of the trace-cmd(1) report output
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.10 - trace-cmd（1）报告输出的部分截图
- en: As you can see, the `write(2)` system call from our user mode app becomes, as
    expected, `vfs_write()`, which itself (after security checks) invokes `__vfs_write()`,
    which, in turn, invokes our driver's write method – the `write_miscdrv_rdwr()`
    function!
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们用户模式应用程序的`write（2）`系统调用变成了预期的`vfs_write()`，它本身（经过安全检查后）调用了`__vfs_write()`，然后调用了我们的驱动程序的写入方法
    - `write_miscdrv_rdwr()`函数！
- en: 'In the (large) Ftrace output stream, we can see that the `schedule_timeout()` function
    has indeed been invoked:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 在（大量的）Ftrace输出流中，我们可以看到`schedule_timeout()`函数确实被调用了：
- en: '![](img/1cd0401a-b6a2-43e1-998d-10994995cdd6.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1cd0401a-b6a2-43e1-998d-10994995cdd6.png)'
- en: Figure 6.11 – A partial screenshot of the trace-cmd(1) report output, showing
    the (buggy!) calls to schedule_timeout() and schedule() within an atomic context
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.11 - trace-cmd（1）报告输出的部分截图，显示了在原子上下文中调用schedule_timeout()和schedule()的（错误的！）调用
- en: 'A few lines of output after `schedule_timeout()`, we can clearly see `schedule()` being
    invoked! So, there we have it: our driver has (deliberately, of course) performed
    something buggy – calling `schedule()` in an atomic context. But again, the key
    point here is that on this Ubuntu system, we are *not* running a "debug" kernel,
    which is why we have the following:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 在`schedule_timeout()`之后的几行输出中，我们可以清楚地看到`schedule()`被调用！所以，我们的驱动程序（当然是故意的）执行了一些错误的操作
    - 在原子上下文中调用`schedule()`。但这里的关键点是，在这个Ubuntu系统上，我们*没有*运行“调试”内核，这就是为什么我们有以下情况：
- en: '[PRE37]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This is why the bug isn't being reported! This proves the usefulness of running
    test cases – and indeed performing kernel development – on a "debug" kernel, a
    kernel with many debug features enabled. (As an exercise, if you haven't done
    so already, prepare a "debug" kernel and run this test case on it.)
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么错误没有被报告的原因！这证明了运行测试用例的有用性 - 事实上，在“调试”内核上进行内核开发 - 一个启用了许多调试功能的内核。（作为练习，如果您还没有这样做，请准备一个“调试”内核并在其上运行此测试用例。）
- en: '**Linux Driver Verification (LDV) project**: In the companion guide *Linux
    Kernel Programming -* *Chapter 1*, *Kernel Workspace Setup*, in the section *The
    LDV – Linux Driver Verification – project*, we mentioned that this project has
    useful "rules" with respect to various programming aspects of Linux modules (drivers,
    mostly) as well as the core kernel.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: Linux驱动程序验证（LDV）项目：在伴随指南* Linux内核编程 - 第1章* *内核工作空间设置*中，我们提到了这个项目对Linux模块（主要是驱动程序）以及核心内核的各种编程方面有用的“规则”。
- en: 'With regard to our current topic, here''s one of the rules: *Usage of spin
    lock and unlock functions* ([http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0039](http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0039)).
    It mentions key points with regard to the correct usage of spinlocks; interestingly,
    here, it shows an actual bug instance in a driver where a spinlock was attempted
    to be released twice – a clear violation of the locking rules, leading to an unstable
    system.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们当前的主题，这是其中一条规则：*使用自旋锁和解锁函数*（[http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0039](http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0039)）。它提到了关于正确使用自旋锁的关键点；有趣的是，它在这里展示了一个驱动程序中实际的错误实例，其中尝试两次释放自旋锁
    - 这是对锁定规则的明显违反，导致系统不稳定。
- en: Locking and interrupts
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁定和中断
- en: So far, we have learned how to use the mutex lock and, for the spinlock, the
    basic `spin_[un]lock()` APIs. A few other API variations on the spinlock exist,
    and we shall examine the more common ones here.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经学会了如何使用互斥锁，对于自旋锁，基本的`spin_[un]lock()` API。自旋锁还有一些其他API变体，我们将在这里检查更常见的一些。
- en: 'To understand exactly why you may need other APIs for spinlocks, let''s go
    over a scenario: as a driver author, you find that the device you''re working
    on asserts a hardware interrupt; accordingly, you write the interrupt handler
    for it. Now, while implementing a `read` method for your driver, you find that
    you have a non-blocking critical section within it. This is easy to deal with:
    as you have learned, you should use a spinlock to protect it. Great! But what
    if, while in the `read` method''s critical section, the device''s hardware interrupt
    fires? As you''re aware, *hardware interrupts preempt anything and everything*;
    thus, control will go to the interrupt handler code preempting the driver''s `read`
    method.'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确切理解为什么你可能需要其他的自旋锁API，让我们来看一个情景：作为驱动程序的作者，你发现你正在处理的设备断言了一个硬件中断；因此，你为其编写了中断处理程序。现在，在为你的驱动程序实现`read`方法时，你发现其中有一个非阻塞的临界区。这很容易处理：正如你所学的，你应该使用自旋锁来保护它。太好了！但是，如果在`read`方法的临界区内，设备的硬件中断触发了怎么办？正如你所知，*硬件中断会抢占任何事情*；因此，控制权将转移到中断处理程序代码，抢占了驱动程序的`read`方法。
- en: 'The key question here: is this an issue? That answer depends both on what your
    interrupt handler and your `read` method were doing and how they were implemented.
    Let''s visualize a few scenarios:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 关键问题在于：这是一个问题吗？答案取决于你的中断处理程序和`read`方法在做什么以及它们是如何实现的。让我们想象一些情景：
- en: The interrupt handler (ideally) uses only local variables, so even if the `read` method
    were in a critical section, it really doesn't matter; the interrupt handling will
    complete very quickly and control will be handed back to whatever was interrupted
    (again, there's more to it than this; as you know, any existing bottom-half, such
    as a tasklet or softirq, may also need to execute). In other words, as such, there
    is really no race in this case.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中断处理程序（理想情况下）仅使用局部变量，因此即使`read`方法处于临界区，它实际上并不重要；中断处理将非常快速地完成，并且控制权将被交还给被中断的内容（同样，这还不止这些；正如你所知，任何现有的底半部，比如任务let或软中断，也可能需要执行）。换句话说，在这种情况下实际上没有竞争。
- en: The interrupt handler is working on (global) shared writeable data but *not* on
    the data items that your read method is using. Thus, again, there is no conflict and
    no race with the read code. What you should realize, of course, is that the interrupt
    code *does have a critical section and that it must be protected* (perhaps with
    another spinlock).
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中断处理程序正在处理（全局）共享可写数据，但*不是*你的读取方法正在使用的数据项。因此，再次，没有冲突，也没有与读取代码的竞争。当然，你应该意识到，中断代码*确实有一个临界区，它必须受到保护*（也许需要另一个自旋锁）。
- en: The interrupt handler is working on the same global shared writeable data that your
    `read` method is using. In this case, we can see that the potential for a race
    definitely exists, so we need locking!
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中断处理程序正在处理与你的`read`方法使用的相同的全局共享可写数据。在这种情况下，我们可以看到存在竞争的潜力，因此我们需要锁！
- en: Let's focus on the third case. Obviously, we should use a spinlock to protect
    the critical section within the interrupt handling code (recall that using a mutex
    is disallowed when we're in any kind of interrupt context). Also, *unless we use
    the very same spinlock* in both the `read` method and the interrupt handler's
    code path, they will not be protected at all! (Be careful when working with locks;
    take the time to think through your design and code in detail.)
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们专注于第三种情况。显然，我们应该使用自旋锁来保护中断处理代码中的临界区（请记住，在任何类型的中断上下文中使用互斥锁是不允许的）。此外，*除非我们在`read`方法和中断处理程序的代码路径中都使用完全相同的自旋锁*，否则它们将根本得不到保护！（在处理锁时要小心；花时间仔细思考你的设计和代码细节。）
- en: 'Let''s try and make this a bit more hands-on (with pseudocode for now): let''s
    say we have a global (shared) data structure named `gCtx`; we''re operating on
    it in both the `read` method as well as the interrupt handler (hardirq handler)
    within our driver. Since it''s shared, it''s a critical section and therefore
    requires protection; since we are running in an atomic (interrupt) context, we
    *can''t use a mutex*, so we must use a spinlock instead (here, the spinlock variable
    is called `slock`). The following pseudocode shows some timestamps (`t1, t2, ...`)
    for this situation:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试更加实际一些（暂时使用伪代码）：假设我们有一个名为`gCtx`的全局（共享）数据结构；我们在驱动程序的`read`方法和中断处理程序（硬中断处理程序）中都在操作它。由于它是共享的，它是一个临界区，因此需要保护；由于我们在一个原子（中断）上下文中运行，我们*不能使用互斥锁*，因此必须使用自旋锁（这里，自旋锁变量称为`slock`）。以下伪代码显示了这种情况的一些时间戳（`t1，t2，...`）：
- en: '[PRE38]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The following pseudocode is for the device driver''s interrupt handler:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 以下伪代码是设备驱动程序的中断处理程序：
- en: '[PRE39]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'This can be summed up with the following diagram:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以用以下图表总结：
- en: '![](img/3d9d5f60-bb83-44a5-a694-2a05f28df4f8.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3d9d5f60-bb83-44a5-a694-2a05f28df4f8.png)'
- en: Figure 6.12 – Timeline – the driver's read method and hardirq handler run sequentially
    when working on global data; there's no issues here
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图6.12 - 时间轴 - 当处理全局数据时，驱动程序的读取方法和硬中断处理程序按顺序运行；这里没有问题
- en: Luckily, everything has gone well – "luckily" because the hardware interrupt
    fired *after *the `read` function's critical section completed. Surely we can't
    count on luck as the exclusive safety stamp of our product! The hardware interrupt
    is asynchronous; what if it fired at a less opportune time (for us) – say, while
    the `read` method's critical section is running between time t1 and t2? Well,
    isn't the spinlock going to do its job and protect our data?
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，一切都进行得很顺利 - “幸运”是因为硬件中断是在`read`函数的临界区完成之后触发的。当然，我们不能指望幸运成为我们产品的唯一安全标志！硬件中断是异步的；如果它在一个不太合适的时间（对我们来说）触发了
    - 比如，在`read`方法的临界区在时间t1和t2之间运行时怎么办？好吧，自旋锁会执行它的工作并保护我们的数据吗？
- en: 'At this point, the interrupt handler''s code will attempt to acquire the same
    spinlock (`&slock`). Wait a minute – it cannot "get" it as it''s currently locked!
    In this situation, it "spins", in effect waiting on the unlock. But how can it
    be unlocked? It cannot, and there we have it: a **(self) deadlock**.'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，中断处理程序的代码将尝试获取相同的自旋锁（`&slock`）。等一下——它无法“获取”它，因为它当前被锁定了！在这种情况下，它“自旋”，实际上是在等待解锁。但它怎么能解锁呢？它不能，这就是我们所面临的一个**(自身)死锁**。
- en: 'Interestingly, the spinlock is more intuitive and makes sense on an SMP (multicore)
    system. Let''s assume that the `read` method is running on CPU core 1; the interrupt
    can be delivered on another CPU core, say core 2\. The interrupt code path will
    "spin" on the lock on CPU core 2, while the `read` method, on core 1, completes
    the critical section and then unlocks the spinlock, thus unblocking the interrupt
    handler. But what about on **UP** (**uniprocessor**, with only one CPU core)?
    How will it work then? Ah, so here''s the solution to this conundrum: when "racing"
    with interrupts, *regardless of uniprocessor or SMP, simply use the* `_irq` *variant*
    *of the spinlock API*:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，自旋锁在SMP（多核）系统上更直观，更有意义。让我们假设`read`方法在CPU核心1上运行；中断可以在另一个CPU核心上，比如核心2上被传递。中断代码路径将在CPU核心2上的锁上“自旋”，而`read`方法在核心1上完成临界区，然后解锁自旋锁，从而解除中断处理程序的阻塞。但是在**UP**（单处理器，只有一个CPU核心）上呢？那么它会怎么工作呢？啊，所以这是解决这个难题的方法：当与中断“竞争”时，*无论是单处理器还是SMP，都简单地使用*自旋锁API*的*`_irq`
    *变体*：
- en: '[PRE40]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The `spin_lock_irq()` API internally disables interrupts on the processor core that
    it's running on; that is, the local core. So, by using this API in our `read`
    method, interrupts will be disabled on the local core, thus making any possible
    "race" impossible via interrupts. (If the interrupt does fire on another CPU core,
    the spinlock technology will simply work as advertised, as discussed previously!)
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '`spin_lock_irq()` API在处理器核心上禁用中断；也就是说，在本地核心上。因此，通过在我们的`read`方法中使用这个API，中断将在本地核心上被禁用，从而通过中断使任何可能的“竞争”变得不可能。（如果中断在另一个CPU核心上触发，自旋锁技术将像之前讨论的那样正常工作！）'
- en: The `spin_lock_irq()` implementation is pretty nested (as with most of the spinlock
    functionality), yet fast; down the line, it ends up invoking the `local_irq_disable()`
    and `preempt_disable()` macros, disabling both interrupts and kernel preemption
    on the local processor core that it's running on. (Disabling hardware interrupts
    has the (desirable) side effect of disabling kernel preemption as well.)
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '`spin_lock_irq()`的实现是相当嵌套的（就像大多数自旋锁功能一样），但是很快；在下一行，它最终调用了`local_irq_disable()`和`preempt_disable()`宏，在运行它的本地处理器核心上禁用了中断和内核抢占。（禁用硬件中断也会有禁用内核抢占的（理想的）副作用。）'
- en: '`spin_lock_irq()` pairs off with the corresponding `spin_unlock_irq()` API.
    So, the correct usage of the spinlock for this scenario (as opposed to what we
    saw previously) is as follows:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '`spin_lock_irq()`与相应的`spin_unlock_irq()` API配对。因此，对于这种情况（与我们之前看到的情况相反），自旋锁的正确用法如下：'
- en: '[PRE41]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Before patting ourselves solidly on the back and taking the rest of the day
    off, let''s consider another scenario. This time, on a more complex product (or
    project), it''s quite possible that, among the several developers working on the
    code base, one has deliberately set the interrupt mask to a certain value, thus blocking
    some interrupts while allowing others. For the sake of our example, let''s say
    that this has occurred earlier, at some point in time `t0`. Now, as we described
    previously, another developer (you!) comes along, and in order to protect a critical
    section within the driver''s read method, uses the `spin_lock_irq()` API. Sounds
    correct, yes? Yes, but this API has the power *to turn off (mask) all hardware
    interrupts* (and kernel preemption, which we''ll ignore for now) on the local
    CPU core. It does so by manipulating, at a low level, the (very arch-specific)
    hardware interrupt mask register. Let''s say that setting a bit corresponding
    to an interrupt to `1` enables that interrupt, while clearing the bit (to `0`)
    disables or masks it. Due to this, we may end up with the following scenario:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们自满地拍拍自己的背并休息一天之前，让我们考虑另一种情况。这一次，在一个更复杂的产品（或项目）上，有可能在代码库上工作的几个开发人员中，有人故意将中断屏蔽设置为某个值，从而阻止一些中断，同时允许其他中断。为了我们的例子，让我们假设这在某个时间点`t0`之前发生过。现在，正如我们之前描述的，另一个开发人员（你！）过来了，为了保护驱动程序`read`方法中的临界区，使用了`spin_lock_irq()`
    API。听起来正确，是吗？是的，但是这个API有权利*关闭（屏蔽）所有硬件中断*（和内核抢占，我们现在将忽略）。它通过在低级别上操作（非常特定于架构的）硬件中断屏蔽寄存器来做到这一点。假设将与中断对应的位设置为`1`会启用该中断，而清除该位（为`0`）会禁用或屏蔽它。由于这个原因，我们可能会得到以下情况：
- en: 'time `t0`: The interrupt mask is set to some value, say, `0x8e (10001110b)`,
    enabling some and disabling some interrupts. This is important to the project
    (here, for simplicity, we''re assuming there''s an 8-bit mask register)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间`t0`：中断屏蔽被设置为某个值，比如`0x8e (10001110b)`，启用了一些中断并禁用了一些中断。这对项目很重要（在这里，为了简单起见，我们假设有一个8位掩码寄存器）
- en: '*[... time elapses ... ].*'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: '*[...时间流逝...].*'
- en: 'time `t1`: Just before entering the driver `read` method''s critical section,
    call'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间`t1`：就在进入驱动程序`read`方法的临界区之前，调用
- en: '`spin_lock_irq(&slock);`. This API will have the internal effect of clearing
    all the bits in the interrupt mask registered to `0`, thus disabling all interrupts
    (as we *think* we desire).'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: '`spin_lock_irq(&slock);`。这个API的内部效果是将中断屏蔽寄存器中的所有位清零，从而禁用所有中断（正如我们*认为*我们所期望的）。'
- en: time `t2`: Now, hardware interrupts cannot fire on this CPU core, so we go ahead
    and complete the critical section. Once we're done, we call `spin_unlock_irq(&slock);`.
    This API will have the internal effect of setting all the bits in the interrupt
    mask register to `1`, reenabling all interrupts.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间`t2`：现在，硬件中断无法在这个CPU核心上触发，所以我们继续完成临界区。完成后，我们调用`spin_unlock_irq(&slock);`。这个API的内部效果是将中断屏蔽寄存器中的所有位设置为`1`，重新启用所有中断。
- en: However, the interrupt mask register has now been wrongly "restored" to a value
    of `0xff (11111111b)`, *not the value* `0x8e` as the original developer wants,
    requires, and assumes! This can (and probably will) break something in the project.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，中断掩码寄存器现在被错误地“恢复”为`0xff (11111111b)`的值，*而不是*原始开发人员想要、需要和假设的`0x8e`的值！这可能会（并且可能会）在项目中出现问题。
- en: 'The solution is quite straightforward: don''t assume anything, **simply save
    and restore the interrupt mask**. This can be achieved with the following API
    pair:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案非常简单：不要假设任何东西，**只需保存和恢复中断掩码**。可以通过以下API对实现这一点：
- en: '[PRE42]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The first parameter to both the lock and unlock functions is the spinlock variable
    to use. The second parameter, `flags`, *must be a local variable* of the `unsigned
    long` type. This will be used to save and restore the interrupt mask:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 锁定和解锁函数的第一个参数都是要使用的自旋锁变量。第二个参数`flags` *必须是*`unsigned long`类型的本地变量。这将用于保存和恢复中断掩码：
- en: '[PRE43]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: To be pedantic, `spin_lock_irqsave()` is not an API, but a macro; we've shown
    it as an API for readability. Also, although the return value of this macro is
    not void, it's an internal detail (the `flags` parameter variable is updated here).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 要严格，`spin_lock_irqsave()`不是一个API，而是一个宏；我们将其显示为API是为了可读性。此宏的返回值虽然不是void，但这是一个内部细节（这里更新了`flags`参数变量）。
- en: 'What about if a tasklet or a softirq (a bottom-half interrupt mechanism) has
    a critical section that "races" with your process-context code paths? In such
    situations, using the `spin_lock_bh()` routine is likely what''s required since
    it can disable bottom halves on the local processor and then take the spinlock,
    thus safeguarding the critical section (similar to the way that `spin_lock_irq[save]()`
    protects the critical section in the process context by disabling hardware interrupts
    on the local core):'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个任务或软中断（底半部中断机制）有一个关键部分与您的进程上下文代码路径“竞争”，在这种情况下，使用`spin_lock_bh()`例程可能是所需的，因为它可以在本地处理器上禁用底半部，然后获取自旋锁，从而保护关键部分（类似于`spin_lock_irq[save]()`在进程上下文中保护关键部分，通过在本地核心上禁用硬件中断）：
- en: '[PRE44]'
  id: totrans-395
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Of course, *overhead* does matter in highly performance-sensitive code paths
    (the network stack being a great example). Thus, using the simplest form of spinlocks
    will help with more complex variants. Having said that, though, there are certainly
    going to be occasions that demand the use of the stronger forms of the spinlock
    API. For example, on the 5.4.0 Linux kernel, this is an approximation of the number
    of usage instances of different forms of the spinlock APIs we have seen: `spin_lock()`:
    over 9,400 usage instances; `spin_lock_irq()`: over 3,600 usage instances; `spin_lock_irqsave()`:
    over 15,000 usage instances; and `spin_lock_bh()`: over 3,700 usage instances.
    (We don''t draw any major inference from this; it''s just that we wish to point
    out that using the stronger form of spinlock APIs is quite widespread in the Linux
    kernel).'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，*开销*在高性能敏感的代码路径中很重要（网络堆栈是一个很好的例子）。因此，使用最简单形式的自旋锁将有助于处理更复杂的变体。尽管如此，肯定会有需要使用更强形式的自旋锁API的情况。例如，在Linux内核5.4.0上，这是我们看到的不同形式自旋锁API的使用实例数量的近似值：`spin_lock()`:超过9,400个使用实例；`spin_lock_irq()`:超过3,600个使用实例；`spin_lock_irqsave()`:超过15,000个使用实例；和`spin_lock_bh()`:超过3,700个使用实例。（我们不从中得出任何重大推论；只是我们希望指出，在Linux内核中广泛使用更强形式的自旋锁API）。
- en: 'Finally, let''s provide a very brief note on the internal implementation of
    the spinlock: in terms of under-the-hood internals, the implementation tends to
    be very arch-specific code, often comprised of atomic machine language instructions
    that execute very fast on the microprocessor. On the popular x86[_64] architecture,
    for example, the spinlock ultimately boils down to an *atomic test-and-set* machine
    instruction on a member of the spinlock structure (typically implemented via the
    `cmpxchg` machine language instruction). On ARM machines, as we mentioned earlier,
    it''s often the `wfe` (Wait For Event, as well as the **SetEvent** (**SEV**))
    machine instruction at the heart of the implementation. (You will find resources
    regarding its internal implementation in the *Further reading *section). Regardless,
    as a kernel or driver author, you should only use the exposed APIs (and macros)
    when using spinlocks.'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们简要介绍一下自旋锁的内部实现：在底层内部实现方面，实现往往是非常特定于体系结构的代码，通常由在微处理器上执行非常快的原子机器语言指令组成。例如，在流行的x86[_64]体系结构上，自旋锁最终归结为自旋锁结构的成员上的*原子测试和设置*机器指令（通常通过`cmpxchg`机器语言指令实现）。在ARM机器上，正如我们之前提到的，实现的核心通常是`wfe`（等待事件，以及**SetEvent**（**SEV**））机器指令。（您将在*进一步阅读*部分找到关于其内部实现的资源）。无论如何，作为内核或驱动程序的作者，您在使用自旋锁时应该只使用公开的API（和宏）。
- en: Using spinlocks – a quick summary
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用自旋锁-快速总结
- en: 'Let''s quickly summarize spinlocks:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速总结一下自旋锁：
- en: '**Simplest, lowest overhead**: Use the non-irq spinlock primitives, `spin_lock()`/`spin_unlock()`,
    when protecting critical sections in the process context (there''s either no interrupts
    to deal with or there are interrupts, but we do not race with them at all; in
    effect, use this when interrupts don''t come into play or don''t matter).'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最简单，开销最低**：在保护进程上下文中的关键部分时，请使用非irq自旋锁原语`spin_lock()`/`spin_unlock()`（要么没有中断需要处理，要么有中断，但我们根本不与它们竞争；实际上，当中断不发挥作用或不重要时使用这个）。'
- en: '**Medium overhead**: Use the irq-disabling (as well as kernel preemption disabling) versions,
    `spin_lock_irq() / spin_unlock_irq()`, when interrupts are in play and do matter
    (the process and interrupt contexts can "race"; that is, they share global data).'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中等开销**：当中断发挥作用并且很重要时，请使用禁用irq（以及内核抢占禁用）版本的`spin_lock_irq() / spin_unlock_irq()`（进程和中断上下文可能会“竞争”；也就是说，它们共享全局数据）。'
- en: '**Strongest (relatively), high overhead**: This is the safest way to use a
    spinlock. It does the same as the medium overhead, except it performs a save-and-restore
    on the interrupt mask via the `spin_lock_irqsave()` / `spin_unlock_irqrestore()` pair,
    so as to guarantee that the previous interrupt mask settings aren''t inadvertently
    overwritten, which could happen with the previous case.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最强（相对）高开销**：这是使用自旋锁的最安全方式。它与中等开销的方式相同，只是通过`spin_lock_irqsave()` / `spin_unlock_irqrestore()`对中断掩码执行保存和恢复，以确保以前的中断掩码设置不会被意外覆盖，这可能会发生在前一种情况下。'
- en: As we saw earlier, the spinlock – in the sense of "spinning" on the processor
    it's running on when awaiting the lock – is impossible on UP (how can you spin
    on the one CPU that's available while another thread runs simultaneously on the
    very same CPU?). Indeed, on UP systems, the only real effect of the spinlock APIs
    is that it can disable hardware interrupts and kernel preemption on the processor!
    On SMP (multicore) systems, however, the spinning logic actually comes into play,
    and thus the locking semantics work as expected. But hang on – this should not
    stress you, budding kernel/driver developer; in fact, the whole point is that
    you should simply use the spinlock APIs as described and you will never have to
    worry about UP versus SMP; the details of what is done and what isn't are all
    hidden by the internal implementation.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所看到的，自旋锁 - 在等待锁时在其运行的处理器上“自旋” - 在UP系统上是不可能的（在另一个线程同时在同一CPU上运行时，您如何在仅有的一个CPU上自旋？）。实际上，在UP系统上，自旋锁API的唯一真正效果是它可以禁用处理器上的硬件中断和内核抢占！然而，在SMP（多核）系统上，自旋逻辑实际上会发挥作用，因此锁定语义会按预期工作。但是请注意
    - 这不应该让您感到压力，新手内核/驱动程序开发人员；事实上，整个重点是您应该简单地按照描述使用自旋锁API，您将永远不必担心UP与SMP之间的区别；做什么和不做什么的细节都被内部实现隐藏起来。
- en: 'Though this book is based on the 5.4 LTS kernel, a new feature was added to
    the 5.8 kernel from the **Real-Time Linux** (**RTL**, previously called PREEMPT_RT)
    project, which deserves a quick mention here: "**local locks**". While the main
    use case for local locks is for (hard) real-time kernels, they help with non-real-time
    kernels too, mainly for lock debugging via static analysis, as well as runtime
    debugging via lockdep (we cover lockdep in the next chapter). Here''s the LWN
    article on the subject: [https://lwn.net/Articles/828477/](https://lwn.net/Articles/828477/).'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书基于5.4 LTS内核，但从**实时Linux**（**RTL**，以前称为PREEMPT_RT）项目中添加了一个新功能到5.8内核，值得在这里快速提一下：“**本地锁**”。虽然本地锁的主要用例是用于（硬）实时内核，但它们也对非实时内核有所帮助，主要用于通过静态分析进行锁调试，以及通过lockdep进行运行时调试（我们将在下一章中介绍lockdep）。这是有关该主题的LWN文章：[https://lwn.net/Articles/828477/](https://lwn.net/Articles/828477/)。
- en: With this, we complete the section on spinlocks, an extremely common and key
    lock used in the Linux kernel by virtually all its subsystems, including drivers.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一部分，我们完成了自旋锁的部分，这是Linux内核中几乎所有子系统（包括驱动程序）都使用的一种极为常见和关键的锁。
- en: Summary
  id: totrans-406
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congratulations on completing this chapter!
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 祝贺您完成了本章！
- en: Understanding concurrency and its related concerns is absolutely critical for
    any software professional. In this chapter, you learned key concepts regarding
    critical sections, the need for exclusive execution within them, and what atomicity
    means. You then learned *why *we need to be concerned with concurrency while writing
    code for the Linux OS. After that, we delved into the actual locking technologies –
    mutex locks and spinlocks – in detail. You also learned what lock you should use
    and when. Finally, learning how to handle concurrency concerns when hardware interrupts
    (and their possible bottom halves) are in play was covered.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 理解并发性及其相关问题对于任何软件专业人员来说都是非常关键的。在本章中，您学习了关于临界区的关键概念，其中需要在其中进行独占执行，以及原子性的含义。然后，您了解了在为Linux操作系统编写代码时为什么需要关注并发性。之后，我们详细探讨了实际的锁技术
    - 互斥锁和自旋锁。您还学会了在何时使用哪种锁。最后，学习了在硬件中断（以及可能的底半部分）参与时如何处理并发性问题。
- en: But we aren't done yet! There are many more concepts and technologies we need
    to learn about, which is just what we will do in the next, and final, chapter
    of this book. I suggest that you digest the content of this chapter well first
    by browsing through it, as well as the resources in the *Further reading *section
    and the exercises provided, before diving into the last chapter!
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们还没有完成！我们还需要学习更多概念和技术，这正是我们将在本书的下一章，也是最后一章中要做的。我建议您先浏览本章的内容，以及*进一步阅读*部分和提供的练习，然后再深入研究最后一章！
- en: Questions
  id: totrans-410
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter''s material: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions).
    You will find some of the questions answered in the book''s GitHub repo: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn).'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们的结束，这里有一些问题供您测试对本章材料的了解：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions)。您会在书的GitHub存储库中找到一些问题的答案：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn)。
- en: Further reading
  id: totrans-412
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: To help you delve deeper into the subject with useful materials, we provide
    a rather detailed list of online references and links (and at times, even books)
    in a Further reading document in this book's GitHub repository. The *Further reading*
    document is available here: [https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md).
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您深入了解这个主题并提供有用的材料，我们在本书的GitHub存储库中提供了一个相当详细的在线参考和链接列表（有时甚至包括书籍）。*进一步阅读*文档在这里可用：[https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md)。
