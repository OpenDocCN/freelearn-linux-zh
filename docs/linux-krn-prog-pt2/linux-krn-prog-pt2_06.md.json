["```\nCalibrating delay loop (skipped), value calculated using timer frequency.. 5199.98 BogoMIPS (lpj=10399968)\n```", "```\n__set_current_state(TASK_UNINTERRUPTIBLE);\nreturn schedule_timeout(timeout);\n```", "```\n#ifdef __KERNEL__\nvoid delay_sec(long);\n/*------------ delay_sec --------------------------------------------------\n * Delays execution for @val seconds.\n * If @val is -1, we sleep forever!\n * MUST be called from process context.\n * (We deliberately do not inline this function; this way, we can see it's\n * entry within a kernel stack call trace).\n */\nvoid delay_sec(long val)\n{\n    asm (\"\"); // force the compiler to not inline it!\n    if (in_task()) {\n        set_current_state(TASK_INTERRUPTIBLE);\n        if (-1 == val)\n            schedule_timeout(MAX_SCHEDULE_TIMEOUT);\n        else\n            schedule_timeout(val * HZ);\n    } \n}\n#endif /* #ifdef __KERNEL__ */\n```", "```\nu64 ktime_get_real_ns(void);\n```", "```\n#include <linux/ktime.h>\nt1 = ktime_get_real_ns();\nfoo();\nbar();\nt2 = ktime_get_real_ns();\ntime_taken_ns = (t2 -> t1);\n```", "```\nDILLY_DALLY(\"udelay() for     10,000 ns\", udelay(10));\n```", "```\n// ch5/delays_sleeps/delays_sleeps.c\n/*\n * DILLY_DALLY() macro:\n * Runs the code @run_this while measuring the time it takes; prints the string\n * @code_str to the kernel log along with the actual time taken (in ns, us\n * and ms).\n * Macro inspired from the book 'Linux Device Drivers Cookbook', PacktPub.\n */\n#define DILLY_DALLY(code_str, run_this) do {    \\\n    u64 t1, t2;                                 \\\n    t1 = ktime_get_real_ns();                   \\\n run_this;                                   \\\n t2 = ktime_get_real_ns();                   \\\n    pr_info(code_str \"-> actual: %11llu ns = %7llu us = %4llu ms\\n\", \\\n        (t2-t1), (t2-t1)/1000, (t2-t1)/1000000);\\\n} while(0)\n```", "```\n    [ ... ]\n    /* Atomic busy-loops, no sleep! */\n    pr_info(\"\\n1\\. *delay() functions (atomic, in a delay loop):\\n\");\n    DILLY_DALLY(\"ndelay() for         10 ns\", ndelay(10));\n    /* udelay() is the preferred interface */\n    DILLY_DALLY(\"udelay() for     10,000 ns\", udelay(10));\n    DILLY_DALLY(\"mdelay() for 10,000,000 ns\", mdelay(10));\n\n    /* Non-atomic blocking APIs; causes schedule() to be invoked */\n    pr_info(\"\\n2\\. *sleep() functions (process ctx, sleeps/schedule()'s out):\\n\");\n    /* usleep_range(): HRT-based, 'flexible'; for approx range [10us - 20ms] */\n    DILLY_DALLY(\"usleep_range(10,10) for 10,000 ns\", usleep_range(10, 10));\n    /* msleep(): jiffies/legacy-based; for longer sleeps (> 10ms) */\n    DILLY_DALLY(\"msleep(10) for      10,000,000 ns\", msleep(10));\n    DILLY_DALLY(\"msleep_interruptible(10)         \", msleep_interruptible(10));\n    /* ssleep() is a wrapper over msleep(): = msleep(ms*1000); */\n    DILLY_DALLY(\"ssleep(1)                        \", ssleep(1));\n```", "```\n// include/linux/delay.h\n/*\n [ ... ]\n * Delay routines, using a pre-computed \"loops_per_jiffy\" value.\n *\n * Please note that ndelay(), udelay() and mdelay() may return early for\n * several reasons:\n * 1\\. computed loops_per_jiffy too low (due to the time taken to\n * execute the timer interrupt.)\n * 2\\. cache behavior affecting the time it takes to execute the\n * loop function.\n * 3\\. CPU clock rate changes.\n *\n * Please see this thread:\n * http://lists.openwall.net/linux-kernel/2011/01/09/56\n```", "```\n$ cd <...>/ch5/delays_sleeps $ make checkpatch \nmake clean\n[ ... ]\n--- cleaning ---\n[ ... ]\n--- kernel code style check with checkpatch.pl ---\n\n/lib/modules/5.4.0-58-generic/build/scripts/checkpatch.pl --no-tree -f --max-line-length=95 *.[ch]\n[ ... ]\nWARNING: usleep_range should not use min == max args; see Documentation/timers/timers-howto.rst\n#63: FILE: delays_sleeps.c:63:\n+ DILLY_DALLY(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\", usleep_range(10, 10));\n\ntotal: 0 errors, 2 warnings, 79 lines checked\n[ ... ]\n```", "```\n// include/linux/timer.h\nstruct timer_list {[ ... ]\n    unsigned long expires;\n    void (*function)(struct timer_list *);\n    u32 flags; \n[ ...] };\n```", "```\ntimer_setup(timer, callback, flags);\n```", "```\n// include/linux/timer.h\n/**\n * @TIMER_DEFERRABLE: A deferrable timer will work normally when the\n * system is busy, but will not cause a CPU to come out of idle just\n * to service it; instead, the timer will be serviced when the CPU\n * eventually wakes up with a subsequent non-deferrable timer.\n  [ ... ]\n * @TIMER_PINNED: A pinned timer will not be affected by any timer\n * placement heuristics (like, NOHZ) and will always expire on the CPU\n * on which the timer was enqueued.\n```", "```\nvoid add_timer(struct timer_list *timer);\n```", "```\n// ch5/timer_simple/timer_simple.c\n#include <linux/timer.h>\n[ ... ]\nstatic struct st_ctx {\n    struct timer_list tmr;\n    int data;\n} ctx;\nstatic unsigned long exp_ms = 420;\n```", "```\nstatic int __init timer_simple_init(void)\n{\n    ctx.data = INITIAL_VALUE;\n\n    /* Initialize our kernel timer */\n    ctx.tmr.expires = jiffies + msecs_to_jiffies(exp_ms);\n    ctx.tmr.flags = 0;\n    timer_setup(&ctx.tmr, ding, 0);\n```", "```\nctx.tmr.expires = jiffies + msecs_to_jiffies(exp_ms);\n```", "```\n    pr_info(\"timer set to expire in %ld ms\\n\", exp_ms);\n    add_timer(&ctx.tmr); /* Arm it; let's get going! */\n    return 0;     /* success */\n}\n```", "```\nstatic void ding(struct timer_list *timer)\n{\n    struct st_ctx *priv = from_timer(priv, timer, tmr);\n    /* from_timer() is in fact a wrapper around the well known\n     * container_of() macro! This allows us to retrieve access to our\n     * 'parent' driver context structure */\n    pr_debug(\"timed out... data=%d\\n\", priv->data--);\n    PRINT_CTX();\n\n    /* until countdown done, fire it again! */\n    if (priv->data)\n        mod_timer(&priv->tmr, jiffies + msecs_to_jiffies(exp_ms));\n}\n```", "```\n // include/linux/timer.h\n #define from_timer(var, callback_timer, timer_fieldname) \\\n           container_of(callback_timer, typeof(*var), timer_fieldname)\n\n```", "```\nint mod_timer(struct timer_list *timer, unsigned long expires);\n```", "```\n[ 4234.290177] timer_simple:ding(): 001) [swapper/1]:0   |  ..s1   /* ding() */\n```", "```\n\u200b kd->data_xform = XF_ENCRYPT;\n ioctl(fd, IOCTL_LLKD_SED_IOC_ENCRYPT_MSG, kd);\n```", "```\n// ch5/sed1/sed1_driver/sed1_drv.c\n[ ... ]\nstatic void encrypt_decrypt_payload(int work, struct sed_ds *kd, struct sed_ds *kdret)\n{\n        int i;\n        ktime_t t1, t2;   // a s64 qty\n        struct stMyCtx *priv = gpriv;\n        [ ... ]\n        /* Start - the timer; set it to expire in TIMER_EXPIRE_MS ms */\n        mod_timer(&priv->timr, jiffies + msecs_to_jiffies(TIMER_EXPIRE_MS));\n        t1 = ktime_get_real_ns();\n\n        // perform the actual processing on the payload\n        memcpy(kdret, kd, sizeof(struct sed_ds));\n        if (work == WORK_IS_ENCRYPT) {\n                for (i = 0; i < kd->len; i++) {\n                        kdret->data[i] ^= CRYPT_OFFSET;\n                        kdret->data[i] += CRYPT_OFFSET;\n                }\n        } else if (work == WORK_IS_DECRYPT) {\n                for (i = 0; i < kd->len; i++) {\n                        kdret->data[i] -= CRYPT_OFFSET;\n                        kdret->data[i] ^= CRYPT_OFFSET;\n                }\n        }\n        kdret->len = kd->len;\n        // work done!\n        [ ... // code to miss the deadline here! (explained below) ... ]\n        t2 = ktime_get_real_ns();\n\n        // work done, cancel the timeout\n        if (del_timer(&priv->timr) == 0)\n                pr_debug(\"cancelled the timer while it's inactive! (deadline missed?)\\n\");\n        else\n                pr_debug(\"processing complete, timeout cancelled\\n\");\n        SHOW_DELTA(t2, t1);\n}\n```", "```\n$ sudo insmod ./sed1_drv.ko\n$ dmesg \n[29519.684832] misc sed1_drv: LLKD sed1_drv misc driver (major # 10) registered, minor# = 55,\n dev node is /dev/sed1_drv\n[29519.689403] sed1_drv:sed1_drv_init(): init done (make_it_fail is off)\n[29519.690358] misc sed1_drv: loaded.\n$ \n```", "```\nstatic void timesup(struct timer_list *timer)\n{\n    struct stMyCtx *priv = from_timer(priv, timer, timr);\n\n    atomic_set(&priv->timed_out, 1);\n    pr_notice(\"*** Timer expired! ***\\n\");\n    PRINT_CTX();\n}\n```", "```\nstatic void encrypt_decrypt_payload(int work, struct sed_ds *kd, struct sed_ds *kdret)\n{\n    [ ... ]\n    // work done!\n    if (make_it_fail == 1)\n msleep(TIMER_EXPIRE_MS + 1);\n    t2 = ktime_get_real_ns();\n```", "```\n$ ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY        STAT START   TIME COMMAND\nroot           1  0.0  0.5 167464 11548 ?          Ss   06:20   0:00 /sbin/init splash 3\nroot           2  0.0  0.0      0     0 ?          S    06:20   0:00 [kthreadd]\nroot           3  0.0  0.0      0     0 ?          I<   06:20   0:00 [rcu_gp]\nroot           4  0.0  0.0      0     0 ?          I<   06:20   0:00 [rcu_par_gp]\nroot           6  0.0  0.0      0     0 ?          I<   06:20   0:00 [kworker/0:0H-kblockd]\nroot           9  0.0  0.0      0     0 ?          I<   06:20   0:00 [mm_percpu_wq]\nroot          10  0.0  0.0      0     0 ?          S    06:20   0:00 [ksoftirqd/0]\nroot          11  0.0  0.0      0     0 ?          I    06:20   0:05 [rcu_sched]\nroot          12  0.0  0.0      0     0 ?          S    06:20   0:00 [migration/0]\n[ ... ]\nroot          18  0.0  0.0      0     0 ?          S    06:20   0:00 [ksoftirqd/1]\n[ ... ]\n```", "```\n// include/linux/kthread.h\n/**\n * kthread_run - create and wake a thread.\n * @threadfn: the function to run until signal_pending(current).\n * @data: data ptr for @threadfn.\n * @namefmt: printf-style name for the thread.\n *\n * Description: Convenient wrapper for kthread_create() followed by\n * wake_up_process(). Returns the kthread or ERR_PTR(-ENOMEM).\n */\n#define kthread_run(threadfn, data, namefmt, ...) \\\n({ \\\n    struct task_struct *__k \\\n        = kthread_create(threadfn, data, namefmt, ## __VA_ARGS__); \\\n    if (!IS_ERR(__k)) \\\n        wake_up_process(__k); \\\n    __k; \\\n})\n```", "```\n// ch5/kthread_simple/kthread_simple.c\nstatic int kthread_simple_init(void)\n{   [ ... ]\n    gkthrd_ts = kthread_run(simple_kthread, NULL, \"llkd/%s\", KTHREAD_NAME);\n    if (IS_ERR(gkthrd_ts)) {\n        ret = PTR_ERR(gkthrd_ts); // it's usually -ENOMEM\n        pr_err(\"kthread creation failed (%d)\\n\", ret);\n        return ret;\n    } \n    get_task_struct(gkthrd_ts); // inc refcnt, marking the task struct as in use\n    [ ... ]\n```", "```\nstatic int simple_kthread(void *arg)\n{\n    PRINT_CTX();\n    if (!current->mm)\n        pr_info(\"mm field NULL, we are a kernel thread!\\n\");\n```", "```\n    allow_signal(SIGINT);\n    allow_signal(SIGQUIT);\n\n    while (!kthread_should_stop()) {\n        pr_info(\"FYI, I, kernel thread PID %d, am going to sleep now...\\n\",\n            current->pid);\n        set_current_state(TASK_INTERRUPTIBLE);\n        schedule(); // yield the processor, go to sleep...\n        /* Aaaaaand we're back! Here, it's typically due to either the\n         * SIGINT or SIGQUIT signal hitting us! */\n        if (signal_pending(current))\n            break;\n    }\n```", "```\n    set_current_state(TASK_RUNNING);\n    pr_info(\"FYI, I, kernel thread PID %d, have been rudely awoken; I shall\"\n            \" now exit... Good day Sir!\\n\", current->pid);\n    return 0;\n}\n```", "```\nstatic void kthread_simple_exit(void)\n{\n    kthread_stop(gkthrd_ts);   /* waits for our kthread to terminate; \n                                * it also internally invokes \n                                * the put_task_struct() to decrement task's  \n                                * reference count\n                                */\n    pr_info(\"kthread stopped, and LKM removed.\\n\");\n}\n```", "```\nwhile (!kthread_should_stop()) {\n```", "```\n$ ps -e |grep kt_simple\n 11372   ?        00:00:00 llkd/kt_simple\n$\n```", "```\n// ch5/sed2/sed2_driver/sed2_drv.c\n[ ... ]\n#if LINUX_VERSION_CODE >= KERNEL_VERSION(2, 6, 36)\nstatic long ioctl_miscdrv(struct file *filp, unsigned int cmd, unsigned long arg)\n#else\nstatic int ioctl_miscdrv(struct inode *ino, struct file *filp, unsigned int cmd, unsigned long arg)\n#endif\n{\n    struct stMyCtx *priv = gpriv;\n\n[ ... ]\nswitch (cmd) {\n    case IOCTL_LLKD_SED_IOC_ENCRYPT_MSG: /* kthread: encrypts the msg passed in */\n        [ ... ]\n        if (atomic_read(&priv->msg_state) == XF_ENCRYPT) { // already encrypted?\n            pr_notice(\"encrypt op: message is currently encrypted; aborting op...\\n\");\n            return -EBADRQC; /* 'Invalid request code' */\n        }\n        if (copy_from_user(priv->kdata, (struct sed_ds *)arg, sizeof(struct sed_ds))) {\n         [ ... ]\n\n        POLL_ON_WORK_DONE(1);\n        /* Wake up our kernel thread and have it encrypt the message ! */\n        if (!wake_up_process(priv->kthrd_work))\n            pr_warn(\"worker kthread already running when awoken?\\n\");\n        [ ... ]\n```", "```\nstatic int __init sed2_drv_init(void)\n{\n    [ ... ]\n    gpriv->kthrd_work = kthread_create(worker_kthread, NULL, \"%s/%s\", DRVNAME, KTHREAD_NAME);\n    if (IS_ERR(gpriv->kthrd_work)) {\n        ret = PTR_ERR(gpriv->kthrd_work); // it's usually -ENOMEM\n        dev_err(dev, \"kthread creation failed (%d)\\n\", ret);\n        return ret;\n    }\n    get_task_struct(gpriv->kthrd_work); // inc refcnt, marking the task struct as in use\n    pr_info(\"worker kthread created... (PID %d)\\n\", task_pid_nr(gpriv->kthrd_work));\n    [ ... ]\n```", "```\nstatic int worker_kthread(void *arg)\n{\n    struct stMyCtx *priv = gpriv;\n\n    while (!kthread_should_stop()) {\n        /* Start - the timer; set it to expire in TIMER_EXPIRE_MS ms */\n        if (mod_timer(&priv->timr, jiffies + msecs_to_jiffies(TIMER_EXPIRE_MS)))\n            pr_alert(\"timer already active?\\n\");\n        priv->t1 = ktime_get_real_ns();\n\n        /*--------------- Critical section begins --------------------------*/\n        atomic_set(&priv->work_done, 0);\n        switch (priv->kdata->data_xform) {\n        [ ... ]\n        case XF_ENCRYPT:\n            pr_debug(\"data transform type: XF_ENCRYPT\\n\");\n            encrypt_decrypt_payload(WORK_IS_ENCRYPT, priv->kdata);\n atomic_set(&priv->msg_state, XF_ENCRYPT);\n            break;\n        case XF_DECRYPT:\n            pr_debug(\"data transform type: XF_DECRYPT\\n\");\n            encrypt_decrypt_payload(WORK_IS_DECRYPT, priv->kdata);\n            atomic_set(&priv->msg_state, XF_DECRYPT);\n            break;\n        [ ... ]\n        priv->t2 = ktime_get_real_ns();\n        // work done, cancel the timeout\n        if (del_timer(&priv->timr) == 0)\n        [ ... ]\n```", "```\n        [ ... ]       \n         POLL_ON_WORK_DONE(1);\n        /* Wake up our kernel thread \n         * and have it encrypt the message ! \n         */\n        if (!wake_up_process(priv->kthrd_work))\n            pr_warn(\"worker kthread already running when awoken?\\n\");\n        /*\n         * Now, our kernel thread is doing the 'work'; \n         * it will either be done, or it will miss it's \n         * deadline and fail. Attempting to lookup the payload \n         * or do anything more here would be a\n         * mistake, a race! Why? We're currently running in \n         * the ioctl() process context; the kernel thread runs \n         * in it's own process context! (If we must look it up, \n         * then we really require a (mutex) lock; we shall\n         * discuss locking in detail in the book's last two chapters.\n         */\n        break;\n```", "```\n/*\n * Is our kthread performing any ongoing work right now? poll...\n * Not ideal (but we'll live with it); ideally, use a lock (we cover locking in\n * this book's last two chapters)\n */\n#define POLL_ON_WORK_DONE(sleep_ms) do { \\\n        while (atomic_read(&priv->work_done) == 0) \\\n            msleep_interruptible(sleep_ms); \\\n} while (0)\n```", "```\n// ch5/sed2/sed2_driver/sed2_drv.c : ioctl() method\n[ ... ]\ncase IOCTL_LLKD_SED_IOC_RETRIEVE_MSG: /* ioctl: retrieves the encrypted msg */\n        if (atomic_read(&priv->timed_out) == 1) {\n            pr_debug(\"the encrypt op had timed out! returning -ETIMEDOUT\\n\");\n            return -ETIMEDOUT;\n        }\n        if (copy_to_user((struct sed_ds *)arg, (struct sed_ds *)priv->kdata, sizeof(struct sed_ds))) {\n           //  [ ... error handling ... ]\n        break;\n    case IOCTL_LLKD_SED_IOC_DESTROY_MSG: /* ioctl: destroys the msg */\n        pr_debug(\"In ioctl 'destroy' cmd option\\n\");\n        memset(priv->kdata, 0, sizeof(struct sed_ds));\n        atomic_set(&priv->msg_state, 0);\n        atomic_set(&priv->work_done, 1);\n        atomic_set(&priv->timed_out, 0);\n        priv->t1 = priv->t2 = 0;\n        break;\n[ ... ]\n```", "```\n[41178.885577] sed2_drv:worker_kthread(): 001) [sed2_drv/worker]:24117   |  ...0   /* worker_kthread() */\n```", "```\n[41178.888875] sed2_drv:worker_kthread(): processing complete, timeout cancelled\n```", "```\ninclude/linux/workqueue.h\nstruct workqueue_struct *alloc_workqueue(const char *fmt, unsigned int flags, int max_active, ...);\n```", "```\n// kernel/workqueue.c\n\u200bint __init workqueue_init_early(void)\n{\n    [ ... ]\n    system_wq = alloc_workqueue(\"events\", 0, 0);\n    system_highpri_wq = alloc_workqueue(\"events_highpri\", WQ_HIGHPRI, 0);\n    system_long_wq = alloc_workqueue(\"events_long\", 0, 0);\n    system_unbound_wq = alloc_workqueue(\"events_unbound\", WQ_UNBOUND, WQ_UNBOUND_MAX_ACTIVE);\n    system_freezable_wq = alloc_workqueue(\"events_freezable\", WQ_FREEZABLE, 0);\n    system_power_efficient_wq = alloc_workqueue(\"events_power_efficient\", WQ_POWER_EFFICIENT, 0);\n    system_freezable_power_efficient_wq = alloc_workqueue(\"events_freezable_power_efficient\",\n                          WQ_FREEZABLE | WQ_POWER_EFFICIENT, 0);\n[ ... ]\n```", "```\n#include <linux/workqueue.h>\nINIT_WORK(struct work_struct *_work, work_func_t _func);\n```", "```\nbool schedule_work(struct work_struct *work);\n```", "```\nbool schedule_delayed_work(struct delayed_work *dwork, unsigned long delay);\n```", "```\nbool schedule_delayed_work_on(int cpu, struct delayed_work *dwork, unsigned long delay);\n```", "```\nbool cancel_work_sync(struct work_struct *work);\nbool cancel_delayed_work(struct delayed_work *dwork);\nbool cancel_delayed_work_sync(struct delayed_work *dwork);\n```", "```\nstatic struct st_ctx {\n    struct work_struct work;\n    struct timer_list tmr;\n    int data;\n} ctx;\n[ ... ]\nstatic int __init workq_simple_init(void)\n{\n    ctx.data = INITIAL_VALUE;\n    /* Initialize our work queue */\n INIT_WORK(&ctx.work, work_func);\n    /* Initialize our kernel timer */\n    ctx.tmr.expires = jiffies + msecs_to_jiffies(exp_ms);\n    ctx.tmr.flags = 0;\n    timer_setup(&ctx.tmr, ding, 0);\n    add_timer(&ctx.tmr); /* Arm it; let's get going! */\n    return 0;\n}\n```", "```\nstatic void ding(struct timer_list *timer)\n{ \n    struct st_ctx *priv = from_timer(priv, timer, tmr);\n    pr_debug(\"timed out... data=%d\\n\", priv->data--);\n    PRINT_CTX();\n\n    /* until countdown done, fire it again! */\n    if (priv->data)\n        mod_timer(&priv->tmr, jiffies + msecs_to_jiffies(exp_ms));\n    /* Now 'schedule' our work queue function to run */\n    if (!schedule_work(&priv->work))\n        pr_notice(\"our work's already on the kernel-global workqueue!\\n\");\n}\n```", "```\n/* work_func() - our workqueue callback function! */\nstatic void work_func(struct work_struct *work)\n{\n    struct st_ctx *priv = container_of(work, struct st_ctx, work);\n\n    t2 = ktime_get_real_ns();\n    pr_info(\"In our workq function: data=%d\\n\", priv->data);\n    PRINT_CTX();\n    SHOW_DELTA(t2, t1);\n}\n```", "```\n$ ps -el | grep -w 55200\n 1 I     0   55200       2  0  80  0 -    0 -    ?       00:00:02 kworker/1:0-mm_percpu_wq\n $\n```", "```\nstatic my_chip_tasklet(void)\n{\n    // ... process data\n    if (!copy_to_user(to, from, count)) {\n        pr_warn(\"...\"); [...]\n    }\n}\nstatic irqreturn_t chip_hardisr(int irq, void *data)\n{\n    // ack irq\n    // << ... fetch data into kfifo ... >>\n    // << ... call func_a(), delay, then call func_b() >>\n    func_a();\n    usleep(100); // 100 us delay required here! see datasheet pg ...\n    func_b();\n    tasklet_schedule(...);\n    return IRQ_HANDLED;\n}\nmy_chip_probe(...)\n{\n    // ...\n    request_irq(CHIP_IRQ, chip_hardisr, ...);\n    // ...\n    tasklet_init(...);\n}\n```"]