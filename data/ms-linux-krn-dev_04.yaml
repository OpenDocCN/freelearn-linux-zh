- en: Memory Management and Allocators
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存管理和分配器
- en: 'The efficiency of memory management broadly sets the efficiency of the whole
    kernel. Casually managed memory systems can seriously impact the performance of
    other subsystems, making memory a critical component of the kernel. This subsystem
    sets all processes and kernel services in motion by virtualizing physical memory
    and managing all dynamic allocation requests initiated by them. The memory subsystem
    also handles a wide spectrum of operations in sustaining operational efficiency
    and optimizing resources. The operations are both architecture specific and independent,
    which mandates the overall design and implementation to be just and tweakable.
    We will closely look at the following aspects in this chapter in our effort to
    comprehend this colossal subsystem:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 内存管理的效率广泛地决定了整个内核的效率。随意管理的内存系统可能严重影响其他子系统的性能，使内存成为内核的关键组成部分。这个子系统通过虚拟化物理内存和管理它们发起的所有动态分配请求来启动所有进程和内核服务。内存子系统还处理维持操作效率和优化资源的广泛操作。这些操作既是特定于架构的，也是独立的，这要求整体设计和实现是公正和可调整的。在本章中，我们将密切关注以下方面，以便努力理解这个庞大的子系统：
- en: Physical memory representation
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 物理内存表示
- en: Concepts of nodes and zones
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点和区域的概念
- en: Page allocator
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 页分配器
- en: Buddy system
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 伙伴系统
- en: Kmalloc allocations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kmalloc分配
- en: Slab caches
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Slab高速缓存
- en: Vmalloc allocations
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vmalloc分配
- en: Contiguous memory allocations
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续内存分配
- en: Initialization operations
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化操作
- en: In most architectures, on *reset,* processor is initialized in normal or physical
    address mode (also called **real mode** in x86) and begins executing the platform's
    firmware instructions found at the **reset vector**. These firmware instructions
    (which can be single binary or multi-stage binary) are programmed to carry out
    various operations, which include initialization of the memory controller, calibration
    of physical RAM, and loading the binary kernel image into a specific region of
    physical memory, among others.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数架构中，在*复位*时，处理器以正常或物理地址模式（也称为x86中的**实模式**）初始化，并开始执行平台固件指令，这些指令位于**复位向量**处。这些固件指令（可以是单一二进制或多阶段二进制）被编程来执行各种操作，包括初始化内存控制器，校准物理RAM，并将二进制内核映像加载到物理内存的特定区域，等等。
- en: When in real mode, processors do not support virtual addressing, and Linux,
    which is designed and implemented for systems with **protected mode**, requires
    **virtual addressing** to enable process protection and isolation, a crucial abstraction
    provided by the kernel (recall from [Chapter 1](part0020.html#J2B80-7300e3ede2f245b0b80e1b18d02a323f),
    *Comprehending Processes, Address Space, and Threads*). This mandates the processor
    to be switched into protected mode and turn on virtual address support before
    the kernel kicks in and begins its boot operations and initialization of subsystems.
    Switching to protected mode requires the MMU chipset to be initialized, by setting
    up appropriate core data structures, in the process enabling *paging*. These operations
    are architecture specific and are implemented in *arch* branch of the kernel source
    tree. During kernel build these sources are compiled and linked as a header to
    protected mode kernel image; this header is referred as the **kernel bootstrap**
    or **real mode kernel**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在实模式下，处理器不支持虚拟寻址，而Linux是为具有**保护模式**的系统设计和实现的，需要**虚拟寻址**来启用进程保护和隔离，这是内核提供的关键抽象（回顾[第1章](part0020.html#J2B80-7300e3ede2f245b0b80e1b18d02a323f)，*理解进程、地址空间和线程*）。这要求处理器在内核启动和子系统初始化之前切换到保护模式并打开虚拟地址支持。切换到保护模式需要初始化MMU芯片组，通过设置适当的核心数据结构，从而启用*分页*。这些操作是特定于架构的，并且在内核源代码树的*arch*分支中实现。在内核构建期间，这些源代码被编译并链接为保护模式内核映像的头文件；这个头文件被称为**内核引导程序**或**实模式内核**。
- en: '![](img/00019.jpeg)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00019.jpeg)'
- en: 'Following is the `main()` routine of x86 architecture''s boot strap; this function
    is executed in real mode and is responsible for allocating appropriate resources
    before stepping into protected mode by invoking `go_to_protected_mode()`:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是x86架构引导程序的`main()`例程；这个函数在实模式下执行，并负责在调用`go_to_protected_mode()`之前分配适当的资源，然后进入保护模式：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Real mode kernel routines that are invoked for setting up MMU and handle transition
    into protected mode are architecture specific (we will not be touching on those
    routines here). Irrespective of the architecture-specific code engaged, the primary
    objective is to enable support for **virtual addressing** by turning on **paging**.
    With paging enabled, system begins to perceive physical memory (RAM) as an array
    of blocks of fixed size, called page frames. Size of a page frame is configured
    by programming the paging unit of MMU appropriately; most MMUs support 4k, 8k,
    16k, 64k up to 4MB options for frame size configuration. However, Linux kernel's
    default build configuration for most architectures chooses 4k as its standard
    page frame size.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 实模式内核例程是为了设置MMU并处理转换到保护模式而调用的，这些例程是特定于架构的（我们不会在这里涉及这些例程）。不管所涉及的特定于架构的代码是什么，主要目标是通过打开分页来启用对虚拟寻址的支持。启用分页后，系统开始将物理内存（RAM）视为固定大小的块数组，称为页帧。页帧的大小通过适当地编程MMU的分页单元来配置；大多数MMU支持4k、8k、16k、64k直到4MB的选项来配置帧大小。然而，Linux内核对大多数架构的默认构建配置选择4k作为其标准页帧大小。
- en: Page descriptor
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 页描述符
- en: '**Page frames** are the smallest possible allocation units of memory and kernel
    needs to utilize them for all its memory needs. Some page frames would be required
    for mapping physical memory to virtual address spaces of user mode processes,
    some for kernel code and its data structures, and some for processing dynamic
    allocation requests raised by process or a kernel service. For efficient management
    of such operations, kernel needs to distinguish between page frames currently
    in *use* from those which are free and available. This purpose is achieved through
    an architecture-independent data structure called `struct page`, which is defined
    to hold all meta data pertaining to a page frame, including its current state.
    An instance of `struct page` is allocated for each physical page frame found,
    and kernel has to maintain a list of page instances in main memory all the time.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**页面帧**是内存的最小分配单元，内核需要利用它们来满足其所有的内存需求。一些页面帧将被用于将物理内存映射到用户模式进程的虚拟地址空间，一些用于内核代码和其数据结构，一些用于处理进程或内核服务提出的动态分配请求。为了有效地管理这些操作，内核需要区分当前*使用*的页面帧和空闲可用的页面帧。这个目的通过一个与架构无关的数据结构`struct
    page`来实现，该结构被定义为保存与页面帧相关的所有元数据，包括其当前状态。为每个找到的物理页面帧分配一个`struct page`的实例，并且内核必须始终在主内存中维护页面实例的列表。'
- en: '**Page structure** is one of the heavily used data structures of the kernel,
    and is referred from various kernel code paths. This structure is populated with
    diverse elements, whose relevance is entirely based on the state of the physical
    frame. For instance, specific members of page structure specify if corresponding
    physical page is mapped to virtual address space of a process, or a group of process.
    Such fields are not considered valid when the physical page has been reserved
    for dynamic allocations. To ensure that page instance in memory is allocated only
    with relevant fields, unions are heavily used to populate member fields. This
    is a prudent choice, since it enables cramming more information into the page
    structure without increasing its size in memory:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**页面结构**是内核中使用最频繁的数据结构之一，并且在各种内核代码路径中被引用。该结构填充有各种元素，其相关性完全基于物理帧的状态。例如，页面结构的特定成员指定相应的物理页面是否映射到进程或一组进程的虚拟地址空间。当物理页面被保留用于动态分配时，这些字段被认为无效。为了确保内存中的页面实例只分配有关字段，联合体被广泛用于填充成员字段。这是一个明智的选择，因为它使得能够在不增加内存中的页面结构大小的情况下将更多的信息塞入页面结构中：'
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Following is a brief description of important members of page structure. Note
    that a lot of the details here assume your familiarity with other aspects of memory
    subsystem which we discuss in further sections of this chapter, such as memory
    allocators, page tables, and so forth. I recommend new readers to skip and revisit
    this section after you get acquainted with the necessary prerequisites.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是页面结构的重要成员的简要描述。请注意，这里的许多细节假定您熟悉我们在本章的后续部分中讨论的内存子系统的其他方面，比如内存分配器、页表等等。我建议新读者跳过并在熟悉必要的先决条件后再回顾本节。
- en: Flags
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标志
- en: 'This is an `unsigned long` bit-field that holds flags which describe state
    of the physical page. Flag constants are defined through an `enum` in kernel header
    `include/linux/page-flags.h`. The following table lists out important flag constants:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个`unsigned long`位字段，它保存描述物理页面状态的标志。标志常量是通过内核头文件`include/linux/page-flags.h`中的`enum`定义的。以下表列出了重要的标志常量：
- en: '| **Flag** | **Description** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| **标志** | **描述** |'
- en: '| `PG_locked` | Used to indicate if page is locked; this bit is set while initiating
    I/O operations on page and cleared on completion. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| `PG_locked` | 用于指示页面是否被锁定；在对页面进行I/O操作时设置此位，并在完成时清除。 |'
- en: '| `PG_error` | Used to indicate an error page. Set on occurrence of an I/O
    error on the page. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| `PG_error` | 用于指示错误页面。在页面发生I/O错误时设置。 |'
- en: '| `PG_referenced` | Set to indicate page reclaim for page cache. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| `PG_referenced` | 设置以指示页面缓存的页面回收。 |'
- en: '| `PG_uptodate` | Set to indicate if page is valid after read operation from
    disk. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| `PG_uptodate` | 设置以指示从磁盘读取操作后页面是否有效。 |'
- en: '| `PG_dirty` | Set when file backed page is modified and is out-of-sync with
    disk image of the same. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| `PG_dirty` | 当文件支持的页面被修改并且与磁盘镜像不同步时设置。 |'
- en: '| `PG_lru` | Used to indicate that the least recently used bit is set which
    helps handle page reclaim. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| `PG_lru` | 用于指示最近最少使用位被设置，有助于处理页面回收。 |'
- en: '| `PG_active` | Used to indicate if page is in active list. |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| `PG_active` | 用于指示页面是否在活动列表中。 |'
- en: '| `PG_slab` | Used to indicate that the page is managed by slab allocator.
    |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| `PG_slab` | 用于指示页面由slab分配器管理。 |'
- en: '| `PG_reserved` | Used to indicate reserved pages which are not swappable.
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| `PG_reserved` | 用于指示不可交换的保留页面。 |'
- en: '| `PG_private` | Used to indicate that the page is used by a filesystem to
    hold its private data. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| `PG_private` | 用于指示页面被文件系统用于保存其私有数据。 |'
- en: '| `PG_writeback` | Set while commencing write-back operation on a file-backed
    page |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `PG_writeback` | 在对文件支持的页面进行写回操作时设置 |'
- en: '| `PG_head` | Used to indicate head page of a compound page. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `PG_head` | 用于指示复合页面的头页面。 |'
- en: '| `PG_swapcache` | Used to indicate if page is in swapcache. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| `PG_swapcache` | 用于指示页面是否在swapcache中。 |'
- en: '| `PG_mappedtodisk` | Used to indicate that page is mapped to *blocks* on storage.
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| `PG_mappedtodisk` | 用于指示页面被映射到存储上的*块*。 |'
- en: '| `PG_swapbacked` | Page is backed by swap. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `PG_swapbacked` | 页面由交换支持。 |'
- en: '| `PG_unevictable` | Used to indicate that page is in unevictable list; generally,
    this bit is set for pages owned by ramfs and `SHM_LOCKed` shared memory pages.
    |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| `PG_unevictable` | 用于指示页面在不可驱逐列表中；通常，此位用于ramfs拥有的页面和`SHM_LOCKed`共享内存页面。 |'
- en: '| `PG_mlocked` | Used to indicate that VMA lock is enabled on the page. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| `PG_mlocked` | 用于指示页面上启用了VMA锁。 |'
- en: 'A number of macros exist to `check`, `set`, and `clear` individual page bits;
    these operations are guaranteed to be `atomic` and are declared in kernel header
    `/include/linux/page-flags.h`. They are invoked to manipulate page flags from
    various kernel code paths:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 存在许多宏来`检查`，`设置`和`清除`单个页面位；这些操作被保证是`原子的`，并且在内核头文件`/include/linux/page-flags.h`中声明。它们被调用以从各种内核代码路径操纵页面标志：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Mapping
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 映射
- en: Another important element of the page descriptor is a pointer `*mapping` of
    type `struct address_space`. However*,* this is one of the tricky pointers which
    might either refer to an instance of `struct address_space`, or to an instance
    of `struct anon_vma`. Before we get into details of how this is achieved, let's
    first understand the importance of those structures and the resources they represent.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 页面描述符的另一个重要元素是类型为`struct address_space`的指针`*mapping`。然而，这是一个棘手的指针，可能是指向`struct
    address_space`的一个实例，也可能是指向`struct anon_vma`的一个实例。在我们深入了解如何实现这一点之前，让我们首先了解这些结构及它们所代表的资源的重要性。
- en: 'Filesystems engage free pages( from page cache) to cache data of recently accessed
    disk files. This mechanism helps minimize disk I/O operations: when file data
    in the cache is modified, the appropriate page is marked dirty by setting the
    `PG_dirty` bit; all dirty pages are written to the corresponding disk block by
    scheduling disk I/O at strategic intervals. `struct address_space` is an abstraction
    that represents a set of pages engaged for a file cache. Free pages of the page
    cache can also be **mapped** to a process or process group for dynamic allocations,
    pages mapped for such allocations are referred to as **anonymous** page mappings.
    An instance of `struct anon_vma` represents a memory block created with anonymous
    pages, that are mapped to the virtual address space (through VMA instance) of
    a process or processes.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 文件系统利用空闲页面（来自页面缓存）来缓存最近访问的磁盘文件的数据。这种机制有助于最小化磁盘I/O操作：当缓存中的文件数据被修改时，适当的页面通过设置`PG_dirty`位被标记为脏；所有脏页面都会在策略性间隔时段通过调度磁盘I/O写入相应的磁盘块。`struct
    address_space`是一个表示为文件缓存而使用的页面集合的抽象。页面缓存的空闲页面也可以被**映射**到进程或进程组以进行动态分配，为这种分配映射的页面被称为**匿名**页面映射。`struct
    anon_vma`的一个实例表示使用匿名页面创建的内存块，这些页面被映射到进程或进程的虚拟地址空间（通过VMA实例）。
- en: The tricky dynamic initialization of the pointer with address to either of the
    data structures is achieved by bit manipulations. If low bit of pointer `*mapping`
    is clear, then it is an indication that the page is mapped to an `inode` and the
    pointer refers to `struct address_space`. If low bit is set, it is an indication
    for anonymous mapping, which means the pointer refers to an instance of `struct
    anon_vma`. This is made possible by ensuring allocation of `address_space` instances
    aligned to `sizeof(long)`, which makes the least significant bit of a pointer
    to `address_space` be unset (that is, set to 0).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 通过位操作实现指针动态初始化为指向这两种数据结构中的任意一种的地址是有技巧的。如果指针`*mapping`的低位清除，则表示页面映射到`inode`，指针指向`struct
    address_space`。如果低位设置，这表示匿名映射，这意味着指针指向`struct anon_vma`的一个实例。这是通过确保`address_space`实例的分配对齐到`sizeof(long)`来实现的，这使得指向`address_space`的指针的最低有效位被清除（即设置为0）。
- en: Zones and nodes
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区域和节点
- en: Principal data structures that are elementary for entire memory management framework
    are **zones** and ***nodes***. Let's familiarize ourselves with core concepts
    behind these data structures.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 对于整个内存管理框架至关重要的主要数据结构是**区域**和***节点***。让我们熟悉一下这些数据结构背后的核心概念。
- en: Memory zones
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存区域
- en: 'For efficient management of memory allocations, physical pages are organized
    into groups called **zones.** Pages in each *zone* are utilized for specific needs
    like DMA, high memory, and other regular allocation needs. An `enum` in kernel
    header `mmzone.h` declares *zone* constants:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效管理内存分配，物理页面被组织成称为**区域**的组。每个*区域*中的页面用于特定需求，如DMA、高内存和其他常规分配需求。内核头文件`mmzone.h`中的`enum`声明了*区域*常量：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`ZONE_DMA`:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZONE_DMA`：'
- en: 'Pages in this *zone* are reserved for devices which cannot initiate DMA on
    all addressable memory. Size of this *zone* is architecture specific:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个*区域*中的页面是为不能在所有可寻址内存上启动DMA的设备保留的。这个*区域*的大小是特定于架构的：
- en: '| Architecture | Limit |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 架构 | 限制 |'
- en: '| parsic, ia64, sparc | <4G |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| parsic, ia64, sparc | <4G |'
- en: '| s390 | <2G |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| s390 | <2G |'
- en: '| ARM | variable |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| ARM | 可变 |'
- en: '| alpha | unlimited or <16MB |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| alpha | 无限制或<16MB |'
- en: '| alpha, i386, x86-64 | <16MB |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| alpha, i386, x86-64 | <16MB |'
- en: '`ZONE_DMA32`: This *zone* is used for supporting 32-bit devices which can perform
    DMA on <4G of memory. This *zone* is only present on x86-64 platforms.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZONE_DMA32`：这个*区域*用于支持可以在<4G内存上执行DMA的32位设备。这个*区域*仅存在于x86-64平台上。'
- en: '`ZONE_NORMAL`: All addressable memory is considered to be normal *zone*. DMA
    operations can be initiated on these pages, provided DMA devices support all addressable
    memory.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZONE_NORMAL`：所有可寻址内存被认为是正常的*区域*。只要DMA设备支持所有可寻址内存，就可以在这些页面上启动DMA操作。'
- en: '`ZONE_HIGHMEM`: This *zone* contains pages that are only accessible by kernel
    through explicit mapping into its address space; in other words, all physical
    memory pages beyond kernel segment fall into this *zone*. This *zone* exists only
    for 32-bit platforms with 3:1 virtual address split (3G for user mode and 1G address
    space for kernel); for instance on i386, allowing the kernel to address memory
    beyond 900 MB will require setting up special mappings (page table entries) for
    each page that the kernel needs to access.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZONE_HIGHMEM`：这个*区域*包含只能通过显式映射到内核地址空间中的内核访问的页面；换句话说，所有超出内核段的物理内存页面都属于这个*区域*。这个*区域*仅存在于3:1虚拟地址分割（3G用于用户模式，1G地址空间用于内核）的32位平台上；例如在i386上，允许内核访问超过900MB的内存将需要为内核需要访问的每个页面设置特殊映射（页表条目）。'
- en: '`ZONE_MOVABLE`: Memory fragmentation is one of the challenges for modern operating
    systems to handle, and Linux is no exception to this. Right from the moment kernel
    boots, throughout its runtime, pages are allocated and deallocated for an array
    of tasks, resulting in small regions of memory with physically contiguous pages.
    Considering Linux support for virtual addressing, fragmentation might not be an
    obstacle for smooth execution of various processes, since physically scattered
    memory can always be mapped to virtually contiguous address space through page
    tables. Yet, there are a few scenarios like DMA allocations and setting up caches
    for kernel data structures that have a stringent need for physically contiguous
    regions.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZONE_MOVABLE`：内存碎片化是现代操作系统处理的挑战之一，Linux也不例外。从内核启动的那一刻开始，直到运行时，页面被分配和释放用于一系列任务，导致具有物理连续页面的小内存区域。考虑到Linux对虚拟寻址的支持，碎片化可能不会成为各种进程顺利执行的障碍，因为物理上分散的内存总是可以通过页表映射到虚拟连续地址空间。然而，有一些场景，比如DMA分配和为内核数据结构设置缓存，对物理连续区域有严格的需求。'
- en: Over the years, kernel developers have been evolving numerous anti-fragmentation
    techniques to alleviate **fragmentation**. Introduction of `ZONE_MOVABLE` is one
    of those attempts. The core idea here is to track *movable* pages in each *zone*
    and represent them under this pseudo *zone*, which helps prevent fragmentation
    (we discuss more on this in the next section on the buddy system).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 多年来，内核开发人员一直在演进各种抗碎片化技术来减轻**碎片化**。引入`ZONE_MOVABLE`就是其中之一。这里的核心思想是跟踪每个*区域*中的*可移动*页面，并将它们表示为这个伪*区域*，这有助于防止碎片化（我们将在下一节关于伙伴系统中更多讨论这个问题）。
- en: The size of this *zone* is to be configured at boot time through one of the
    kernel parameters `kernelcore`; note that the value assigned specifies the amount
    of memory considered *non-movable,* and the rest, *movable*. As a general rule,
    the memory manager is configured to consider migration of pages from the highest
    populated *zone* to `ZONE_MOVABLE`, which is probably going to be `ZONE_HIGHMEM`
    for x86 32-bit machines and `ZONE_DMA32` on x86_64.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这个*区域*的大小将在启动时通过内核参数`kernelcore`进行配置；请注意，分配的值指定了被视为*不可移动*的内存量，其余的是*可移动*的。一般规则是，内存管理器被配置为考虑从最高填充的*区域*迁移页面到`ZONE_MOVABLE`，对于x86
    32位机器来说，这可能是`ZONE_HIGHMEM`，对于x86_64来说，可能是`ZONE_DMA32`。
- en: '`ZONE_DEVICE`: This *zone* has been carved out to support hotplug memories,
    like large capacity *persistent-memory arrays*. **Persistent memories** are very
    similar to DRAM in many ways; specifically, CPUs can directly address them at
    byte level. However, characteristics such as persistence, performance (slower
    writes), and size (usually measured in terabytes) separate them from normal memory.
    For the kernel to support such memories with 4 KB page size, it would need to
    enumerate billions of page structures, which would consume significant percent
    of main memory or not be fit at all. As a result, it was chosen by kernel developers
    to consider persistent memory a **device**, rather than like **memory**; which
    means that the kernel can fall back on appropriate **drivers** to manage such
    memories.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZONE_DEVICE`：这个*区域*被划分出来支持热插拔内存，比如大容量的*持久内存数组*。**持久内存**在许多方面与DRAM非常相似；特别是，CPU可以直接以字节级寻址它们。然而，特性如持久性、性能（写入速度较慢）和大小（通常以TB为单位）使它们与普通内存有所区别。为了让内核支持这样的具有4KB页面大小的内存，它需要枚举数十亿个页结构，这将消耗主内存的大部分或根本不适合。因此，内核开发人员选择将持久内存视为**设备**，而不是像**内存**一样；这意味着内核可以依靠适当的**驱动程序**来管理这样的内存。'
- en: '[PRE4]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `devm_memremap_pages()` routine of the persistent memory driver maps a region
    of persistent memory into kernel's address space with relevant page structures
    set up in persistent device memory. All pages under these mappings are grouped
    under `ZONE_DEVICE`. Having a distinct *zone* to tag such pages allows the memory
    manager to distinguish them from regular uniform memory pages.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 持久内存驱动程序的`devm_memremap_pages()`例程将持久内存区域映射到内核的地址空间，并在持久设备内存中设置相关的页结构。这些映射下的所有页面都被分组到`ZONE_DEVICE`下。为这样的页面设置一个独特的*区域*可以让内存管理器将它们与常规统一内存页面区分开来。
- en: Memory nodes
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存节点
- en: Linux kernel is implemented to support multi-processor machine architectures
    for a long time now. Kernel implements various resources such as per-CPU data
    caches, mutual exclusion locks, and atomic operation macros, which are used across
    various SMP-aware subsystems, such as process scheduler and device management,
    among others. In particular, the role of memory management subsystem is crucial
    for kernel to tick on such architectures, since it needs to virtualize memory
    as viewed by each processor. Multi-processor machine architectures are broadly
    categorized into two types based on each processor's perception, and access latency
    to memory on the system.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核长期以来一直实现了对多处理器机器架构的支持。内核实现了各种资源，比如每CPU数据缓存、互斥锁和原子操作宏，这些资源在各种SMP感知子系统中被使用，比如进程调度器和设备管理等。特别是，内存管理子系统的作用对于内核在这样的架构上运行至关重要，因为它需要将每个处理器所看到的内存虚拟化。多处理器机器架构基于每个处理器的感知和对系统内存的访问延迟，被广泛分类为两种类型。
- en: '**Uniform Memory Access Architecture (UMA):** These are multi-processor architecture
    machines, where processors are joined through an interconnect and share physical
    memory and I/O ports. They are named as UMA systems due to memory access latency,
    which is uniform and fixed irrespective of the processor from which they were
    initiated. Most symmetric multi-processor systems are UMA.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**统一内存访问架构（UMA）**：这些是多处理器架构的机器，处理器通过互连连接并共享物理内存和I/O端口。它们被称为UMA系统，因为无论从哪个处理器发起，内存访问延迟都是统一和固定的。大多数对称多处理器系统都是UMA。'
- en: '**Non-Uniform Memory Access Architecture (NUMA):** These are multi-processor
    machines with a contrasting design to that of UMA**.** These systems are designed
    with dedicated memory for each processor with fixed time access latencies. However,
    processors can initiate access operations on local memory of other processors
    through appropriate interconnects, and such operations render variable time access
    latencies.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**非均匀内存访问架构（NUMA）：**这些是多处理器机器，设计与UMA相反。这些系统为每个处理器设计了专用内存，并具有固定的访问延迟时间。但是，处理器可以通过适当的互连发起对其他处理器本地内存的访问操作，并且这样的操作会产生可变的访问延迟时间。'
- en: 'Machines of this model are appropriately named **NUMA** due to non-uniform
    (non-contiguous) view of systems memory for each processor:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模型的机器由于每个处理器对系统内存的非均匀（非连续）视图而得名为**NUMA**：
- en: '**![](img/00020.jpeg)**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/00020.jpeg)**'
- en: 'To extend support for NUMA machines, kernel views each non uniform memory partition
    (local memory) as a `node`. Each node is identified by a descriptor of `type pg_data_t`
    , which refers to pages under that node as per zoning policy, discussed earlier.
    Each *zone* is represented through an instance of `struct zone`. UMA machines
    would contain one node descriptor under which the entire memory is represented,
    and on NUMA machines, a list of node descriptors are enumerated, each representing
    a contiguous memory node. The following diagram illustrates the relationship between
    these data structures:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展对NUMA机器的支持，内核将每个非均匀内存分区（本地内存）视为一个`node`。每个节点由`type pg_data_t`的描述符标识，该描述符根据之前讨论的分区策略引用该节点下的页面。每个*区域*通过`struct
    zone`的实例表示。UMA机器将包含一个节点描述符，该描述符下表示整个内存，而在NUMA机器上，将枚举一系列节点描述符，每个描述一个连续的内存节点。以下图表说明了这些数据结构之间的关系：
- en: '![](img/00021.jpeg)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00021.jpeg)'
- en: We shall follow on with *node* and *zone* descriptor data structure definitions.
    Note that we do not intend to describe every element of these structures as they
    are related to various aspects of memory management which are out of scope of
    this chapter.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用*节点*和*区域*描述符数据结构定义。请注意，我们不打算描述这些结构的每个元素，因为它们与内存管理的各个方面有关，而这超出了本章的范围。
- en: Node descriptor structure
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点描述符结构
- en: 'Node descriptor structure `pg_data_t` is declared in kernel header `mmzone.h`:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 节点描述符结构`pg_data_t`在内核头文件`mmzone.h`中声明：
- en: '[PRE5]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Depending on the type of machine and kernel configuration chosen, various elements
    are compiled into this structure. We''ll look at few important elements:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 根据选择的机器类型和内核配置，各种元素被编译到这个结构中。我们将看一些重要的元素：
- en: '| Field | Description |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 描述 |'
- en: '| `node_zones` | An array that holds *zone* instances for pages in this node.
    |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| `node_zones` | 一个包含此节点中页面的*区域*实例的数组。 |'
- en: '| `node_zonelists` | An array that specifies preferred allocation order for
    zones in the node. |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| `node_zonelists` | 一个指定节点中区域的首选分配顺序的数组。 |'
- en: '| `nr_zones` | Count of zones in the current node. |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| `nr_zones` | 当前节点中区域的计数。'
- en: '| `node_mem_map` | Pointer to list of page descriptors in the current node.
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| `node_mem_map` | 指向当前节点中页面描述符列表的指针。'
- en: '| `bdata` | Pointer to boot memory descriptor (discussed in later section)
    |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| `bdata` | 指向引导内存描述符的指针（在后面的部分中讨论） |'
- en: '| `node_start_pfn` | Holds frame number of the first physical page in this
    node; this value would be *zero* for UMA systems. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `node_start_pfn` | 持有此节点中第一个物理页面的帧编号；对于UMA系统，此值将为*零*。'
- en: '| `node_present_pages` | Total count of pages in the node |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `node_present_pages` | 节点中页面的总数 |'
- en: '| `node_spanned_pages` | Total size of physical page range, including holes
    if any. |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `node_spanned_pages` | 物理页面范围的总大小，包括任何空洞。'
- en: '| `node_id` | Holds unique node identifier (nodes are numbered from zero) |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `node_id` | 持有唯一节点标识符（节点从零开始编号） |'
- en: '| `kswapd_wait` | Wait queue of `kswapd` kernel thread |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| `kswapd_wait` | `kswapd`内核线程的等待队列 |'
- en: '| `kswapd` | Pointer to task structure of `kswapd` kernel thread |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| `kswapd` | 指向`kswapd`内核线程的任务结构的指针 |'
- en: '| `totalreserve_pages` | Count of reserve pages not used for user space allocations
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| `totalreserve_pages` | 未用于用户空间分配的保留页面的计数。'
- en: Zone descriptor structure
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区域描述符结构
- en: 'The `mmzone.h` header also declares `struct zone`, which serves as *zone* descriptor.
    Following is a code snippet of structure definition and is well commented. We
    shall follow on with descriptions of a few important fields:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`mmzone.h`头文件还声明了`struct zone`，它充当*区域*描述符。以下是结构定义的代码片段，并且有很好的注释。我们将继续描述一些重要字段：'
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Following is the summarized table of important fields, with short descriptions
    for each of them:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是重要字段的总结表，每个字段都有简短的描述：
- en: '| Field | Description |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 描述 |'
- en: '| `watermark` | An array of unsigned long with `WRMARK_MIN, WRMARK_LOW`, and
    `WRMARK_HIGH` offsets. Values in these offsets impact swap operations carried
    out by `kswapd` kernel thread. |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| `watermark` | 一个无符号长整型数组，具有`WRMARK_MIN`、`WRMARK_LOW`和`WRMARK_HIGH`的偏移量。这些偏移量中的值会影响`kswapd`内核线程执行的交换操作。'
- en: '| `nr_reserved_highatomic` | Holds count of reserved high order atomic pages
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| `nr_reserved_highatomic` | 保留高阶原子页面的计数 |'
- en: '| `lowmem_reserve` | Array that specifies count of pages for each *zone* that
    are reserved for critical allocations |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| `lowmem_reserve` | 指定为每个*区域*保留用于关键分配的页面计数的数组。'
- en: '| `zone_pgdat` | Pointer to node descriptor for this *zone*. |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| `zone_pgdat` | 指向此*区域*的节点描述符的指针。'
- en: '| `pageset` | Pointer to per-CPU hot-and-cold page lists. |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| `pageset` | 指向每个CPU的热和冷页面列表。'
- en: '| `free_area` | An array of instances of type `struct free_area`, each abstracting
    contiguous free pages made available for buddy allocator. More on buddy allocator
    in a later section. |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| `free_area` | 一个`struct free_area`类型实例的数组，每个实例抽象出为伙伴分配器提供的连续空闲页面。更多关于伙伴分配器的内容将在后面的部分中介绍。'
- en: '| `flags` | Unsigned long variable used to store current status of the *zone*.
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| `flags` | 用于存储*区域*当前状态的无符号长变量。 |'
- en: '| `zone_start_pfn` | Index of first page frame in the *zone* |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| `zone_start_pfn` | *区域*中第一个页面帧的索引 |'
- en: '| `vm_stat` | Statistical information of the *zone* |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| `vm_stat` | *区域*的统计信息 |'
- en: Memory allocators
  id: totrans-110
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存分配器
- en: Having looked at how physical memory is organized, and represented through core
    data structures, we will now shift our attention to management of physical memory
    for processing allocation and deallocation requests. Memory allocation requests
    can be raised by various entities in the system, such as usermode process, drivers,
    and filesystems. Depending on the type of entity and context from which allocation
    is being requested, allocations returned might need to meet certain characteristics,
    such as page-aligned physically contiguous large blocks or physically contiguous
    small blocks, hardware cache aligned memory, or physically fragmented blocks that
    are mapped to virtually contiguous address space.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了物理内存是如何组织和通过核心数据结构表示之后，我们现在将把注意力转向处理分配和释放请求的物理内存管理。系统中的各种实体，如用户模式进程、驱动程序和文件系统，可以提出内存分配请求。根据提出分配请求的实体和上下文的类型，返回的分配可能需要满足某些特性，例如页面对齐的物理连续大块或物理连续小块、硬件缓存对齐内存，或映射到虚拟连续地址空间的物理碎片化块。
- en: To efficiently manage physical memory, and cater to memory as per chosen priority
    and pattern, the kernel engages with a group of memory allocators. Each allocator
    has a distinct set of interface routines, which are backed by precisely designed
    algorithms optimized for a specific allocation pattern.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地管理物理内存，并根据选择的优先级和模式满足内存需求，内核与一组内存分配器进行交互。每个分配器都有一组不同的接口例程，这些例程由专门设计的算法支持，针对特定的分配模式进行了优化。
- en: Page frame allocator
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 页面帧分配器
- en: 'Also called the zoned page frame allocator, this serves as an interface for
    physically contiguous allocations in multiples of page size. Allocation operations
    are carried out by looking into appropriate zones for free pages. Physical pages
    in each *zone* are managed by **Buddy System**, which serves as the backend algorithm
    for the page frame allocator:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为分区页帧分配器，这用作以页面大小的倍数进行物理连续分配的接口。通过查找适当的区域以获取空闲页面来执行分配操作。每个*zone*中的物理页面由**伙伴系统**管理，该系统作为页面帧分配器的后端算法：
- en: '![](img/00022.jpeg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00022.jpeg)'
- en: 'Kernel code can initiate memory allocation/deallocation operations on this
    algorithm through interface inline functions and macros provided in the kernel
    header `linux/include/gfp.h`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 内核代码可以通过内核头文件`linux/include/gfp.h`中提供的接口内联函数和宏来启动对该算法的内存分配/释放操作：
- en: '[PRE7]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The first parameter `gfp_mask` serves as a means to specify attributes as per
    which allocations are to be fulfilled; we will look into details of the attribute
    flags in coming sections. The second parameter `order` is used to specify size
    of the allocation; the value assigned is considered 2^(order). On success, it
    returns the address of the first page structure, and NULL on failure. For single
    page allocations an alternate macro is made available, which again falls back
    on `alloc_pages()`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数`gfp_mask`用作指定属性的手段，根据这些属性来满足分配的需求；我们将在接下来的部分详细了解属性标志。第二个参数`order`用于指定分配的大小；分配的值被认为是2^(order)。成功时，它返回第一个页面结构的地址，失败时返回NULL。对于单页分配，还提供了一个备用宏，它再次回退到`alloc_pages()`：
- en: '[PRE8]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Allocated page(s) are mapped on to contiguous kernel address space, through
    appropriate page table entries (for paged address translation during access operations).
    Addresses generated after page table mapping, for use in kernel code, are referred
    to as **linear addresses**. Through another function interface `page_address()`,
    the caller code can retrieve the start linear address of the allocated block.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 分配的页面被映射到连续的内核地址空间，通过适当的页表项（用于访问操作期间的分页地址转换）。在页表映射后生成的地址，用于内核代码中的使用，被称为**线性地址**。通过另一个函数接口`page_address()`，调用者代码可以检索分配块的起始线性地址。
- en: 'Allocations can also be initiated through a set of **wrapper** routines and
    macros to `alloc_pages()`, which marginally extend functionality and return the
    start linear address for the allocated chunk, instead of pointer to page structure.
    The following code snippet shows a list of wrapper functions and macros:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 分配也可以通过一组**包装器**例程和宏来启动到`alloc_pages()`的操作，这些例程和宏略微扩展了功能，并返回分配块的起始线性地址，而不是页面结构的指针。以下代码片段显示了一组包装器函数和宏：
- en: '[PRE9]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Following are the interfaces for releasing memory back to the system. We need
    to invoke an appropriate one that matches the allocation routine; passing an incorrect
    address will cause corruption:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是释放内存返回到系统的接口。我们需要调用一个与分配例程匹配的适当接口；传递不正确的地址将导致损坏。
- en: '[PRE10]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Buddy system
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 伙伴系统
- en: While the page allocator serves as an interface for memory allocations (in multiples
    of page size), the buddy system operates at the back-end to administer physical
    page management. This algorithm manages all physical pages for each *zone*. It
    is optimized to accomplish allocations of large physically contiguous blocks (pages),
    by minimizing external fragmentation*.* Let's explore its operational details*.*
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然页面分配器用作内存分配的接口（以页面大小的倍数），但伙伴系统在后台运行以管理物理页面管理。该算法管理每个*zone*的所有物理页面。它经过优化，以最小化外部碎片化，实现大型物理连续块（页面）的分配。让我们探索其操作细节*.*
- en: 'The *zone* descriptor structure contains an array of *`struct free_area`,*
    and the size of the array is defined through a kernel macro `MAX_ORDER` whose
    default value is `11`:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*zone*描述符结构包含一个*`struct free_area`*数组，数组的大小是通过内核宏`MAX_ORDER`定义的，默认值为`11`：'
- en: '[PRE11]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Each offset contains an instance of `free_area` structure. All free pages are
    split into 11 (`MAX_ORDER`) lists, each containing a list of blocks of 2^(order)
    pages, with order values in the range of 0 to 11 (that is, a list of of 2² would
    contain 16 KB sized blocks, and 2³ to be 32 KB sized blocks, and so on). This
    strategy ensures each block to be naturally aligned. Blocks in each list are exactly
    double in size to that of blocks in lower lists, resulting in faster allocation
    and deallocation operations. It also provides the allocator with the capability
    to handle contiguous allocations, of upto 8 MB block size (2^(11) list):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 每个偏移包含一个`free_area`结构的实例。所有空闲页面被分成11个（`MAX_ORDER`）列表，每个列表包含2^(order)页的块列表，其中order的值在0到11的范围内（也就是说，2²的列表包含16KB大小的块，2³包含32KB大小的块，依此类推）。这种策略确保每个块都自然对齐。每个列表中的块大小恰好是低级列表中块大小的两倍，从而实现更快的分配和释放操作。它还为分配器提供了处理连续分配的能力，最多可达8MB的块大小（2^(11)列表）。
- en: '![](img/00023.jpeg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00023.jpeg)'
- en: When an allocation request is made for a particular size, the *buddy system*
    looks into the appropriate list for a free block, and returns its address, if
    available. However, if it cannot find a free block, it moves to check in the next
    high-order list for a larger block, which if available it splits the higher-order
    block into equal parts called *buddies*, returns one for the allocator, and queues
    the second into a lower-order list. When both buddy blocks become free at some
    future time, they are coalesced to create a larger block. Algorithm can identify
    buddy blocks through their aligned address, which makes it possible to coalesce
    them.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 当针对特定大小的分配请求时，*伙伴系统*会查找适当的空闲块列表，并返回其地址（如果有的话）。然而，如果找不到空闲块，它会移动到下一个高阶列表中查找更大的块，如果有的话，它会将高阶块分割成称为*伙伴*的相等部分，返回一个给分配器，并将第二个排入低阶列表。当两个伙伴块在将来某个时间变为空闲时，它们将合并为一个更大的块。算法可以通过它们对齐的地址来识别伙伴块，这使得它们可以合并。
- en: Let's consider an example to comprehend this better, assuming there were a request
    to allocate an 8k block (through page allocator routines). Buddy system looks
    for free blocks in an 8k list of the `free_pages` array(first offset containing
    2¹ sized blocks), and returns the start linear address of the block if available;
    however, if there are no free blocks in the 8k list, it moves on to the next higher-order
    list, which is of 16k blocks (second offset of the `free_pages` array) to find
    a free block. Let's further assume that there were no free block in this list
    as well. It then moves ahead into the next high-order list of size 32k(third offset
    in the *free_pages* array) to find a free block; if available, it splits the 32k
    block into two equal halves of 16k each (*buddies*). The first 16k chunk is further
    split into two halves of 8k (*buddies*) of which one is allocated for the caller
    and other is put into the 8k list. The second chunk of 16k is put into the 16k
    free list, when lower order (8k) buddies become free at some future time, they
    are coalesced to form a higher-order 16k block. When both 16k buddies become free,
    they are again coalesced to arrive at a 32k block which is put back into the free
    list.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们举个例子来更好地理解这一点，假设有一个请求来分配一个8k的块（通过页面分配器例程）。伙伴系统在`free_pages`数组的8k列表中查找空闲块（第一个偏移包含2¹大小的块），如果有的话，返回块的起始线性地址；然而，如果在8k列表中没有空闲块，它会移动到下一个更高阶的列表，即16k块（`free_pages`数组的第二个偏移）中查找空闲块。假设在这个列表中也没有空闲块。然后它继续前进到大小为32k的下一个高阶列表（*free_pages*数组的第三个偏移）中查找空闲块；如果有的话，它将32k块分成两个相等的16k块（*伙伴*）。第一个16k块进一步分成两个8k的半块（*伙伴*），其中一个分配给调用者，另一个放入8k列表。第二个16k块放入16k空闲列表，当低阶（8k）伙伴在将来的某个时间变为空闲时，它们将合并为一个更高阶的16k块。当两个16k伙伴块都变为空闲时，它们再次合并为一个32k块，然后放回空闲列表。
- en: 'When a request for allocation from a desired *zone* cannot be processed, the
    buddy system uses a fallback mechanism to look for other zones and nodes:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当无法处理来自所需*区域*的分配请求时，伙伴系统使用回退机制来查找其他区域和节点：
- en: '![](img/00024.jpeg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00024.jpeg)'
- en: '*The* buddy system has a long history with extensive implementations across
    various *nix operating systems with appropriate optimizations. As discussed earlier,
    it helps faster memory allocation and deallocations, and it also minimizes external
    fragmentation to some degree. With the advent of *huge pages,* which provide much-needed
    performance benefits, it has become all the more important to further efforts
    toward anti-fragmentation. To accomplish this, the Linux kernel''s implementation
    of the buddy system is equipped with anti-fragmentation capability through page
    migration.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '*伙伴系统*在各种*nix操作系统中有着悠久的历史，并进行了广泛的实现和适当的优化。正如前面讨论的那样，它有助于更快的内存分配和释放，并且在一定程度上最小化了外部碎片化。随着提供了急需的性能优势的*大页*的出现，进一步努力以抵制碎片化变得更加重要。为了实现这一点，Linux内核对伙伴系统的实现配备了通过页面迁移实现抵制碎片化的能力。'
- en: '**Page migration** is a process of *moving* data of a virtual page from one
    physical memory region to another. This mechanism helps create larger blocks with
    contiguous pages. To realize this, pages are categorized into the following types:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**页面迁移**是将虚拟页面的数据从一个物理内存区域移动到另一个的过程。这种机制有助于创建具有连续页面的更大块。为了实现这一点，页面被归类为以下类型：'
- en: '**1\. Unmovable pages**: Physical pages which are pinned and reserved for a
    specific allocation are considered unmovable. Pages pinned for the core kernel
    fall into this category. These pages are non reclaimable.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 不可移动页面**：被固定并保留用于特定分配的物理页面被视为不可移动。核心内核固定的页面属于这一类。这些页面是不可回收的。'
- en: '**2\. Reclaimable pages**: Physical pages mapped to a dynamic allocation that
    can be evicted to a backstore, and those which can be regenerated are considered
    *reclaimable*. Pages held for file caching, anonymous page mappings, and those
    held by the kernel''s slab caches fall into this category. Reclaim operations
    are carried out in two modes: periodic and direct reclaim, the former is achieved
    through a kthread called *`kswapd`.* When system runs exceedingly short of memory,
    kernel enters into *direct reclaim.*'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 可回收页面：映射到动态分配的物理页面可以被驱逐到后备存储器，并且可以重新生成的页面被认为是*可回收*的。用于文件缓存，匿名页面映射以及内核的slab缓存持有的页面都属于这个类别。回收操作以两种模式进行：周期性回收和直接回收，前者通过称为*`kswapd`*的kthread实现。当系统内存严重不足时，内核进入*直接回收*。
- en: '**3\. Movable pages:** Physical pages that can be *moved to* different regions
    through page migration mechanism. Pages mapped to virtual address space of user-mode
    *process* are considered movable, since all the VM subsystem needs to do is copy
    data and change relevant page table entries. This works, considering all access
    operations from the user mode *process* are put through page table translations.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 可移动页面：可以通过页面迁移机制*移动到*不同区域的物理页面。映射到用户模式*进程*的虚拟地址空间的页面被认为是可移动的，因为所有VM子系统需要做的就是复制数据并更改相关的页表条目。这是有效的，考虑到所有来自用户模式*进程*的访问操作都经过页表翻译。
- en: 'The buddy system groups pages on the basis of *movability* into independent
    lists, and uses them for appropriate allocations. This is achieved by organizing
    each 2^n list in `struct free_area` as a group of autonomous lists based on mobility
    of pages. Each `free_area` instance holds an array of lists of size `MIGRATE_TYPES`.
    Each offset holds `list_head` of a respective group of pages:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 伙伴系统根据页面的*可移动性*将页面分组为独立列表，并将它们用于适当的分配。这是通过将`struct free_area`中的每个2^n列表组织为基于页面移动性的自主列表组实现的。每个`free_area`实例都持有大小为`MIGRATE_TYPES`的列表数组。每个偏移量都持有相应页面组的`list_head`：
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`nr_free` is a counter that holds the total number of free pages for this `free_area`
    (all migration lists put together). The following diagram depicts free lists for
    each migration type:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`nr_free`是一个计数器，它保存了此`free_area`（所有迁移列表放在一起）的空闲页面总数。以下图表描述了每种迁移类型的空闲列表：'
- en: '![](img/00025.jpeg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00025.jpeg)'
- en: 'The following enum defines page migration types:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下枚举定义了页面迁移类型：
- en: '[PRE13]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We have discussed key migration types `MIGRATE_MOVABLE`, `MIGRATE_UNMOVABLE`,
    and `MIGRATE_RECLAIMABLE` types. `MIGRATE_PCPTYPES` is a special type introduced
    to improve systems performance; each *zone* maintains a list of cache-hot pages
    in a per-CPU page cache. These pages are used to serve allocation requests raised
    by the local CPU. The *zone* descriptor structures `pageset` element points to
    pages in the per-CPU cache:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了关键的迁移类型`MIGRATE_MOVABLE`，`MIGRATE_UNMOVABLE`和`MIGRATE_RECLAIMABLE`类型。`MIGRATE_PCPTYPES`是一种特殊类型，用于提高系统性能；每个*区域*维护一个每CPU页缓存中的热缓存页面列表。这些页面用于为本地CPU提出的分配请求提供服务。*区域*描述符结构`pageset`元素指向每CPU缓存中的页面：
- en: '[PRE14]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '`struct per_cpu_pageset` is an abstraction that represents *unmovable*, *reclaimable*,
    and *movable* page lists. `MIGRATE_PCPTYPES` is a count of per-CPU page lists
    sorted as per page *mobility.* `MIGRATE_CMA` is list of pages for the contiguous
    memory allocator, which we shall discuss in further sections:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`struct per_cpu_pageset`是一个表示*不可移动*，*可回收*和*可移动*页面列表的抽象。`MIGRATE_PCPTYPES`是按页面*移动性*排序的每CPU页面列表的计数。`MIGRATE_CMA`是连续内存分配器的页面列表，我们将在后续部分中讨论：'
- en: '**![](img/00026.jpeg)**'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**![](img/00026.jpeg)**'
- en: 'The buddy system is implemented to *fall back* on the alternate list, to process
    an allocation request when pages of desired mobility are not available. The following
    array defines the fallback order for various migration types; we will not go into
    further elaboration as it is self explanatory:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当所需移动性的页面不可用时，伙伴系统实现了*回退*到备用列表，以处理分配请求。以下数组定义了各种迁移类型的回退顺序；我们不会进一步详细说明，因为它是不言自明的：
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: GFP mask
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GFP掩码
- en: 'Page allocator and other allocator routines (which we''ll discuss in the following
    sections) need the `gfp_mask` flag as an argument, which is of type `gfp_t`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 页面分配器和其他分配器例程（我们将在以下部分讨论）需要`gfp_mask`标志作为参数，其类型为`gfp_t`：
- en: '[PRE16]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Gfp flags are used to supply two vital attributes for the allocator functions:
    the first is the **mode** of the allocation, which controls the behavior of the
    allocator function*,* and the second is the *source* of the allocation, which
    indicates the *zone* or list of *zones* from which memory can be sourced*.* The
    kernel header `gfp.h` defines various flag constants that are categorized into
    distinct groups, called **zone modifiers, mobility and** **placement flags, watermark
    modifiers, reclaim modifiers,** and **action modifiers.**'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Gfp标志用于为分配器函数提供两个重要属性：第一个是分配的**模式**，它控制分配器函数的行为*，*第二个是分配的*来源*，它指示可以从中获取内存的*区域*或*区域*列表*。*内核头文件`gfp.h`定义了各种标志常量，这些常量被分类为不同的组，称为**区域修饰符，移动性和**
    **放置标志，水位标志，回收修饰符**和**操作修饰符。**
- en: Zone modifiers
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 区域修饰符
- en: 'Following is a summarized list of modifiers used to specify the *zone* from
    which memory is to be sourced. Recall our discussions on *zones* in an earlier
    section; for each of them, a `gfp` flag is defined:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是用于指定要从中获取内存的*区域*的修饰符的总结列表。回顾我们在前一节中对*区域*的讨论；对于每个*区域*，都定义了一个`gfp`标志：
- en: '[PRE17]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Page mobility and placement
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 页面移动性和放置
- en: 'The following code snippet defines page mobility and placement flags:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段定义了页面移动性和放置标志：
- en: '[PRE18]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Following is a list of page mobility and placement flags:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是页面移动性和放置标志的列表：
- en: '**`__GFP_RECLAIMABLE`**: Most kernel subsystems are designed to engage *memory
    caches* for caching frequently needed resources such as data structures, memory
    blocks, persistent file data, and so on. The memory manager maintains such caches
    and allows them to dynamically expand on demand. However, such caches cannot be
    allowed to expand boundlessly, or they will eventually consume all memory. The
    memory manager handles this issue through the **shrinker** interface, a mechanism
    by which the memory manager can shrink a cache, and reclaim pages when needed.
    Enabling this flag while allocating pages (for the cache) is an indication to
    the shrinker that the page is *reclaimable.* This flag is used by the slab allocator,
    which is discussed in a later section.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_RECLAIMABLE`：大多数内核子系统都设计为使用*内存缓存*来缓存频繁需要的资源，例如数据结构、内存块、持久文件数据等。内存管理器维护这些缓存，并允许它们根据需要动态扩展。但是，不能无限制地扩展这些缓存，否则它们最终会消耗所有内存。内存管理器通过**shrinker**接口处理此问题，这是一种内存管理器可以在需要时缩小缓存并回收页面的机制。在分配页面（用于缓存）时启用此标志表示向shrinker指示页面是*可回收*的。这个标志由后面的部分讨论的slab分配器使用。'
- en: '**`__GFP_WRITE`**: When this flag is used, it indicates to the kernel that
    the caller intends to dirty the page. The memory manager allocates the appropriate
    page as per the fair-zone allocation policy, which round-robins the allocation
    of such pages across local *zones* of the node to avoid all the dirty pages being
    in one *zone*.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_WRITE`：当使用此标志时，表示向内核指示调用者打算污染页面。内存管理器根据公平区分配策略分配适当的页面，该策略在节点的本地*区域*之间轮流分配这些页面，以避免所有脏页面都在一个*区域*中。'
- en: '`__GFP_HARDWALL`: This flag ensures that allocation is carried out on same
    node or nodes to which the caller is bound; in other words, it enforces the CPUSET
    memory allocation policy.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_HARDWALL`：此标志确保分配在与调用者绑定的相同节点或节点上进行；换句话说，它强制执行CPUSET内存分配策略。'
- en: '**`__GFP_THISNODE`**: This flag forces the allocation to be satisfied from
    the requested node with no fallbacks or placement policy enforcements.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_THISNODE`：此标志强制满足分配请求来自请求的节点，没有回退或放置策略的强制执行。'
- en: '`__GFP_ACCOUNT`: This flag causes allocations to be accounted for the kmem
    control group.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_ACCOUNT`：此标志导致分配被kmem控制组记录。'
- en: Watermark modifiers
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 水印修饰符
- en: 'The following code snippet defines the watermark modifiers:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段定义了水印修饰符：
- en: '[PRE19]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Following is list of watermark modifiers, which provide control over emergency
    reserve pools of memory:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是水印修饰符的列表，它们可以控制内存的紧急保留池：
- en: '**`__GFP_ATOMIC`**: This flag indicates that allocation is high priority and
    the caller context cannot be put into wait.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_ATOMIC`：此标志表示分配具有高优先级，并且调用者上下文不能被置于等待状态。'
- en: '**`__GFP_HIGH`**: This flag indicates that the caller is high priority and
    granting allocation request is necessary for the system to make progress. Setting
    this flag will cause the allocator to access the emergency pool.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_HIGH`：此标志表示调用者具有高优先级，并且必须满足分配请求以使系统取得进展。设置此标志将导致分配器访问紧急池。'
- en: '**`__GFP_MEMALLOC`**: This flag allows access to all memory. This should only
    be used when the caller guarantees the allocation will allow more memory to be
    freed very shortly, for example, process exiting or swapping.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_MEMALLOC`：此标志允许访问所有内存。只有在调用者保证分配很快就会释放更多内存时才应使用，例如，进程退出或交换。'
- en: '**`__GFP_NOMEMALLOC`**: This flag is used to forbid access to all reserved
    emergency pools.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_NOMEMALLOC`：此标志用于禁止访问所有保留的紧急池。'
- en: Page reclaim modifiers
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 页面回收修饰符
- en: 'As systems load increases, the amount of free memory in *zones* might fall
    below the *low watermark,* resulting in memory crunch that will acutely impact
    overall performance of the system*.* To handle such eventuality, the memory manager
    is equipped with **page reclaim algorithms,** which are implemented to identify
    and reclaim pages. Kernel memory allocator routines, engage reclaim algorithms
    when invoked with appropriate GFP constants called **page reclaim modifiers**:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 随着系统负载的增加，*区域*中的空闲内存量可能会低于*低水位标记*，导致内存紧缩，这将严重影响系统的整体性能*。为了处理这种可能性，内存管理器配备了**页面回收算法**，用于识别和回收页面。当使用适当的GFP常量调用内核内存分配器例程时，会启用回收算法，称为**页面回收修饰符**：
- en: '[PRE20]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Following is a list of reclaim modifiers that can be passed as arguments to
    allocation routines; each flag enables reclaim operations on a specific region
    of memory:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可以作为参数传递给分配例程的回收修饰符列表；每个标志都可以在特定内存区域上启用回收操作：
- en: '**`__GFP_IO`**: This flag indicates that the allocator can start physical I/O
    (swap) to reclaim memory.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_IO`：此标志表示分配器可以启动物理I/O（交换）以回收内存。'
- en: '`__GFP_FS`: This flag indicates that the allocator may call down to the low-level
    FS for reclaim.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_FS`：此标志表示分配器可以调用低级FS进行回收。'
- en: '**`__GFP_DIRECT_RECLAIM`**: This flag indicates that the caller is willing
    to enter direct reclaim. This might cause the caller to block.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_DIRECT_RECLAIM`：此标志表示调用者愿意进行直接回收。这可能会导致调用者阻塞。'
- en: '**`__GFP_KSWAPD_RECLAIM`**: This flag indicates that the allocator can wake
    the `kswapd` kernel thread to initiate reclaim, when the low watermark is reached.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_KSWAPD_RECLAIM`：此标志表示分配器可以唤醒`kswapd`内核线程来启动回收，当低水位标记达到时。'
- en: '**`__GFP_RECLAIM`**: This flag is used to enable direct and `kswapd` reclaim.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_RECLAIM`：此标志用于启用直接和`kswapd`回收。'
- en: '**`__GFP_REPEAT`**: This flag indicates to try hard to allocate the memory,
    but the allocation attempt might fail.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_REPEAT`：此标志表示尝试努力分配内存，但分配尝试可能失败。'
- en: '**`__GFP_NOFAIL`**: This flag forces the virtual memory manager to *retry*
    until the allocation request. succeeds. This might cause the VM to trigger the
    OOM killer to reclaim memory.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_NOFAIL`：此标志强制虚拟内存管理器*重试*，直到分配请求成功。这可能会导致VM触发OOM killer来回收内存。'
- en: '`__GFP_NORETRY`: This flag will cause the allocator to return appropriate failure
    status when the request cannot be served.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_NORETRY`：当无法满足请求时，此标志将导致分配器返回适当的失败状态。'
- en: Action modifiers
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动作修饰符
- en: 'The following code snippet defines action modifiers:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段定义了动作修饰符：
- en: '[PRE21]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Following is a list of action modifier flags; these flags specify additional
    attributes to be considered by the allocator routines while processing a request:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是动作修饰符标志的列表；这些标志指定了在处理请求时分配器例程要考虑的附加属性：
- en: '**`__GFP_COLD`**: To enable quick access, a few pages in each *zone* are cached
    into per-CPU caches; pages held in cache are referred to as **hot**, and uncached
    pages are referred to as **cold.** This flag indicates that the allocator should
    serve memory requests through cache cold page(s).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`__GFP_COLD`**：为了实现快速访问，每个*区域*中的一些页面被缓存在每个CPU的缓存中；缓存中保存的页面被称为**热**，而未缓存的页面被称为**冷**。此标志表示分配器应通过缓存冷页面来处理内存请求。'
- en: '**`__GFP_NOWARN`**: This flag causes the allocator to run in silent mode, which
    results in warning and error conditions to go unreported.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`__GFP_NOWARN`**：此标志导致分配器以静默模式运行，导致警告和错误条件不被报告。'
- en: '**`__GFP_COMP`**: This flag is used to allocate a compound page with appropriate
    metadata. A compound page is a group of two or more physically contiguous pages,
    which are treated as a single large page. Metadata makes a compound page distinct
    from other physically contiguous pages. The first physical page of a compound
    page is called the **head page** with the `PG_head` flag set in its page descriptor,
    and the rest of the pages are referred to as **tail pages**.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`__GFP_COMP`**：此标志用于分配带有适当元数据的复合页面。复合页面是两个或更多个物理上连续的页面组成的，被视为单个大页面。元数据使复合页面与其他物理上连续的页面不同。复合页面的第一个物理页面称为**头页面**，其页面描述符中设置了`PG_head`标志，其余页面称为**尾页面**。'
- en: '**`__GFP_ZERO`**: This flag causes the allocator to return zero filled page(s).'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`__GFP_ZERO`**：此标志导致分配器返回填充为零的页面。'
- en: '**`__GFP_NOTRACK`**: kmemcheck is one of the in-kernel debuggers which is used
    detect and warn about uninitialized memory access. Nonetheless, such checks cause
    memory access operations to be delayed. When performance is a criteria, the caller
    might want to allocate memory which is not tracked by kmemcheck. This flag causes
    the allocator to return such memory.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`__GFP_NOTRACK`**：kmemcheck是内核中的一个调试器，用于检测和警告未初始化的内存访问。尽管如此，这些检查会导致内存访问操作被延迟。当性能是一个标准时，调用者可能希望分配不被kmemcheck跟踪的内存。此标志导致分配器返回这样的内存。'
- en: '**`__GFP_NOTRACK_FALSE_POSITIVE`**: This flag is an alias of **`__GFP_NOTRACK`**.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`__GFP_NOTRACK_FALSE_POSITIVE`**：此标志是**`__GFP_NOTRACK`**的别名。'
- en: '`__GFP_OTHER_NODE`: This flag is used for allocation of transparent huge pages
    (THP).'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__GFP_OTHER_NODE`：此标志用于分配透明巨大页面（THP）。'
- en: Type flags
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类型标志
- en: 'With so many categories of modifier flags (each addressing different attributes),
    programmers exercise extreme care when choosing flags for corresponding allocations.
    To make the process easier and quicker, type flags were introduced, which enable
    programmers to make quick allocation choices. **Type flags** are derived from
    combinations of various modifier constants (listed previously) for specific allocation
    use cases. Programmers however can further customize type flags if required:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有这么多类别的修饰符标志（每个都涉及不同的属性），程序员在选择相应分配的标志时要非常小心。为了使这个过程更容易、更快速，引入了类型标志，使程序员能够快速进行分配选择。**类型标志**是从各种修饰常量的组合（前面列出的）中派生出来的，用于特定的分配用例。然而，如果需要，程序员可以进一步自定义类型标志：
- en: '[PRE22]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following is the list of type flags:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是类型标志的列表：
- en: '**`GFP_ATOMIC`**: This flag is specified for non blocking allocations that
    cannot fail. This flag will cause allocations from emergency reserves. This is
    generally used while invoking the allocator from an atomic context.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GFP_ATOMIC`**：指定非阻塞分配的标志，这种分配不会失败。此标志将导致从紧急储备中分配。通常在从原子上下文调用分配器时使用。'
- en: '**`GFP_KERNEL`**: This flag is used while allocating memory for kernel use.
    These requests are processed from normal *zone*. This flag might cause the allocator
    to enter direct reclaim.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GFP_KERNEL`**：在为内核使用分配内存时使用此标志。这些请求是从正常*区域*处理的。此标志可能导致分配器进入直接回收。'
- en: '**`GFP_KERNEL_ACCOUNT`**: Same as `GFP_KERNEL` with an addition that allocation
    is tracked by the kmem control group**.**'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GFP_KERNEL_ACCOUNT`**：与`GFP_KERNEL`相同，但额外增加了由kmem控制组跟踪分配的标志**。**'
- en: '`GFP_NOWAIT`: This flag is used for kernel allocations that are non-blocking.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GFP_NOWAIT`：此标志用于非阻塞的内核分配。'
- en: '`GFP_NOIO`: This flag allows the allocator to begin direct reclaim on clean
    pages that do not require physical I/O(swap).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GFP_NOIO`：此标志允许分配器在不需要物理I/O（交换）的干净页面上开始直接回收。'
- en: '`GFP_NOFS`: This flag allows the allocator to begin direct reclaim but prevents
    invocation of filesystem interfaces.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GFP_NOFS`：此标志允许分配器开始直接回收，但阻止调用文件系统接口。'
- en: '**`GFP_TEMPORARY`**: This flag is used while allocating pages for kernel caches,
    which are reclaimable through the appropriate shrinker interface. This flag sets
    the `__GFP_RECLAIMABLE` flag we discussed earlier.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GFP_TEMPORARY`**：在为内核缓存分配页面时使用此标志，通过适当的收缩器接口可以回收这些页面。此标志设置了我们之前讨论过的`__GFP_RECLAIMABLE`标志。'
- en: '**`GFP_USER`**: This flag is used for user-space allocations. Memory allocated
    is mapped to a user process and can also be accessed by kernel services or hardware
    for DMA transfers from device into buffer or vice versa.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GFP_USER`**：此标志用于用户空间分配。分配的内存被映射到用户进程，并且也可以被内核服务或硬件访问，用于从设备到缓冲区或反之的DMA传输。'
- en: '**`GFP_DMA`**: This flag causes allocation from the lowest *zone*, called `ZONE_DMA`.
    This flag is still supported for backward compatibility.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GFP_DMA`**：此标志导致从最低的*区域*`ZONE_DMA`中分配。这个标志仍然为向后兼容而支持。'
- en: '`GFP_DMA32`: This flag causes allocation to be processed from `ZONE_DMA32`
    which contains pages in < 4G memory.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GFP_DMA32`：此标志导致从包含<4G内存的`ZONE_DMA32`中处理分配。'
- en: '`GFP_HIGHUSER`: This flag is used for user space allocations from **`ZONE_HIGHMEM`**
    (relevant only on 32-bit platforms).'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GFP_HIGHUSER`：此标志用于从**`ZONE_HIGHMEM`**（仅在32位平台上相关）分配用户空间分配。'
- en: '`GFP_HIGHUSER_MOVABLE`: This flag is similar to `GFP_HIGHUSER`, with an addition
    that allocations are carried out from movable pages, which enables page migration
    and reclaim.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GFP_HIGHUSER_MOVABLE`：此标志类似于`GFP_HIGHUSER`，另外还可以从可移动页面中进行分配，这使得页面迁移和回收成为可能。'
- en: '**`GFP_TRANSHUGE_LIGHT`**: This causes the allocation of transparent huge allocations
    (THP), which are compound allocations. This type flag sets `__GFP_COMP`, which
    we discussed earlier.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**`GFP_TRANSHUGE_LIGHT`**：这会导致透明巨大分配（THP）的分配，这是复合分配。这种类型的标志设置了`__GFP_COMP`，我们之前讨论过。'
- en: Slab allocator
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 粘土块分配器
- en: As discussed in earlier sections, the page allocator (in coordination with buddy
    system) does an efficient job of handling memory allocation requests in multiples
    of page size. However, most allocation requests initiated by kernel code for its
    internal use are for smaller blocks (usually less than a page); engaging the page
    allocator for such allocations results in *internal fragmentation,* causing wastage
    of memory. The slab allocator is implemented precisely to address this; it is
    built on top of the buddy system and is used to allocate small memory blocks,
    to hold structure objects or data used by kernel services.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的部分所讨论的，页面分配器（与伙伴系统协调）有效地处理了页面大小的多重内存分配请求。然而，内核代码发起的大多数分配请求用于其内部使用的较小块（通常小于一页）；为这样的分配请求启用页面分配器会导致*内部碎片*，导致内存浪费。粘土块分配器正是为了解决这个问题而实现的；它建立在伙伴系统之上，用于分配小内存块，以容纳内核服务使用的结构对象或数据。
- en: 'Design of the slab allocator is based on an idea of *object* *cache****.***
    The concept of an **object cache** is quite simple: it involves reserving a set
    of free page frames, dividing and organize them into independent free lists (with
    each list containing a few free pages) called **slab caches**, and using each
    list for allocation of a pool of objects or memory blocks of a fixed size, called
    a **unit**. This way, each list is assigned a unique *unit* size, and would contain
    a pool of objects or memory blocks of that size. When an allocation request arrives
    for a block of memory of a given size, the allocator algorithm selects an appropriate
    *slab cache* whose *unit* size is the best fit for the requested size, and returns
    the address of a free block.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 粘土块分配器的设计基于*对象* *缓存*的概念。**对象缓存**的概念非常简单：它涉及保留一组空闲页面帧，将它们分割并组织成独立的空闲列表（每个列表包含一些空闲页面），称为**粘土块缓存**，并使用每个列表来分配一组固定大小的对象或内存块，称为**单元**。这样，每个列表被分配一个唯一的*单元*大小，并包含该大小的对象或内存块的池。当收到对给定大小的内存块的分配请求时，分配器算法会选择一个适当的*粘土块缓存*，其*单元*大小最适合请求的大小，并返回一个空闲块的地址。
- en: However, at a low level, there is fair bit of complexity involved in terms of
    initialization and management of slab caches. The algorithm needs to consider
    various issues such as object tracking, dynamic expansion, and safe reclaim through
    the shrinker interface. Addressing all these issues and achieving a proper balance
    between enhanced performance and optimum memory footprint is quite a challenge.
    We shall explore more on these challenges in subsequent sections, but for now
    we will continue our discussion with allocator function interfaces.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在低级别上，初始化和管理粘土块缓存涉及相当复杂的问题。算法需要考虑各种问题，如对象跟踪、动态扩展和通过shrinker接口进行安全回收。解决所有这些问题，并在增强性能和最佳内存占用之间取得适当的平衡是相当具有挑战性的。我们将在后续部分更多地探讨这些挑战，但现在我们将继续讨论分配器函数接口。
- en: Kmalloc caches
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kmalloc缓存
- en: 'Slab allocator maintains a set of generic slab caches to cache memory blocks
    of *unit* sizes in multiples of 8\. It maintains two sets of slab caches for each
    *unit* size, one to maintain a pool of memory blocks allocated from `ZONE_NORMAL`
    pages and another from `ZONE_DMA` pages. These caches are global and shared by
    all kernel code. Users can track the status of these caches through a special
    file `/proc/slabinfo`*.* Kernel services can allocate and release memory blocks
    from these caches through the `kmalloc` family of routines*.* They are referred
    to as `kmalloc` caches:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 粘土块分配器维护一组通用粘土块缓存，以缓存8的倍数的*单元*大小的内存块。它为每个*单元*大小维护两组粘土块缓存，一组用于维护从`ZONE_NORMAL`页面分配的内存块池，另一组用于维护从`ZONE_DMA`页面分配的内存块池。这些缓存是全局的，并由所有内核代码共享。用户可以通过特殊文件`/proc/slabinfo`跟踪这些缓存的状态。内核服务可以通过`kmalloc`系列例程从这些缓存中分配和释放内存块。它们被称为`kmalloc`缓存：
- en: '[PRE23]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '`kmalloc-96` and `kmalloc-192` are caches used to maintain memory blocks aligned
    with the level 1 hardware cache. For allocations above 8k (large blocks), the
    slab allocator falls back on buddy system.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`kmalloc-96`和`kmalloc-192`是用于维护与一级硬件缓存对齐的内存块的缓存。对于大于8k的分配（大块），粘土块分配器会回退到伙伴系统。'
- en: 'Following are the kmalloc family of allocator routines; all of these need appropriate
    GFP flags:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是kmalloc系列分配器例程；所有这些都需要适当的GFP标志：
- en: '[PRE24]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Following routines return the allocated block to the free pool. Callers need
    to ensure that address passed as argument is of a valid allocated block:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下例程将分配的块返回到空闲池中。调用者需要确保作为参数传递的地址是有效的分配块：
- en: '[PRE25]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Object caches
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对象缓存
- en: 'The slab allocator provides function interfaces for setting up slab caches,
    which can be owned by a kernel service or a subsystem. Such caches are considered
    private since they are local to kernel services (or a kernel subsystem) like device
    drivers, file systems, process scheduler, and so on. This facility is used by
    most kernel subsystems to set up object caches and pool intermittently needed
    data structures. Most data structures we''ve encountered so far (since [Chapter
    1](part0020.html#J2B80-7300e3ede2f245b0b80e1b18d02a323f), *Comprehending Processes,
    Address Space, and Threads*) including process descriptor, signal descriptor,
    page descriptor, and so on are maintained in such object pools. The pseudo file
    `/proc/slabinfo` shows the status of object caches:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: slab分配器提供了用于设置slab缓存的函数接口，这些缓存可以由内核服务或子系统拥有。由于这些缓存是局部于内核服务（或内核子系统）的，因此被认为是私有的，例如设备驱动程序、文件系统、进程调度程序等。大多数内核子系统使用此功能来设置对象缓存和池化间歇性需要的数据结构。到目前为止，我们遇到的大多数数据结构（自[第1章](part0020.html#J2B80-7300e3ede2f245b0b80e1b18d02a323f)以来，*理解进程、地址空间和线程*），包括进程描述符、信号描述符、页面描述符等，都是在这样的对象池中维护的。伪文件`/proc/slabinfo`显示了对象缓存的状态：
- en: '[PRE26]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `*kmem_cache_create()*` routine sets up a new *cache* as per the parameter
    passed. On success, it returns the address to the cache descriptor structure of
    type `*kmem_cache*`:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`*kmem_cache_create()*`例程根据传递的参数设置一个新的*cache*。成功后，它将返回`*kmem_cache*`类型的缓存描述符结构的地址：'
- en: '[PRE27]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '*The cache* is created by allocating free page frames (from buddy system),
    and data objects of *size* specified (second argument) are populated. Though each
    cache starts by hosting a fixed number of data objects during creation*,* they
    can grow dynamically when required to accommodate more number of data objects.
    Data structures can be complicated (we have encountered a few), and can contain
    varied elements such as list headers, sub-objects, arrays, atomic counters, bit-fields,
    and so on. Setting up each object might require all its fields to be initialized
    to the default state; this can be achieved through an initializer routine assigned
    to a `*ctor` function pointer (last argument). The initializer is called for each
    new object allocated, both during cache creation and when it grows to add more
    free objects. However, for simple objects, a *cache* can be created without an
    initializer.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 缓存是通过分配空闲页面帧（来自伙伴系统）创建的，并且指定大小的数据对象（第二个参数）会被填充。尽管每个缓存在创建时都会托管固定数量的数据对象，但在需要时它们可以动态增长以容纳更多的数据对象。数据结构可能会很复杂（我们遇到了一些），并且可能包含各种元素，如列表头、子对象、数组、原子计数器、位字段等。设置每个对象可能需要将其所有字段初始化为默认状态；这可以通过分配给`*ctor`函数指针（最后一个参数）的初始化程序来实现。初始化程序会在分配每个新对象时调用，无论是在缓存创建时还是在增长以添加更多空闲对象时。然而，对于简单的对象，可以创建一个没有初始化程序的缓存。
- en: '[PRE28]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[PRE29]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Flags are used to enable debug checks, and enhance the performance of access
    operations on cache by aligning objects with the hardware cache. The following
    flag constants are supported:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 标志用于启用调试检查，并通过将对象与硬件缓存对齐来增强对缓存的访问操作的性能。支持以下标志常量：
- en: '[PRE30]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Subsequently, *objects* can be allocated and released through relevant functions.
    Upon release, *objects* are put back into the free list of the *cache*, making
    them available for reuse; this results in a possible performance boost, particularly
    when *objects* are cache hot:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，*对象*可以通过相关函数进行分配和释放。释放后，*对象*将放回到*cache*的空闲列表中，使其可以重新使用；这可能会带来性能提升，特别是当*对象*是缓存热点时。
- en: '[PRE31]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: kmem caches can be destroyed when all hosted data objects are *free* (not in
    use)*,* by calling `kmem_cache_destroy().`
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有托管的数据对象都是*free*（未使用）时，可以通过调用`kmem_cache_destroy()`来销毁kmem缓存。
- en: Cache management
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存管理
- en: All slab caches are managed internally by **slab core**, which is a low-level
    algorithm. It defines various control structures that describe the physical layout
    for each **cache list**, and implements core cache-management operations which
    are invoked by interface routines. The slab allocator was originally implemented
    in Solaris 2.4 kernels, and used by most other *nix kernels, based on a paper
    by Bonwick.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 所有slab缓存都由**slab核心**在内部管理，这是一个低级算法。它定义了描述每个**缓存列表**的物理布局的各种控制结构，并实现了由接口例程调用的核心缓存管理操作。slab分配器最初是在Solaris
    2.4内核中实现的，并且被大多数其他*nix内核使用，基于Bonwick的一篇论文。
- en: Traditionally, Linux was used on uniprocessor desktop and server systems with
    moderate memories, and the kernel adopted the classic model of Bonwick with appropriate
    performance improvements. Over the years, due to diversity of the platforms with
    distinct priorities for which the Linux kernel is ported and used, it turns out
    that the classic implementation of the slab core algorithm is inefficient to cater
    to all the needs. While memory-constrained embedded platforms cannot afford the
    higher footprint of the allocator (space used to manage metadata and density of
    allocator operations), SMP systems with huge memories need consistent performance,
    scalability, and better mechanisms to generate trace and debug information on
    allocations.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 传统上，Linux被用于具有中等内存的单处理器桌面和服务器系统，并且内核采用了Bonwick的经典模型，并进行了适当的性能改进。多年来，由于Linux内核被移植和使用的平台多样性，对于所有需求来说，slab核心算法的经典实现都是低效的。虽然内存受限的嵌入式平台无法承受分配器的更高占用空间（用于管理元数据和分配器操作的密度），但具有大内存的SMP系统需要一致的性能、可伸缩性，并且需要更好的机制来生成分配的跟踪和调试信息。
- en: 'To cater to these dissimilar requirements, current versions of the kernel provide
    three distinct implementations of the slab algorithm: **slob**, a classic K&R
    type list allocator, designed for low-memory systems with scarce allocation needs,
    and was default object allocator for Linux during its initial years(1991-1999);
    **slab**, a classic Solaris-style slab allocator that has been around in Linux
    since 1999; and **slub**, improved for current generation SMP hardware with huge
    memories, and delivers consistent performance with better control and debug mechanisms.
    The default kernel configuration for most architectures enables **slub** as default
    slab allocator; this can be changed during kernel build through kernel configuration
    options.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足这些不同的要求，当前版本的内核提供了slab算法的三种不同实现：**slob**，一个经典的K&R类型的链表分配器，设计用于内存稀缺的低内存系统，并且在Linux的最初几年（1991-1999）是默认的对象分配器；**slab**，一个经典的Solaris风格的slab分配器，自1999年以来一直存在于Linux中；以及**slub**，针对当前一代SMP硬件和巨大内存进行了改进，并提供了更好的控制和调试机制。大多数架构的默认内核配置都将**slub**作为默认的slab分配器；这可以在内核构建过程中通过内核配置选项进行更改。
- en: '`CONFIG_SLAB`: The regular slab allocator that is established and known to
    work well in all environments. It organizes cache hot objects in per-CPU and per
    node queues.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`CONFIG_SLAB`：常规的slab分配器在所有环境中都已经建立并且运行良好。它将缓存热对象组织在每个CPU和每个节点队列中。'
- en: '`CONFIG_SLUB`: **SLUB** is a slab allocator that minimizes cache line usage
    instead of managing queues of cached objects (SLAB approach). per-CPU caching
    is realized using slabs of objects instead of queues of objects. SLUB can use
    memory efficiently and has enhanced diagnostics. SLUB is the default choice for
    a slab allocator.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '`CONFIG_SLUB`：**SLUB**是一个最小化缓存行使用而不是管理缓存对象队列（SLAB方法）的slab分配器。使用对象的slab而不是对象队列来实现每个CPU的缓存。SLUB可以高效地使用内存，并具有增强的诊断功能。SLUB是slab分配器的默认选择。'
- en: '`CONFIG_SLOB`: **SLOB** replaces the stock allocator with a drastically simpler
    allocator. SLOB is generally more space efficient but does not perform as well
    on large systems.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '`CONFIG_SLOB`：**SLOB**用一个极其简化的分配器替换了原始的分配器。SLOB通常更节省空间，但在大型系统上的性能不如原始分配器。'
- en: 'Irrespective of the type of allocator chosen, the programming interface remains
    unchanged. In fact, at low level, all three allocators share some common code
    base:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 无论选择了哪种分配器，编程接口都保持不变。实际上，在低级别，所有三种分配器共享一些公共代码基础：
- en: '![](img/00027.jpeg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00027.jpeg)'
- en: We shall now look into physical layout of a *cache* and its control structures.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将研究*cache*的物理布局及其控制结构。
- en: Cache layout - generic
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存布局 - 通用
- en: Each cache is represented by a cache descriptor structure `kmem_cache`; this
    structure contains all crucial metadata of the cache. It includes a list of slab
    descriptors, each hosting a page or a group of page frames*.* Pages under slabs
    contain objects or memory blocks, which are the allocation *units* of the cache.
    The **slab descriptor** points to a list of objects contained in the pages and
    tracks their state. A slab may be in one of three possible states--full, partial
    or empty--based on the state of the objects it is hosting. A s*lab* is considered
    *full* when all its objects are *in use* with no *free* objects left for allocation.
    *A slab* with at least one free object is considered to be in *partial* state,
    and those with all objects in *free* state are considered *empty*.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 每个缓存都由一个缓存描述符结构`kmem_cache`表示；这个结构包含了缓存的所有关键元数据。它包括一个slab描述符列表，每个描述符承载一个页面或一组页面帧。slab下的页面包含对象或内存块，这些是缓存的分配单元。**slab描述符**指向页面中包含的对象列表并跟踪它们的状态。根据它承载的对象的状态，一个slab可能处于三种可能的状态之一--满的、部分的或空的。当一个slab中的所有对象都被使用并且没有剩余的自由对象可供分配时，*slab*被认为是*full*。至少有一个自由对象的slab被认为处于*partial*状态，而所有对象都处于*free*状态的slab被认为是*empty*。
- en: '![](img/00028.jpeg)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00028.jpeg)'
- en: This arrangement enables quick object allocations, since allocator routines
    can look up to the *partial* slab for a free object, and possibly move on to an
    *empty* slab if required. It also helps easier expansion of the cache with new
    page frames to accommodate more objects (when required), and facilitates safe
    and quick reclaims (slabs in *empty* state can be reclaimed).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 这种安排使得对象分配更快，因为分配器例程可以查找*partial* slab以获取一个自由对象，并在需要时可能转移到*empty* slab。它还有助于通过新的页面帧扩展缓存以容纳更多对象（在需要时），并促进安全和快速的回收（*empty*状态的slab可以被回收）。
- en: Slub data structures
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Slub数据结构
- en: 'Having looked at the layout of a cache and descriptors involved at a generic
    level, let''s push further to view specific data structures used by the **slub**
    allocator and explore the management of free lists. A s**lub** defines its version
    of cache descriptor, `struct kmem_cache`, in kernel header `/include/linux/slub-def.h`:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在通用级别上查看了缓存的布局和涉及的描述符之后，让我们进一步查看**slub**分配器使用的特定数据结构，并探索空闲列表的管理。一个**slub**在内核头文件`/include/linux/slub-def.h`中定义了它的版本的缓存描述符`struct
    kmem_cache`：
- en: '[PRE32]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The `list` element refers to a list of slab caches. When a new slab is allocated,
    it is stored on a list in the cache descriptor, and is considered *empty,* since
    all its objects are *free* and available. Upon allocation of an object, the slab
    turns into *partial* state. Partial slabs are the only type of slabs that the
    allocator needs to keep track of and are connected in a list inside the `kmem_cache`
    structure. The **SLUB** allocator has no interest in tracking *full* slabs whose
    objects have all been allocated, or *empty* slabs whose objects are *free*. **SLUB**
    tracks partial slabs for each node through an array of pointers of type `struct
    kmem_cache_node[MAX_NUMNODES]`, which encapsulates a list of *partial* slabs:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '`list`元素指的是一个slab缓存列表。当分配一个新的slab时，它被存储在缓存描述符的列表中，并被认为是*empty*，因为它的所有对象都是*free*并且可用的。在分配对象后，slab变为*partial*状态。部分slab是分配器需要跟踪的唯一类型的slab，并且在`kmem_cache`结构内部的列表中连接在一起。**SLUB**分配器对已分配所有对象的*full*
    slabs或对象都是*free*的*empty* slabs没有兴趣。**SLUB**通过`struct kmem_cache_node[MAX_NUMNODES]`类型的指针数组来跟踪每个节点的*partial*
    slabs，这个数组封装了*partial* slabs的列表。'
- en: '[PRE33]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: All *free* objects in a slab form a linked list; when allocation requests arrive,
    the first free object is removed from the list and its address is returned to
    the caller. Tracking free objects through a linked list requires significant metadata;
    while the traditional **SLAB** allocator maintained metadata for all pages of
    a slab within the slab header (causing data alignment issues), **SLUB** maintains
    per-page metadata for pages in a slab by cramming more fields into the page descriptor
    structure, thereby eliminating metadata from the slab head. **SLUB** metadata
    elements in the page descriptor are only valid when the corresponding page is
    part of a slab. Pages engaged for slab allocations have the `PG_slab` flag set.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: slab中的所有*free*对象形成一个链表；当分配请求到达时，从列表中移除第一个空闲对象，并将其地址返回给调用者。通过链表跟踪空闲对象需要大量的元数据；而传统的**SLAB**分配器在slab头部维护了所有slab页面的元数据（导致数据对齐问题），**SLUB**通过将更多字段塞入页面描述符结构中，从而消除了slab头部的元数据，为slab中的页面维护每页元数据。**SLUB**页面描述符中的元数据元素仅在相应页面是slab的一部分时才有效。用于slab分配的页面已设置`PG_slab`标志。
- en: 'The following are fields of the page descriptor relevant to SLUB:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是与SLUB相关的页面描述符的字段：
- en: '[PRE34]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The `freelist` pointer refers to the first free object in the list. Each free
    object is composed of a metadata area that contain a pointer to the next free
    object in the list. `index` holds the offset to the metadata area of the first
    free object (contains a pointer to next free object). The metadata area of last
    free object would contain the next free object pointer set to NULL. `inuse` contains
    the total count of allocated objects, and `objects` contains the total number
    of objects. `frozen` is a flag that is used as a page lock: if a page has been
    frozen by a CPU core, only that core can retrieve free objects from the page.
    `slab_cache` is a pointer to the kmem cache currently using this page:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '`freelist`指针指向列表中的第一个空闲对象。每个空闲对象由一个包含指向列表中下一个空闲对象的指针的元数据区域组成。`index`保存到第一个空闲对象的元数据区域的偏移量（包含指向下一个空闲对象的指针）。最后一个空闲对象的元数据区域将包含下一个空闲对象指针设置为NULL。`inuse`包含分配对象的总数，`objects`包含对象的总数。`frozen`是一个标志，用作页面锁定：如果页面被CPU核心冻结，只有该核心才能从页面中检索空闲对象。`slab_cache`是指向当前使用该页面的kmem缓存的指针：'
- en: '![](img/00029.jpeg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00029.jpeg)'
- en: When an allocation request arrives, the first free object is located through
    the `freelist` pointer, and is removed from the list by returning its address
    to the caller. The `inuse` counter is also incremented to indicate an increase
    in the number of allocated objects. The `freelist` pointer is then updated with
    the address of the next free object in the list.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当分配请求到达时，通过`freelist`指针找到第一个空闲对象，并通过将其地址返回给调用者来从列表中移除它。`inuse`计数器也会递增，以指示分配对象的数量增加。然后，`freelist`指针将更新为列表中下一个空闲对象的地址。
- en: 'For achieving enhanced allocation efficiency, each CPU is assigned a private
    active-slab list, which comprises a partial/free slab list for each object type.
    These slabs are referred to as CPU local slabs, and are tracked by struct `kmem_cache_cpu`:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现增强的分配效率，每个CPU被分配一个私有的活动slab列表，其中包括每种对象类型的部分/空闲slab列表。这些slab被称为CPU本地slab，并由struct
    `kmem_cache_cpu`跟踪：
- en: '[PRE35]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: When an allocation request arrives, the allocator takes the fast path and looks
    into the `freelist` of the per-CPU cache, and it then returns free objects. This
    is referred as the fast path since allocations are carried out through interrupt-safe
    atomic instructions that does not require lock contention. When the fast path
    fails, the allocator takes the slow path and looks through `*page*` and `*partial*`
    lists of the cpu cache sequentially. If no free objects are found, the allocator
    moves into the *partial* lists of nodes; this operation requires the allocator
    to contend for appropriate exclusion lock. On failure, the allocator gets a new
    slab from the buddy system. Fetching from either node lists or acquiring a new
    slab from buddy system are considered very slow paths, since both of these operations
    are not deterministic.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 当分配请求到达时，分配器会采用快速路径，并查看每个CPU缓存的`freelist`，然后返回空闲对象。这被称为快速路径，因为分配是通过中断安全的原子指令进行的，不需要锁竞争。当快速路径失败时，分配器会采用慢速路径，依次查看CPU缓存的`*page*`和`*partial*`列表。如果找不到空闲对象，分配器会移动到节点的*partial*列表；这个操作需要分配器争夺适当的排他锁。失败时，分配器从伙伴系统获取一个新的slab。从节点列表获取或从伙伴系统获取新的slab都被认为是非常慢的路径，因为这两个操作都不是确定性的。
- en: 'The following diagram depicts the relationship between slub data structures
    and free lists:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表描述了slub数据结构和空闲列表之间的关系：
- en: '![](img/00030.jpeg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![](img/00030.jpeg)'
- en: Vmalloc
  id: totrans-271
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vmalloc
- en: Page and slab allocators both allocate physically contiguous blocks of memory,
    mapped to contiguous kernel address space. Most of the time, kernel services and
    subsystems prefer to allocate physically contiguous blocks for exploiting caching,
    address translation, and other performance-related benefits. Nonetheless, allocation
    requests for very large blocks might fail due to fragmentation of physical memory,
    and there are few situations that necessitate allocation of large blocks, such
    as support for dynamically loadable modules, swap management operations, large
    file caches and so on.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 页面和slab分配器都分配物理连续的内存块，映射到连续的内核地址空间。大多数情况下，内核服务和子系统更喜欢分配物理连续的块，以利用缓存、地址转换和其他与性能相关的好处。尽管如此，对于非常大的块的分配请求可能会因为物理内存的碎片化而失败，而且有一些情况需要分配大块，比如支持动态可加载模块、交换管理操作、大文件缓存等等。
- en: As a solution, the kernel provides **vmalloc**, a fragmented memory allocator
    that attempts to allocate memory, by joining physically scattered memory regions
    through virtually contiguous address space. A range of virtual addresses within
    the kernel segment are reserved for vmalloc mappings, called vmalloc address space.
    Total memory that can be mapped through the vmalloc interface depends on the size
    of the vmalloc address space, which is defined by architecture-specific kernel
    macros `VMALLOC_START` and `VMALLOC_END`; for x86-64 systems, the total range
    of vmalloc address space is a staggering 32 TB**.** However, on the flip side,
    this range is too little for most 32-bit architectures (a mere 12o MB). Recent
    kernel versions use the vmalloc range for setting up a virtually mapped kernel
    stack (x86-64 only), which we discussed in the first chapter.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 作为解决方案，内核提供了**vmalloc**，这是一种分段内存分配器，通过虚拟连续地址空间将物理分散的内存区域连接起来进行内存分配。内核段内保留了一系列虚拟地址用于vmalloc映射，称为vmalloc地址空间。通过vmalloc接口可以映射的总内存量取决于vmalloc地址空间的大小，这由特定于架构的内核宏`VMALLOC_START`和`VMALLOC_END`定义；对于x86-64系统，vmalloc地址空间的总范围达到了惊人的32
    TB。然而，另一方面，这个范围对于大多数32位架构来说太小了（只有120 MB）。最近的内核版本使用vmalloc范围来设置虚拟映射的内核栈（仅限x86-64），这是我们在第一章中讨论过的。
- en: 'Following are interface routines for vmalloc allocations and deallocations:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是vmalloc分配和释放的接口例程：
- en: '[PRE36]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Most kernel developers avoid vmalloc allocations due to allocation overheads
    (since those are not identity mapped and require specific page table tweaks, resulting
    in TLB flushes) and performance penalties involved during access operations.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数内核开发人员避免使用vmalloc分配，因为分配开销较大（因为它们不是身份映射的，并且需要特定的页表调整，导致TLB刷新）并且在访问操作期间涉及性能惩罚。
- en: Contiguous Memory Allocator (CMA)
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连续内存分配器（CMA）
- en: Albeit with significant overheads, virtually mapped allocations solve the problem
    of large memory allocations to a greater extent. However, there are a few scenarios
    that mandate the allocation of physically contiguous buffers. DMA transfers are
    one such case. Device drivers often find a stringent need for physically contiguous
    buffer allocations (for setting up DMA transfers), which are carried out through
    any of the physically contiguous allocators discussed earlier.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在较大的开销，但虚拟映射的分配在很大程度上解决了大内存分配的问题。然而，有一些情况需要物理连续缓冲区的分配。DMA传输就是这样一种情况。设备驱动程序经常需要物理连续缓冲区的分配（用于设置DMA传输），这是通过之前讨论过的任何一个物理连续分配器来完成的。
- en: 'However, drivers dealing with specific classes of devices such as multimedia
    often find themselves searching for huge blocks of contiguous memory. To meet
    this end, over the years, such drivers have been *reserving* memory during system
    boot through the kernel parameter `mem`, which allows setting aside enough contiguous
    memory at boot, which can be *remapped* into linear address space during driver
    runtime. Though valuable, this strategy has its limitations: first, such reserved
    memories lie momentarily unused when the corresponding device is not initiating
    access operations, and second, depending on the number of devices to be supported,
    the size of reserved memories might increase substantially, which might severely
    impact system performance due to cramped physical memory.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，处理特定类别设备的驱动程序，如多媒体，经常发现自己在搜索大块连续内存。为了实现这一目标，多年来，这些驱动程序一直通过内核参数`mem`在系统启动时*保留*内存，这允许在驱动程序运行时设置足够的连续内存，并且可以在线性地址空间中*重新映射*。尽管有价值，这种策略也有其局限性：首先，当相应设备未启动访问操作时，这些保留内存暂时未被使用，其次，根据需要支持的设备数量，保留内存的大小可能会大幅增加，这可能会严重影响系统性能，因为物理内存被挤压。
- en: A **contiguous Memory Allocator** (**CMA**) is a kernel mechanism introduced
    to effectively manage *reserved* memories. The crux of *CMA* is to bring in *reserved*
    memories under the allocator algorithm, and such memory is referred to as *CMA
    area. CMA* allows allocations from the *CMA area* for both devices' and system's
    use. This is achieved by building a page descriptor list for pages in reserve
    memory, and enumerating it into the buddy system, which enables allocation of
    *CMA pages* through the page allocator for regular needs (kernel subsystems) and
    through DMA allocation routines for device drivers*.*
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '**连续内存分配器**（**CMA**）是一种内核机制，用于有效管理*保留*内存。*CMA*的核心是将*保留*内存引入分配器算法中，这样的内存被称为*CMA区域。CMA*允许从*CMA区域*为设备和系统的使用进行分配。这是通过为保留内存中的页面构建页面描述符列表，并将其列入伙伴系统来实现的，这使得可以通过页面分配器为常规需求（内核子系统）和通过DMA分配例程为设备驱动程序分配*CMA页面*。'
- en: However*,* it must be ensured that DMA allocations do not fail due to the usage
    of *CMA pages* for other purposes, and this is taken care through the `migratetype`
    attribute, which we discussed earlier*.* Pages enumerated by CMA into buddy system
    are assigned the `MIGRATE_CMA` property, which indicates that pages are movable*.*
    While allocating memory for non-DMA purposes *,* the page allocator can use CMA
    pages only for movable allocations (recall that such allocations can be made through
    the `__GFP_MOVABLE` flag). When a DMA allocation request arrives, CMA pages held
    by kernel allocations are *moved* out of the reserved region (through a page-migration
    mechanism), resulting in the availability of memory for the device driver's use.
    Further, when pages are allocated for DMA, their *migratetype* is changed from
    `MIGRATE_CMA` to `MIGRATE_ISOLATE`, making them invisible to the buddy system.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，必须确保DMA分配不会因为CMA页面用于其他目的而失败，这是通过`migratetype`属性来处理的，我们之前讨论过。CMA列举的页面被分配给伙伴系统的`MIGRATE_CMA`属性，表示页面是可移动的。在为非DMA目的分配内存时，页面分配器只能使用CMA页面进行可移动分配（回想一下，这样的分配可以通过`__GFP_MOVABLE`标志进行）。当DMA分配请求到达时，内核分配的CMA页面会从保留区域中移出（通过页面迁移机制），从而为设备驱动程序的使用提供内存。此外，当为DMA分配页面时，它们的`migratetype`从`MIGRATE_CMA`更改为`MIGRATE_ISOLATE`，使它们对伙伴系统不可见。
- en: The size of the *CMA area* can be chosen during kernel build through its configuration
    interface; optionally, it can also be passed through the kernel parameter `cma=`.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '*CMA区域*的大小可以在内核构建过程中通过其配置界面进行选择；可选地，也可以通过内核参数`cma=`进行传递。'
- en: Summary
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We have traversed through one of the most crucial aspects of the Linux kernel,
    comprehending various nuances of memory representations and allocations. By understanding
    this subsystem, we have also succinctly captured the design acumen and implementation
    efficiency of the kernel, and more importantly understood the kernel's dynamism
    in accommodating finer and newer heuristics and mechanisms for continuous enhancements.
    Apart from the specifics of memory management, we also gauged the efficiency of
    the kernel in maximizing resource usage at minimal costs, ushering all classical
    mechanisms of code reuse and modular code structures.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经穿越了Linux内核最关键的一个方面，理解了内存表示和分配的各种微妙之处。通过理解这个子系统，我们也简洁地捕捉到了内核的设计才能和实现效率，更重要的是理解了内核在容纳更精细和更新的启发式和机制以持续增强方面的动态性。除了内存管理的具体细节，我们还评估了内核在最大化资源利用方面的效率，引领了所有经典的代码重用机制和模块化代码结构。
- en: Though the specifics of memory management may vary in correspondence to the
    underlying architecture, the generalities of design and implementation styles
    would mostly remain the same to achieve code stability and sensitivity to change.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管内存管理的具体细节可能会根据底层架构而有所不同，但设计和实现风格的一般性大部分仍然保持一致，以实现代码稳定性和对变化的敏感性。
- en: 'In the next chapter, we will go further and look at another fundamental abstraction
    of the kernel: *files.* We will look through file I/O and explore its architecture
    and implementation details.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将进一步探讨内核的另一个基本抽象：*文件*。我们将浏览文件I/O并探索其架构和实现细节。
