["```\n[elasticsearch-6.x]\nname=Elasticsearch repository for 6.x packages\nbaseurl=https://artifacts.elastic.co/packages/6.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n```", "```\nyum makecache\n```", "```\nyum install java-1.8.0-openjdk\n```", "```\njava -version\n```", "```\n[root@elastic1 ~]# java -version\nopenjdk version \"1.8.0_191\"\nOpenJDK Runtime Environment (build 1.8.0_191-b12)\nOpenJDK 64-Bit Server VM (build 25.191-b12, mixed mode)\n```", "```\nyum install elasticsearch\n```", "```\n# ---------------------------------Paths-------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\npath.data: /var/lib/elasticsearch\n```", "```\nsudo parted /dev/sdX mklabel gpt\n```", "```\nsudo parted /dev/sdX mkpart xfs 0GB 64GB\n```", "```\nsudo parted /dev/sdX print\n```", "```\n[root@elastic1 ~]# parted /dev/sdb print\nModel: ATA VBOX HARDDISK (scsi)\nDisk /dev/sdb: 68.7GB\nSector size (logical/physical): 512B/512B\nPartition Table: gpt\nDisk Flags:\nNumber  Start End     Size    File system  Name Flags\n1      1049kB  64.0GB 64.0GB               xfs\n```", "```\n[root@elastic1]# mkfs.xfs /dev/sdb1\nmeta-data=/dev/sdb1              isize=512    agcount=4, agsize=3906176 blks\n         =                       sectsz=512   attr=2, projid32bit=1\n         =                       crc=1        finobt=0, sparse=0\ndata     =                       bsize=4096   blocks=15624704, imaxpct=25\n         =                       sunit=0      swidth=0 blks\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\nlog      =internal log           bsize=4096   blocks=7629, version=2\n         =                       sectsz=512   sunit=0 blks, lazy-count=1\nrealtime =none                   extsz=4096   blocks=0, rtextents=0\n```", "```\n[root@elastic1 ~]# blkid\n/dev/sda1: UUID=\"58c91edb-c361-470e-9805-a31efd85a472\" TYPE=\"xfs\"\n/dev/sda2: UUID=\"H3KcJ3-gZOS-URMD-CD1J-8wIn-f7v9-mwkTWn\" TYPE=\"LVM2_member\"\n/dev/sdb1: UUID=\"561fc663-0b63-4d2a-821e-12b6caf1115e\" TYPE=\"xfs\" PARTLABEL=\"xfs\" PARTUUID=\"7924e72d-15bd-447d-9104-388dd0ea4eb0\"\n```", "```\nUUID=561fc663-0b63-4d2a-821e-12b6caf1115e       /var/lib/elasticsearch  xfs     defaults,nobarrier,noatime,nofail       0 0\n```", "```\n[root@elastic1 /]# df -h\nFilesystem               Size  Used Avail Use% Mounted on\n/dev/mapper/centos-root   14G  1.6G   12G  12% /\ndevtmpfs                 1.9G     0  1.9G   0% /dev\ntmpfs                    1.9G     0  1.9G   0% /dev/shm\ntmpfs                    1.9G  8.5M  1.9G   1% /run\ntmpfs                    1.9G     0  1.9G   0% /sys/fs/cgroup\n/dev/sdb1                 60G   33M   60G   1% /var/lib/elasticsearch\n/dev/sda1               1014M  184M  831M  19% /boot\ntmpfs                    379M     0  379M   0% /run/user/0\n```", "```\nchown elasticsearch: /var/lib/elasticsearch\n```", "```\n# --------------------------------Cluster------------------------------\n#\n# Use a descriptive name for your cluster:\n#\ncluster.name: elastic-cluster\n#\n```", "```\n# -----------------------------Discovery-------------------------------\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\ndiscovery.zen.ping.unicast.hosts: [\"elastic2\"]\n#\n# Prevent the \"split brain\" by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):\n#\ndiscovery.zen.minimum_master_nodes: 2\n#\n# For more information, consult the zen discovery module documentation.\n```", "```\n#------------------------------Node---------------------------------\n#\n# Use a descriptive name for the node:\n#\nnode.name: elastic1\n```", "```\n#-----------------------------Network-------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: 0.0.0.0\n```", "```\n#-------------------------------Paths---------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\npath.data: /var/lib/elasticsearch\n#\n# Path to log files:\n#\npath.logs: /var/log/elasticsearch\n```", "```\nsystemctl start elasticsearch && systemctl enable elasticsearch\n```", "```\ncurl -X GET \"elastic1:9200\"\n```", "```\n[root@elastic1 /]# curl -X GET \"elastic1:9200\"\n{\n \"name\" : \"elastic1\",\n \"cluster_name\" : \"elastic-cluster\",\n \"cluster_uuid\" : \"pIH5Z0yAQoeEGXcDuyEKQA\",\n \"version\" : {\n \"number\" : \"6.5.3\",\n \"build_flavor\" : \"default\",\n \"build_type\" : \"rpm\",\n \"build_hash\" : \"159a78a\",\n \"build_date\" : \"2018-12-06T20:11:28.826501Z\",\n \"build_snapshot\" : false,\n \"lucene_version\" : \"7.5.0\",\n \"minimum_wire_compatibility_version\" : \"5.6.0\",\n \"minimum_index_compatibility_version\" : \"5.0.0\"\n },\n \"tagline\" : \"You Know, for Search\"\n}\n```", "```\n[2018-12-23T01:39:03,834][INFO ][o.e.c.s.ClusterApplierService] [elastic2] detected_master {elastic1}{XVaIWexSQROVVxYuSYIVXA}{fgpqeUmBRVuXzvlf0TM8sA}{192.168.1.150}{192.168.1.150:9300}{ml.machine_memory=3973599232, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true}, added {{elastic1}{XVaIWexSQROVVxYuSYIVXA}{fgpqeUmBRVuXzvlf0TM8sA}{192.168.1.150}{192.168.1.150:9300}{ml.machine_memory=3973599232, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true},}, reason: apply cluster state (from master [master {elastic1}{XVaIWexSQROVVxYuSYIVXA}{fgpqeUmBRVuXzvlf0TM8sA}{192.168.1.150}{192.168.1.150:9300}{ml.machine_memory=3973599232, ml.max_open_jobs=20, xpack.installed=true, ml.enabled=true} committed version [1]])\n```", "```\ncurl -X GET \"elastic1:9200/_cluster/state?human&pretty\"\n```", "```\n{\n  \"cluster_name\" : \"elastic-cluster\",\n  \"compressed_size\" : \"10kb\",\n  \"compressed_size_in_bytes\" : 10271,\n  \"cluster_uuid\" : \"pIH5Z0yAQoeEGXcDuyEKQA\",\n  \"version\" : 24,\n  \"state_uuid\" : \"k6WuQsnKTECeRHFpHDPKVQ\",\n  \"master_node\" : \"XVaIWexSQROVVxYuSYIVXA\",\n  \"blocks\" : { },\n  \"nodes\" : {\n    \"XVaIWexSQROVVxYuSYIVXA\" : {\n      \"name\" : \"elastic1\",\n      \"ephemeral_id\" : \"fgpqeUmBRVuXzvlf0TM8sA\",\n      \"transport_address\" : \"192.168.1.150:9300\",\n      \"attributes\" : {\n        \"ml.machine_memory\" : \"3973599232\",\n        \"xpack.installed\" : \"true\",\n        \"ml.max_open_jobs\" : \"20\",\n        \"ml.enabled\" : \"true\"\n      }\n    },\n    \"ncVAbF9kTnOB5K9pUhsvZQ\" : {\n      \"name\" : \"elastic2\",\n      \"ephemeral_id\" : \"GyAq8EkiQGqG9Ph-0RbSkg\",\n      \"transport_address\" : \"192.168.1.151:9300\",\n      \"attributes\" : {\n        \"ml.machine_memory\" : \"3973599232\",\n        \"ml.max_open_jobs\" : \"20\",\n        \"xpack.installed\" : \"true\",\n        \"ml.enabled\" : \"true\"\n      }\n    }\n  },\n  \"metadata\" : {\n...(truncated)\n```", "```\nsudo /usr/share/logstash/bin/system-install\n```", "```\nsudo yum install elasticsearch\n```", "```\n# ------------ Queuing Settings --------------\n#\n# Internal queuing model, \"memory\" for legacy in-memory based queuing and\n# \"persisted\" for disk-based acked queueing. Defaults is memory\n#\nqueue.type: persisted\n#\n```", "```\n# If using queue.type: persisted, the directory path where the data files will be stored.\n# Default is path.data/queue\n#\n# path.queue:\n#\n```", "```\n# If using queue.type: persisted, the total capacity of the queue in number of bytes.\n# If you would like more unacked events to be buffered in Logstash, you can increase the\n# capacity using this setting. Please make sure your disk drive has capacity greater than\n# the size specified here. If both max_bytes and max_events are specified, Logstash will pick\n# whichever criteria is reached first\n# Default is 1024mb or 1gb\n#\nqueue.max_bytes: 25gb\n```", "```\n# The # character at the beginning of a line indicates a comment. Use\n # comments to describe your configuration.\n input {\n }\n # The filter part of this file is commented out to indicate that it is\n # optional.\n # filter {\n #\n # }\n output {\n }\n```", "```\nsudo vim /etc/logstash/conf.d/beats-syslog.conf\n```", "```\ninput {\n  beats {\n    port => 5044\n  }\n}\nfilter {\n  if [fileset][module] == \"system\" {\n    if [fileset][name] == \"auth\" {\n      grok {\n        match => { \"message\" => [\"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} %{DATA:[system][auth][ssh][method]} for (invalid user )?%{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]} port %{NUMBER:[system][auth][ssh][port]} ssh2(: %{GREEDYDATA:[system][auth][ssh][signature]})?\",\n                  \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{DATA:[system][auth][ssh][event]} user %{DATA:[system][auth][user]} from %{IPORHOST:[system][auth][ssh][ip]}\",\n                  \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sshd(?:\\[%{POSINT:[system][auth][pid]}\\])?: Did not receive identification string from %{IPORHOST:[system][auth][ssh][dropped_ip]}\",\n                  \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} sudo(?:\\[%{POSINT:[system][auth][pid]}\\])?: \\s*%{DATA:[system][auth][user]} :( %{DATA:[system][auth][sudo][error]} ;)? TTY=%{DATA:[system][auth][sudo][tty]} ; PWD=%{DATA:[system][auth][sudo][pwd]} ; USER=%{DATA:[system][auth][sudo][user]} ; COMMAND=%{GREEDYDATA:[system][auth][sudo][command]}\",\n                  \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} groupadd(?:\\[%{POSINT:[system][auth][pid]}\\])?: new group: name=%{DATA:system.auth.groupadd.name}, GID=%{NUMBER:system.auth.groupadd.gid}\",\n                  \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} useradd(?:\\[%{POSINT:[system][auth][pid]}\\])?: new user: name=%{DATA:[system][auth][user][add][name]}, UID=%{NUMBER:[system][auth][user][add][uid]}, GID=%{NUMBER:[system][auth][user][add][gid]}, home=%{DATA:[system][auth][user][add][home]}, shell=%{DATA:[system][auth][user][add][shell]}$\",\n                  \"%{SYSLOGTIMESTAMP:[system][auth][timestamp]} %{SYSLOGHOST:[system][auth][hostname]} %{DATA:[system][auth][program]}(?:\\[%{POSINT:[system][auth][pid]}\\])?: %{GREEDYMULTILINE:[system][auth][message]}\"] }\n        pattern_definitions => {\n          \"GREEDYMULTILINE\"=> \"(.|\\n)*\"\n        }\n        remove_field => \"message\"\n      }\n      date {\n        match => [ \"[system][auth][timestamp]\", \"MMM  d HH:mm:ss\", \"MMM dd HH:mm:ss\" ]\n      }\n      geoip {\n        source => \"[system][auth][ssh][ip]\"\n        target => \"[system][auth][ssh][geoip]\"\n      }\n    }\n    else if [fileset][name] == \"syslog\" {\n      grok {\n        match => { \"message\" => [\"%{SYSLOGTIMESTAMP:[system][syslog][timestamp]} %{SYSLOGHOST:[system][syslog][hostname]} %{DATA:[system][syslog][program]}(?:\\[%{POSINT:[system][syslog][pid]}\\])?: %{GREEDYMULTILINE:[system][syslog][message]}\"] }\n        pattern_definitions => { \"GREEDYMULTILINE\" => \"(.|\\n)*\" }\n        remove_field => \"message\"\n      }\n      date {\n        match => [ \"[system][syslog][timestamp]\", \"MMM  d HH:mm:ss\", \"MMM dd HH:mm:ss\" ]\n      }\n    }\n  }\n}\noutput {\n  elasticsearch {\n    hosts => [\"elastic1\", \"elastic2\"]\n    manage_template => false\n    index => \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n  }\n}\n\n```", "```\noutput {\n elasticsearch {\n    hosts => [\"elastic1\", \"elastic2\"]\n    manage_template => false\n    index => \"%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}\"\n }\n}\n```", "```\n# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.\n # The default is 'localhost', which usually means remote machines will not be able to connect.\n # To allow connections from remote users, set this parameter to a non-loopback address.\n server.host: \"0.0.0.0\"\n```", "```\n# The Kibana server's name.  This is used for display purposes.\nserver.name: \"kibana\"\n```", "```\nelasticsearch.url: \"http://localhost:9200\"\n```", "```\ncluster.name: elastic-cluster\nnode.name: coordinate\nnetwork.host: 0.0.0.0\nnode.master: false\nnode.data: false\nnode.ingest: false\ncluster.remote.connect: false\ndiscovery.zen.ping.unicast.hosts: [\"elastic1\", \"elastic2\"]\n```", "```\nsudo systemctl start logstash && sudo systemctl enable logstash\n```", "```\nsudo systemctl start elasticsearch && sudo systemctl enable elasticsearch\n```", "```\nsudo systemctl start kibana && sudo systemctl enable kibana\n```", "```\nsudo yum install -y filebeat\n```", "```\nfilebeat version\n```", "```\n[root@elastic1 ~]# filebeat version\nfilebeat version 6.5.4 (amd64), libbeat 6.5.4 [bd8922f1c7e93d12b07e0b3f7d349e17107f7826 built 2018-12-17 20:22:29 +0000 UTC]\n```", "```\nsudo yum install metricbeat\n```", "```\n#=========================== Filebeat inputs =============================\nfilebeat.inputs:\n# Each - is an input. Most options can be set at the input level, so\n# you can use different inputs for various configurations.\n# Below are the input specific configurations.\n- type: log\n # Change to true to enable this input configuration.\n enabled: true\n # Paths that should be crawled and fetched. Glob based paths.\n paths:\n    - /var/log/*.log\n```", "```\n#==============================Kibana================================\n# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.\n# This requires a Kibana endpoint configuration.\nsetup.kibana:\n # Kibana Host\n # Scheme and port can be left out and will be set to the default (http and 5601)\n # In case you specify and additional path, the scheme is required: http://localhost:5601/path\n# IPv6 addresses should always be defined as: https://[2001:db8::1]:5601\n host: \"kibana:5601\"\n```", "```\nfilebeat setup --dashboards\n```", "```\n#------------------------ Elasticsearch output ----------------------------\n#output.elasticsearch:\n # Array of hosts to connect to.\n # hosts: [\"localhost:9200\"]\n # Optional protocol and basic auth credentials.\n #protocol: \"https\"\n #username: \"elastic\"\n #password: \"changeme\"\n#-------------------------- Logstash output -------------------------------\noutput.logstash:\n # The Logstash hosts\n hosts: [\"logstash:5044\"]\n\n```", "```\nfilebeat modules enable system\n```", "```\nfilebeat setup --template -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=[\"elastic1:9200\", \"elastic2\"]'\n```", "```\nsudo systemctl enable filebeat && sudo systemctl start filebeat\n```", "```\nsetup.kibana:\n host: \"kibana:5601\"\n```", "```\n#------------------------ Elasticsearch output ----------------------------\noutput.elasticsearch:\n # Array of hosts to connect to.\n hosts: [\"elastic1:9200\", \"elastic2:9200\"]\n```", "```\nmetricbeat setup --dashboards\n```", "```\nsudo systemctl enable metricbeat && sudo systemctl start metricbeat\n```"]