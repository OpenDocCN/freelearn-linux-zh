- en: The CPU Scheduler - Part 2
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: CPU调度程序-第2部分
- en: In this, our second chapter on the Linux kernel CPU scheduler, we continue our
    coverage from the previous chapter. In the preceding chapter, we covered several
    key areas regarding the workings (and visualization) of the CPU scheduler on the
    Linux OS. This included topics on what exactly the KSE on Linux is, the POSIX
    scheduling policies that Linux implements, using `perf` to see the scheduler flow,
    and how the design of the modern scheduler is based upon modular scheduling classes. We
    also covered how to query any thread's scheduling policy and priority (using a
    couple of command line utilities), and delved deeper into the internal workings
    of the OS scheduler.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第二章中，我们继续讨论Linux内核CPU调度程序，延续了上一章的内容。在上一章中，我们涵盖了关于Linux操作系统CPU调度程序工作（和可视化）的几个关键领域。这包括关于Linux上的KSE是什么，Linux实现的POSIX调度策略，使用`perf`来查看调度程序流程，以及现代调度程序设计是基于模块化调度类的。我们还介绍了如何查询任何线程的调度策略和优先级（使用一些命令行实用程序），并深入了解了操作系统调度程序的内部工作。
- en: 'With this background in place, we''re now ready to explore more on the CPU
    scheduler on Linux; in this chapter, we shall cover the following areas:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些背景，我们现在准备在Linux上更多地探索CPU调度程序；在本章中，我们将涵盖以下领域：
- en: Visualizing the flow with LTTng and `trace-cmd`
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LTTng和`trace-cmd`可视化流程
- en: Understanding, querying, and setting the CPU affinity mask
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解、查询和设置CPU亲和性掩码
- en: Querying and setting a thread's scheduling policy and priority
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询和设置线程的调度策略和优先级
- en: CPU bandwidth control with cgroups
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用cgroups控制CPU带宽
- en: Converting mainline Linux into an RTOS
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将主线Linux转换为RTOS
- en: Latency and its measurement
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟及其测量
- en: We do expect that you've read (or have the equivalent knowledge of) the previous
    chapter before tackling this one.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望您在阅读本章之前已经阅读过（或具有相应的知识）之前的章节。
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: I assume you have gone through [Chapter 1](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml), *Kernel
    Workspace Setup*, and have appropriately prepared a guest **Virtual Machine**
    (**VM**) running Ubuntu 18.04 LTS (or a later stable release) and installed all
    the required packages. If not, I highly recommend you do this first.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我假设您已经阅读了（或具有相应的知识）之前的章节[第1章](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml) *内核工作空间设置*，并已经适当准备了一个运行Ubuntu
    18.04 LTS（或更高版本）的客户**虚拟机**（**VM**）并安装了所有必需的软件包。如果没有，我强烈建议您首先这样做。
- en: To get the most out of this book, I strongly recommend you first set up the
    workspace environment, including cloning this book's GitHub repository for the
    code, and work on it in a hands-on fashion. The repository can be found here: [https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用本书，我强烈建议您首先设置工作环境，包括克隆本书的GitHub存储库以获取代码，并进行实际操作。存储库可以在这里找到：[https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming)。
- en: Visualizing the flow with LTTng and trace-cmd
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LTTng和trace-cmd可视化流程
- en: 'In the previous chapter, we saw how we can visualize the flow of threads across
    the processor(s) with `perf` (and a few alternatives). Now, we proceed to do so
    with more powerful, more visual profiling tools: with LTTng (and the Trace Compass
    GUI) and with `trace-cmd` (an Ftrace frontend and the KernelShark GUI).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们看到了如何使用`perf`（和一些替代方案）可视化线程在处理器上的流动。现在，我们将使用更强大、更直观的性能分析工具来做到这一点：使用LTTng（和Trace
    Compass GUI）以及`trace-cmd`（一个Ftrace前端和KernelShark GUI）。
- en: Do note that the intent here is to introduce you to these powerful tracing technologies
    only; we do not have the scope nor space required to do full justice to these
    topics.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这里的意图是仅介绍您这些强大的跟踪技术；我们没有足够的范围或空间来充分涵盖这些主题。
- en: Visualization with LTTng and Trace Compass
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用LTTng和Trace Compass进行可视化
- en: The **Linux Trace Toolkit Next Generation** (**LTTng**) is a set of open source
    tools enabling you to simultaneously trace both user and kernel space. A bit ironically,
    tracing the kernel is easy, whereas tracing user space (apps, libraries, and even
    scripts) requires the developer to manually insert instrumentation (so-called
    tracepoints) into the application (the tracepoint instrumentation for the kernel
    is supplied by LTTng as kernel modules). The high-quality LTTng documentation
    is available online here: [https://lttng.org/docs/v2.12/](https://lttng.org/docs/v2.12/)
    (covering version 2.12 as of the time of writing).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**Linux Trace Toolkit Next Generation**（**LTTng**）是一组开源工具，使您能够同时跟踪用户空间和内核空间。有点讽刺的是，跟踪内核很容易，而跟踪用户空间（应用程序、库甚至脚本）需要开发人员手动将仪器插入应用程序（所谓的tracepoints）（内核的tracepoint仪器由LTTng作为内核模块提供）。高质量的LTTng文档可以在这里在线获得：[https://lttng.org/docs/v2.12/](https://lttng.org/docs/v2.12/)（截至撰写本文时，覆盖版本2.12）。'
- en: 'We do not cover the installation of LTTng here; the details are available at [https://lttng.org/docs/v2.12/#doc-installing-lttng](https://lttng.org/docs/v2.12/#doc-installing-lttng).
    Once installed (it''s kind of heavy – on my native x86_64 Ubuntu system, there
    are over 40 kernel modules loaded up pertaining to LTTng!), using LTTng - for
    a system-wide kernel session as we do here - is easy and is performed in two distinct
    stages: recording, followed by data analysis; these steps follow. (As this book
    is focused on kernel development, we don''t cover using LTTng to trace user space
    apps.)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里不涵盖LTTng的安装；详细信息可在[https://lttng.org/docs/v2.12/#doc-installing-lttng](https://lttng.org/docs/v2.12/#doc-installing-lttng)找到。一旦安装完成（它有点庞大-在我的本机x86_64
    Ubuntu系统上，有超过40个与LTTng相关的内核模块加载！），使用LTTng-就像我们在这里做的系统范围内的内核会话-是容易的，并且分为两个明显的阶段：记录，然后是数据分析；这些步骤如下。（由于本书专注于内核开发，我们不涵盖使用LTTng跟踪用户空间应用程序。）
- en: Recording a kernel tracing session with LTTng
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用LTTng记录内核跟踪会话
- en: 'You can record a system-wide kernel tracing session as follows (here, we deliberately
    keep the discussion as simple as possible):'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以按照以下方式记录系统范围内的内核跟踪会话（在这里，我们故意保持讨论尽可能简单）：
- en: 'Create a new session and set the output directory to `<dir>` for saving tracing
    metadata:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新会话，并将输出目录设置为`<dir>`以保存跟踪元数据：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Simply enable all kernel events (can lead to a large amount of tracing metadata
    being generated though):'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只需启用所有内核事件（可能会导致生成大量跟踪元数据）：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Start recording a "kernel session":'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始记录“内核会话”：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Allow some time to elapse (the longer you trace for, the more the disk space
    that's used by the tracing metadata). During this period, all kernel activity
    is being recorded by LTTng.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 允许一些时间流逝（您跟踪的时间越长，跟踪元数据使用的磁盘空间就越多）。在此期间，LTTng正在记录所有内核活动。
- en: 'Stop recording:'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 停止记录：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Destroy the session; don''t worry, this does not delete the tracing metadata:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 销毁会话；不用担心，这不会删除跟踪元数据：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: All the preceding commands should be run with admin privileges (or equivalent).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所有前面的命令都应该以管理员权限（或等效权限）运行。
- en: I have a few wrapper scripts to perform tracing with (LTTng, Ftrace, `trace-cmd`)
    at [https://github.com/kaiwan/L5_debug_trg/tree/master/kernel_debug/tracing](https://github.com/kaiwan/L5_debug_trg/tree/master/kernel_debug/tracing);
    do check them out.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一些包装脚本可以进行跟踪（LTTng、Ftrace、`trace-cmd`），在[https://github.com/kaiwan/L5_debug_trg/tree/master/kernel_debug/tracing](https://github.com/kaiwan/L5_debug_trg/tree/master/kernel_debug/tracing)中查看。
- en: The tracing metadata files (in the **Common Trace Format** (**CTF**) file format)
    gets saved to the preceding specified output directory.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪元数据文件（以**通用跟踪格式**（**CTF**）文件格式）保存到前面指定的输出目录。
- en: Reporting with a GUI – Trace Compass
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用GUI进行报告 - Trace Compass
- en: The data analysis can be performed in two broad ways – using a CLI-based system
    typically packaged along with LTTng called `babeltrace`, or via a sophisticated
    GUI called **Trace Compass**. The GUI is far more appealing; we only show its
    basic usage here.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 数据分析可以通过两种方式进行 - 使用通常与LTTng捆绑在一起的基于CLI的系统`babeltrace`，或者通过一个复杂的GUI称为**Trace
    Compass**。GUI更具吸引力；我们这里只展示了它的基本用法。
- en: 'Trace Compass is a powerful cross-platform GUI application and integrates well
    with Eclipse. In fact, we quote directly from the Eclipse Trace Compass site ([https://projects.eclipse.org/projects/tools.tracecompass](https://projects.eclipse.org/projects/tools.tracecompass)):'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: Trace Compass是一个功能强大的跨平台GUI应用程序，并且与Eclipse集成得很好。实际上，我们直接引用自Eclipse Trace Compass网站（[https://projects.eclipse.org/projects/tools.tracecompass](https://projects.eclipse.org/projects/tools.tracecompass)）：
- en: '"*Eclipse Trace Compass is an open source application to solve performance
    and reliability issues by reading and analyzing logs or traces of a system. Its
    goal is to provide views, graphs, metrics, and more to help extract useful information
    from traces, in a way that is more user-friendly and informative than huge text
    dumps.*"'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: “*Eclipse Trace Compass是一个开源应用程序，通过读取和分析系统的日志或跟踪来解决性能和可靠性问题。它的目标是提供视图、图形、指标等，以帮助从跟踪中提取有用信息，这种方式比庞大的文本转储更加用户友好和信息丰富。*”
- en: It can be downloaded (and installed) from here: [https://www.eclipse.org/tracecompass/](https://www.eclipse.org/tracecompass/).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以从这里下载（和安装）：[https://www.eclipse.org/tracecompass/](https://www.eclipse.org/tracecompass/)。
- en: Trace Compass minimally requires a **Java Runtime Environment** (**JRE**) to
    be installed as well. I installed one on my Ubuntu 20.04 LTS system with `sudo
    apt install openjdk-14-jre`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Trace Compass最低需要安装**Java Runtime Environment**（**JRE**）。我在我的Ubuntu 20.04 LTS系统上安装了一个，使用`sudo
    apt install openjdk-14-jre`。
- en: 'Once installed, fire up Trace Compass, click on the File | Open Trace menu,
    and navigate to the output directory where you saved the trace metadata for your
    tracing session in the preceding steps. Trace Compass will read the metadata and
    display it visually, along with various perspectives and tool views made available.
    A partial screenshot from our brief system-wide kernel tracing session is shown
    here (*Figure 11.1*); you can literally see the context switch (shown as the `sched_switch` event
    – see the Event type column) from the `gnome-shell` process to the `swapper/1`
    kernel thread (the idle thread running on CPU #1):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，启动Trace Compass，单击“文件”|“打开跟踪”菜单，并导航到您在前面步骤中保存跟踪会话的跟踪元数据的输出目录。Trace Compass将读取元数据并以可视化方式显示，以及提供各种透视图和工具视图。我们的简短系统范围内的内核跟踪会话的部分屏幕截图显示在这里（*图11.1*）；您可以清楚地看到上下文切换（显示为`sched_switch`事件
    - 请参阅事件类型列）从`gnome-shell`进程到`swapper/1`内核线程（在CPU＃1上运行的空闲线程）：
- en: '![](img/1ac935e2-5441-4d2a-ac44-12283d2fadec.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1ac935e2-5441-4d2a-ac44-12283d2fadec.png)'
- en: Figure 11.1 – Trace Compass GUI showing a sample kernel tracing session obtained
    via LTTng
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 - Trace Compass GUI显示通过LTTng获得的示例内核跟踪会话
- en: Look carefully at the preceding screenshot (Figure 11.1); in the lower horizontal
    pane, not only do you get to see which kernel function executed, you *also *get
    (under the column labeled Contents) the parameter list along with the value each
    parameter had at the time! This can be very useful indeed.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细看前面的屏幕截图（图11.1）；在下方的水平窗格中，不仅可以看到执行的内核函数，*还*可以（在标签为内容的列下）看到每个参数在那个时间点的值！这确实非常有用。
- en: Visualizing with trace-cmd
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用trace-cmd进行可视化
- en: Modern Linux kernels (from 2.6.27) embed a very powerful tracing engine called **Ftrace**.
    Ftrace is the rough kernel equivalent of the user space `strace(1)` utility, but
    that would be short-selling it! Ftrace allows the sysad (or developer, tester,
    or anyone with root privileges really) to literally look under the hood, seeing
    every single function being executed in kernel space, who (which thread) executed
    it, how long it ran for, what APIs it invoked, with interrupts (hard and soft)
    included as they occur, various types of latency measurements, and more. You can
    use Ftrace to learn about how system utilities, applications, and the kernel actually
    work, as well as to perform deep tracing at the level of the OS.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现代Linux内核（从2.6.27开始）嵌入了一个非常强大的跟踪引擎，称为**Ftrace**。Ftrace是用户空间`strace(1)`实用程序的粗糙内核等效物，但这样说有点贬低它了！Ftrace允许系统管理员（或开发人员、测试人员，或任何具有root权限的人）直接查看内核空间中执行的每个函数，执行它的是谁（哪个线程），运行时间有多长，它调用了哪些API，包括发生的中断（硬中断和软中断），各种类型的延迟测量等等。您可以使用Ftrace了解系统实用程序、应用程序和内核的实际工作原理，以及在操作系统级别执行深度跟踪。
- en: Here, in this book, we refrain from delving into the depths of raw Ftrace usage
    (as it deviates from the subject at hand); instead, it is just quicker and easier
    to use a user space wrapper over Ftrace, a more convenient interface to it, called `trace-cmd(1)` (again,
    we only scratch the surface, showing an example of how `trace-cmd` can be used).
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们不深入研究原始Ftrace的用法（因为这偏离了手头的主题）；相反，使用一个用户空间包装器覆盖Ftrace，一个更方便的接口，称为`trace-cmd(1)`，只是更快更容易（再次强调，我们只是浅尝辄止，展示了`trace-cmd`的一个示例）。
- en: For Ftrace details and usage, the interested reader will find this kernel document
    useful: [https://www.kernel.org/doc/Documentation/trace/ftrace.rst](https://www.kernel.org/doc/Documentation/trace/ftrace.rst).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Ftrace的详细信息和用法，感兴趣的读者会发现这个内核文档有用：[https://www.kernel.org/doc/Documentation/trace/ftrace.rst](https://www.kernel.org/doc/Documentation/trace/ftrace.rst)。
- en: 'Most modern Linux distros will allow the installation of `trace-cmd` via their
    package management system; on Ubuntu, for example, `sudo apt install trace-cmd` is
    sufficient to install it (if required for a custom Linux on, say, ARM, you can
    always cross-compile it from the source on its GitHub repository: [https://git.kernel.org/pub/scm/linux/kernel/git/rostedt/trace-cmd.git/tree/](https://git.kernel.org/pub/scm/linux/kernel/git/rostedt/trace-cmd.git/tree/)).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代Linux发行版都允许通过其软件包管理系统安装`trace-cmd`；例如，在Ubuntu上，`sudo apt install trace-cmd`就足以安装它（如果需要在自定义的Linux上，比如ARM，您总是可以从其GitHub存储库上的源代码进行交叉编译：[https://git.kernel.org/pub/scm/linux/kernel/git/rostedt/trace-cmd.git/tree/](https://git.kernel.org/pub/scm/linux/kernel/git/rostedt/trace-cmd.git/tree/)）。
- en: Let's perform a simple `trace-cmd` session; first, we shall record data samples while
    the `ps(1)` utility runs; then we shall examine the captured data both via the
    `trace-cmd report` **Command-Line Interface** (**CLI**) as well as a GUI frontend
    called KernelShark (it's in fact part of the `trace-cmd` package).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进行一个简单的`trace-cmd`会话；首先，我们将在运行`ps(1)`实用程序时记录数据样本；然后，我们将通过`trace-cmd report`**命令行界面**（CLI）以及一个名为KernelShark的GUI前端来检查捕获的数据（它实际上是`trace-cmd`包的一部分）。
- en: Recording a sample session with trace-cmd record
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用trace-cmd record记录一个示例会话
- en: 'In this section, we record a session with `trace-cmd(1)`; we use a few (of
    the many possible) option switches to `trace-cmd  record`; as usual, the man pages
    on `trace-cmd-foo(1)` (substitute `foo`with `check-events`, `hist`, `record`,
    `report`, `reset`, and so on) are very useful for finding various option switches
    and usage details. A few of the useful option switches particularly for `trace-cmd
    record` are as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们使用`trace-cmd(1)`记录一个会话；我们使用了一些（许多可能的）选项开关来记录`trace-cmd`；通常，`trace-cmd-foo(1)`（用`check-events`、`hist`、`record`、`report`、`reset`等替换`foo`）的man页面非常有用，可以找到各种选项开关和用法详情。特别适用于`trace-cmd
    record`的一些有用选项开关如下：
- en: '`-o`: Specifies the output filename (if not specified, it defaults to `trace.dat`).'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-o`：指定输出文件名（如果未指定，则默认为`trace.dat`）。'
- en: '`-p`: The plugin to use, one of `function`, `function_graph`, `preemptirqsoff`,
    `irqsoff`, `preemptoff`, and `wakeup`; here, in our small demo, we use the `function-graph` plugin
    (several other plugins can be configured in the kernel as well).'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-p`：要使用的插件之一，如`function`、`function_graph`、`preemptirqsoff`、`irqsoff`、`preemptoff`和`wakeup`；在我们的小型演示中，我们使用了`function-graph`插件（内核中还可以配置其他几个插件）。'
- en: '`-F`: The command (or app) to trace; this is very useful, allowing you to specify
    exactly which process (or thread) to exclusively trace (otherwise, tracing all
    threads can result in a lot of noise when attempting to decipher the output);
    similarly, you can use the `-P` option switch to specify the PID to trace.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: -F：要跟踪的命令（或应用程序）；这非常有用，可以让您精确指定要独占跟踪的进程（或线程）（否则，跟踪所有线程在尝试解密输出时可能会产生大量噪音）；同样，您可以使用`-P`选项开关来指定要跟踪的PID。
- en: '`-r priority`: Runs the `trace-cmd` threads at the real-time priority specified
    (the typical range being 1 to 99; we shall cover querying and setting a thread''s
    scheduling policy and priority shortly); this gives a better bet on `trace-cmd`
    being able to capture samples as required.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-r priority`：以指定的实时优先级运行`trace-cmd`线程（典型范围为1到99；我们将很快介绍查询和设置线程的调度策略和优先级）；这样可以更好地捕获所需的样本。'
- en: 'Here, we run a quick demo: we run `ps -LA`; while it runs, all kernel traffic
    it generates is (exclusively) captured by `trace-cmd` via it''s `record` functionality
    (we employ the `function-graph` plugin):'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们进行了一个快速演示：我们运行`ps -LA`；在运行时，所有内核流量都（独占地）由`trace-cmd`通过其`record`功能捕获（我们使用了`function-graph`插件）：
- en: '[PRE5]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: A rather large data file results (as we captured all events and did a `ps -LA` displaying
    all threads alive, it took a while, and thus the data samples captured are large-ish.
    Also realize that by default, kernel tracing is performed across all CPUs on the
    system; you can change this via the `-M cpumask` option.)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个相当大的数据文件（因为我们捕获了所有事件并且进行了`ps -LA`显示所有活动线程，所以花了一些时间，因此捕获的数据样本相当大。还要意识到，默认情况下，内核跟踪是在系统上的所有CPU上执行的；您可以通过`-M
    cpumask`选项进行更改）。
- en: 'In the preceding example, we captured all events. The `-e` option switch to
    `trace-cmd(1)` allows you to specify a class of events to trace; for example,
    to trace the `ping(1)` utility and capture only events related to networking and
    kernel memory, run the following command:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，我们捕获了所有事件。`-e`选项开关允许您指定要跟踪的事件类别；例如，要跟踪`ping(1)`实用程序并仅捕获与网络和内核内存相关的事件，请运行以下命令：
- en: '`sudo trace-cmd record -e kmem -e net -p function_graph -F ping -c1 packtpub.com`.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`sudo trace-cmd record -e kmem -e net -p function_graph -F ping -c1 packtpub.com`。'
- en: Reporting and interpretation with trace-cmd report (CLI)
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用trace-cmd report（CLI）进行报告和解释
- en: 'Continuing from the preceding section, on the command line, we can get a (very!)
    detailed report of what occurred within the kernel when the `ps` process ran;
    use the `trace-cmd report` command to see this. We also pass along the `-l` option
    switch: it displays the report in what is referred to as Ftrace''s **latency format**, revealing
    many useful details; the `-i` switch of course specifies the input file to use:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 从前一节继续，在命令行上，我们可以得到一个（非常！）详细的报告，说明了`ps`进程运行时内核中发生了什么；使用`trace-cmd report`命令来查看这个。我们还传递了`-l`选项开关：它以Ftrace的**延迟格式**显示报告，显示了许多有用的细节；`-i`开关当然指定了要使用的输入文件：
- en: '[PRE6]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now it gets very interesting! We show a few partial screenshots of the (huge)
    output file that we opened with `vim(1)`; first we have the following:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在变得非常有趣！我们展示了我们用`vim(1)`打开的（巨大）输出文件的一些部分截图；首先我们有以下内容：
- en: '![](img/d48a8129-fe10-4ecf-bebe-95c94684e5bd.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d48a8129-fe10-4ecf-bebe-95c94684e5bd.png)'
- en: Figure 11.2 – A partial screenshot showing the output of the trace-cmd report
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 - 显示trace-cmd报告输出的部分屏幕截图
- en: 'Look at Figure 11.2; the call to the kernel API, `schedule()`, is deliberately
    highlighted and in bold font (*Figure 11.2*, on line `785303`!). In order to interpret
    everything on this line, we must understand each (white-space delimited) column;
    there are eight of them:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 看看图11.2；对内核API`schedule()`的调用被故意突出显示并以粗体字显示（*图11.2*，在第`785303`行！）。为了解释这一行上的所有内容，我们必须理解每个（以空格分隔的）列；共有八列：
- en: 'Column 1: Here, it''s just the line number in the file that vim shows (let''s
    ignore it).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一列：这里只是`vim`显示的文件中的行号（让我们忽略它）。
- en: 'Column 2: This is the process context that invoked this function (the function
    itself is in column #8); clearly, here, the process is `ps-PID` (its PID is appended
    after a `-` character).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二列：这是调用此函数的进程上下文（函数本身在第8列）；显然，在这里，进程是`ps-PID`（其PID在`-`字符后附加）。
- en: 'Column 3: useful! A series of five characters, which shows up in **latency
    format** (we used the `-l` option switch to `trace-cmd record`, remember!); this
    (in our preceding case, it''s `2.N..`) is very useful and can be interpreted as
    follows:'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三列：有用！一系列五个字符，显示为**延迟格式**（我们使用了`-l`选项切换到`trace-cmd record`，记住！）；这（在我们之前的情况下，是`2.N..`）非常有用，可以解释如下：
- en: 'The very first character is the CPU core it was running upon (so here it was
    core #2) (note that, as a general rule, besides the first one, if the character
    is a period `.`, it means it''s zero or not applicable).'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个字符是它运行的CPU核心（所以这里是核心＃2）（请注意，作为一个一般规则，除了第一个字符外，如果字符是一个句点`。`，它意味着它是零或不适用）。
- en: 'The second character represents the hardware interrupt status:'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个字符代表硬件中断状态：
- en: '`.` implies the default hardware interrupts are enabled.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.` 意味着默认的硬件中断被启用。'
- en: '`d` implies hardware interrupts are currently disabled.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d` 意味着硬件中断当前被禁用。'
- en: 'The third character represents the `need_resched` bit (we explained this in
    the previous chapter, in the *When does the scheduler run?* section):'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个字符代表了`need_resched`位（我们在前一章节中解释过，在*调度程序何时运行？*部分）：
- en: '`.` implies it''s cleared.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.` 意味着它被清除。'
- en: '`N` implies it''s set (which implies that the kernel requires rescheduling
    to be performed ASAP!).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`N` 意味着它被设置（这意味着内核需要尽快执行重新调度！）。'
- en: 'The fourth character has meaning only when an interrupt is in progress, otherwise,
    it is merely a `.`, implying we are in a process context; if an interrupt is in
    progress – implying we''re in an interrupt context – its value is one of the following:'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四个字符只有在中断正在进行时才有意义，否则，它只是一个`。`，意味着我们处于进程上下文中；如果中断正在进行 - 意味着我们处于中断上下文中 - 其值是以下之一：
- en: '`h` implies we are executing in a hardirq (or top half) interrupt context.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`h` 意味着我们正在执行硬中断（或者顶半部中断）上下文。'
- en: '`H` implies we are executing in a hardirq that occurred within a softirq.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`H` 意味着我们正在软中断中发生的硬中断中执行。'
- en: '`s` implies we are executing in a softirq (or bottom half) interrupt context.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s` 意味着我们正在软中断（或者底半部）中断上下文中执行。'
- en: The fifth character represents the preemption count or depth; if it's a `.`,
    it's zero, implying the kernel is running in a preemptible state; if nonzero,
    an integer number shows up, implying that many kernel-level lock(s) have been
    taken, forcing the kernel into a non-preemptible state.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五个字符代表抢占计数或深度；如果是`。`，它是零，意味着内核处于可抢占状态；如果不为零，会显示一个整数，意味着已经获取了那么多内核级别的锁，迫使内核进入不可抢占状态。
- en: 'By the way, the output is very similar to Ftrace''s raw output except that
    in the case of raw Ftrace, we would see only four characters – the first one (the
    CPU core number) does *not* show up here; it shows up as the leftmost column instead;
    here''s a partial screenshot of the raw Ftrace (not `trace-cmd`) latency format:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顺便说一句，输出与Ftrace的原始输出非常相似，只是在原始Ftrace的情况下，我们只会看到四个字符 - 第一个字符（CPU核心编号）在这里不会显示；它显示为最左边的列；这是原始Ftrace（而不是`trace-cmd`）延迟格式的部分屏幕截图：
- en: '![](img/eacd0313-28f8-4d88-92ae-6ad938231293.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eacd0313-28f8-4d88-92ae-6ad938231293.png)'
- en: Figure 11.3 – A partial screenshot focused on raw Ftrace's four-character latency
    format (fourth field)
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 - 专注于原始Ftrace的四字符延迟格式（第四字段）的部分屏幕截图
- en: The preceding screenshot was culled directly from the raw Ftrace output.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的屏幕截图直接从原始Ftrace输出中整理出来。
- en: 'So, interpreting our example for the call to `schedule()`, we can see that
    the characters are `2.N..` implying that the process `ps` with PID `22922` was
    executing on CPU core #2 in a process context (no interrupts) and the `need-resched`
    (technically, `thread_info.flags:TIF_NEED_RESCHED`) bit was set (indicating the
    need for a reschedule ASAP!).'
  id: totrans-88
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因此，解释我们对`schedule()`调用的例子，我们可以看到字符是`2.N..`，意味着进程`ps`的PID为`22922`在CPU核心＃2上执行在进程上下文中（没有中断），并且`need-resched`（技术上，`thread_info.flags:TIF_NEED_RESCHED`）位被设置（表示需要尽快重新调度！）。
- en: (Back to the remaining columns in Figure 11.2 now)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （现在回到图11.2中的剩余列）
- en: 'Column 4: Timestamp in *seconds:microseconds* format.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 第四列：以*秒:微秒*格式的时间戳。
- en: 'Column 5: The name of the event that occurred (here, as we''ve used the `function_graph` plugin,
    it will be either `funcgraph_entry` or `fungraph_exit`, implying function entry
    or exit respectively).'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第5列：发生的事件的名称（在这里，我们使用了`function_graph`插件，它将是`funcgraph_entry`或`fungraph_exit`，分别表示函数的进入或退出）。
- en: 'Column 6 [optional]: The duration of the preceding function call with the time
    taken shown along with its unit (us = microseconds); a prefix character is used
    to denote whether the function execution took a long time (we simply treat it
    as part of this column); from the kernel Ftrace documentation (here: [https://www.kernel.org/doc/Documentation/trace/ftrace.rst](https://www.kernel.org/doc/Documentation/trace/ftrace.rst)),
    we have this:'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第6列[可选]：前一个函数调用的持续时间，显示了所花费的时间及其单位（us = 微秒）；前缀字符用于表示函数执行时间很长（我们简单地将其视为此列的一部分）；来自内核Ftrace文档（这里：[https://www.kernel.org/doc/Documentation/trace/ftrace.rst](https://www.kernel.org/doc/Documentation/trace/ftrace.rst)），我们有以下内容：
- en: '`+`, which implies that a function surpassed 10 microseconds'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`+`，这意味着一个函数超过了10微秒'
- en: '`!`, which implies that a function surpassed 100 microseconds'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`!`，这意味着一个函数超过了100微秒'
- en: '`#`, which implies that a function surpassed 1,000 microseconds'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`#`，这意味着一个函数超过了1,000微秒'
- en: '`*`, which implies that a function surpassed 10 milliseconds'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`*`，这意味着一个函数超过了10毫秒'
- en: '`@`, which implies that a function surpassed 100 milliseconds'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@`，这意味着一个函数超过了100毫秒'
- en: '`$`, which implies that a function surpassed 1 second'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`$`，这意味着一个函数超过了1秒'
- en: 'Column 7: Just the separator character `|`.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第7列：只是分隔符`|`。
- en: 'Column 8: The extreme-right column is the name of the kernel function being
    executed; an open brace on the right, `{`, implies the function is invoked just
    now; the column with only a close brace, `}`, implies the preceding function''s
    end (matching the open brace).'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第8列：极右列是正在执行的内核函数的名称；右边的开括号`{`表示刚刚调用了该函数；只有一个闭括号`}`的列表示前一个函数的结束（与开括号匹配）。
- en: This level of detail can be extremely valuable in both troubleshooting kernel
    (and even user space) issues, and understanding the flow of the kernel in great
    detail.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这种详细程度在排除内核（甚至用户空间）问题和深入了解内核流程方面非常有价值。
- en: 'When `trace-cmd record` is used without the `-p function-graph` option switch,
    we do lose the nicely indented function call graph-like output, but we do gain
    something as well: you will now see all function parameters along with their runtime
    values to the right of every single function call! A truly valuable aid at times.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`trace-cmd record`而没有使用`-p function-graph`选项开关时，我们失去了漂亮的缩进函数调用图形式的输出，但我们也得到了一些东西：现在你将看到每个函数调用右侧的所有函数参数及其运行时值！这在某些时候确实是一个非常有价值的辅助工具。
- en: 'I can''t resist showing another snippet from the same report – another interesting
    example with regard to the very things we learned about how scheduling classes
    work on modern Linux (covered in the previous chapter); this actually shows up
    here in the `trace-cmd` output:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我忍不住想展示同一份报告中的另一个片段 - 另一个关于我们在现代Linux上学到的调度类如何工作的有趣例子（在上一章中介绍过）；这实际上在`trace-cmd`输出中显示出来了：
- en: '![](img/dcdea06f-b228-4418-acb3-399effdf5053.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![ ](img/dcdea06f-b228-4418-acb3-399effdf5053.png)'
- en: Figure 11.4 – A partial screenshot of trace-cmd report output
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4 - `trace-cmd`报告输出的部分截图
- en: 'Interpret the preceding screenshot (*Figure 11.4*) closely: the second line
    (with the right-most function name column in bold font, as are the two functions
    immediately following it) shows that the `pick_next_task_stop()` function was
    invoked; this implies that a schedule occurred and the core scheduling code within
    the kernel went through its routine – it walks the linked list of scheduling classes
    in priority order, asking each whether it has a thread to schedule; if they do,
    the core scheduler context switches to it (as was explained in some detail in the
    previous chapter, in the *Modular scheduling classes* section).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细解释前面的截图（*图11.4*）：第二行（右侧函数名列为粗体字体，紧随其后的两个函数也是如此）显示了`pick_next_task_stop()`函数被调用；这意味着发生了一次调度，内核中的核心调度代码按照优先级顺序遍历调度类的链表，询问每个类是否有要调度的线程；如果有，核心调度程序上下文切换到它（正如在前一章中详细解释的那样，在*模块化调度类*部分）。
- en: 'In Figure 11.4, you literally see this happen: the core scheduling code asks
    the **stop-sched** (**SS**), **deadline** (**DL**), and **real-time** (**RT**)
    classes whether they have any thread that wants to run, by invoking, in turn,
    the `pick_next_task_stop()`, `pick_next_task_dl()`, and `pick_next_task_rt()` functions.
    Apparently, for all of them, the answer is no, as the next function to run is
    that of the fair (CFS) class (why doesn''t the `pick_next_task_fair()` function
    show up in the preceding screenshot then? Ah, again, that''s code optimization
    for you: the kernel developers understand that this being the likely case, they
    check for it and directly invoke the fair class code most of the time).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在图11.4中，你真的看到了这种情况发生：核心调度代码询问**stop-sched**（**SS**）、**deadline**（**DL**）和**real-time**（**RT**）类是否有任何想要运行的线程，依次调用`pick_next_task_stop()`、`pick_next_task_dl()`和`pick_next_task_rt()`函数。显然，对于所有这些类，答案都是否定的，因为接下来要运行的函数是公平（CFS）类的函数（为什么`pick_next_task_fair()`函数在前面的截图中没有显示呢？啊，这又是代码优化：内核开发人员知道这是可能的情况，他们会直接调用公平类代码大部分时间）。
- en: What we've covered here on the powerful Ftrace framework and the `trace-cmd`
    utility is just the basics; I urge you to look up the man pages on `trace-cmd-<foo>`(where
    `<foo>` is replaced with `record`, `report`, and so on)there are typically good
    examples shown there. Also, there are several very well-written articles on Ftrace
    (and `trace-cmd`) – please refer to the *Further reading *section for them.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里介绍的强大的Ftrace框架和`trace-cmd`实用程序只是基础；我建议你查阅`trace-cmd-<foo>`（其中`<foo>`被替换为`record`、`report`等）的man页面，那里通常会显示很好的示例。此外，关于Ftrace（和`trace-cmd`）还有一些非常好的文章
    - 请参考*进一步阅读*部分。
- en: Reporting and interpretation with a GUI frontend
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用GUI前端进行报告和解释
- en: 'More good news: the `trace-cmd` toolset includes a GUI frontend, for more human-friendly
    interpretation and analysis, called KernelShark (though, in my opinion, it isn''t
    as full-featured as Trace Compass is). Installing it on Ubuntu/Debian is as simple
    as doing `sudo apt install kernelshark`.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 更多好消息：`trace-cmd`工具集包括一个GUI前端，用于更人性化的解释和分析，称为KernelShark（尽管在我看来，它不像Trace Compass那样功能齐全）。在Ubuntu/Debian上安装它就像执行`sudo
    apt install kernelshark`一样简单。
- en: 'Below, we run `kernelshark`, passing the trace data file output from our preceding `trace-cmd` record
    session as the parameter to it (adjust the parameter to KernelShark to refer to
    the location where you''ve saved the tracing metadata):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 下面，我们运行`kernelshark`，将我们之前的`trace-cmd`记录会话的跟踪数据文件输出作为参数传递给它（将参数调整为KernelShark所在位置，以引用您保存跟踪元数据的位置）：
- en: '[PRE7]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'A screenshot of KernelShark running with the preceding trace data is shown
    here:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 显示了运行前述跟踪数据的KernelShark的屏幕截图：
- en: '![](img/a1406860-f2ad-4331-a266-5727a90114de.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a1406860-f2ad-4331-a266-5727a90114de.png)'
- en: Figure 11.5 – A screenshot of the kernelshark GUI displaying the earlier-captured
    data via trace-cmd
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 - 显示先前捕获的数据的kernelshark GUI的屏幕截图
- en: 'Interesting; the `ps` process ran on CPU #2 (as we saw with the CLI version
    previously). Here, we also see the functions executed in the lower tiled horizontal
    window pane; as an example, we have highlighted the entry for `pick_next_task_fair()`.
    The columns are quite obvious, with the `Latency` column format (four characters,
    not five) interpreted as we explained previously for (raw) Ftrace.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，`ps`进程在CPU＃2上运行（正如我们之前在CLI版本中看到的）。在这里，我们还可以看到在较低的平铺水平窗格中执行的函数；例如，我们已经突出显示了`pick_next_task_fair()`的条目。列是相当明显的，`Latency`列格式（四个字符，而不是五个）的解释如我们之前为（原始）Ftrace解释的那样。
- en: '**Quick quiz**: What does the Latency format field `dN..`, seen in Figure 11.5, imply?'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速测验**：在图11.5中看到的Latency格式字段`dN..`意味着什么？'
- en: 'Answer: It implies that, currently, right now, we have the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：它意味着，当前，我们有以下情况：
- en: 'First column `d`: Hardware interrupts are disabled.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一列 `d`：硬件中断被禁用。
- en: 'Second column `N`: The `need_resched` bit is set (implying the need to invoke
    the scheduler at the next available scheduling opportunity point).'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二列 `N`：`need_resched`位被设置（暗示需要在下一个可用的调度机会点调用调度程序）。
- en: 'Third column `.`: The kernel `pick_next_task_fair()` function''s code is running
    in a process context (the task being `ps` with a PID of `22545`; remember, Linux
    is a monolithic kernel!).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三列 `.`：内核`pick_next_task_fair()`函数的代码正在进程上下文中运行（任务是`ps`，PID为`22545`；记住，Linux是一个单内核！）。
- en: 'Fourth column `.`: The preemption depth (count) is zero, implying the kernel
    is in a preemptible state.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四列 `.`：抢占深度（计数）为零，暗示内核处于可抢占状态。
- en: 'Now that we have covered using these powerful tools to help generate and visualize
    data related to kernel execution and scheduling, let''s move on to another area:
    in the next section, we focus on another important aspect – what exactly a thread''s
    CPU affinity mask is, and how you can programmatically (and otherwise) get/set
    it.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了使用这些强大工具来帮助生成和可视化与内核执行和调度相关的数据，让我们继续下一个领域：在下一节中，我们将专注于另一个重要方面 - 线程的CPU亲和性掩码到底是什么，以及如何以编程方式（以及其他方式）获取/设置它。
- en: Understanding, querying, and setting the CPU affinity mask
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解、查询和设置CPU亲和性掩码
- en: 'The task structure, the root data structure containing several dozen thread
    attributes, has a few attributes directly pertaining to scheduling: the priority
    (the *nice* as well as the RT priority values), the scheduling class structure
    pointer, the runqueue the thread is on (if any), and so on.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 任务结构是一个根数据结构，包含几十个线程属性，其中有一些属性直接与调度有关：优先级（*nice*以及RT优先级值），调度类结构指针，线程所在的运行队列（如果有的话），等等。
- en: Among these is an important member, the **CPU affinity bitmask** (the actual
    structure member is `cpumask_t cpus_allowed`). This also tells you that the CPU
    affinity bitmask is a per-thread quantity; this makes sense - the KSE on Linux
    is a thread, after all. It's essentially an array of bits, each bit representing
    a CPU core (with sufficient bits available within the variable); if the bit corresponding
    to a core is set (`1`), the thread is allowed to be scheduled on and execute on
    that core; if cleared (`0`), it's not.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个重要成员是**CPU亲和性位掩码**（实际的结构成员是`cpumask_t cpus_allowed`）。这也告诉你CPU亲和性位掩码是每个线程的数量；这是有道理的
    - 在Linux上，KSE是一个线程。它本质上是一个位数组，每个位代表一个CPU核心（在变量内有足够的位可用）；如果对应于核心的位被设置（`1`），则允许在该核心上调度和执行线程；如果清除（`0`），则不允许。
- en: By default, all the CPU affinity mask bits are set; thus, the thread can run
    on any core. For example, on a box with (the OS seeing) four CPU cores, the default
    CPU affinity bitmask for each thread would be binary `1111` (`0xf`). (Glance at
    Figure 11.6 to see how the CPU affinity bitmask looks, conceptually speaking.)
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，所有CPU亲和性掩码位都被设置；因此，线程可以在任何核心上运行。例如，在一个有（操作系统看到的）四个CPU核心的盒子上，每个线程的默认CPU亲和性位掩码将是二进制`1111`（`0xf`）。（看一下图11.6，看看CPU亲和性位掩码的概念上是什么样子。）
- en: 'At runtime, the scheduler decides which core the thread will actually run upon.
    In fact, think about it, it''s really implicit: by default, each CPU core has
    a runqueue associated with it; every runnable thread will be on a single CPU runqueue;
    it''s thus eligible to run and by default runs on the CPU that it''s runqueue
    represents. Of course, the scheduler has a load balancer component that can migrate
    threads to other CPU cores (runqueues, really) as the need arises (kernel threads
    called `migration/n`, where `n` is the core number assist in this task).'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行时，调度程序决定线程实际上将在哪个核心上运行。事实上，想想看，这真的是隐含的：默认情况下，每个CPU核心都有一个与之关联的运行队列；每个可运行的线程将在单个CPU运行队列上；因此，它有资格运行，并且默认情况下在表示它的运行队列的CPU上运行。当然，调度程序有一个负载平衡器组件，可以根据需要将线程迁移到其他CPU核心（实际上是运行队列）（称为`migration/n`的内核线程在这个任务中协助）。
- en: The kernel does expose APIs to user space (system calls, of course, `sched_{s,g}etaffinity(2)` and
    their `pthread` wrapper library APIs), which allows an application to affine,
    or associate, a thread (or multiple threads) to particular CPU cores as it sees
    fit (and by the same logic, we can do this within the kernel as well for any given
    kernel thread). For example, setting the CPU affinity mask to `1010` binary, which
    equals `0xa` in hexadecimal, implies that the thread can execute *only* upon CPU
    cores one and three (counting starts from zero).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 内核确实向用户空间暴露了API（系统调用，当然，`sched_{s,g}etaffinity(2)`及其`pthread`包装库API），这允许应用程序根据需要将线程（或多个线程）关联到特定的CPU核心上（按照相同的逻辑，我们也可以在内核中为任何给定的内核线程执行此操作）。例如，将CPU亲和性掩码设置为`1010`二进制，相当于十六进制的`0xa`，意味着该线程只能在CPU核心一和三上执行（从零开始计数）。
- en: 'A key point: though you can manipulate the CPU affinity mask, the recommendation
    is to avoid doing so; the kernel scheduler understands the CPU topography in detail
    and can best load-balance the system.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一个关键点：尽管您可以操纵CPU亲和性掩码，但建议避免这样做；内核调度程序详细了解CPU拓扑，并且可以最佳地平衡系统负载。
- en: 'Having said that, explicitly setting the CPU affinity mask of a thread can
    be beneficial due to the following reasons:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，显式设置线程的CPU亲和性掩码可能是有益的，原因如下：
- en: Cache invalidation (and thus unpleasant cache "bouncing") can be greatly reduced
    by ensuring a thread always runs on the same CPU core.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过确保线程始终在同一CPU核心上运行，可以大大减少缓存失效（从而减少不愉快的缓存“跳动”）。
- en: Thread migration costs between cores are effectively eliminated.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 核心之间的线程迁移成本被有效地消除。
- en: CPU reservation—a strategy to bestow the core(s) exclusively to one thread by
    guaranteeing all other threads are explicitly not allowed to execute upon that
    core.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU保留——一种策略，通过保证所有其他线程明确不允许在该核心上执行，将核心（或核心）专门分配给一个线程。
- en: The first two are useful in some corner cases; the third one, CPU reservation,
    tends to be a technique used in some time-critical real-time systems where the
    cost of doing so is justified. Performing CPU reservation in practice is quite
    difficult to do though,  requiring OS-level intervention at (every!) thread creation;
    the cost might be prohibitive. For this reason, this is actually implemented by
    specifying that a certain CPU (or more) be *isolated* from all tasks; the Linux
    kernel provides a kernel parameter, `isolcpus`, for this very job.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 前两者在某些特殊情况下很有用；第三个，CPU保留，往往是在一些时间关键的实时系统中使用的一种技术，其成本是合理的。但实际上，进行CPU保留是相当困难的，需要在（每个！）线程创建时进行操作；成本可能是禁止的。因此，这实际上是通过指定某个CPU（或更多）从所有任务中*隔离*出来来实现的；Linux内核提供了一个内核参数`isolcpus`来完成这项工作。
- en: 'In this regard, we quote directly from the man page on the `sched_{s,g}etaffinity(2)` system
    calls:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这方面，我们直接引用了`sched_{s,g}etaffinity(2)`系统调用的man页面上的内容：
- en: The isolcpus boot option can be used to isolate one or more CPUs at boot time,
    so that no processes are scheduled onto those CPUs. Following the use of this
    boot option, the only way to schedule processes onto the isolated CPUs is via sched_setaffinity() or
    the cpuset(7) mechanism. For further information, see the kernel source file Documentation/admin-guide/kernel-parameters.txt.
    As noted in that file, isolcpus is the preferred mechanism of isolating CPUs (versus
    the alternative of manually setting the CPU affinity of all processes on the system).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: isolcpus引导选项可用于在引导时隔离一个或多个CPU，以便不会安排任何进程到这些CPU上运行。在使用此引导选项之后，将进程调度到被隔离的CPU的唯一方法是通过sched_setaffinity()或cpuset(7)机制。有关更多信息，请参阅内核源文件Documentation/admin-guide/kernel-parameters.txt。如该文件中所述，isolcpus是隔离CPU的首选机制（与手动设置系统上所有进程的CPU亲和性的替代方案相比）。
- en: Note, though, the previously mentioned `isolcpus` kernel parameter is now considered
    deprecated; it's preferable to use the cgroups `cpusets` controller instead (`cpusets`
    is a cgroup feature or controller; we do have some coverage on cgroups later in
    this chapter, in the *CPU bandwidth control with cgroups* section).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，先前提到的`isolcpus`内核参数现在被认为是不推荐使用的；最好使用cgroups的`cpusets`控制器代替（`cpusets`是一个cgroup特性或控制器；我们稍后在本章中会对cgroups进行一些介绍，在*使用cgroups进行CPU带宽控制*部分）。
- en: We refer you to more details in the kernel parameter documentation (here: [https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt](https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt)),
    specifically under the parameter labeled `isolcpus=`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议您在内核参数文档中查看更多详细信息（在此处：[https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt](https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt)），特别是在标记为`isolcpus=`的参数下。
- en: Now that you understand the theory behind it, let's actually write a user space
    C program to query and/or set the CPU affinity mask of any given thread.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经了解了它的理论，让我们实际编写一个用户空间C程序来查询和/或设置任何给定线程的CPU亲和性掩码。
- en: Querying and setting a thread's CPU affinity mask
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询和设置线程的CPU亲和性掩码
- en: 'As a demonstration, we provide a small user space C program to query and set
    a user space process (or thread''s) CPU affinity mask. Querying the CPU affinity
    mask is achieved with the `sched_getaffinity(2)` system call and by setting it
    with its counterpart:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 作为演示，我们提供了一个小型用户空间C程序来查询和设置用户空间进程（或线程）的CPU亲和性掩码。使用`sched_getaffinity(2)`系统调用来查询CPU亲和性掩码，并使用其对应的设置来设置它。
- en: '[PRE8]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'A specialized data type called `cpu_set_t` is what is used to represent the
    CPU affinity bitmask; it''s quite sophisticated: its size is dynamically allocated
    based on the number of CPU cores seen on the system. This CPU mask (of type `cpu_set_t`)
    must first be initialized to zero; the `CPU_ZERO()` macro achieves this (several
    similar helper macros exist; do refer to the man page on `CPU_SET(3)`). The second
    parameter in both the preceding system calls is the size of the CPU set (we simply
    use the `sizeof` operator to obtain it).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 一种名为`cpu_set_t`的专门数据类型用于表示CPU亲和掩码；它非常复杂：它的大小是根据系统上看到的CPU核心数量动态分配的。这种CPU掩码（类型为`cpu_set_t`）必须首先初始化为零；`CPU_ZERO()`宏可以实现这一点（还有几个类似的辅助宏；请参考`CPU_SET(3)`的手册页）。在前面的系统调用中的第二个参数是CPU集的大小（我们只需使用`sizeof`运算符来获取它）。
- en: 'To understand this better, it''s instructive to see a sample run of our code
    (`ch11/cpu_affinity/userspc_cpuaffinity.c`); we run it on a native Linux system
    with 12 CPU cores:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这一点，值得看一下我们的代码的一个示例运行（`ch11/cpu_affinity/userspc_cpuaffinity.c`）；我们在一个具有12个CPU核心的本机Linux系统上运行它：
- en: '![](img/b138bc28-5b26-4aa3-9362-ea201aaa2598.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b138bc28-5b26-4aa3-9362-ea201aaa2598.png)'
- en: Figure 11.6 – Our demo user space app showing the CPU affinity mask
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6 - 我们的演示用户空间应用程序显示CPU亲和掩码
- en: 'Here, we have run the app with no parameters. In this mode, it queries the
    CPU affinity mask of itself (meaning, of the `userspc_cpuaffinity` calling process).
    We print out the bits of the bitmask: as you can clearly see in the preceding
    screenshot, it''s binary `1111 1111 1111` (which is equivalent to `0xfff`), implying
    that by default the process is eligible to run on any of the 12 CPU cores available
    on the system.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们没有使用任何参数运行应用程序。在这种模式下，它查询自身的CPU亲和掩码（即`userspc_cpuaffinity`调用进程的亲和掩码）。我们打印出位掩码的位数：正如您在前面的屏幕截图中清楚地看到的那样，它是二进制`1111
    1111 1111`（相当于`0xfff`），这意味着默认情况下该进程有资格在系统上的任何12个CPU核心上运行。
- en: The app detects the number of CPU cores available by running the `nproc(1)`
    utility via the useful `popen(3)` library API. Do note though, that the value
    returned by `nproc` is the number of CPU cores available to the calling process;
    it may be less than the actual number of CPU cores (it's usually the same); the
    number of available cores can be changed in a few ways, the proper way being via
    the cgroup `cpuset` resource controller (we cover some information on cgroups
    later in this chapter).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序通过有用的`popen(3)`库API运行`nproc(1)`实用程序来检测可用的CPU核心数量。请注意，`nproc`返回的值是调用进程可用的CPU核心数量；它可能少于实际的CPU核心数量（通常是相同的）；可用核心数量可以通过几种方式进行更改，正确的方式是通过cgroup
    `cpuset`资源控制器（我们稍后在本章中介绍一些关于cgroups的信息）。
- en: 'The querying code is as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 查询代码如下：
- en: '[PRE9]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Our `disp_cpumask()` function draws the bitmask (we leave it to you to check
    it out).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`disp_cpumask()`函数绘制位掩码（请自行查看）。
- en: If additional parameters are passed – the PID of the process (or thread), as
    the first parameter, and a CPU bitmask, as the second parameter – we then attempt
    to *set* the CPU affinity mask of that process (or thread) to the value passed.
    Of course, changing the CPU affinity bitmask requires you to own the process or
    have root privileges (more correctly, to have the `CAP_SYS_NICE` capability).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 如果传递了额外的参数 - 进程（或线程）的PID作为第一个参数，CPU位掩码作为第二个参数 - 那么我们将尝试*设置*该进程（或线程）的CPU亲和掩码为传递的值。当然，更改CPU亲和掩码需要您拥有该进程或具有root权限（更正确地说，需要具有`CAP_SYS_NICE`权限）。
- en: 'A quick demo: in Figure 11.7, `nproc(1)` shows us the number of CPU cores;
    then, we run our app to query and set our shell process''s CPU affinity mask.
    On a laptop, let''s say that the affinity mask of `bash` is `0xfff` (binary `1111
    1111 1111`) to begin with, as expected; we change it to `0xdae` (binary `1101
    1010 1110`) and query it again to verify the change:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 一个快速演示：在图11.7中，`nproc(1)`显示了CPU核心的数量；然后，我们运行我们的应用程序来查询和设置我们的shell进程的CPU亲和掩码。在笔记本电脑上，假设`bash`的亲和掩码一开始是`0xfff`（二进制`1111
    1111 1111`），如预期的那样；我们将其更改为`0xdae`（二进制`1101 1010 1110`），然后再次查询以验证更改：
- en: '![](img/3c6f31dd-946f-4559-9c3a-9c8de84d45f4.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c6f31dd-946f-4559-9c3a-9c8de84d45f4.png)'
- en: Figure 11.7 – Our demo app queries then sets the CPU affinity mask of bash to
    0xdae
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7 - 我们的演示应用程序查询然后设置bash的CPU亲和掩码为0xdae
- en: 'Okay, this is interesting: to begin with, the app correctly detects the number
    of CPU cores available to it as 12; it then queries the (default) CPU affinity
    mask of the bash process (as we pass its PID as the first parameter); it shows
    up, as `0xfff`, as expected. Then, as we''ve also passed a second parameter –
    the bitmask to now set (`0xdae`) – it does so, setting the CPU affinity mask of
    bash to `0xdae`. Now, as the terminal window we''re on is this very same bash
    process, running `nproc` again shows the value as 8, not 12! That''s indeed correct:
    the bash process now has only eight CPU cores available to it. (This is as we
    don''t revert the CPU affinity mask to its original value on exit.)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这很有趣：首先，该应用程序正确地检测到了可用的CPU核心数量为12；然后，它查询了（默认的）bash进程的CPU亲和掩码（因为我们将其PID作为第一个参数传递）；如预期的那样，它显示为`0xfff`。然后，因为我们还传递了第二个参数
    - 要设置的位掩码（`0xdae`） - 它这样做了，将bash的CPU亲和掩码设置为`0xdae`。现在，由于我们所在的终端窗口正是这个bash进程，再次运行`nproc`会显示值为8，而不是12！这是正确的：bash进程现在只有八个CPU核心可用。（这是因为我们在退出时没有将CPU亲和掩码恢复到其原始值。）
- en: 'Here''s the relevant code to set the CPU affinity mask:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是设置CPU亲和掩码的相关代码：
- en: '[PRE10]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the preceding code snippet, you can see we first set up the `cpu_set_t` bitmask
    appropriately (by looping over each bit) and then employ the `sched_setaffinity(2)`
    system call to set the new CPU affinity mask on the given `pid`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，您可以看到我们首先适当地设置了`cpu_set_t`位掩码（通过循环遍历每个位），然后使用`sched_setaffinity(2)`系统调用在给定的`pid`上设置新的CPU亲和掩码。
- en: Using taskset(1) to perform CPU affinity
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用taskset(1)执行CPU亲和
- en: 'Akin to how (in the preceding chapter) we used the convenient user space utility
    program, `chrt(1)` to get (or set) a process'' (or thread''s) scheduling policy
    and/or priority, you can use the user space `taskset(1)` utility to get and/or
    set a given process'' (or thread''s) CPU affinity mask. A couple of quick examples
    follow; note that these examples were run on an x86_64 Linux system with 4 CPU
    cores:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于我们在前一章中使用方便的用户空间实用程序`chrt(1)`来获取（或设置）进程（或线程）的调度策略和/或优先级，您可以使用用户空间`taskset(1)`实用程序来获取和/或设置给定进程（或线程）的CPU亲和性掩码。以下是一些快速示例；请注意，这些示例是在一个具有4个CPU核心的x86_64
    Linux系统上运行的：
- en: 'Use `taskset` to query the CPU affinity mask of systemd (PID 1):'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`taskset`查询systemd（PID 1）的CPU亲和性掩码：
- en: '[PRE11]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Use `taskset` to ensure that the compiler – and its descendants (the assembler
    and linker) – run only on the first two CPU cores; the first parameter to taskset
    is the CPU affinity bitmask (`03` is binary `0011`):'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`taskset`确保编译器及其后代（汇编器和链接器）仅在前两个CPU核心上运行；taskset的第一个参数是CPU亲和性位掩码（`03`是二进制`0011`）：
- en: '[PRE12]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Do look up the man page on `taskset(1)` for complete usage details.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 查阅`taskset(1)`的手册页面以获取完整的使用详情。
- en: Setting the CPU affinity mask on a kernel thread
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在内核线程上设置CPU亲和性掩码
- en: 'As an example, if we want to demonstrate a synchronization technique called
    per-CPU variables, we are required to create two kernel threads and guarantee
    that each of them runs on a separate CPU core. To do so, we must set the CPU affinity
    mask of each kernel thread (the first one to `0`, the second to `1`, in order
    to have them execute on only CPUs `0` and `1` respectively). The thing is, it''s
    not a clean job – quite a *hack,* to be honest, and definitely *not* recommended.
    The following comment from that code shows why:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们想演示一种称为per-CPU变量的同步技术，我们需要创建两个内核线程，并确保它们分别在不同的CPU核心上运行。为此，我们必须设置每个内核线程的CPU亲和性掩码（第一个设置为`0`，第二个设置为`1`，以便它们只在CPU
    `0`和`1`上执行）。问题是，这不是一个干净的工作 - 老实说，相当*糟糕*，绝对*不*推荐。代码中的以下注释显示了原因：
- en: '[PRE13]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Later, we invoke the function pointer, in effect invoking the `sched_setaffinity` code,
    like so:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，我们调用函数指针，实际上调用`sched_setaffinity`代码，如下所示：
- en: '[PRE14]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Unconventional and controversial; it does work, but please avoid hacks like
    this in production.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 非常不寻常和有争议；它确实有效，但请在生产中避免这样的黑客行为。
- en: 'Now that you know how to get/set a thread''s CPU affinity mask, let''s move
    on to the next logical step: how to get/set a thread''s scheduling policy and
    priority! The next section delves into the details.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道如何获取/设置线程的CPU亲和性掩码，让我们继续下一个逻辑步骤：如何获取/设置线程的调度策略和优先级！下一节将深入细节。
- en: Querying and setting a thread’s scheduling policy and priority
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查询和设置线程的调度策略和优先级
- en: In [Chapter 10](5391e3c1-30ad-4c75-a106-301259064881.xhtml), *The CPU Scheduler
    – Part 1*, in the *Threads – which scheduling policy and priority* section, you
    learned how to query the scheduling policy and priority of any given thread via
    `chrt(1)` (we also demonstrated a simple bash script to do so). There, we mentioned
    the fact that `chrt(1)` internally invokes the `sched_getattr(2)` system call
    in order to query these attributes.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](5391e3c1-30ad-4c75-a106-301259064881.xhtml)中，*CPU调度器-第1部分*，在*线程-哪种调度策略和优先级*部分，您学会了如何通过`chrt(1)`查询任何给定线程的调度策略和优先级（我们还演示了一个简单的bash脚本来实现）。在那里，我们提到了`chrt(1)`内部调用`sched_getattr(2)`系统调用来查询这些属性。
- en: 'Very similarly, setting the scheduling policy and priority can be performed
    either by using the `chrt(1)` utility (making it simple to do so within a script,
    for example), or programmatically within a (user space) C application with the `sched_setattr(2)` system
    call. In addition, the kernel exposes other APIs: `sched_{g,s}etscheduler(2)` and
    its `pthread` library wrapper APIs, `pthread_{g,s}etschedparam(3)` (as these are
    all user space APIs, we leave it to you to browse through their man pages to get
    the details and try them out for yourself).'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 非常类似地，可以通过使用`chrt(1)`实用程序（例如在脚本中简单地这样做）或在（用户空间）C应用程序中使用`sched_setattr(2)`系统调用来设置调度策略和优先级。此外，内核还公开其他API：`sched_{g,s}etscheduler(2)`及其`pthread`库包装器API，`pthread_{g,s}etschedparam(3)`（由于这些都是用户空间API，我们让您自行查阅它们的手册页面以获取详细信息并尝试它们）。
- en: Within the kernel – on a kernel thread
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在内核中-在内核线程上
- en: As you know by now, the kernel is most certainly not a process nor a thread.
    Having said that, the kernel does contain kernel threads; like their user space
    counterparts, kernel threads can be created as required (from within the core
    kernel, a device driver, a kernel module). They *are* schedulable entities (KSEs!)
    and, of course, each of them has a task structure; thus, their scheduling policy
    and priority can be queried or set as required..
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道，内核绝对不是一个进程也不是一个线程。话虽如此，内核确实包含内核线程；与它们的用户空间对应物一样，内核线程可以根据需要创建（从核心内核、设备驱动程序、内核模块中）。它们是可调度实体（KSEs！），当然，它们每个都有一个任务结构；因此，它们的调度策略和优先级可以根据需要查询或设置。
- en: 'So, to the point at hand: to set the scheduling policy and/or priority of a
    kernel thread, the kernel typically makes use of the `kernel/sched/core.c:sched_setscheduler_nocheck()` (GFP
    exported) kernel API; here, we show its signature and an example of its typical
    usage; the comments that follow make it quite self-explanatory:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，就要点而言：要设置内核线程的调度策略和/或优先级，内核通常使用`kernel/sched/core.c:sched_setscheduler_nocheck()`（GFP导出）内核API；在这里，我们展示了它的签名和典型用法的示例；随后的注释使其相当不言自明。
- en: '[PRE15]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'One good example of the kernel''s usage of kernel threads is when the kernel
    (quite commonly) uses threaded interrupts. Here, the kernel must create a dedicated
    kernel thread with the `SCHED_FIFO` (soft) real-time scheduling policy and a real-time
    priority value of `50` (halfway between), for interrupt handling purposes. The
    (relevant) code to do this is shown here as an example of setting scheduling policy
    and priority on a kernel thread:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 内核对内核线程的一个很好的例子是内核（相当常见地）使用线程化中断。在这里，内核必须创建一个专用的内核线程，其具有`SCHED_FIFO`（软）实时调度策略和实时优先级值为`50`（介于中间），用于处理中断。这里展示了设置内核线程调度策略和优先级的相关代码：
- en: '[PRE16]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: (Here, we don't show the code that creates the kernel thread via the `kthread_create()`
    API. Also, FYI, `MAX_USER_RT_PRIO` is the value `100`.)
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: （这里我们不展示通过`kthread_create()` API创建内核线程的代码。另外，FYI，`MAX_USER_RT_PRIO`的值是`100`。）
- en: Now that you understand to a good extent how CPU scheduling works at the level
    of the OS, we'll move on to yet another quite compelling discussion – that of
    cgroups; read on!
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您在很大程度上了解了操作系统级别的CPU调度是如何工作的，我们将继续进行另一个非常引人入胜的讨论——cgroups；请继续阅读！
- en: CPU bandwidth control with cgroups
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用cgroups进行CPU带宽控制
- en: 'In the hazy past, the kernel community struggled mightily with a rather vexing
    issue: though scheduling algorithms and their implementations – the early 2.6.0
    O(1) scheduler, and a little later (with 2.6.23), the **Completely Fair Scheduler**
    (**CFS**) – promised, well, completely fair scheduling, it really wasn''t. Think
    about this for a moment: let''s say you are logged into a Linux server along with
    nine other people. Everything else being equal, it is likely that processor time
    is (more or less) fairly shared between all ten  people; of course, you will understand
    that it''s not really people that run, it''s processes and threads that run on
    their behalf.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去，内核社区曾经为一个相当棘手的问题而苦苦挣扎：尽管调度算法及其实现（早期的2.6.0 O(1)调度器，稍后（2.6.23）的**完全公平调度器**（CFS））承诺了完全公平的调度，但实际上并非如此。想想这个：假设您与其他九个人一起登录到Linux服务器。其他一切都相等的情况下，处理器时间可能（或多或少）在所有十个人之间（相对）公平地共享；当然，您会明白，真正运行的不是人，而是代表他们运行的进程和线程。
- en: For now at least, let's assume it's mostly fairly shared. But, what if you write
    a user space program that, in a loop, indiscriminately spawns off several new
    threads, each of which perform a lot of CPU-intensive work (and perhaps as an
    added bonus, allocates large swathes of memory as well; a file (un)compressor
    app perhaps) in each loop iteration!? The CPU bandwidth allocation is no longer
    fair in any real sense of the term, your account will effectively hog the CPUs
    (and perhaps other system resources, such as memory, as well)!
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 至少目前，让我们假设它基本上是公平的。但是，如果您编写一个用户空间程序，在循环中不加选择地生成多个新线程，每个线程都执行大量的CPU密集型工作（也许还额外分配大量内存；例如文件（解）压缩应用程序）！那么CPU带宽分配在任何实际意义上都不再公平，您的账户将有效地占用CPU（也许还占用其他系统资源，如内存）！
- en: 'A solution that precisely and effectively allocated and managed CPU (and other
    resource) bandwidth was required; ultimately, Google engineers obliged with patches
    that put the modern-day cgroups solution into the Linux kernel (in version 2.6.24).
    In a nutshell, cgroups is a kernel feature that allows the system administrator
    (or anyone with root access) to perform bandwidth allocation and fine-grained
    resource management on the various resources (or *controllers*, as they are called
    in the cgroup lexicon) on a system. Do note: using cgroups, it''s not just the
    processors (CPU bandwidth), but also memory, network, block I/O (and more)  bandwidth
    that can be carefully allocated and monitored as required by your project or product.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 需要一个精确有效地分配和管理CPU（和其他资源）带宽的解决方案；最终，谷歌工程师提供了补丁，将现代cgroups解决方案放入了Linux内核（在2.6.24版本）。简而言之，cgroups是一个内核功能，允许系统管理员（或任何具有root访问权限的人）对系统上的各种资源（或在cgroup词汇中称为*控制器*）执行带宽分配和细粒度资源管理。请注意：使用cgroups，不仅可以仔细分配和监视处理器（CPU带宽），还可以根据项目或产品的需要仔细分配和监视内存、网络、块I/O（等等）带宽。
- en: 'So, hey, you''re interested now! How do you enable this cgroups feature? Simple
    – it''s a kernel feature you enable (or disable) at quite a fine granularity in
    the usual way: by configuring the kernel! The relevant menu (via the convenient
    `make menuconfig` interface) is `General setup / Control Group support`. Try this:
    `grep` your kernel config file for `CGROUP`; if required, tweak your kernel config,
    rebuild, reboot with the new kernel, and test. (We covered kernel configuration
    in detail back in [Chapter 2](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml), *Building
    the 5.x Linux Kernel from Source – Part 1*, and the kernel build and install in
    [Chapter 3](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml), *Building the 5.x Linux
    Kernel from Source – Part 2.*)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，嘿，您现在感兴趣了！如何启用这个cgroups功能？简单——这是一个您可以通过通常的方式在内核中启用（或禁用）的内核功能：通过配置内核！相关菜单（通过方便的`make
    menuconfig`界面）是`General setup / Control Group support`。尝试这样做：在内核配置文件中使用`grep`查找`CGROUP`；如果需要，调整内核配置，重新构建，使用新内核重新启动并进行测试。（我们在[第2章](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml)中详细介绍了内核配置，*从源代码构建5.x
    Linux内核–第1部分*，以及在[第3章](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml)中介绍了内核构建和安装，*从源代码构建5.x
    Linux内核–第2部分*）。
- en: 'Good news: cgroups is enabled by default on any (recent enough) Linux system
    that runs the systemd init framework. As mentioned just now, you can query the
    cgroup controllers enabled by `grep`-ping your kernel config file, and modify
    the config as desired.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息：cgroups在运行systemd init框架的任何（足够新的）Linux系统上默认启用。正如刚才提到的，您可以通过查询cgroup控制器来查看启用的控制器，并根据需要修改配置。
- en: From it's initiation in 2.6.24, cgroups, like all other kernel features, continually
    evolves. Fairly recently, a point was reached where sufficiently improved cgroup
    features became incompatible with the old, resulting in a new cgroup release,
    one christened cgroups v2 (or simply cgroups2); this was declared production-ready
    in the 4.5 kernel series (with the older one now referred to as cgroups v1 or
    as the legacy cgroups implementation). Note that, as of the time of this writing,
    both can and do exist together (with some limitations; many applications and frameworks
    still use the older cgroups v1 and are yet to migrate to v2).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 从2.6.24开始，与所有其他内核功能一样，cgroups不断发展。最近，已经达到了足够改进的cgroup功能与旧版本不兼容的地步，导致了一个新的cgroup发布，即被命名为cgroups
    v2（或简称为cgroups2）；这在4.5内核系列中被宣布为生产就绪（旧版本现在被称为cgroups v1或遗留cgroups实现）。请注意，截至目前为止，两者可以并且确实共存（有一些限制；许多应用程序和框架仍然使用旧的cgroups
    v1，并且尚未迁移到v2）。
- en: A detailed rationale of why to use cgroups v2 as opposed to cgroups v1 can be
    found within the kernel documentation here: [https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#issues-with-v1-and-rationales-for-v2](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#issues-with-v1-and-rationales-for-v2)
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要使用cgroups v2而不是cgroups v1的详细原因可以在内核文档中找到：[https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#issues-with-v1-and-rationales-for-v2](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#issues-with-v1-and-rationales-for-v2)
- en: 'The man page on `cgroups(7)` describes in some detail the interfaces and various
    available (resource) controllers (or *subsystems* as they are sometimes referred
    to); for cgroups v1, they are `cpu`, `cpuacct`, `cpuset`, `memory`, `devices`,
    `freezer`, `net_cls`, `blkio`, `perf_event`, `net_prio`, `hugetlb`, `pids`, and
    `rdma`. We refer interested readers to said man page for details; as an example,
    the PIDS controller is very useful in preventing fork bombs (often, a silly but
    nevertheless deadly DoS attack where the `fork(2)` system call is issued within
    an infinite loop!), allowing you to limit the number of processes that can be
    forked off from that cgroup (or its descendants). On a Linux box with cgroups
    v1 running, peek at the content of `/proc/cgroups`: it reveals the v1 controllers
    available and their current usage.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`cgroups(7)`手册详细描述了接口和各种可用的（资源）控制器（有时称为*子系统*）；对于cgroups v1，它们是`cpu`、`cpuacct`、`cpuset`、`memory`、`devices`、`freezer`、`net_cls`、`blkio`、`perf_event`、`net_prio`、`hugetlb`、`pids`和`rdma`。我们建议感兴趣的读者查阅该手册以获取详细信息；例如，PIDS控制器在防止fork炸弹（通常是一个愚蠢但仍然致命的DoS攻击，在其中`fork(2)`系统调用在无限循环中被发出！）方面非常有用，允许您限制可以从该cgroup（或其后代）fork出的进程数量。在运行cgroups
    v1的Linux系统上，查看`/proc/cgroups`的内容：它显示了可用的v1控制器及其当前使用情况。'
- en: Control groups are exposed via a purpose-built synthetic (pseudo) filesystem,
    typically mounted under `/sys/fs/cgroup`. In cgroups v2, all controllers are mounted
    in a single hierarchy (or tree). This is unlike cgroups v1, where multiple controllers
    could be mounted under multiple hierarchies or groups. The modern init framework, *systemd,* is
    a user of both the v1 and v2 cgroups. The `cgroups(7)` man page indeed mentions
    the fact that `systemd(1)` auto-mounts a cgroups v2 filesystem during startup
    (at `/sys/fs/cgroup/unified`).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 控制组通过一个专门构建的合成（伪）文件系统进行公开，通常挂载在`/sys/fs/cgroup`下。在cgroups v2中，所有控制器都挂载在单个层次结构（或树）中。这与cgroups
    v1不同，cgroups v1中可以将多个控制器挂载在多个层次结构或组下。现代init框架*systemd*同时使用v1和v2 cgroups。`cgroups(7)`手册确实提到了`systemd(1)`在启动时自动挂载cgroups
    v2文件系统（在`/sys/fs/cgroup/unified`处）的事实。
- en: In cgroups v2, these are the supported controllers (or resource limiters or
    subsystems, if you will): `cpu`, `cpuset`, `io`, `memory`, `pids`, `perf_event`,
    and `rdma` (the first five being commonly deployed).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在cgroups v2中，这些是支持的控制器（或资源限制器或子系统）：`cpu`、`cpuset`、`io`、`memory`、`pids`、`perf_event`和`rdma`（前五个通常被部署）。
- en: In this chapter, the focus is on CPU scheduling; thus, we do not delve further
    into other controllers, but limit our discussions to an example of using the cgroups
    v2 `cpu` controller to limit CPU bandwidth allocation. For more on employing the
    other controllers, we refer you to the resources mentioned previously (along with
    several more found in the *Further reading* section of this chapter).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，重点是CPU调度；因此，我们不深入研究其他控制器，而是限制我们的讨论在使用cgroups v2 `cpu`控制器来限制CPU带宽分配的示例上。有关使用其他控制器的更多信息，请参考前面提到的资源（以及本章的*进一步阅读*部分中找到的其他资源）。
- en: Looking up cgroups v2 on a Linux system
  id: totrans-198
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Linux系统上查找cgroups v2
- en: 'First, let''s look up the available v2 controllers; to do so, locate the cgroups
    v2 mount point; it''s usually here:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们查找可用的v2控制器；要这样做，请找到cgroups v2挂载点；通常在这里：
- en: '[PRE17]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Hey, there aren''t any controllers present in `cgroup2`!? Actually, it will
    be this way in the presence of *mixed* cgroups, v1 and v2, which is the default
    (as of the time of writing). To exclusively make use of the later version – and
    thus have all configured controllers visible – you must first disable cgroups
    v1 by passing this kernel command-line parameter at boot: `cgroup_no_v1=all` (recall,
    all available kernel parameters can be conveniently seen here: [https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt](https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt)).'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 嘿，`cgroup2`中没有任何控制器吗？实际上，在存在*混合* cgroups，v1和v2的情况下，这是默认情况（截至目前为止）。要专门使用较新版本，并且使所有配置的控制器可见，您必须首先通过在启动时传递此内核命令行参数来禁用cgroups
    v1：`cgroup_no_v1=all`（请注意，所有可用的内核参数可以方便地在此处查看：[https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt](https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt)）。
- en: 'After rebooting the system with the preceding option, you can check that the
    kernel parameters you specified (via GRUB on an x86, or perhaps via U-Boot on
    an embedded system) have indeed been parsed by the kernel:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述选项重新启动系统后，您可以检查您在GRUB（在x86上）或者在嵌入式系统上可能通过U-Boot指定的内核参数是否已被内核解析：
- en: '[PRE18]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Okay; now let''s retry looking up the `cgroup2` controllers; you should find
    that it''s typically mounted under `/sys/fs/cgroup/` - the `unified` folder is
    no longer present (now that we''ve booted with the `cgroup_no_v1=all` parameter):'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在让我们重试查找`cgroup2`控制器；您应该会发现它通常挂载在`/sys/fs/cgroup/`下 - `unified`文件夹不再存在（因为我们使用了`cgroup_no_v1=all`参数进行引导）：
- en: '[PRE19]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Ah, now we see them (the exact controllers you see depend on how the kernel's
    configured).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，现在我们看到它们了（您看到的确切控制器取决于内核的配置方式）。
- en: 'The rules governing the working of cgroups2 is beyond this book''s scope; if
    you''d like to, I suggest you read through it here: [https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#control-group-v2](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#control-group-v2).
    Also, all the `cgroup.<foo>` pseudo files under a cgroup are described in detail
    in the *Core Interface Files* section ([https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#core-interface-files](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#core-interface-files)). Similar
    information is presented, in a simpler way, within the excellent man page on `cgroups(7)` (look
    it up with `man 7 cgroups` on Ubuntu).'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: cgroups2的工作规则超出了本书的范围；如果您愿意，建议您阅读这里的内容：[https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#control-group-v2](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#control-group-v2)。此外，cgroup中的所有`cgroup.<foo>`伪文件都在*核心接口文件*部分（[https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#core-interface-files](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#core-interface-files)）中有详细描述。类似的信息也以更简单的方式呈现在`cgroups(7)`的出色man页面中（在Ubuntu上使用`man
    7 cgroups`查找）。
- en: Trying it out – a cgroups v2 CPU controller
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 试一试 - cgroups v2 CPU控制器
- en: 'Let''s try something interesting: we shall create a new sub-group under the
    cgroups v2 hierarchy on the system. We''ll then set up a CPU controller for it,
    run a couple of test processes (that hammer away on the system''s CPU cores),
    and set a user-specified upper limit on how much CPU bandwidth these processes
    can actually make use of!'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一些有趣的事情：我们将在系统的cgroups v2层次结构下创建一个新的子组。然后我们将为其设置一个CPU控制器，运行一些测试进程（这些进程会占用系统的CPU核心），并设置一个用户指定的上限，限制这些进程实际可以使用多少CPU带宽！
- en: 'Here, we outline the steps you will typically take to do this (all of these
    steps require you to be running with root access):'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们概述了您通常会采取的步骤（所有这些步骤都需要您以root访问权限运行）：
- en: 'Ensure your kernel supports cgroups v2:'
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保您的内核支持cgroups v2：
- en: You should be running on a 4.5 or later kernel.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您应该在运行4.5或更高版本的内核。
- en: In the presence of mixed cgroups (both legacy v1 and newer v2, which, as of
    the time of writing, is the default), check that your kernel command line includes
    the `cgroup_no_v1=all` string. Here, we shall assume that the cgroup v2 hierarchy
    is supported and mounted at `/sys/fs/cgroup`.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在存在混合cgroups（旧的v1和较新的v2，这是写作时的默认设置）的情况下，请检查您的内核命令行是否包含`cgroup_no_v1=all`字符串。在这里，我们假设cgroup
    v2层次结构得到支持并挂载在`/sys/fs/cgroup`下。
- en: 'Add a `cpu` controller to the cgroups v2 hierarchy; this is achieved by doing
    this, as root:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向cgroups v2层次结构添加`cpu`控制器；这是通过以下方式实现的，作为root用户：
- en: '[PRE20]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The kernel documentation on cgroups v2 ([https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu)) does
    mention this point: *WARNING: cgroup2 doesn’t yet support control of realtime
    processes and the cpu controller can only be enabled when all RT processes are
    in the root cgroup. Be aware that system management software may already have
    placed RT processes into nonroot cgroups during the system boot process, and these
    processes may need to be moved to the root cgroup before the cpu controller can
    be enabled.*'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: cgroups v2的内核文档（[https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu)）提到了这一点：*警告：cgroup2尚不支持对实时进程的控制，cpu控制器只能在所有RT进程位于根cgroup时启用。请注意，系统管理软件可能已经在系统引导过程中将RT进程放入非根cgroup中，这些进程可能需要移动到根cgroup中，然后才能启用cpu控制器。*
- en: 'Create a sub-group: this is done by simply creating a directory with the required
    sub-group name under the cgroup v2 hierarchy; for example, to create a sub-group
    called `test_group`, use the following:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个子组：这是通过在cgroup v2层次结构下创建一个具有所需子组名称的目录来完成的；例如，要创建一个名为`test_group`的子组，使用以下命令：
- en: '[PRE21]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The interesting bit''s here: set up the max allowable CPU bandwidth for the
    processes that will belong to this sub-group; this is effected by writing into
    the `<cgroups-v2-mount-point>/<sub-group>/cpu.max` (pseudo) file. For clarity,
    the explanation of this file, as per the kernel documentation ([https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu-interface-files](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu-interface-files)),
    is reproduced here:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有趣的地方在于：设置将属于此子组的进程的最大允许CPU带宽；这是通过写入`<cgroups-v2-mount-point>/<sub-group>/cpu.max`（伪）文件来实现的。为了清楚起见，根据内核文档（[https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu-interface-files](https://www.kernel.org/doc/html/latest/admin-guide/cgroup-v2.html#cpu-interface-files)）对此文件的解释如下：
- en: '[PRE22]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In effect, all processes in the sub-control group will be collectively allowed to
    run for `$MAX` out of a period of `$PERIOD` microseconds; so, for example, with
    `MAX = 300,000` and `PERIOD = 1,000,000`, we're effectively allowing all processes
    within the sub-control group to run for 0.3 seconds out of a period of 1 second!
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，子控制组中的所有进程将被允许在`$PERIOD`微秒内运行`$MAX`次；例如，当`MAX = 300,000`和`PERIOD = 1,000,000`时，我们实际上允许子控制组中的所有进程在1秒内运行0.3秒！
- en: 'Insert some processes into the new sub-control group; this is achieved by writing
    their PIDs into the `<cgroups-v2-mount-point>/<sub-group>/cgroup.procs` pseudo-file:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将一些进程插入新的子控制组；这是通过将它们的PID写入`<cgroups-v2-mount-point>/<sub-group>/cgroup.procs`伪文件来实现的：
- en: You can further verify that they actually belong to this sub-group by looking
    up the content of each process's `/proc/<PID>/cgroup` pseudo-file; if it contains
    a line of the form `0::/<sub-group>`, then it indeed belongs to the sub-group!
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以通过查找每个进程的`/proc/<PID>/cgroup`伪文件的内容进一步验证它们是否实际属于这个子组；如果它包含形式为`0::/<sub-group>`的行，则它确实属于该子组！
- en: That's it; *the processes under the new sub-group will now perform their work
    under the CPU bandwidth constraint imposed*; when done, they will die as usual...
    you can remove (or delete) the sub-group with a simple `rmdir <cgroups-v2-mount-point>/<sub-group>`.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就是这样；*新子组下的进程现在将在强加的CPU带宽约束下执行它们的工作*；完成后，它们将像往常一样终止...您可以通过简单的`rmdir <cgroups-v2-mount-point>/<sub-group>`来删除子组。
- en: 'A bash script that actually carries out the preceding steps is available here:
    `ch11/cgroups_v2_cpu_eg/cgv2_cpu_ctrl.sh`. Do check it out! To make it interesting,
    it allows you to pass the maximum allowed CPU bandwidth – the `$MAX` value discussed
    in *step 4*! Not only that; we deliberately write a test script (`simp.sh`) that
    hammers on the CPU(s) – they generate integer values that we redirect to files.
    Thus, the number of integers they generated during their lifetime is an indication
    of how much CPU bandwidth was available to them... this way, we can test the script
    and actually see cgroups (v2) in action!'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 实际执行上述步骤的bash脚本在这里可用：`ch11/cgroups_v2_cpu_eg/cgv2_cpu_ctrl.sh`。一定要查看它！为了使其有趣，它允许您传递最大允许的CPU带宽-在*步骤4*中讨论的`$MAX`值！不仅如此；我们还故意编写了一个测试脚本（`simp.sh`），它会在CPU上进行大量操作-它们会生成我们重定向到文件的整数值。因此，它们在其生命周期内生成的整数数量是它们可用的CPU带宽的指示...通过这种方式，我们可以测试脚本并实际看到cgroups（v2）的运行！
- en: 'A couple of test runs here will help you understand this:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这里进行几次测试运行将帮助您理解这一点：
- en: '[PRE23]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: You're expected to run it as root and to pass, as a parameter, the `$MAX` value
    (the usage screen seen previously quite clearly explains it, including displaying
    the valid range (the microseconds value)).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要以root身份运行它，并将`$MAX`值作为参数传递（之前看到的使用屏幕已经很清楚地解释了它，包括显示有效范围（微秒值））。
- en: 'In the following screenshot, we run the bash script with the parameter `800000`,
    implying a CPU bandwidth of 800,000 out of a period of 1,000,000; in effect, a
    quite high CPU utilization of 0.8 seconds out of every 1 second on the CPU (80%):'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的截图中，我们使用参数`800000`运行bash脚本，意味着CPU带宽为1,000,000中的800,000；实际上，CPU利用率为每秒0.8秒的相当高的CPU利用率（80%）：
- en: '![](img/06814296-3ae2-44b7-911c-080a0dfa7de9.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![](img/06814296-3ae2-44b7-911c-080a0dfa7de9.png)'
- en: Figure 11.8 – Screenshot of running our cgroups v2 CPU controller demo bash
    script with an effective max CPU bandwidth of 80%
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8-运行我们的cgroups v2 CPU控制器演示bash脚本，有效的最大CPU带宽为80%
- en: 'Study our script''s output in *Figure 11.8*; you can see that it does its job:
    after verifying cgroup v2 support, it adds a `cpu` controller and creates a sub-group
    (called `test_group`). It then proceeds to launch two test processes called `j1`
    and `j2` (in reality, they''re just symbolic links to our `simp.sh` script). Once
    launched, they run of course. The script then queries and adds their PIDs to the
    sub-control group (as shown in *step 5*). We give the two processes 5 seconds
    to run; the script then displays the content of the files into which they wrote.
    It''s designed such that job `j1` writes integers starting from `1`, and job `j2`
    writes integers starting from `900`. In the preceding screenshot, you can clearly
    see that, in their lifetime, and under the effectively 80% CPU bandwidth available
    to it, job `j1` emits numbers from 1 to 68; similarly (under the same constraints),
    job `j2` emits numbers from `900` to `965` (a similar quantity of work, in effect).
    The script then cleans up, killing off the jobs and deleting the sub-group.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 研究我们脚本的*图11.8*输出；您可以看到它完成了它的工作：在验证cgroup v2支持后，它添加了一个`cpu`控制器并创建了一个子组（称为`test_group`）。然后继续启动两个名为`j1`和`j2`的测试进程（实际上，它们只是指向我们的`simp.sh`脚本的符号链接）。一旦启动，它们当然会运行。然后脚本查询并将它们的PID添加到子控制组（如*步骤5*所示）。我们给这两个进程5秒钟来运行；然后脚本显示它们写入的文件的内容。它被设计成作业`j1`从`1`开始写入整数，作业`j2`从`900`开始写入整数。在前面的截图中，您可以清楚地看到，在其生命周期内，并在有效的80%
    CPU带宽下，作业`j1`从1到68输出数字；同样（在相同的约束下），作业`j2`从`900`到`965`输出数字（实际上是相似数量的工作）。然后脚本清理，终止作业并删除子组。
- en: 'However, to really appreciate the effect, we run our script again (study the
    following output), but this time with a maximum CPU bandwidth of just 1,000 (the
    `$MAX` value) – in effect, a max CPU utilization of just 0.1%!:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，为了真正欣赏效果，我们再次运行我们的脚本（研究以下输出），但这次最大CPU带宽只有1,000（`$MAX`值）-实际上，最大CPU利用率只有0.1%！：
- en: '[PRE24]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: What a difference! This time our jobs `j1` and `j2` could literally emit between
    just two and three integers (the values `1 2 3` for job j1 and `900 901 `for job
    j2, as seen in the preceding output), clearly proving the efficacy of the cgroups
    v2 CPU controller.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 有何不同！这次我们的作业`j1`和`j2`实际上只能输出两到三个整数（如前面输出中看到的作业j1的值为`1 2 3`，作业j2的值为`900 901`），清楚地证明了cgroups
    v2 CPU控制器的有效性。
- en: Containers, essentially lightweight VMs (to some extent), are currently a hot
    commodity. The majority of container technologies in use today (Docker, LXC, Kubernetes,
    and others) are, at heart, a marriage of two built-in Linux kernel technologies, namespaces,
    and cgroups.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 容器，本质上是轻量级的虚拟机（在某种程度上），目前是一个炙手可热的商品。今天使用的大多数容器技术（Docker、LXC、Kubernetes等）在本质上都是两种内置的Linux内核技术，即命名空间和cgroups的结合。
- en: 'With that, we complete our brief coverage of a really powerful and useful kernel
    feature: cgroups. Let''s move on to the final section of this chapter: learning
    how you can turn regular Linux into a real-time operating system!'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这样，我们完成了对一个非常强大和有用的内核特性：cgroups的简要介绍。让我们继续本章的最后一部分：学习如何将常规Linux转换为实时操作系统！
- en: Converting mainline Linux into an RTOS
  id: totrans-238
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将主线Linux转换为RTOS
- en: 'Mainline or vanilla Linux (the kernel you download from [https://kernel.org](https://kernel.org))
    is decidedly *not* a **Real-Time Operating System** (**RTOS**); it''s a **General
    Purpose Operating System** (**GPOS**; as is Windows, macOS, Unix). In an RTOS,
    where hard real-time characteristics come into play, not only must the software
    obtain the correct result, there are deadlines associated with doing so; it must
    guarantee it meets these deadlines, every single time. The mainline Linux OS,
    though not an RTOS, does a tremendous job: it easily qualifies as being a soft
    real-time OS (one where deadlines are met most of the time). Nevertheless, true
    hard real-time domains (for example, military operations, many types of transport,
    robotics, telecom, factory floor automation, stock exchanges, medical electronics,
    and so on) require an RTOS.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 主线或原始的Linux（从[https://kernel.org](https://kernel.org)下载的内核）明显*不是*一个**实时操作系统**（**RTOS**）；它是一个**通用操作系统**（**GPOS**；就像Windows，macOS，Unix一样）。在RTOS中，当硬实时特性发挥作用时，软件不仅必须获得正确的结果，还有与此相关的截止日期；它必须保证每次都满足这些截止日期。尽管主线Linux操作系统不是RTOS，但它的表现非常出色：它很容易符合软实时操作系统的标准（在大多数情况下都能满足截止日期）。然而，真正的硬实时领域（例如军事行动，许多类型的交通，机器人技术，电信，工厂自动化，股票交易，医疗电子设备等）需要RTOS。
- en: Another key point in this context is that of **determinism**: an oft missed
    point regarding real-time is that the software response time need not always be
    really fast (responding, say, within a few microseconds); it may be a lot slower
    (in the range of, say, tens of milliseconds); by itself, that isn't what really
    matters in an RTOS. What does matter is that the system is reliable, working in
    the same consistent manner and always guaranteeing the deadline is met.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下的另一个关键点是**确定性**：关于实时的一个经常被忽视的点是，软件响应时间并不总是需要非常快（比如说在几微秒内响应）；它可能会慢得多（在几十毫秒的范围内）；这本身并不是RTOS中真正重要的事情。真正重要的是系统是可靠的，以相同一致的方式工作，并始终保证截止日期得到满足。
- en: For example, the time taken to respond to a scheduling request, should be consistent
    and not bounce all over the place. The variance from the required time (or baseline)
    is often referred to as the **jitter**; an RTOS works to keep the jitter tiny,
    even negligible. In a GPOS, this is often impossible and the jitter can vary tremendously
    - at one point being low and the next very high. Overall, the ability to maintain
    a stable even response with minimal jitter - even in the face of extreme workload
    pressures - is termed determinism, and is the hallmark of an RTOS. To provide
    such a deterministic response, algorithms must, as far as possible, be designed
    to correspond to *O(1)* time complexity.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对调度请求的响应时间应该是一致的，而不是一直在变化。与所需时间（或基线）的差异通常被称为**抖动**；RTOS致力于保持抖动微小，甚至可以忽略不计。在GPOS中，这通常是不可能的，抖动可能会变化得非常大
    - 一会儿很低，下一刻很高。总的来说，能够在极端工作负荷的情况下保持稳定的响应和最小的抖动的能力被称为确定性，并且是RTOS的标志。为了提供这样的确定性响应，算法必须尽可能地设计为*O(1)*时间复杂度。
- en: Thomas Gleixner, along with community support, has worked toward that goal for
    a long while now; for many years, in fact, ever since the 2.6.18 kernel, there
    have been offline patches that convert the Linux kernel into an RTOS. These patches
    can be found, for many versions of the kernel, here: [https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/).
    The older name for this project was `PREEMPT_RT`; later (October 2015 onward),
    the **Linux Foundation** (**LF**) took over stewardship of this project – a very
    positive step! – and renamed it the **Real-Time Linux** (**RTL**) Collaborative
    Project ([https://wiki.linuxfoundation.org/realtime/rtl/start#the_rtl_collaborative_project](https://wiki.linuxfoundation.org/realtime/rtl/start#the_rtl_collaborative_project)),
    or RTL (don't confuse this project with co-kernel approaches such as Xenomai or
    RTAI, or the older and now-defunct attempt called RTLinux).
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: Thomas Gleixner和社区支持已经为此目标努力了很长时间；事实上，自2.6.18内核以来，已经有了将Linux内核转换为RTOS的离线补丁。这些补丁可以在许多内核版本中找到，网址是：[https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/)。这个项目的旧名称是`PREEMPT_RT`；后来（2015年10月起），**Linux基金会**（**LF**）接管了这个项目
    - 这是一个非常积极的举措！ - 并将其命名为**实时Linux**（**RTL**）协作项目（[https://wiki.linuxfoundation.org/realtime/rtl/start#the_rtl_collaborative_project](https://wiki.linuxfoundation.org/realtime/rtl/start#the_rtl_collaborative_project)），或RTL（不要将这个项目与Xenomai或RTAI等共核方法，或者旧的、现在已经废弃的尝试称为RTLinux混淆）。
- en: 'An FAQ, of course, is "why aren''t these patches in mainline itself?" Well,
    it turns out that:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一个常见的问题是“为什么这些补丁不直接合并到主线中呢？”事实证明：
- en: Much of the RTL work has indeed been merged into the mainline kernel; this includes
    important areas such as the scheduling subsystem, mutexes, lockdep, threaded interrupts,
    PI, tracing, and so on. In fact, an ongoing primary goal of RTL is to get it merged
    as much as is feasible (we show a table summarizing this in the *Mainline and
    RTL – technical differences summarized* section).
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很多RTL工作确实已经合并到了主线内核中；这包括重要领域，如调度子系统，互斥锁，lockdep，线程中断，PI，跟踪等。事实上，RTL的一个持续的主要目标是尽可能多地合并它（我们在*主线和RTL
    - 技术差异总结*部分展示了一个总结表）。
- en: Linus Torvalds deems that Linux, being primarily designed and architected as
    a GPOS, should not have highly invasive features that only an RTOS really requires;
    so, though patches do get merged in, it's a slow deliberated process.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linus Torvalds认为，Linux作为一个主要设计和架构为GPOS，不应该具有只有RTOS真正需要的高度侵入性功能；因此，尽管补丁确实被合并了，但这是一个缓慢的审慎过程。
- en: We have included several interesting articles and references to RTL (and hard
    real time) in the *Further reading* section of this chapter; do take a look.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的*进一步阅读*部分，我们包括了一些有趣的文章和有关RTL（和硬实时）的参考资料；请阅读一下。
- en: 'What you''re going to do next is interesting indeed: you will learn how to
    patch the mainline 5.4 LTS kernel with the RTL patches, configure it, build, and
    boot it; you will thus end up running an RTOS – *Real-Time Linux or RTL*! We shall
    do this on our x86_64 Linux VM (or native system).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来您将要做的事情确实很有趣：您将学习如何使用RTL补丁对主线5.4 LTS内核进行打补丁、配置、构建和引导；因此，您最终将运行一个RTOS - *实时Linux或RTL*！我们将在我们的x86_64
    Linux VM（或本机系统）上执行此操作。
- en: We won't stop there; you will then learn more – the technical differences between
    regular Linux and RTL, what system latency is, and how, practically, to measure
    it. To do so, we shall first apply the RTL patch on the kernel source of the Raspberry
    Pi device, configure and build it, and use it as a test-bed for system latency
    measurement using the *cyclictest* app (you'll also learn to use modern BPF tools
    for measuring scheduler latencies). Let's get a move on, first building an RTL
    kernel for our 5.4 kernel on an x86_64!
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会止步于此；然后您将学习更多内容 - 常规Linux和RTL之间的技术差异，系统延迟是什么，以及如何实际测量它。为此，我们将首先在树莓派设备的内核源上应用RTL补丁，配置和构建它，并将其用作使用*cyclictest*应用程序进行系统延迟测量的测试平台（您还将学习使用现代BPF工具来测量调度程序延迟）。让我们首先在x86_64上为我们的5.4内核构建一个RTL内核！
- en: Building RTL for the mainline 5.x kernel (on x86_64)
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为主线5.x内核（在x86_64上）构建RTL
- en: In this section, you will learn, in a step-by-step, hands-on fashion, how exactly
    to patch, configure, and build Linux as an RTOS. As mentioned in the preceding
    section, these real-time patches have been around a long while; it's time to make
    use of them.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将逐步学习如何以实际操作的方式打补丁、配置和构建Linux作为RTOS。如前一节所述，这些实时补丁已经存在很长时间了；现在是时候利用它们了。
- en: Obtaining the RTL patches
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取RTL补丁
- en: 'Navigate to [https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/) (or,
    if you''re on an alternate kernel, go to one directory level above this and select
    the required kernel version):'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 导航至[https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/)（或者，如果您使用的是另一个内核，转到此目录的上一级目录并选择所需的内核版本）：
- en: '![](img/8335c076-4a92-4ece-b80e-f38139e5bc15.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8335c076-4a92-4ece-b80e-f38139e5bc15.png)'
- en: Figure 11.9 – Screenshot of the RTL patches for the 5.4 LTS Linux kernels
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.9 - 5.4 LTS Linux内核的RTL补丁的截图
- en: 'You will quickly notice that the RTL patches are available for only some versions
    of the kernel in question (here, 5.4.y); more on this follows. In the preceding
    screenshot, you can spot two broad types of patch files – interpret it as follows:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 您很快会注意到RTL补丁仅适用于所讨论的内核的某些版本（在这里是5.4.y）；接下来会有更多内容。在前面的截图中，您可以看到两种类型的补丁文件 - 解释如下：
- en: '`patch-<kver>rt[nn].patch.[gz|xz]`: The prefix is `patch-`; this is the complete
    collection of patches required to patch the mainline kernel (version `<kver>`)
    **in one unified** (and compressed) file.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patch-<kver>rt[nn].patch.[gz|xz]`：前缀是`patch-`；这是补丁的完整集合，用于在一个统一的（压缩的）文件中打补丁到主线内核（版本`<kver>`）。'
- en: '`patches-<kver>-rt[nn].patch.[gz|xz]`: The prefix is `patches-`; this compressed
    file contains every individual patch (as a separate file) that went into making
    up the patch series for this version of RTL.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`patches-<kver>-rt[nn].patch.[gz|xz]`：前缀是`patches-`；这个压缩文件包含了用于这个版本的RTL的每个单独的补丁（作为单独的文件）。'
- en: (Also, as you should be aware, `<fname>.patch.gz` and `<fname>.patch.xz` are
    the same archive; it's just that the compressor differs – the `.sign` files are the
    PGP signature files.)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: （还有，正如您应该知道的，`<fname>.patch.gz`和`<fname>.patch.xz`是相同的存档；只是压缩器不同 - `.sign`文件是PGP签名文件。）
- en: We shall use the first type; download the `patch-<kver>rt[nn].patch.xz` file
    to your target system by clicking on the link (or via `wget(1)`).
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用第一种类型；通过单击链接（或通过`wget(1)`）将`patch-<kver>rt[nn].patch.xz`文件下载到目标系统。
- en: Notice that for the 5.4.x kernels (as of the time of writing), the RTL patches
    seem to be present only for version 5.4.54 and 5.4.69 (and not for 5.4.0, the
    kernel that we have been working with all along).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，对于5.4.x内核（截至撰写时），RTL补丁似乎只存在于5.4.54和5.4.69版本（而不是5.4.0，我们一直在使用的内核）。
- en: In fact, the particular kernel version that the RTL patches apply against can
    certainly vary from what I've mentioned here at the time of this writing. That's
    expected - just follow the steps substituting the release number you're using
    with what's mentioned here.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，RTL补丁适用的特定内核版本可能与我在撰写本文时提到的不同。这是预期的 - 只需按照这里提到的步骤用您正在使用的发布号替换即可。
- en: 'Don''t be worried – we shall show you a workaround in a moment. This is indeed
    going to be the case; the community cannot feasibly build patches against every
    single kernel release – there are just too many. This does have an important implication:
    either we patch our 5.4.0 kernel to, say, 5.4.69, or, we simply download the 5.4.69
    kernel to begin with and apply the RTL patches against it.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 别担心 - 我们马上就会向您展示一个解决方法。这确实是事实；社区不可能针对每个单独的内核发布构建补丁 - 这些实在太多了。这确实有一个重要的含义：要么我们将我们的5.4.0内核打补丁到5.4.69，要么我们只需下载5.4.69内核并对其应用RTL补丁。
- en: 'The first approach is doable but is more work (especially in the absence of
    a patching tools such as git/ketchup/quilt or similar; here, we choose not to
    use git to apply patches, just working on the stable kernel tree instead). As
    the Linux kernel patches are incremental, we will have to download every single
    patch from 5.4.0 until 5.4.69 (a total of 69 patches!), and apply them successively
    and in order: first 5.4.1, then 5.4.2, then 5.4.3, and so on until the final one!
    Here, to help keep things simple, since we know that the kernel to patch against
    is 5.4.69, it''s just easier to download and extract it instead. So, head on over
    to [https://www.kernel.org/](https://www.kernel.org/) and do so. Thus, here, we
    end up downloading two files:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法可行，但工作量更大（特别是在没有git/ketchup/quilt等补丁工具的情况下；在这里，我们选择不使用git来应用补丁，而是直接在稳定的内核树上工作）。由于Linux内核补丁是增量的，我们将不得不下载从5.4.0到5.4.69的每个补丁（总共69个补丁！），并依次按顺序应用它们：首先是5.4.1，然后是5.4.2，然后是5.4.3，依此类推，直到最后一个！在这里，为了简化事情，我们知道要打补丁的内核是5.4.69，所以最好直接下载并提取它。因此，前往[https://www.kernel.org/](https://www.kernel.org/)并这样做。因此，我们最终下载了两个文件：
- en: The compressed kernel source for mainline 5.4.69: [https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.4.69.tar.xz](https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.4.69.tar.xz)
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主线5.4.69的压缩内核源代码：[https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.4.69.tar.xz](https://mirrors.edge.kernel.org/pub/linux/kernel/v5.x/linux-5.4.69.tar.xz)
- en: The RTL patch for 5.4.69: [https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/patches-5.4.69-rt39.tar.xz](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/patches-5.4.69-rt39.tar.xz)
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5.4.69的RTL补丁：[https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/patches-5.4.69-rt39.tar.xz](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/patches-5.4.69-rt39.tar.xz)
- en: (As explained in detail in [Chapter 3](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml),
    *Building the 5.x Linux Kernel from Source – Part 2*, if you intend to cross-compile
    the kernel for another target, the usual procedure is to build it on a suitably
    powerful workstation, so download it there.)
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: （如[第3章](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml) *从源代码构建5.x Linux内核-第2部分*中详细解释的那样，如果您打算为另一个目标交叉编译内核，通常的做法是在功能强大的工作站上构建它，然后在那里下载。）
- en: 'Next, extract both the RTL patch file as well as the kernel code base `tar.xz`
    file to obtain the kernel source tree (here, it''s version 5.4.69; of course,
    these details have been well covered back in [Chapter 2](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml),
    *Building the 5.x Linux Kernel from Source – Part 1*). By now, your working directory
    content should look similar to this:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，提取RTL补丁文件以及内核代码基础`tar.xz`文件，以获取内核源代码树（这里是版本5.4.69；当然，这些细节在[第2章](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml)
    *从源代码构建5.x Linux内核-第1部分*中已经详细介绍过）。到目前为止，您的工作目录内容应该类似于这样：
- en: '[PRE25]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '(FYI, the `unxz(1)` utility can be used to extract the `.xz`-compressed patch
    file.) For the curious reader: take a peek at the patch (the file `patch-5.4.69-rt39.patch`),
    to see all the code-level changes wrought to bring about a hard real-time kernel;
    it''s non-trivial of course! An overview of the technical changes will be seen
    in the upcoming *Mainline and RTL – technical differences summarized* section.
    Now that we have things in place, let''s begin by applying the patch to the stable
    5.4.69 kernel tree; the following section covers just this.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: （FYI，`unxz(1)`实用程序可用于提取`.xz`压缩的补丁文件。）对于好奇的读者：看一下补丁（文件`patch-5.4.69-rt39.patch`），看看为实现硬实时内核所做的所有代码级更改；当然不是简单的！技术更改的概述将在即将到来的*主线和RTL-技术差异摘要*部分中看到。既然我们已经准备就绪，让我们开始将补丁应用到稳定的5.4.69内核树上；接下来的部分只涵盖这一点。
- en: Applying the RTL patch
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用RTL补丁
- en: 'Ensure you keep the extracted patch file, `patch-5.4.69-rt39.patch`, in the
    directory immediately above the 5.4.69 kernel source tree (as seen previously).
    Now, let''s apply the patch. Careful – (obviously) don''t attempt to apply the
    compressed file as the patch; extract and use the uncompressed patch file. To
    ensure that the patch applies correctly, we first employ the `--dry-run` (dummy
    run) option to `patch(1)`:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 确保将提取的补丁文件`patch-5.4.69-rt39.patch`放在5.4.69内核源代码树的上一级目录中（如前所示）。现在，让我们应用补丁。小心-（显然）不要尝试将压缩文件应用为补丁；提取并使用未压缩的补丁文件。为了确保补丁正确应用，我们首先使用`--dry-run`（虚拟运行）选项来使用`patch(1)`：
- en: '[PRE26]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'All''s well, let''s now actually apply it:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 一切顺利，现在让我们实际应用它：
- en: '[PRE27]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Great – we have the patched kernel for RTL ready now!
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了-我们现在已经准备好了RTL补丁内核！
- en: Of course, there are multiple ways and various shortcuts that can be employed;
    for example, you can also achieve the preceding via the `xzcat ../patch-5.4.69-rt39.patch.xz
    | patch -p1` command (or similar).
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，有多种方法和各种快捷方式可以使用；例如，您还可以通过`xzcat ../patch-5.4.69-rt39.patch.xz | patch -p1`命令（或类似命令）来实现前面的操作。
- en: Configuring and building the RTL kernel
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置和构建RTL内核
- en: 'We have covered the kernel configuration and build steps in detail in [Chapter
    2](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml), *Building the 5.x Linux Kernel
    from Source – Part 1*, and [Chapter 3](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml),
    *Building the 5.x Linux Kernel from Source – Part 2*, hence we shan''t repeat
    it here. Pretty much everything remains the same; the only significant difference
    being that we must configure this kernel to take advantage of RTL (this is explained
    on the new RTL wiki site, here: [https://wiki.linuxfoundation.org/realtime/documentation/howto/applications/preemptrt_setup](https://wiki.linuxfoundation.org/realtime/documentation/howto/applications/preemptrt_setup)).'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第2章](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml) *从源代码构建5.x Linux内核-第1部分*和[第3章](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml)
    *从源代码构建5.x Linux内核-第2部分*中详细介绍了内核配置和构建步骤，因此我们不会在这里重复。几乎所有内容都保持不变；唯一的显著区别是我们必须配置此内核以利用RTL（这在新的RTL维基网站上有解释，网址为：[https://wiki.linuxfoundation.org/realtime/documentation/howto/applications/preemptrt_setup](https://wiki.linuxfoundation.org/realtime/documentation/howto/applications/preemptrt_setup)）。
- en: 'To cut down the kernel features to be built to approximately match the present
    system configuration, we first, within the kernel source tree directory (`linux-5.4.69`),
    do the following (we also covered this back in [Chapter 2](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml),
    *Building the 5.x Linux Kernel from Source - Part 1*, under the *Tuned kernel
    config via the localmodconfig approach* section):'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将要构建的内核特性减少到大约匹配当前系统配置，我们首先在内核源树目录（`linux-5.4.69`）中执行以下操作（我们也在[第2章](e0b89a37-18a3-424d-8983-58c4ac0725f6.xhtml)中介绍过，*从源代码构建5.x
    Linux内核 - 第1部分*，在*通过localmodconfig方法调整内核配置*部分）：
- en: '[PRE28]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Next, fire up the kernel configuration with `make menuconfig`:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用`make menuconfig`启动内核配置：
- en: 'Navigate to the `General setup` sub-menu:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导航到`通用设置`子菜单：
- en: '![](img/f11d2aa0-2ff7-4939-b420-fbbfe1a49bd2.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f11d2aa0-2ff7-4939-b420-fbbfe1a49bd2.png)'
- en: 'Figure 11.10 – make menuconfig / General setup: configuring the RTL-patched
    kernel'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.10 - 进行menuconfig / 通用设置：配置RTL补丁内核
- en: Once there, scroll down to the `Preemption Model` sub-menu; we see it highlighted
    in the preceding screenshot, along with the fact that the currently (by default)
    selected preemption model is `Voluntary Kernel Preemption (Desktop)`.
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦到达那里，向下滚动到`抢占模型`子菜单；我们在前面的截图中看到它被突出显示，以及当前（默认）选择的抢占模型是`自愿内核抢占（桌面）`。
- en: 'Pressing *Enter* here leads us into the `Preemption Model` sub-menu:'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里按*Enter*会进入`抢占模型`子菜单：
- en: '![](img/a9390c2b-8923-4583-bbe4-d037b7ff4a86.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9390c2b-8923-4583-bbe4-d037b7ff4a86.png)'
- en: 'Figure 11.11 – make menuconfig / General setup / Preemption Model: configuring
    the RTL-patched kernel'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11 - 进行menuconfig / 通用设置 / 抢占模型的配置RTL补丁内核
- en: There it is! Recall from the previous chapter, in the *Preemptible kernel* section,
    we described the fact that this very kernel configuration menu had three items
    (the first three seen in Figure 11.11). Now it has four. The fourth item – the
    `Fully Preemptible Kernel (Real-Time)` option – has been added on thanks to the
    RTL patch we just applied!
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！回想一下前一章，在*可抢占内核*部分，我们描述了这个内核配置菜单实际上有三个项目（在图11.11中看到的前三个）。现在有四个。第四个项目 -
    `完全可抢占内核（实时）`选项 - 是由于我们刚刚应用的RTL补丁而添加的！
- en: 'So, to configure the kernel for RTL, scroll down and select the `Fully Preemptible
    Kernel (Real-Time)` menu option (refer Figure 11.1). This corresponds to the kernel
    `CONFIG_PREEMPT_RT` config macro, whose `< Help >` is quite descriptive (do take
    a gander); it does, in fact, conclude with the statement: *select this if you
    are building a kernel for systems which require real-time guarantees*.'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，要为RTL配置内核，请向下滚动并选择`完全可抢占内核（实时）`菜单选项（参见图11.1）。这对应于内核`CONFIG_PREEMPT_RT`配置宏，其`<帮助>`非常描述性（确实要看一看）；事实上，它以这样的陈述结束：*如果您正在构建需要实时保证的系统内核，请选择此选项*。
- en: 'In earlier versions of the kernel (including 5.0.x), the `Preemption Model`
    sub-menu displayed five choices; two were for RT: one was termed Basic RT and
    the other was what we see here as the fourth choice – now (5.4.x) they''ve simply
    been folded into one true real-time option.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在较早版本的内核（包括5.0.x）中，`抢占模型`子菜单显示了五个选择项；其中两个是用于RT：一个称为基本RT，另一个是我们在这里看到的第四个选择 -
    现在（5.4.x）它们已经被简单地合并为一个真正的实时选项。
- en: 'Once you have selected the fourth option and saved and exited the `menuconfig`
    UI, (re)check that the full preemptible kernel – in effect, RTL – is selected:'
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦选择了第四个选项并保存并退出`menuconfig` UI，（重新）检查已选择完全可抢占内核 - 实际上是RTL：
- en: '[PRE29]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: All right, looks good! (Of course, before building, you can tweak other kernel
    config options as required for your product.)
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，看起来不错！（当然，在构建之前，您可以根据产品的需要调整其他内核配置选项。）
- en: 'Let''s now build the RTL kernel:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们构建RTL内核：
- en: '[PRE30]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Once it successfully builds and installs, reboot the system; at boot, press
    a key to display the GRUB bootloader menu (holding down one of the *Shift* keys
    can help ensure the GRUB menu is displayed at boot); within the GRUB menu, select
    the newly built `5.4.69-rtl` RTL kernel (in fact, the kernel just installed is
    usually the default one selected at boot). It should boot now; once logged in
    and on a shell, let''s verify the kernel version:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦成功构建和安装，重新启动系统；在启动时，按下一个键以显示GRUB引导加载程序菜单（按住其中一个*Shift*键可以确保在启动时显示GRUB菜单）；在GRUB菜单中，选择新构建的`5.4.69-rtl`
    RTL内核（实际上，刚刚安装的内核通常是默认选择的）。现在应该可以启动了；一旦登录并进入shell，让我们验证内核版本：
- en: '[PRE31]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Notice `CONFIG_LOCALVERSION` set to the value `-rtl-llkd1`. (Also, with `uname
    -a`, the `PREEMPT RT` string will be seen.) We're now - as promised - running
    Linux, RTL, as a hard real-time operating system, an RTOS!
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`CONFIG_LOCALVERSION`设置为值`-rtl-llkd1`。（还可以通过`uname -a`看到`PREEMPT RT`字符串。）现在我们
    - 如承诺的那样 - 运行Linux，RTL，作为硬实时操作系统，即RTOS！
- en: 'It''s very important to understand, though, that for true hard real time, simply
    having a hard real-time kernel is *not* enough; you must also very carefully design
    and write your user space (apps, libraries, and tooling) as well as your kernel
    modules / drivers, to conform to real time as well. For example, frequent page
    faulting can throw determinism out of the proverbial window and result in high
    latencies (and high jitter). (Recall what you learned in [Chapter 9](dbb888a2-8145-4132-938c-1313a707b2f2.xhtml),
    *Kernel Memory Allocation for Module Authors – Part 2*, in the *A brief note on
    memory allocations and demand paging* section. Page faulting is a fact of life
    and can and does often occur; minor page faults will usually cause little to worry
    about. But in a hard RT scenario? And in any case, "major faults" will hamper
    performance.) Techniques such as using `mlockall(2)` to lock down all the pages
    of a real-time application process might well be required. This and several other
    techniques and tips for writing real-time code are provided here: [https://rt.wiki.kernel.org/index.php/HOWTO:_Build_an_
    RT-application](https://rt.wiki.kernel.org/index.php/HOWTO:_Build_an_RT-application).
    (Similarly, topics regarding CPU affinity and shielding, `cpuset` management,
    IRQ prioritization, and so on can be found on the older RT wiki site mentioned
    previously; [https://rt.wiki.kernel.org/index.php/Main_Page](https://rt.wiki.kernel.org/index.php/Main_Page).)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，非常重要的是要理解，对于真正的硬实时，仅仅拥有一个硬实时内核是*不够的；你必须非常小心地设计和编写你的用户空间（应用程序、库和工具）以及你的内核模块/驱动程序，以符合实时性。例如，频繁的页面错误可能会使确定性成为过去式，并导致高延迟（和高抖动）。
    （回想一下你在[第9章](dbb888a2-8145-4132-938c-1313a707b2f2.xhtml)中学到的，*模块作者的内核内存分配 - 第2部分*，在*内存分配和需求分页的简短说明*部分。页面错误是生活的一部分，经常发生；小的页面错误通常不会引起太多担忧。但在硬实时的情况下呢？无论如何，“主要错误”都会妨碍性能。）诸如使用`mlockall(2)`来锁定实时应用程序进程的所有页面可能是必需的。这里提供了编写实时代码的几种其他技术和建议：[https://rt.wiki.kernel.org/index.php/HOWTO:_Build_an_
    RT-application](https://rt.wiki.kernel.org/index.php/HOWTO:_Build_an_RT-application)。（同样，关于CPU亲和性和屏蔽、`cpuset`管理、中断请求（IRQ）优先级等主题可以在先前提到的旧RT维基站点上找到；[https://rt.wiki.kernel.org/index.php/Main_Page](https://rt.wiki.kernel.org/index.php/Main_Page)。）
- en: So, great – you now know how to configure and build Linux as an RTOS! I encourage
    you to try this out for yourself. Moving along, we'll next summarize the key differences
    between the standard and RTL kernels.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，很好 - 现在你知道如何配置和构建Linux作为RTOS！我鼓励你自己尝试一下。接下来，我们将总结标准和RTL内核之间的关键差异。
- en: Mainline and RTL – technical differences summarized
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主线和RTL - 技术差异总结
- en: 'To give you a deeper understanding of this interesting topic area, in this
    section, we delve further into it: we summarize the key differences between the
    standard (or mainline) and RTL kernels.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让你更深入地了解这个有趣的主题领域，在本节中，我们将进一步深入探讨：我们总结了标准（或主线）和RTL内核之间的关键差异。
- en: 'In the following table, we summarize some of the key differences between the
    standard (or mainline) and RTL kernels. A primary goal of the RTL project is to
    ultimately become fully integrated into the regular mainline kernel tree. As this
    process is evolutionary, the merging of patches from RTL into mainline is slow
    but steady; interestingly, as you can see from the rightmost column in the following
    table, most of (around 80% at the time of writing) the RTL work has actually been
    already merged into the mainline kernel, and it continues to be:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，我们总结了标准（或主线）和RTL内核之间的一些关键差异。RTL项目的主要目标是最终完全整合到常规主线内核树中。由于这个过程是渐进的，从RTL合并到主线的补丁是缓慢但稳定的；有趣的是，正如你可以从下表的最右列看到的那样，在撰写本文时，大部分（约80%）的RTL工作实际上已经合并到了主线内核中，并且它还在继续：
- en: '| **Component / Feature** | **Standard or mainline (vanilla) Linux** | **RTL
    (fully preemptible / hard real-time Linux)** | **RT work merged into mainline?**
    |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| **组件/特性** | **标准或主线（原始）Linux** | **RTL（完全可抢占/硬实时Linux）** | **RT工作合并到主线？**
    |'
- en: '| Spinlocks | The spinlock critical section is  non-preemptible kernel code
    | As preemptible as is humanly possible; called "sleeping spinlocks"! In effect,
    spinlocks have been converted into mutexes. | No |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 自旋锁 | 自旋锁关键部分是不可抢占的内核代码 | 尽可能可抢占；称为“睡眠自旋锁”！实际上，自旋锁已转换为互斥锁。 | 否 |'
- en: '| Interrupt handling | Traditionally done via the top and bottom half (hardirq/tasklet/softirq)
    mechanism | Threaded interrupts: the majority of interrupt processing is done
    within a kernel thread (2.6.30, June 2009). | Yes |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 中断处理 | 传统上通过顶半部分和底半部分（hardirq/tasklet/softirq）机制完成 | 线程中断：大多数中断处理在内核线程内完成（2.6.30，2009年6月）。
    | 是 |'
- en: '| HRTs (High-Resolution Timers) | Available here due to merge from RTL | Timers
    with nanosecond resolution (2.6.16, March 2006). | Yes |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| HRTs（高分辨率定时器） | 由于从RTL合并而可用 | 具有纳秒分辨率的定时器（2.6.16，2006年3月）。 | 是 |'
- en: '| RW locks | Unbounded; writers may starve | Fair RW locks with bounded writer
    latency. | No |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| RW锁 | 无界；写者可能会挨饿 | 具有有界写入延迟的公平RW锁。 | 否 |'
- en: '| lockdep | Available here due to merge from RTL | Very powerful (kernel space)
    tool to detect and prove locking correctness or the lack thereof. | Yes |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| lockdep | 由于从RTL合并而可用 | 非常强大（内核空间）的工具，用于检测和证明锁的正确性或缺乏正确性。 | 是 |'
- en: '| Tracing | Some tracing technologies available here due to merge from RTL
    | Ftrace''s origins (and to some extent perf''s) were with the RT developers attempting
    to find latency issues. | Yes |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 跟踪 | 由于从RTL合并而可用的一些跟踪技术 | Ftrace的起源（在某种程度上也包括perf）是RT开发人员试图找到延迟问题。 | 是 |'
- en: '| Scheduler | Many scheduler features available here due to merge from RTL
    | Work on real-time scheduling as well as the deadline scheduling class (`SCHED_DEADLINE`)
    was first done here (3.14, March 2014); also, full tickless operation (3.10, June
    2013). | Yes |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| 调度器 | 由于从RTL合并而可用的许多调度器功能 | 首先在这里进行了实时调度的工作以及截止时间调度类（`SCHED_DEADLINE`）（3.14，2014年3月）；此外，完全无滴答操作（3.10，2013年6月）。
    | 是 |'
- en: (Don't worry – we shall definitely cover many of the preceding details in subsequent
    chapters of the book.)
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 不要担心-我们一定会在书的后续章节中涵盖许多前面的细节。
- en: Of course, a well-known (at least it should be) rule of thumb is simply this: *there
    is no silver bullet*. This implies, of course, that no one solution will fit every
    need.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一个众所周知的（至少应该是）经验法则就是：*没有银弹*。这当然意味着，没有一个解决方案适用于所有需求。
- en: Please, if you haven't yet done so, do yourself a huge favor and read the still-so-relevant
    book *The Mythical Man-Month: Essays on Software Engineering *by Frederick P Brooks.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有这样做，请务必读一读弗雷德里克·P·布鲁克斯的《神话般的程序员：软件工程论文》这本仍然相关的书。
- en: As mentioned in [Chapter 10](5391e3c1-30ad-4c75-a106-301259064881.xhtml), *The
    CPU Scheduler – Part 1*, in the *Preemptible kernel* section, the Linux kernel
    can be configured with the `CONFIG_PREEMPT` option; this is often referred to
    as the **low-latency** (or **LowLat**) kernel and provides near real-time performance.
    In many domains (virtualization, telecoms, and so on) using a LowLat kernel might
    turn out to be better than using a hard real-time RTL kernel, mainly due to RTL's
    overheads. You often find that, with hard real-time, user space apps can suffer
    from throughput, reduced CPU availability, and thus higher latencies. (Refer to
    the *Further reading* section for a whitepaper from Ubuntu that conducts a comparison
    between a vanilla distro kernel, a low-latency preemptible, and a fully preemptible
    – effectively an RTL – kernel.)
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 如[第10章](5391e3c1-30ad-4c75-a106-301259064881.xhtml)中所述，《CPU调度器-第1部分》，在*可抢占内核*部分，Linux内核可以配置为使用`CONFIG_PREEMPT`选项；这通常被称为**低延迟**（或**LowLat**）内核，并提供接近实时的性能。在许多领域（虚拟化、电信等），使用LowLat内核可能比使用硬实时RTL内核更好，主要是由于RTL的开销。通常情况下，使用硬实时，用户空间应用程序可能会受到吞吐量的影响，CPU可用性降低，因此延迟更高。（请参阅*进一步阅读*部分，了解Ubuntu的一份白皮书，其中对比了原始发行版内核、低延迟可抢占内核和完全可抢占内核-实际上是RTL内核。）
- en: With latencies in mind, the following section will help you understand what
    exactly is meant by system latencies; then, you'll learn some ways to measure
    it on a live system. On, on!
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到延迟，接下来的部分将帮助您了解系统延迟的确切含义；然后，您将学习一些在实时系统上测量它的方法。继续！
- en: Latency and its measurement
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 延迟及其测量
- en: 'We often come across the term latency; what exactly does it mean in the context
    of the kernel? A synonym for latency is delay and that''s a good hint. *The latency
    (or delay) is the time taken to react* – in our context here, the time between
    the kernel scheduler waking up a user space thread (or process), thus making it
    runnable, and the time when it does actually run on the processor is the **scheduling
    latency**. (Do be aware, though, the term scheduling latency is also used in another
    context, to mean the time interval within which every runnable task is guaranteed
    to run at least once; the tunable is here: `/proc/sys/kernel/sched_latency_ns`,
    and, at least on recent x86_64 Linux, defaults to 24 ms). Similarly, the time
    elapsed from when a hardware interrupt occurs (say a network interrupt) to when
    it''s actually serviced by it''s handler routine, is the interrupt latency.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常遇到术语延迟；在内核的上下文中，它到底是什么意思呢？延迟的同义词是延迟，这是一个很好的提示。*延迟（或延迟）是反应所需的时间* - 在我们这里的上下文中，内核调度程序唤醒用户空间线程（或进程）的时间，使其可运行，以及它实际在处理器上运行的时间是**调度延迟**。（不过，请注意，调度延迟这个术语也在另一个上下文中使用，指的是每个可运行任务保证至少运行一次的时间间隔；在这里的可调整项是：`/proc/sys/kernel/sched_latency_ns`，至少在最近的x86_64
    Linux上，默认值为24毫秒）。类似地，从硬件中断发生（比如网络中断）到它实际由其处理程序例程服务的经过的时间是中断延迟。
- en: 'The **cyclictest** user space program was written by Thomas Gleixner; its purpose:
    to measure kernel latencies. Its output values are in microseconds units. The
    average and maximum latency values are usually the ones of interest – if they
    fall within the acceptable range for the system, then all''s good; if not, it
    points to perhaps product-specific redesign and/or kernel configuration tweaking,
    checking other time-critical code paths (including user space), and so on.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '**cyclictest**用户空间程序是由Thomas Gleixner编写的；它的目的是测量内核延迟。其输出值以微秒为单位。平均延迟和最大延迟通常是感兴趣的值-如果它们在系统的可接受范围内，那么一切都很好；如果不在范围内，这可能指向产品特定的重新设计和/或内核配置调整，检查其他时间关键的代码路径（包括用户空间）等。'
- en: Let's use the cyclictest process itself as an example to clearly understand
    scheduling latency. The cyclictest process is run; internally, it issues `nanosleep(2)` (or,
    if the `-n` option switch is passed, the `clock_nanosleep(2)` system call), putting
    itself into a sleep state for the time interval specified. As these `*sleep()`
    system calls are obviously blocking, the kernel internally enqueues the cyclictest
    (for simplicity, we refer to it as `ct` in the following diagram) process into
    a wait queue, simply a kernel data structure that holds sleeping tasks.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以cyclictest进程本身作为一个例子，来清楚地理解调度延迟。cyclictest进程被运行；在内部，它发出`nanosleep(2)`（或者，如果传递了`-n`选项开关，则是`clock_nanosleep(2)`系统调用），将自己置于指定的时间间隔的睡眠状态。由于这些`*sleep()`系统调用显然是阻塞的，内核在内部将cyclictest（为简单起见，我们在下图中将其称为`ct`）进程排入等待队列，这只是一个保存睡眠任务的内核数据结构。
- en: 'A wait queue is associated with an event; when that event occurs, the kernel
    awakens all tasks sleeping on that event. Here, the event in question is the expiry
    of a timer; this is communicated by the timer hardware by emitting a hardware
    interrupt (or IRQ); this starts the chain of events that must happen to make the
    cyclictest process wake up and run on the processor. The key point here, of course,
    is that it''s easier said than done: many potential delays might occur on the
    path to the process actually running on a processor core! This is what the following
    diagram seeks to convey – the potential sources of latency:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 等待队列与事件相关联；当事件发生时，内核唤醒所有在该事件上休眠的任务。在这里，所讨论的事件是定时器的到期；这是由定时器硬件发出的硬件中断（或IRQ）来传达的；这开始了必须发生的事件链，以使cyclictest进程唤醒并在处理器上运行。当然，关键点在于，说起来容易做起来难：在进程实际在处理器核心上运行的路径上可能发生许多潜在的延迟！以下图表试图传达的就是潜在的延迟来源：
- en: '![](img/73e35574-dce9-40e5-ab2a-1c2a7f5a50eb.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73e35574-dce9-40e5-ab2a-1c2a7f5a50eb.png)'
- en: Figure 11.12 – The path to waking, context-switching, and running the cyclictest
    (ct) process; several latencies can occur
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12 - 唤醒、上下文切换和运行cyclictest（ct）进程的路径；可能发生多个延迟
- en: (Some of the preceding inputs stem from the excellent presentation *Using and
    Understanding the Real-Time Cyclictest Benchmark, Rowand, Oct 2013*.) Study Figure
    11.12 carefully; it shows the timeline from the hardware interrupt's assertion
    due to timer expiry (at time `t0`, as the sleep issued via the `nanosleep()` API
    by the cyclictest process is done at time `t1`), through IRQ handling (`t1` to
    `t3`), and the wakeup of the ct process – as a result of which it gets enqueued
    into the runqueue (between `t3` and `t4`) of the core it will eventually run upon.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: （部分前述输入来自于优秀的演示*使用和理解实时Cyclictest基准测试，Rowand，2013年10月*。）仔细研究图11.12；它显示了从硬件中断由于定时器到期的断言（在时间`t0`，因为cyclictest进程通过`nanosleep()`
    API发出的休眠在时间`t1`完成），通过IRQ处理（`t1`到`t3`），以及ct进程唤醒的时间线 - 作为其结果，它被排入将来运行的核心的运行队列（在`t3`和`t4`之间）。
- en: From there, it will eventually become the highest priority, or best or most
    deserving, task for the scheduling class it belongs to (at time `t6`; we covered
    these details in the preceding chapter), thus, it will preempt the currently running
    thread (`t6`). The `schedule()` code will then execute (time `t7 `to `t8`), the
    context switch will occur at the tail-end of `schedule()`, and finally(!), and
    the cyclictest process will actually execute on a processor core (time `t9`).
    Though it might at first appear complex, the reality is that this is a simplified
    diagram as several other potential latency sources have been omitted (for example,
    latencies due to IPI, SMI, cache migration, multiple occurrences of the preceding
    events, additional interrupts firing at an inopportune moment causing more delays,
    and so on).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 从那里，它最终将成为调度类别的最高优先级，或者最好或最值得的任务（在时间`t6`；我们在前一章中介绍了这些细节），因此，它将抢占当前正在运行的线程（`t6`）。`schedule()`代码将执行（时间`t7`到`t8`），上下文切换将发生在`schedule()`的尾端，最后(!)，cyclictest进程将实际在处理器核心上执行（时间`t9`）。虽然乍看起来可能很复杂，但实际情况是这是一个简化的图表，因为其他潜在的延迟源已被省略（例如，由于IPI、SMI、缓存迁移、前述事件的多次发生、额外中断在不合适的时刻触发导致更多延迟等）。
- en: 'A rule of thumb for determining the maximum latency value of a user space task
    running with real-time priority is the following:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 确定具有实时优先级的用户空间任务的最大延迟值的经验法则如下：
- en: '[PRE32]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: As an example, the Raspberry Pi Model 3 CPU clock runs at a frequency of 1 GHz;
    its wavelength (the time between one clock cycle to the next) is the inverse of
    the frequency, that is, 10^(-9) or 1 nanosecond. So, from the preceding equation,
    the theoretical maximum latency should be (within) 10^(-7) seconds which is about
    10 ns (nanoseconds). As you shall soon discover, this is merely theoretical.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，树莓派3型号的CPU时钟运行频率为1 GHz；其波长（一个时钟周期到下一个时钟周期之间的时间）是频率的倒数，即10^(-9)或1纳秒。因此，根据前述方程，理论最大延迟应该是（在）10^(-7)秒，约为10纳秒。正如您很快会发现的，这仅仅是理论上的。
- en: Measuring scheduling latency with cyclictest
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用cyclictest测量调度延迟
- en: 'To make this more interesting (as well as to run the latency test on a constrained
    system), we shall perform latency measurements using the well-known cyclictest app
    – while the system is under some amount of load (via the `stress(1)` utility)
    – on the equally well-known Raspberry Pi device. This section is divided into
    four logical parts:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这更有趣（以及在受限系统上运行延迟测试），我们将使用众所周知的cyclictest应用程序进行延迟测量，同时系统处于一定负载（通过`stress(1)`实用程序）下运行，使用同样著名的树莓派设备。本节分为四个逻辑部分：
- en: First, set up the working environment on the Raspberry Pi device.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在树莓派设备上设置工作环境。
- en: Second, download and apply the RT patches on the kernel source, configure, and
    build it.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 其次，在内核源上下载和应用RT补丁，进行配置和构建。
- en: Third, install the cyclictest app, as well as a few other required packages
    (including `stress`), on the device.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第三，安装cyclictest应用程序，以及设备上的其他一些必需的软件包（包括`stress`）。
- en: Fourth, run the test cases and analyze the results (even plotting graphs to
    help do so).
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第四，运行测试用例并分析结果（甚至绘制图表来帮助分析）。
- en: The first step and most parts of the second have already been covered in detail
    in [Chapter 3](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml), *Building the 5.x
    Linux Kernel from Source – Part 2*, in the *Kernel build for the Raspberry Pi*
    section. This includes downloading the Raspberry Pi-specific kernel source tree,
    configuring the kernel, and installing an appropriate toolchain; we won't repeat
    this information here. The only significant difference here is that we shall first
    have to apply the RT patches to the kernel source tree and configure for hard
    real-time; we cover this in the next section.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步和第二步的大部分内容已经在[第3章](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml)中详细介绍过，*从源代码构建5.x
    Linux内核-第2部分*，在*树莓派的内核构建*部分。这包括下载树莓派特定的内核源树，配置内核和安装适当的工具链；我们不会在这里重复这些信息。唯一的显著差异是，我们首先必须将RT补丁应用到内核源树中，并配置为硬实时；我们将在下一节中介绍这一点。
- en: Let's get going!
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Getting and applying the RTL patchset
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取并应用RTL补丁集
- en: Check the mainline or distribution kernel version that is running on your Raspberry
    Pi device (substitute the Raspberry Pi with any other device you may be running
    Linux on); for example, on the Raspberry Pi 3B+ I'm using, it's running the stock
    Raspbian (or Raspberry Pi OS) GNU/Linux 10 (buster) with the 5.4.51-v7+ kernel.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 检查运行在您的树莓派设备上的主线或发行版内核版本（用任何其他设备替换树莓派，您可能在其上运行Linux）；例如，在我使用的树莓派3B+上，它正在运行带有5.4.51-v7+内核的标准Raspbian（或树莓派OS）GNU/Linux
    10（buster）。
- en: We'd like to build an RTL kernel for the Raspberry Pi with the closest possible
    matching kernel to the standard one it's currently running; for our case here,
    with it running 5.4.51[-v7+], the closest available RTL patches are for kernel
    versions 5.4.y-rt[nn] ([https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/));
    we shall come back to this shortly...
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望为树莓派构建一个RTL内核，使其与当前运行的标准内核尽可能匹配；对于我们的情况，它正在运行5.4.51[-v7+]，最接近的可用RTL补丁是内核版本5.4.y-rt[nn]（[https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/](https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/)）；我们马上就会回到这一点...
- en: 'Let''s go step by step:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们一步一步来：
- en: The steps to download the Raspberry Pi specific kernel source tree onto your
    host system disk have already been covered in [Chapter 3](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml),
    *Building the 5.x Linux Kernel from Source – Part 2*, in the *Kernel build for
    the Raspberry Pi* section*;* do refer to it and obtain the source tree.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载树莓派特定的内核源树到您的主机系统磁盘的步骤已经在[第3章](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml)中详细介绍过，*从源代码构建5.x
    Linux内核-第2部分*，在*树莓派的内核构建*部分；请参考并获取源树。
- en: 'Once this step completes, you should see a directory named `linux`; it holds
    the Raspberry Pi kernel source for (as of the time of writing) kernel version
    5.4.y. What''s the value of `y`? That''s easy; just do the following:'
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成此步骤后，您应该会看到一个名为`linux`的目录；它保存了树莓派内核源代码，截至撰写本文的时间，内核版本为5.4.y。`y`的值是多少？这很容易；只需执行以下操作：
- en: '[PRE33]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `SUBLEVEL` variable here is the value of `y`; clearly, it's 70, making the
    kernel version 5.4.70.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的`SUBLEVEL`变量是`y`的值；显然，它是70，使得内核版本为5.4.70。
- en: 'Next, let''s download the appropriate real-time (RTL) patch: the best one would
    be an exact match, that is, the patch should be named something like `patch-5.4.70-rt[nn].tar.xz`.
    Lucky for us, it does indeed exist on the server; let''s get it (notice that we
    download the `patch-<kver>-rt[nn]` file; it''s simpler to work with as it''s the
    unified patch):'
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们下载适当的实时（RTL）补丁：最好是一个精确匹配，也就是说，补丁的名称应该类似于`patch-5.4.70-rt[nn].tar.xz`。幸运的是，它确实存在于服务器上；让我们获取它（请注意，我们下载`patch-<kver>-rt[nn]`文件；因为它是统一的补丁，所以更容易处理）：
- en: '`wget https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/patch-5.4.70-rt40.patch.xz`.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '`wget https://mirrors.edge.kernel.org/pub/linux/kernel/projects/rt/5.4/patch-5.4.70-rt40.patch.xz`。'
- en: 'This does raise the question: what if the versions of the available RTL patches
    do *not *precisely match that of the device''s kernel version? Well, unfortunately,
    that does happen. In cases like this, to have the best chance of applying it against
    the device kernel, select the closest match and attempt to apply it; it often
    succeeds with perhaps minor warnings... If not, you will have to either manually
    tweak the code base to suit the patchset, or just switch to using a kernel version
    for which the RTL patch exists (recommended).'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实引发了一个问题：如果可用的RTL补丁的版本与设备的内核版本*不完全匹配*会怎么样？很不幸，这确实会发生。在这种情况下，为了最有可能将其应用于设备内核，选择最接近的匹配并尝试应用它；通常会成功，也许会有轻微的警告...
    如果不行，您将不得不手动调整代码库以适应补丁集，或者切换到存在RTL补丁的内核版本（推荐）。
- en: Don't forget to uncompress the patch file!
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记解压补丁文件！
- en: 'Now apply the patch (as shown previously, in the *Applying the RTL patch* section):'
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在应用补丁（如前面所示，在*应用RTL补丁*部分）：
- en: '[PRE34]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Configure the patched kernel, turning on the `CONFIG_PREEMPT_RT` kernel config
    option (as explained previously):'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置打补丁的内核，打开`CONFIG_PREEMPT_RT`内核配置选项（如前面所述）：
- en: 'First, though, as we learned in [Chapter 3](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml), *Building
    the 5.x Linux Kernel from Source – Part 2*, it''s *critical* that you set up the
    initial kernel config appropriately for the target; here, as the target device
    is the Raspberry Pi 3[B+], do this:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不过，正如我们在[第3章](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml)中学到的，*从源代码构建5.x Linux内核-第2部分*，对于目标，设置初始内核配置是*至关重要*的；在这里，由于目标设备是树莓派3[B+]，请执行以下操作：
- en: '[PRE35]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Customize your kernel configuration with the `make ARCH=arm menuconfig` command.
    Here, of course, you should go to `General setup / Preemption Model`, and select
    the fourth option, `CONFIG_PREEMPT_RT`, to turn on the hard real-time preemption
    features.
  id: totrans-355
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`make ARCH=arm menuconfig`命令自定义您的内核配置。在这里，当然，您应该转到`General setup / Preemption
    Model`，并选择第四个选项，`CONFIG_PREEMPT_RT`，以打开硬实时抢占特性。
- en: 'I shall also assume that you have an appropriate toolchain for x86_64-to-ARM32
    for the Raspberry Pi installed:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我还假设您已经为树莓派安装了适当的x86_64到ARM32的工具链：
- en: '[PRE36]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Hint: Installing an appropriate toolchain (for x86_64-to-ARM32) can be as simple
    as `sudo apt install ​crossbuild-essential-armhf`. Now build the kernel (again,
    identical to the process we described previously, in the *Configuring and building
    the RTL kernel* section), with the difference being that we cross-compile it (using
    the x86_64-to-ARM32 cross-compiler we installed previously).'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：安装适当的工具链（用于x86_64到ARM32）可以像这样简单地进行：`sudo apt install ​crossbuild-essential-armhf`。现在构建内核（与我们之前描述的*配置和构建RTL内核*部分相同），不同之处在于我们进行交叉编译（使用之前安装的x86_64到ARM32交叉编译器）。
- en: 'Install the just-built kernel modules; ensure you specify the location as the
    SD card''s root filesystem with the `INSTALL_MOD_PATH` environment variable (else
    it might overwrite your host''s modules, which would be disastrous!). Let''s say
    that the microSD card''s second partition (which contains the root filesystem)
    is mounted under `/media/${USER}/rootfs`, then do the following (in one single
    line):'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装刚构建的内核模块；确保你使用`INSTALL_MOD_PATH`环境变量指定了SD卡的根文件系统的位置（否则它可能会覆盖你主机上的模块，这将是灾难性的！）。假设microSD卡的第二个分区（包含根文件系统）挂载在`/media/${USER}/rootfs`下，然后执行以下操作（一行命令）：
- en: '[PRE37]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Copy across the image files (the bootloader files, the kernel `zImage` file,
    the **Device Tree Blobs** (**DTBs**), the kernel modules) onto the Raspberry Pi
    SD card (these details are covered in the official Raspberry Pi documentation
    here: [https://www.raspberrypi.org/documentation/linux/kernel/building.md](https://www.raspberrypi.org/documentation/linux/kernel/building.md);
    we have also (lightly) covered this in [Chapter 3](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml),
    *Building the 5.x Linux Kernel from Source – Part 2*).
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像文件（引导加载程序文件，内核`zImage`文件，**设备树块**（**DTB**），内核模块）复制到树莓派SD卡上（这些细节在官方树莓派文档中有介绍：[https://www.raspberrypi.org/documentation/linux/kernel/building.md](https://www.raspberrypi.org/documentation/linux/kernel/building.md)；我们也在[第3章](93e5c09d-6c80-47e7-91ab-d3f3f25d00e1.xhtml)中（轻微地）介绍了这一点，*从源代码构建5.x
    Linux内核-第2部分*）。
- en: 'Test: boot the Raspberry Pi with the new kernel image in the SD card. You should
    be able to log in to a shell (typically over `ssh`). Verify the kernel version
    and config:'
  id: totrans-362
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试：使用SD卡中的新内核映像引导树莓派。你应该能够登录到一个shell（通常是通过`ssh`）。验证内核版本和配置：
- en: '[PRE38]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We are indeed running a hard real-time kernel on the device! So, good – that
    takes care of the "prep" portion; you are now in a position to proceed with the
    next step.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 我们确实在设备上运行了一个硬实时内核！所以，很好 - 这解决了“准备”部分；现在你可以继续下一步了。
- en: Installing cyclictest (and other required packages) on the device
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在设备上安装cyclictest（和其他所需的软件包）
- en: We intend to run test cases via the cyclictest app against both the standard
    and the newly minted RTL kernel. This implies, of course, that we must first obtain
    the cyclictest sources and build it on the device (note that the work here is
    being carried out on the Raspberry Pi).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 我们打算通过cyclictest应用程序对标准和新创建的RTL内核运行测试用例。这意味着，当然，我们必须首先获取cyclictest的源代码并在设备上构建它（请注意，这里的工作是在树莓派上进行的）。
- en: Here's an article that does this very thing: *Latency of Raspberry Pi 3 on Standard
    and Real-Time Linux 4.9* *Kernel*: [https://metebalci.com/blog/latency-of-raspberry-pi-3-on-standard-and-real-time-linux-4.9-kernel/](https://metebalci.com/blog/latency-of-raspberry-pi-3-on-standard-and-real-time-linux-4.9-kernel/).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一篇文章介绍了这个过程：*树莓派3在标准和实时Linux 4.9内核上的延迟*：[https://metebalci.com/blog/latency-of-raspberry-pi-3-on-standard-and-real-time-linux-4.9-kernel/](https://metebalci.com/blog/latency-of-raspberry-pi-3-on-standard-and-real-time-linux-4.9-kernel/)。
- en: 'It mentions an issue faced running the RTL kernel on the Raspberry Pi 3 as
    well as a workaround (important!): (in addition to the usual ones) pass along
    these two kernel parameters: `dwc_otg.fiq_enable=0` and `dwc_otg.fiq_fsm_enable=0`. You
    can put these in the `/boot/cmdline.txt` file on the device.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 它提到了在树莓派3上运行RTL内核时遇到的问题以及一个解决方法（重要！）：（除了通常的参数之外）还要传递这两个内核参数：`dwc_otg.fiq_enable=0`和`dwc_otg.fiq_fsm_enable=0`。你可以将这些参数放在设备上的`/boot/cmdline.txt`文件中。
- en: 'First, do ensure that all required packages are installed onto your Raspberry
    Pi:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，确保所有所需的软件包都已安装到你的树莓派上：
- en: '[PRE39]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The `libnuma-dev` package is optional and may not be available on the Raspberry
    Pi OS (you can proceed even without it).
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '`libnuma-dev`软件包是可选的，可能在树莓派OS上不可用（即使没有也可以继续）。'
- en: 'Let''s now get the source code of cyclictest:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们获取cyclictest的源代码：
- en: '[PRE40]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'A bit peculiarly, initially, there will exist precisely one file, the `README`.
    Read it (surprise, surprise). It informs you how to obtain and build the stable
    version; it''s simple, just do the following:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 有点奇怪的是，最初只会存在一个文件，`README`。阅读它（惊喜，惊喜）。它告诉你如何获取和构建稳定版本；很简单，只需按照以下步骤进行：
- en: '[PRE41]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Happily for us, the **Open Source Automation Development Lab** (**OSADL**)
    has a very useful bash script wrapper over cyclictest; it runs cyclictest and
    even plots a latency graph. Grab the script from here: [https://www.osadl.org/uploads/media/mklatencyplot.bash](https://www.osadl.org/uploads/media/mklatencyplot.bash) (explanatory
    note on it: [https://www.osadl.org/Create-a-latency-plot-from-cyclictest-hi.bash-script-for-latency-plot.0.html?&no_cache=1&sword_list[0]=cyclictest](https://www.osadl.org/Create-a-latency-plot-from-cyclictest-hi.bash-script-for-latency-plot.0.html?&no_cache=1&sword_list%5B0%5D=cyclictest)).
    I have lightly modified it for our purposes; it''s here in the GitHub repository
    for this book: `ch11/latency_test/latency_test.sh`.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说很幸运，**开源自动化开发实验室**（**OSADL**）有一个非常有用的bash脚本包装器，可以运行cyclictest甚至绘制延迟图。从这里获取脚本：[https://www.osadl.org/uploads/media/mklatencyplot.bash](https://www.osadl.org/uploads/media/mklatencyplot.bash)（关于它的说明：[https://www.osadl.org/Create-a-latency-plot-from-cyclictest-hi.bash-script-for-latency-plot.0.html?&no_cache=1&sword_list[0]=cyclictest](https://www.osadl.org/Create-a-latency-plot-from-cyclictest-hi.bash-script-for-latency-plot.0.html?&no_cache=1&sword_list%5B0%5D=cyclictest)）。我已经对它进行了轻微修改以适应我们的目的；它在本书的GitHub存储库中：`ch11/latency_test/latency_test.sh`。
- en: Running the test cases
  id: totrans-377
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行测试用例
- en: 'To get a good idea regarding the system (scheduling) latencies, we shall run
    three test cases; in all three, the cyclictest app will sample system latency
    while the `stress(1)` utility is putting the system under load:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 为了对系统（调度）延迟有一个好的概念，我们将运行三个测试用例；在所有三个测试中，`cyclictest` 应用程序将在 `stress(1)` 实用程序将系统置于负载下时对系统延迟进行采样：
- en: Raspberry Pi 3 model B+ (4 CPU cores) running the 5.4 32-bit RTL-patched kernel
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 树莓派3型B+（4个CPU核心）运行5.4 32位RTL补丁内核
- en: Raspberry Pi 3 model B+ (4 CPU cores) running the standard 5.4 32-bit Raspberry
    Pi OS kernel
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 树莓派3型B+（4个CPU核心）运行标准5.4 32位树莓派OS内核
- en: x86_64 (4 CPU cores) Ubuntu 20.04 LTS running the standard 5.4 (mainline) 64-bit
    kernel
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: x86_64（4个CPU核心）Ubuntu 20.04 LTS运行标准的5.4（主线）64位内核
- en: 'We use a small wrapper script called `runtest` over the `latency_test.sh` script for
    convenience. It runs the `latency_test.sh` script to measure system latency while
    running the `stress(1)` utility; it invokes `stress` with the following parameters,
    to impose CPU, I/O, and memory loads on the system:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个名为 `runtest` 的小包装脚本覆盖 `latency_test.sh` 脚本以方便起见。它运行 `latency_test.sh`
    脚本来测量系统延迟，同时运行 `stress(1)` 实用程序；它使用以下参数调用 `stress`，对系统施加CPU、I/O和内存负载：
- en: '[PRE42]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '(FYI, a later version of `stress` called `stress-ng` is available as well.)
    While the `stress` app executes, loading the system, the `cyclictest(8)` app samples
    system latencies, writing its `stdout` to a file:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: （顺便说一句，还有一个名为 `stress-ng` 的后续版本可用。）当 `stress` 应用程序执行加载系统时，`cyclictest(8)` 应用程序对系统延迟进行采样，并将其
    `stdout` 写入文件：
- en: '[PRE43]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: (Do refer to the man pages on both `stress(1)` and `cyclictest(8)` to understand
    the parameters.) It will run for an hour (for more accurate results, I suggest
    you run the test for a longer duration – perhaps 12 hours). Our `runtest` script
    (and the underlying ones) internally runs `cyclictest` with appropriate parameters;
    it captures and displays the minimum, average, and maximum latency wall clock
    time taken (via `time(1)`), and generates a histogram plot. Note that here, we
    run `cyclictest` for a (maximum) duration of an hour.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: （请参考`stress(1)`和`cyclictest(8)`的man页面以了解参数。）它将运行一个小时（为了更准确的结果，建议您将测试运行更长时间 -
    也许12小时）。我们的 `runtest` 脚本（以及底层脚本）在内部使用适当的参数运行 `cyclictest`；它捕获并显示最小、平均和最大延迟的挂钟时间（通过`time(1)`），并生成直方图图表。请注意，这里我们运行
    `cyclictest` 的最长持续时间为一小时。
- en: By default, our `runtest` wrapper script has a variable LAT with the pathname
    to the `latency_tests` directory set as follows: `LAT=~/booksrc/ch11/latency_tests`.
    Ensure that you first update it to reflect the location of the `latency_tests`
    directory on your system.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，我们的 `runtest` 包装脚本具有一个名为LAT的变量，其中包含以下设置的 `latency_tests` 目录的路径名：`LAT=~/booksrc/ch11/latency_tests`。确保您首先更新它以反映系统上
    `latency_tests` 目录的位置。
- en: 'A screenshot of running the scripts for our test case #1 – on the Raspberry
    Pi 3B+ running the RTL kernel – is seen here:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在树莓派3B+上运行RTL内核的测试用例#1的脚本截图如下：
- en: '![](img/a153d37e-90f6-41a0-bd42-98f3529de031.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a153d37e-90f6-41a0-bd42-98f3529de031.png)'
- en: Figure 11.13 – Running our first test case for cyclictest on a Raspberry Pi
    3B+ on the RTL kernel while under stress
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13 - 在受压力的RTL内核上运行树莓派3B+的cyclictest的第一个测试用例
- en: Study the preceding screenshot; you can clearly see the system details, the
    kernel version (notice it's the RTL-patched `PREEMPT_RT` kernel!), and cyclictest's
    latency measurement results for the minimum, average, and maximum (scheduling)
    latency.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 研究前面的截图；您可以清楚地看到系统详细信息，内核版本（请注意，这是RTL补丁的`PREEMPT_RT`内核！），以及cyclictest的最小、平均和最大（调度）延迟测量结果。
- en: Viewing the results
  id: totrans-392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看结果
- en: 'We carry out a similar procedure for the remaining two test cases and summarize
    the results of all three in Figure 11.14:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对剩下的两个测试用例进行类似的过程，并在图11.14中总结所有三个的结果：
- en: '![](img/fda2c55a-4879-4baf-98d8-3ee0c4021206.png)'
  id: totrans-394
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fda2c55a-4879-4baf-98d8-3ee0c4021206.png)'
- en: Figure 11.14 – Results of the (simplistic) test cases we ran showing the min/avg/max
    latencies for different kernels and systems while under some stress
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.14 - 我们运行的（简单的）测试用例结果，显示了在一些压力下不同内核和系统的最小/平均/最大延迟
- en: Interesting; though the maximum latency of the RTL kernel is much below the
    other standard kernels, both the minimum and, more importantly, average latencies
    are superior for the standard kernels. This ultimately results in superior overall
    throughput for the standard kernels (this very same point was stressed upon earlier).
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，尽管RTL内核的最大延迟远低于其他标准内核，但最小延迟，更重要的是平均延迟，对于标准内核来说更好。这最终导致标准内核的整体吞吐量更高（这个观点之前也强调过）。
- en: 'The `latency_test.sh` bash script invokes the `gnuplot(1)` utility to generate
    graphs, in such a manner that the title line shows the minimum/average/maximum
    latency values (in microseconds) and the kernel the test was run upon. Recollect
    that test case #1 and #2 ran on the Raspberry Pi 3B+ device, whereas test case
    #3 ran on a generic (and more powerful) x86_64 system). See here the `gnuplot`-ed
    graphs (for all three test cases):'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '`latency_test.sh` bash脚本调用 `gnuplot(1)` 实用程序生成图表，标题行显示最小/平均/最大延迟值（以微秒为单位）和运行测试的内核。请记住，测试用例#1和#2在树莓派3B+设备上运行，而测试用例#3在通用（更强大）的x86_64系统上运行。这里是所有三个测试用例的
    `gnuplot` 图表：'
- en: '![](img/9039fe61-7614-4f9f-96c8-6cdfd4dae665.png)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9039fe61-7614-4f9f-96c8-6cdfd4dae665.png)'
- en: 'Figure 11.15 – Test case #1 plot: cyclictest latency measurement on Raspberry
    Pi 3B+ running the 5.4 RTL kernel'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.15 - 测试用例#1绘图：树莓派3B+运行5.4 RTL内核的cyclictest延迟测量
- en: 'Figure 11.15 shows the graph plotted by `gnuplot(1)` (called from within our `ch11/latency_test/latency_test.sh`
    script) for test case #1\. The **Device Under Test** (**DUT**), the Raspberry
    Pi 3B+, has four CPU cores (as seen by the OS). Notice how the graph shows us
    the story – the vast majority of samples are on the upper left, implying that,
    most of the time, the latency was very small (between 100,000 to 1 million latency
    samples (y-axis) fall between a few microseconds to 50 microseconds (x-axis)!).
    That''s really good! Of course, there will be outliers at the other extreme –
    samples on all CPU cores have much higher latencies (between 100 and 256 microseconds)
    though the number of samples is much smaller. The cyclictest app gives us the
    minimum, average, and maximum system latency values. With the RTL-patched kernel,
    while the max latency is actually excellent (quite low), the average latency can
    be fairly high:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.15显示了由`gnuplot(1)`（从我们的`ch11/latency_test/latency_test.sh`脚本中调用）绘制的测试用例＃1的图表。被测试设备（DUT），Raspberry
    Pi 3B+，有四个CPU核心（由操作系统看到）。注意图表如何告诉我们故事 - 绝大多数样本位于左上角，意味着大部分时间延迟非常小（100,000到1,000,000延迟样本（y轴）落在几微秒到50微秒（x轴）之间！）。这真的很好！当然，在另一个极端会有离群值
    - 所有CPU核心的样本具有更高的延迟（在100到256微秒之间），尽管样本数量要小得多。cyclictest应用程序给出了最小、平均和最大系统延迟值。使用RTL补丁内核，虽然最大延迟实际上非常好（非常低），但平均延迟可能相当高：
- en: '![](img/e65ec4f6-374d-49c3-91bb-07520aaff1e2.png)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e65ec4f6-374d-49c3-91bb-07520aaff1e2.png)'
- en: 'Figure 11.16 – Test case #2 plot: cyclictest latency measurement on Raspberry
    Pi 3B+ running the standard (mainline) 5.4 kernel'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.16 - 测试用例＃2图：在运行标准（主线）5.4内核的Raspberry Pi 3B+上进行的cyclictest延迟测量
- en: 'Figure 11.16 shows the plot for test case #2\. Again, as with the previous
    test case – in fact, even more pronounced here – the vast majority of system latency
    samples exhibit very low latency! The standard kernel thus does a tremendous job;
    even the average latency is a "decent" value. However, the worst-case (max) latency
    value can be very large indeed – *showing us exactly why it''s not an RTOS*. For
    most workloads, the latency tends to be excellent "usually", but a few corner
    cases will tend to show up. In other words, it''s *not deterministic* – the key
    characteristic of an RTOS:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.16显示了测试用例＃2的图表。与先前的测试用例一样，实际上，在这里甚至更加明显，系统延迟样本的绝大多数表现出非常低的延迟！标准内核因此做得非常好；即使平均延迟也是一个“不错”的值。然而，最坏情况（最大）延迟值确实可能非常大
    - *这正是为什么它不是一个RTOS*。对于大多数工作负载，延迟往往是“通常”很好的，但是一些特殊情况往往会出现。换句话说，它是*不确定的* - 这是RTOS的关键特征：
- en: '![](img/d539b8dd-14e8-43cc-a86f-9db98d5af156.png)'
  id: totrans-404
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d539b8dd-14e8-43cc-a86f-9db98d5af156.png)'
- en: 'Figure 11.17 – Test case #3 plot: cyclictest latency measurement on an x86_64
    Ubuntu 20.04 LTS running the standard (mainline) 5.4 kernel'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.17 - 测试用例＃3图：在运行标准（主线）5.4内核的x86_64 Ubuntu 20.04 LTS上进行的cyclictest延迟测量
- en: 'Figure 11.17 shows the plot for test case #3\. The variance – or **jitter** –
    here is even more pronounced (again, non-deterministic!), though the minimum and
    average system latency values are really very good. Of course, it''s run on a
    far more powerful system – a desktop-class x86_64 – than the previous two test
    cases. The max latency value – the few corner cases, although there are more of
    them here – tends to be quite high. Again, it''s not an RTOS – it''s not deterministic.'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.17显示了测试用例＃3的图表。这里的方差 - 或**抖动** - 更加明显（再次，非确定性！），尽管最小和平均系统延迟值确实非常好。当然，它是在一个远比前两个测试用例更强大的系统上运行的
    - 一个桌面级的x86_64 - 最大延迟值 - 尽管这里有更多的特殊情况，但往往相当高。再次强调，这不是一个RTOS - 它不是确定性的。
- en: 'Did you notice how the graphs clearly exhibit *jitter*: with test case #1 having
    the least amount (the graph tends to drop down to the x-axis quite quickly - meaning
    a very tiny number of latency samples, if not zero, exhibit high(er) latencies)
    and test case #3 having the most jitter (with much of the graph remaining well
    above the *x* axis!).'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否注意到图表清楚地展示了*抖动*：测试用例＃1具有最少的抖动（图表往往很快下降到x轴 - 这意味着很少数量的延迟样本，如果不是零，表现出较高的延迟），而测试用例＃3具有最多的抖动（图表大部分仍然远高于*x*轴！）。
- en: 'Again, we emphasize this point: the results quite clearly show that it''s deterministic
    (a very small amount of jitter) with an RTOS and highly non-deterministic with
    a GPOS! (As a rule of thumb, standard Linux will result in approximately +/- 10
    microseconds of jitter for interrupt processing, whereas on a microcontroller
    running an RTOS, the jitter will be far less, around +/- 10 nanoseconds!)'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调这一点：结果清楚地表明，它是确定性的（非常少的抖动）与RTOS，而与GPOS则是高度非确定性的！（作为一个经验法则，标准Linux在中断处理方面会产生大约+/-
    10微秒的抖动，而在运行RTOS的微控制器上，抖动会小得多，大约+/- 10纳秒！）
- en: Doing this experiment, you will realize that benchmarking is a tricky thing;
    you shouldn't read too much into a few test runs (running the tests for a long
    while, having a large sample set, is important). Testing with realistic work loads
    you expect to experience on the system would be a far better way to see which
    kernel configuration yields superior performance; it does indeed vary with the
    workload!
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 进行这个实验，你会意识到基准测试是一件棘手的事情；你不应该对少数测试运行读太多（长时间运行测试，有一个大样本集是重要的）。使用您期望在系统上体验的真实工作负载进行测试，将是查看哪个内核配置产生更优越性能的更好方法；它确实会随着工作负载的变化而变化！
- en: (An interesting case study by Canonical shows statistics for regular, low-latency,
    and real-time kernels for certain workloads; look it up in the *Further reading*
    section of this chapter.) As mentioned before, quite often, the superior *max*
    latency characteristics of an RTL kernel can lead to inferior overall throughput
    (user space might suffer from reduced CPU due to RTL's rather ruthless prioritization).
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: （Canonical的一个有趣案例研究显示了某些工作负载的常规、低延迟和实时内核的统计数据；在本章的*进一步阅读*部分查找）。如前所述，通常情况下，RTL内核的*最大*延迟特性往往会导致整体吞吐量较低（用户空间可能因为RTL的相当无情的优先级而遭受降低的CPU）。
- en: Measuring scheduler latency via modern BPF tools
  id: totrans-411
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过现代BPF工具测量调度器延迟
- en: Without going into too many details, we'd be amiss to leave out the recent and
    powerful [e]BPF Linux kernel feature and it's associated frontends; there are
    a few to specifically measure scheduler and runqueue-related system latencies.
    (We covered the installation of the [e]BPF tools back in [Chapter 1](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml), *Kernel
    Workspace Setup* under the *Modern tracing and performance analysis with [e]BPF* section).
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 不详细介绍，但我们不得不提及最近和强大的[e]BPF Linux内核功能及其相关前端；有一些专门用于测量调度器和运行队列相关系统延迟的工具。 （我们在[第1章](ad75db43-a1a2-4f3f-92c7-a544f47baa23.xhtml)中介绍了[e]BPF工具的安装，*现代跟踪和性能分析与[e]BPF*部分）。
- en: 'The following table summarizes some of these tools (BPF frontends); all these
    tools need to be run as root (as with any BPF tool); they show their output as
    a histogram (with the time in microseconds by default):'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了一些这些工具（BPF前端）；所有这些工具都需要以root身份运行（与任何BPF工具一样）；它们将它们的输出显示为直方图（默认为微秒）：
- en: '| **BPF tool** | ** What it measures** |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| **BPF工具** | **它测量什么** |'
- en: '| `runqlat-bpfcc` | Time a task spends waiting on a runqueue for it''s turn
    to run on the processor |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| `runqlat-bpfcc` | 计算任务在运行队列上等待的时间，等待在处理器上运行|'
- en: '| `runqslower-bpfcc` | (read as runqueue slower); time a task spends waiting
    on a runqueue for it''s turn to run on the processor, showing only those threads
    that exceed a given threshold, which is 10 ms by default (can be tuned by passing
    the time threshold as a parameter, in microseconds); in effect, you can see which
    tasks face (relatively) long scheduling delays |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| `runqslower-bpfcc` |（读作runqueue slower）；计算任务在运行队列上等待的时间，显示只有超过给定阈值的线程，默认为10毫秒（可以通过传递微秒为单位的时间阈值来调整）；实际上，您可以看到哪些任务面临（相对）较长的调度延迟。'
- en: '| `runqlen-bpfcc` | Shows scheduler runqueue length + occupancy (number of
    threads currently enqueued, waiting to run) |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| `runqlen-bpfcc` | 显示调度器运行队列长度+占用（当前排队等待运行的线程数）|'
- en: The tools can also provide these metrics on a per-task basis, for every process
    on the system or even by PID namespace (for container analysis; of course, these
    options depend on the tool in question). Do look up more details (and even example
    usage!) from the man pages (section 8) on these tools.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具还可以根据每个进程的任务基础提供这些指标，或者甚至可以根据PID命名空间（用于容器分析；当然，这些选项取决于具体的工具）。请查阅这些工具的man页面（第8节），了解更多细节（甚至包括示例用法！）。
- en: 'There are even more [e]BPF frontends related to scheduling: `cpudist- cpudist-bpfcc`, `cpuunclaimed-bpfcc`,
    `offcputime-bpfcc`, `wakeuptime-bpfcc`, and so on. See the *Further reading* section
    for resources.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至还有更多与调度相关的[e]BPF前端：`cpudist- cpudist-bpfcc`、`cpuunclaimed-bpfcc`、`offcputime-bpfcc`、`wakeuptime-bpfcc`等等。请参阅*进一步阅读*部分获取资源。
- en: 'So, there you are: by now, you''re able to not only understand but even measure
    system latencies (via both the `cyclictest` app and a few modern BPF tools).'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，到目前为止，您不仅能够理解，甚至可以测量系统的延迟（通过`cyclictest`应用程序和一些现代BPF工具）。
- en: 'We close this chapter with a few miscellaneous, yet useful small (kernel space)
    routines to check out:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本章中结束时列出了一些杂项但有用的小（内核空间）例程供查看：
- en: '`rt_prio()`: Given the priority as a parameter, returns a Boolean to indicate
    whether it''s a real-time task or not.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rt_prio()`: 给定优先级作为参数，返回一个布尔值，指示它是否是实时任务。'
- en: '`rt_task()`: Based on the priority value of the task, given the task structure
    pointer as a parameter, returns a Boolean to indicate whether it''s a real-time
    task or not (a wrapper over `rt_prio()`).'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rt_task()`: 基于任务的优先级值，给定任务结构指针作为参数，返回一个布尔值，指示它是否是实时任务（是`rt_prio()`的包装）。'
- en: '`task_is_realtime()`: Similar, but based on the scheduling policy of the task.
    Given the task structure pointer as a parameter, returns a Boolean to indicate
    whether it''s a real-time task or not.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_is_realtime()`: 类似，但基于任务的调度策略。给定任务结构指针作为参数，返回一个布尔值，指示它是否是实时任务。'
- en: Summary
  id: totrans-425
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this, our second chapter on CPU scheduling on the Linux OS, you have learned
    several key things. Among them, you learned how to visualize kernel flow with
    powerful tools such as LTTng and the Trace Compass GUI, as well as with the `trace-cmd(1)`
    utility, a convenient frontend to the kernel's powerful Ftrace framework. You
    then saw how to programatically query and set any thread's CPU affinity mask.
    This naturally led to a discussion on how you can programmatically query and set
    any thread's scheduling policy and priority. The whole notion of being "completely
    fair" (via the CFS implementation) was brought into question, and some light was
    shed on the elegant solution called cgroups. You even learned how to leverage
    the cgroups v2 CPU controller to allocate CPU bandwidth as desired to processes
    in a sub-group. We then understood that though Linux is a GPOS, an RTL patchset
    very much exists, which, once applied and the kernel is configured and built,
    has you running Linux as a true hard real-time system, an RTOS.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本关于Linux操作系统上CPU调度的第二章中，您学到了一些关键内容。其中，您学会了如何使用强大的工具（如LTTng和Trace Compass GUI）来可视化内核流，以及使用`trace-cmd(1)`实用程序，这是内核强大的Ftrace框架的便捷前端。然后，您了解了如何以编程方式查询和设置任何线程的CPU亲和力掩码。这自然而然地引出了如何以编程方式查询和设置任何线程的调度策略和优先级的讨论。整个“完全公平”的概念（通过CFS实现）被质疑，并且对称为cgroups的优雅解决方案进行了一些阐述。您甚至学会了如何利用cgroups
    v2 CPU控制器为子组中的进程分配所需的CPU带宽。然后我们了解到，尽管Linux是一个GPOS，但RTL补丁集确实存在，一旦应用并且内核配置和构建完成，您就可以将Linux运行为真正的硬实时系统，即RTOS。
- en: Finally, you learned how to measure latencies on the system, via both the cyclictest
    app as well as a few modern BPF tools. We even tested with cyclictest on a Raspberry
    Pi 3 device, measuring and contrasting them on an RTL and a standard kernel.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您学会了如何通过cyclictest应用程序以及一些现代BPF工具来测量系统的延迟。我们甚至在Raspberry Pi 3设备上使用cyclictest进行了测试，并在RTL和标准内核上进行了对比。
- en: That's quite a bit! Do take the time to properly understand the material, and
    work on it in a hands-on fashion.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 这是相当多的内容！一定要花时间透彻理解材料，并且以实际操作的方式进行工作。
- en: Questions
  id: totrans-429
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter''s material: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions).
    You will find some of the questions answered in the book''s GitHub repo: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn).'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束时，这里有一些问题列表，供您测试对本章材料的了解：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions)。您会发现一些问题的答案在书的GitHub存储库中：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn)。
- en: Further reading
  id: totrans-431
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: To help you delve deeper into the subject with useful materials, we provide
    a rather detailed list of online references and links (and at times, even books)
    in a Further reading document in this book's GitHub repository. The *Further reading*
    document is available here: [https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md).
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您深入了解这个主题并提供有用的材料，我们在本书的GitHub存储库中提供了一个相当详细的在线参考和链接列表（有时甚至包括书籍）的《进一步阅读》文档。*进一步阅读*文档在这里可用：[https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md)。
