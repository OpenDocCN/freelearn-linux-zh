- en: Chapter 12. A Better lastlog with Awk
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第12章。使用Awk改进lastlog
- en: We have already seen in [Chapter 11](part0069_split_000.html#21PMQ1-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 11. Summarizing Logs with Awk"), *Summarizing Logs with Awk*, how we
    can create complex reports from large amounts of data mined from purely text files.
    Similarly, we can create extensive reports using the output from standard command-line
    tools, such as the `lastlog` tool. In itself `lastlog` can report the last login
    time for all users. Often though, we may wish to filter the output from `lastlog`.
    Perhaps you need to exclude the user accounts that have never been used to login
    to the system. It may also be irrelevant to report on `root`, as the account may
    be predominately used for `sudo` only and not used to record regularly for standard
    logins.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[第11章](part0069_split_000.html#21PMQ1-747571d9b4814e1dbffcdef2eb0dec8d
    "第11章。使用Awk总结日志")中看到了如何从纯文本文件中挖掘大量数据并创建复杂报告。同样，我们可以使用标准命令行工具的输出来创建广泛的报告，比如`lastlog`工具。`lastlog`本身可以报告所有用户的最后登录时间。然而，我们可能希望过滤`lastlog`的输出。也许您需要排除从未用于登录系统的用户帐户。也可能不相关报告`root`，因为该帐户可能主要用于`sudo`，而不用于记录标准登录。
- en: 'In working through this chapter, we will work both with `lastlog` and formatting
    of XML data. As this is the last chapter in which we investigate awk, we will
    configure record separators. We have already seen the use of field separators
    in awk but we can change the default record separator from a newline to something
    more specific to our need. More specifically, within this chapter we will cover:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将同时使用`lastlog`和XML数据格式化。由于这是我们调查awk的最后一章，我们将配置记录分隔符。我们已经看到了awk中字段分隔符的使用，但我们可以将默认记录分隔符从换行符更改为更符合我们需求的内容。具体来说，在本章中我们将涵盖：
- en: Using awk ranges to exclude data
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用awk范围来排除数据
- en: Conditions based on the number of fields in a row
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于行中字段数量的条件
- en: Manipulating the awk record separator to report on XML data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作awk记录分隔符以报告XML数据
- en: Using awk ranges to exclude data
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用awk范围来排除数据
- en: So far in this book, we have predominately looked at including data with ranges
    either for `sed` or for `awk`. With both of these tools, we can negate the range
    so that we exclude the specified rows. This suits the need that we have been using
    the output from `lastlog`. This will print all the login data for all the users,
    including accounts that have never been logged in. These accounts that have never
    been logged in might be service accounts or for new users that have not logged
    into the system so far.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，我们主要关注包括`sed`或`awk`的范围内的数据。使用这两个工具，我们可以否定范围，以便排除指定的行。这符合我们一直使用`lastlog`输出的需求。这将打印出所有用户的登录数据，包括从未登录的帐户。这些从未登录的帐户可能是服务帐户或尚未登录系统的新用户。
- en: The lastlog command
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: lastlog命令
- en: 'If we look at the output from `lastlog`, when it is used without any options,
    we can begin to understand the issue. From the command line, we execute the command
    as a standard user. There is no requirement to run it as the root account. The
    command is shown in the following example:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看`lastlog`的输出，当它没有任何选项时，我们可以开始理解问题。从命令行，我们以标准用户身份执行命令。没有必要以root帐户运行它。命令如下示例所示：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The partial output is shown within the following screenshot:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 部分输出如下截图所示：
- en: '![The lastlog command](img/00118.jpeg)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![lastlog命令](img/00118.jpeg)'
- en: We can see, even from this limited output that we have a cluttered output due
    to the virtual noise being created by the accounts that have not logged in. It
    is possible to alleviate this to some degree using the `lastlog` options but it
    may not entirely resolve the issue. To demonstrate this, we can add an option
    to `lastlog` that only users accounts usually used by standard accounts should
    be included. This may vary on your system but on the sample CentOS 6 host that
    I am using, the first user will be UID 500.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 即使从这有限的输出中，我们可以看到由于从未登录的帐户创建的虚拟噪音而产生的混乱输出。使用`lastlog`选项可能在一定程度上缓解这一问题，但可能并不能完全解决问题。为了证明这一点，我们可以向`lastlog`添加一个选项，只包括通常由标准帐户使用的用户帐户。这可能因系统而异，但在我使用的样本CentOS
    6主机上，第一个用户将是UID 500。
- en: 'If we use the `lastlog -u 500-5000` command, we will only print data for those
    users with a UID within this range. On the simple demonstration system, we have
    just three user accounts for which the output is acceptable. However, we can understand
    that we may still have some clutter die to these accounts that have not yet been
    used. This is shown in the following screenshot:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用`lastlog -u 500-5000`命令，我们将只打印UID在此范围内的用户的数据。在简单的演示系统中，我们只有三个用户帐户的输出是可以接受的。然而，我们可以理解到我们可能仍然有一些混乱，因为这些帐户尚未被使用。如下截图所示：
- en: '![The lastlog command](img/00119.jpeg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![lastlog命令](img/00119.jpeg)'
- en: In addition to the superfluous data being printed from the **Never logged in**
    accounts, we may only be interested in the **Username** and **Latest** fields.
    This is another reason to support the need to use awk as our data filter. In this
    way, we can provide both horizontal and vertical data filtering, rows, and columns.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 除了从**从未登录**帐户打印出的多余数据之外，我们可能只对**用户名**和**最新**字段感兴趣。这是支持使用awk作为数据过滤器的另一个原因。通过这种方式，我们可以提供水平和垂直数据过滤，行和列。
- en: Horizontal filtering rows with awk
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用awk进行水平过滤行
- en: 'To provide this filtering using awk, we will pipe the data from `lastlog` directly
    to `awk`. We will make use of a simple control file initially providing the horizontal
    filtering or reducing the rows that we see. First, the command pipeline will be
    as simple as the following command example:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用awk提供这种过滤，我们将把数据从`lastlog`直接传输到`awk`。我们将首先使用一个简单的控制文件来提供水平过滤或减少我们看到的行。首先，命令管道将如下命令示例一样简单：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Of course, the complexity is abstracted from the command line and concealed
    within the control file that we use. Initially, the control file is kept simple
    and would read as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，复杂性是从命令行中抽象出来的，并隐藏在我们使用的控制文件中。最初，控制文件保持简单，读起来如下：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The range is setup as we have seen previously and precedes the main code block.
    Using the exclamation mark in front of the parentheses negates or reverses the
    selected range. The double vertical bar acts as a logical `OR`. We do not include
    lines that contain `Never logged in`, nor do we include lines that start with
    `Username`. This removes the header-line that is printed by `lastlog`. Finally,
    we exclude the root account from the display. This initiates the rows that we
    work with and the main code block will print those lines.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 范围设置与我们之前看到的一样，并在主代码块之前。在括号前使用感叹号可以否定或颠倒所选范围。双竖线作为逻辑`OR`。我们不包括包含`Never logged
    in`的行，也不包括以`Username`开头的行。这将移除`lastlog`打印的标题行。最后，我们排除root账户的显示。这初始化了我们要处理的行，主代码块将打印这些行。
- en: Counting matched rows
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 匹配行的计数
- en: 'We may also want to count the number of rows that are returned by the filter.
    For example, using the internal `NR` variable will show all rows and not just
    the matched rows; for us to be able to report the number of users that have logged
    in, we must use our own variable. The following code will maintain the count within
    the variable that we name `cnt`. We increment this using the C style `++` for
    each iteration of the main code block. We can use the `END` code block to display
    the closing value of this variable:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能还想计算过滤返回的行数。例如，使用内部的`NR`变量将显示所有行而不仅仅是匹配的行；为了能够报告已登录用户的数量，我们必须使用我们自己的变量。以下代码将在我们命名为`cnt`的变量中维护计数。我们使用C风格的`++`来增加主代码块的每次迭代。我们可以使用`END`代码块来显示这个变量的最终值：
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can see from the following code and output how this appears on my system:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从以下代码和输出中看到这在我的系统上是如何显示的：
- en: '![Counting matched rows](img/00120.jpeg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![匹配行的计数](img/00120.jpeg)'
- en: From the display output, we can now see that we show only users that have logged
    in and in this case, it is just the single user. However, we may also decide that
    we want to abstract the data further and display only certain fields from the
    matched rows. This should be a simple task but it is complicated, as the number
    of fields will vary depending on how the login was executed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从显示输出中，我们现在可以看到我们只显示已登录的用户，这种情况下只有一个用户。然而，我们可能还决定要进一步抽象数据，并且只显示匹配行中的某些字段。这应该是一个简单的任务，但它很复杂，因为字段的数量将取决于登录的方式。
- en: Conditions based on the number of fields
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于字段数量的条件
- en: If a user logs onto the server's physical console directly rather than logging
    on through a remote or graphical pseudo-terminal, then the `lastlog` output will
    not display the host field. To demonstrate this, I have logged onto my CentOS
    host directly to the `tty1` console and avoided the GUI. The output from the previous
    awk control file shows that we now have the users **tux** and **bob**; **bob**
    though is lacking the host field as he is connected to a console.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果用户直接登录到服务器的物理控制台，而不是通过远程或图形伪终端登录，那么`lastlog`输出将不会显示主机字段。为了证明这一点，我直接登录到我的CentOS主机的`tty1`控制台，并避免了图形界面。之前awk控制文件的输出显示我们现在有用户**tux**和**bob**；然而**bob**缺少主机字段，因为他连接到控制台。
- en: '![Conditions based on the number of fields](img/00121.jpeg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![基于字段数量的条件](img/00121.jpeg)'
- en: Although in itself it's not an issue but it will be if we want to filter the
    fields and the two row's field numbers will vary where a field is omitted from
    some lines. For `lastlog` we will have `9` fields for most connections and only
    `8` fields for those that connect directly to the server console. The desire for
    the application is that we print the username and the date, but not the time of
    the last login. We will also print our own header in the `BEGIN` block. To ensure
    that we use the correct placements we will need to count the fields in each row
    using the `NF` internal variable.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这本身不是问题，但如果我们想要过滤字段，两行的字段编号将有所不同，因为某些行中省略了字段。对于`lastlog`，大多数连接将有`9`个字段，而直接连接到服务器控制台的连接只有`8`个字段。应用程序的要求是打印用户名和日期，但不打印最后登录的时间。我们还将在`BEGIN`块中打印我们自己的标题。为了确保我们使用正确的位置，我们需要使用`NF`内部变量来计算每行的字段数。
- en: 'For the `8` fields lines we want to print fields `1`, `4`, `5`, and `8`; for
    the longer lines with additional host information, we will use fields `1`, `5`,
    `6` and `9`. We will also use `printf` so that we can align the column data correctly.
    The control file should be edited, as shown in the following example:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有`8`个字段的行，我们想要打印字段`1`、`4`、`5`和`8`；对于有额外主机信息的较长行，我们将使用字段`1`、`5`、`6`和`9`。我们还将使用`printf`来正确对齐列数据。控制文件应该被编辑，如下例所示：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can see the command and the output it produces in the following screenshot.
    We can see how we can create a more suitable display based on information that
    we want to focus on:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在以下截图中看到命令和它产生的输出。我们可以看到如何基于我们想要关注的信息创建更合适的显示：
- en: '![Conditions based on the number of fields](img/00122.jpeg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![基于字段数量的条件](img/00122.jpeg)'
- en: If we look at the output, I have chosen to display the date before the month
    so we do not display the fields in the numeric order. This, of course, is a personal
    choice and customizable to suit the way you feel the data should be displayed.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们看一下输出，我选择在月份之前显示日期，这样我们就不按数字顺序显示字段。当然，这是个人选择，可以根据你认为数据应该如何显示进行自定义。
- en: We can use the principles of what we have seen in the `lastlog` control file
    with output from any command and you should practise with the commands that you
    want to filter the data from.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`lastlog`控制文件中所见原则的输出来过滤任何命令的输出，并且你应该练习使用你想要过滤数据的命令。
- en: Manipulating the awk record separator to report on XML data
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操纵awk记录分隔符以报告XML数据
- en: So far, while we have been working with awk we have limited ourselves to working
    with individual rows, with each new row representing a new record. Although this
    is often what we want, where we work with tagged data, such as XML where an individual
    record may span multiple lines. In this case, we may need to look at setting the
    `RS` or `record` separator internal variable.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，虽然我们一直在使用awk，但我们只限于处理单独的行，每一行代表一个新记录。虽然这通常是我们想要的，当我们处理带有标记数据的情况时，比如XML，其中一个单独的记录可能跨越多行。在这种情况下，我们可能需要设置`RS`或`record`分隔符内部变量。
- en: Apache Virtual Hosts
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache虚拟主机
- en: 'In [Chapter 9](part0060_split_000.html#1P71O2-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 9. Automating Apache Virtual Hosts"), *Automating Apache Virtual Hosts*
    we worked with **Apache Virtual Hosts**. This uses tagged data that defines the
    start and end of each Virtual Host. Even though we prefer to store each Virtual
    Host in their own file, they can be combined into a single file. Consider the
    following file that stores the possible Virtual Host definitions, this can be
    stored as the `virtualhost.conf` file, as shown:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](part0060_split_000.html#1P71O2-747571d9b4814e1dbffcdef2eb0dec8d "第9章。自动化Apache虚拟主机")中，*自动化Apache虚拟主机*，我们使用了**Apache虚拟主机**。这使用了定义每个虚拟主机的开始和结束的标记数据。即使我们更喜欢将每个虚拟主机存储在自己的文件中，它们也可以合并到单个文件中。考虑以下文件，它存储了可能的虚拟主机定义，可以存储为`virtualhost.conf`文件，如下所示：
- en: '[PRE5]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We have the three Virtual Hosts within a single file. Each record is separated
    by an empty line, meaning that we have two new line characters that logically
    separate each entry. We will explain this to awk by setting the `RS` variable
    as follows: `RS="\n\n"`. With this in place, we can then print the required Virtual
    Host record. This will be set in the `BEGIN` code block of the control file.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在单个文件中有三个虚拟主机。每个记录由一个空行分隔，这意味着我们有两个逻辑上分隔每个条目的新行字符。我们通过设置`RS`变量来告诉awk这一点：`RS="\n\n"`。有了这个设置，我们就可以打印所需的虚拟主机记录。这将在控制文件的`BEGIN`代码块中设置。
- en: 'We will also need to dynamically search the command line for the desired host
    configuration. We build this into the control file. The control file should look
    similar to the following code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要动态搜索命令行以获取所需的主机配置。我们将这构建到控制文件中。控制文件应该类似于以下代码：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The `BEGIN` block sets the variable and then we move onto the range. The range
    is set so that the record (`$0`) matches (`~`) the `search` variable. We must
    set the variable when `awk` is executed. The following command demonstrates the
    command line execution where the control file and configuration file are located
    within our working directory:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`BEGIN`块设置变量，然后我们进入范围。范围设置为记录(`$0`)匹配(`~`)`search`变量。我们必须在执行`awk`时设置变量。以下命令演示了命令行执行，控制文件和配置文件位于我们的工作目录中：'
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can see this more clearly by looking at the command and the output that
    is produced in the following screenshot:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看以下屏幕截图中生成的命令和输出，我们可以更清楚地看到这一点：
- en: '![Apache Virtual Hosts](img/00123.jpeg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![Apache虚拟主机](img/00123.jpeg)'
- en: XML catalog
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: XML目录
- en: 'We can extend this further into XML files where we may not want to display
    the complete record, but just certain fields. If we consider the following product
    `catalog`:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步扩展到XML文件，其中我们可能不想显示完整的记录，而只是某些字段。如果我们考虑以下产品`目录`：
- en: '[PRE8]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Logically, each record is delimited as before with the empty line. Each field
    though is a little more detailed and we need to use the delimiter as follows:
    `FS="[><]"`. We define either the opening or closing angle bracket as the field
    delimiter.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑上，每个记录都与之前的空行分隔。每个字段都更详细，我们需要使用分隔符`FS="[><]"`。我们将开头或结尾的尖括号定义为字段分隔符。
- en: 'To help analyze this, we can print a single record as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助分析这一点，我们可以打印单个记录如下：
- en: '[PRE9]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Each angle brace is a field separator, which means that we will have some empty
    fields. We could rewrite this line as a CSV file:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 每个尖括号都是一个字段分隔符，这意味着我们将有一些空字段。我们可以将这行重写为CSV文件：
- en: '[PRE10]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We just replace each angle bracket with a comma, in this way it is more easily
    read by us. We can see that the content of field `5` is the `top` value.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需用逗号替换每个尖括号，这样我们更容易阅读。我们可以看到字段`5`的内容是`top`值。
- en: Of course, we will not edit the XML file, we will leave it in the XML format.
    The conversion here is just to highlight how the field separators can be read.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们不会编辑XML文件，我们会保留它的XML格式。这里的转换只是为了突出字段分隔符的读取方式。
- en: 'The control file that we use to extract data from the XML file is illustrated
    in the following code example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用于从XML文件中提取数据的控制文件在以下代码示例中说明：
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Within the `BEGIN` code block, we set the `FS` and `RS` variables as we have
    discussed. We also set the `OFS` or **Output Field Separator** to a space. In
    this way, when we print the fields we separate the values with a space rather
    than leaving in the angle brackets. The ranch makes use of the same match as we
    used before when looking at the Virtual Hosts.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在`BEGIN`代码块中，我们设置了`FS`和`RS`变量，正如我们讨论过的。我们还将`OFS`或**输出字段分隔符**设置为一个空格。这样，当我们打印字段时，我们用空格分隔值，而不是保留尖括号。这个范围使用了与我们之前查看虚拟主机时使用的相同匹配。
- en: 'If we need to search for the product drill from within the `catalog` we can
    use the command laid out in the following example:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们需要在`目录`中搜索产品`drill`，我们可以使用以下示例中列出的命令：
- en: '[PRE12]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following screenshot shows the output in detail:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图详细显示了输出：
- en: '![XML catalog](img/00124.jpeg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![XML目录](img/00124.jpeg)'
- en: We have now been able to take a rather messy XML file and create readable reports
    from the catalog. The power of awk is highlighted again and for us, the last time
    within this book. By now, I hope you too can start to make use of this on a regular
    basis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经能够从一个相当混乱的XML文件中创建可读的报告。awk的强大再次得到了突出，并且对我们来说，这是本书中的最后一次。到目前为止，我希望你也能开始经常使用它。
- en: Summary
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We have had three Chapters where we have used awk. Starting with some basic
    usage statements in [Chapter 10](part0063_split_000.html#1S2JE1-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 10. Awk Fundamentals"), *Awk Fundamentals* where we became comfortable.
    Within [Chapter 11](part0069_split_000.html#21PMQ1-747571d9b4814e1dbffcdef2eb0dec8d
    "Chapter 11. Summarizing Logs with Awk"), *Summarizing Logs with Awk* and this
    chapter we started building our bespoke applications.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了三个章节，在这些章节中我们使用了awk。从[第10章](part0063_split_000.html#1S2JE1-747571d9b4814e1dbffcdef2eb0dec8d
    "第10章。Awk基础")开始，*Awk基础*，我们变得更加熟悉。在[第11章](part0069_split_000.html#21PMQ1-747571d9b4814e1dbffcdef2eb0dec8d
    "第11章。使用Awk总结日志")中，*使用Awk总结日志*以及这一章，我们开始构建我们定制的应用程序。
- en: Specifically, in this chapter we saw how we could create reports from the output
    of standard commands, such as `lastlog`. We saw that we could negate ranges and
    additionally make use of the `OR` statement. We then built the application that
    will allow us to query XML data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，在这一章中，我们看到了如何从标准命令的输出中创建报告，比如`lastlog`。我们看到我们可以否定范围，并且另外利用`OR`语句。然后我们构建了一个允许我们查询XML数据的应用程序。
- en: For the next two chapters, we will move away from the shell scripts and look
    at scripts using perl and Python so we can compare the scripting languages and
    make appropriate choices.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的两章中，我们将远离shell脚本，转而使用perl和Python编写脚本，这样我们可以比较脚本语言并做出适当的选择。
