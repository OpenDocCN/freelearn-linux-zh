- en: Kernel Synchronization - Part 2
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 内核同步-第2部分
- en: This chapter continues the discussion from the previous chapter, on the topic
    of kernel synchronization and dealing with concurrency within the kernel in general.
    I suggest that if you haven't already, first read the previous chapter, and then
    continue with this one.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章继续讨论上一章的话题，即内核同步和一般内核中处理并发的问题。我建议如果你还没有阅读上一章，那么先阅读上一章，然后再继续阅读这一章。
- en: 'Here, we shall continue our learning with respect to the vast topic of kernel synchronization
    and handling concurrency when in kernel space. As before, the material is targeted
    at kernel and/or device driver developers. In this chapter, we shall cover the
    following:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将继续学习有关内核同步和处理内核空间并发的广泛主题。与以往一样，这些材料针对内核和/或设备驱动程序开发人员。在本章中，我们将涵盖以下内容：
- en: Using the atomic_t and refcount_t interfaces
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用atomic_t和refcount_t接口
- en: Using the RMW atomic operators
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用RMW原子操作符
- en: Using the reader-writer spinlock
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用读写自旋锁
- en: Cache effects and false sharing
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存效应和伪共享
- en: Lock-free programming with per-CPU variables
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用每CPU变量的无锁编程
- en: Lock debugging within the kernel
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核内的锁调试
- en: Memory barriers – an introduction
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存屏障-简介
- en: Using the atomic_t and refcount_t interfaces
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用atomic_t和refcount_t接口
- en: 'In our simple demo misc character device driver program''s (`miscdrv_rdwr/miscdrv_rdwr.c`)
    `open` method (and elsewhere), we defined and manipulated two static global integers, `ga`
    and `gb`:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们简单的演示杂项字符设备驱动程序的`（miscdrv_rdwr/miscdrv_rdwr.c）`的`open`方法（以及其他地方），我们定义并操作了两个静态全局整数`ga`和`gb`：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'By now, it should be obvious to you that this – the place where we operate
    on these integers – is a potential bug if left as is: it''s shared writable data
    (in a shared state) and therefore *a critical section, thus requiring protection
    against* *concurrent access*. You get it; so, we progressively improved upon this.
    In the previous chapter, understanding the issue, in our `ch12/1_miscdrv_rdwr_mutexlock/1_miscdrv_rdwr_mutexlock.c`
    program, we first used a *mutex lock* to protect the critical section. Later,
    you learned that using a *spinlock* to protect non-blocking critical sections
    such as this one would be (far) superior to using a mutex in terms of performance;
    so, in our next driver, `ch12/2_miscdrv_rdwr_spinlock/2_miscdrv_rdwr_spinlock.c`,
    we used a spinlock instead:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该明显意识到，我们操作这些整数的地方是一个潜在的错误，如果保持原样：它是共享的可写数据（在共享状态下），因此*是一个关键部分，因此需要保护*
    *并发访问*。你明白了；因此，我们逐步改进了这一点。在上一章中，我们的`ch12/1_miscdrv_rdwr_mutexlock/1_miscdrv_rdwr_mutexlock.c`程序中，首先使用*互斥锁*来保护关键部分。后来，您了解到，使用*自旋锁*来保护非阻塞关键部分，例如这个，从性能上来说会（远远）优于使用互斥锁；因此，在我们的下一个驱动程序`ch12/2_miscdrv_rdwr_spinlock/2_miscdrv_rdwr_spinlock.c`中，我们使用了自旋锁：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: That's good, but we can do better still! Operating upon global integers turns
    out to be such a common occurrence within the kernel (think of reference or resource
    counters getting incremented and decremented, and so on) that the kernel provides
    a class of operators called the **refcount** and **atomic integer operators**
    or interfaces; these are very specifically designed to atomically (safely and
    indivisibly) operate on **only integers**.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但我们仍然可以做得更好！原来在内核中操作全局整数是如此普遍（考虑引用或资源计数器的增加和减少等），以至于内核提供了一类操作符称为**refcount**和**原子整数操作符**或接口；这些操作符专门设计用于原子地（安全和不可分割地）操作**只有整数**。
- en: The newer refcount_t versus older atomic_t interfaces
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 新的refcount_t与旧的atomic_t接口
- en: 'At the outset of this topic area, it''s important to mention this: from the
    4.11 kernel, there is a newer and better set of interfaces christened the `refcount_t` APIs,
    meant for a kernel space object''s reference counters. It greatly improves the
    security posture of the kernel (via much-improved **Integer OverFlow** (**IoF**) and
    **Use After Free **(**UAF**) protection as well as memory ordering guarantees,
    which the older `atomic_t` APIs lack). The `refcount_t` interfaces, like several
    other security technologies used on Linux, have their origins in work done by
    The PaX Team – [https://pax.grsecurity.net/](https://pax.grsecurity.net/) (it
    was called `PAX_REFCOUNT`).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个话题领域的开始，重要的是要提到这一点：从4.11内核开始，有一个新的更好的接口集被命名为`refcount_t`接口，用于内核空间对象的引用计数。它极大地改善了内核的安全性（通过大大改进的**整数溢出**（**IoF**）和**使用后释放**（**UAF**）保护以及内存排序保证，而旧的`atomic_t`接口缺乏）。`refcount_t`接口，就像Linux上使用的其他几种安全技术一样，起源于The
    PaX Team的工作- [https://pax.grsecurity.net/](https://pax.grsecurity.net/)（它被称为`PAX_REFCOUNT`）。
- en: Having said that, the reality is that (as of the time of writing) the older
    `atomic_t` interfaces are still very much in use within the kernel core and drivers
    (they are slowly being converted, with the older `atomic_t` interfaces being moved
    to the newer `refcount_t` model and the API set). Thus, in this topic, we cover
    both, pointing out differences and mentioning which `refcount_t` API supersedes
    an `atomic_t` API wherever applicable. Think of the `refcount_t` interfaces as
    a variant of the (older) `atomic_t` interfaces, which are specialized toward reference
    counting.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，现实情况是（截至撰写本文时），旧的`atomic_t`接口在内核核心和驱动程序中仍然被广泛使用（它们正在逐渐转换，旧的`atomic_t`接口正在移动到新的`refcount_t`模型和API集）。因此，在这个话题中，我们同时涵盖了两者，指出差异，并提到哪些`refcount_t`
    API在适用的地方取代了`atomic_t` API。将`refcount_t`接口视为（旧的）`atomic_t`接口的一种变体，专门用于引用计数。
- en: 'A key difference between the `atomic_t` operators and the `refcount_t` ones
    is that the former works upon signed integers whereas the latter is essentially
    designed to work upon only an `unsigned int` quantity; more specifically, and
    this is important, it works only within a strictly specified range: `1` to **`UINT_MAX-1` **(or
    `[1..INT_MAX]` when `!CONFIG_REFCOUNT_FULL`). The kernel has a config option named
    `CONFIG_REFCOUNT_FULL`; if set, it performs a (slower and more thorough) "full"
    reference count validation. This is beneficial for security but can result in
    slightly degraded performance (the typical default is to keep this config turned
    off; it''s the case with our x86_64 Ubuntu guest).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`atomic_t`操作符和`refcount_t`操作符之间的一个关键区别是前者适用于有符号整数，而后者基本上设计为仅适用于`unsigned int`数量；更具体地说，这很重要，它仅在严格指定的范围内工作：`1`到**`UINT_MAX-1`**（或`[1..INT_MAX]`当`!CONFIG_REFCOUNT_FULL`）。内核有一个名为`CONFIG_REFCOUNT_FULL`的配置选项；如果设置，它将执行（更慢和更彻底的）"完整"引用计数验证。这对安全性有益，但可能会导致性能略有下降（典型的默认情况是保持此配置关闭；这是我们的x86_64
    Ubuntu客户机的情况）。'
- en: Attempting to set a `refcount_t` variable to `0` or negative, or to `[U]INT_MAX` or
    above, is impossible; this is good for preventing integer underflow/overflow issues
    and thus preventing the use-after-free class bug in many cases! (Well, it's not
    impossible; it results in a (noisy) warning being fired via the `WARN()` macro.)
    Think about it, `refcount_t` variables are meant to be used *only for kernel object
    reference counting, nothing else*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 试图将`refcount_t`变量设置为`0`或负数，或设置为`[U]INT_MAX`或更高，是不可能的；这有助于防止整数下溢/上溢问题，从而在许多情况下防止使用后释放类错误！（好吧，这不是不可能的；它会通过`WARN()`宏触发（吵闹的）警告。）想一想，`refcount_t`变量只能用于内核对象引用计数，什么都不能用。
- en: Thus, this is indeed the required behavior; the reference counter must start
    at a positive value (typically `1` when the object is newly instantiated), is
    incremented (or added to) whenever the code gets or takes a reference, and is
    decremented (or subtracted from) whenever the code puts or leaves a reference
    on the object. You are expected to carefully manipulate the reference counter
    (matching your gets and puts), always keeping its value within the legal range.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这确实是所需的行为；引用计数器必须从一个正值开始（通常是`1`，当对象新实例化时），每当代码获取或获取引用时，它会增加（或添加到），并且每当代码放置或离开对象上的引用时，它会减少（或减去）。您应该仔细操作引用计数器（匹配您的获取和放置），始终保持其值在合法范围内。
- en: 'Quite non-intuitively, at least for the generic arch-independent refcount implementation,
    the `refcount_t` APIs are internally implemented over the `atomic_t` API set.
    For example, the `refcount_set()` API – which atomically sets a refcount''s value
    to the parameter passed – is implemented like this within the kernel:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 相当令人费解的是，至少对于通用的与体系结构无关的refcount实现来说，`refcount_t` API是在`atomic_t` API集上内部实现的。例如，`refcount_set()`
    API - 用于将引用计数的值原子设置为传递的参数 - 在内核中是这样实现的：
- en: '[PRE2]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'It''s a thin wrapper over `atomic_set()` (which we will cover very shortly).
    The obvious FAQ here is: why use the refcount API at all? There are a few reasons:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是对`atomic_set()`的薄包装（我们很快会介绍）。这里的明显常见问题是：为什么要使用refcount API？有几个原因：
- en: 'The counter saturates at the `REFCOUNT_SATURATED` value (which is set to `UINT_MAX` by
    default) and will not budge once there. This is critical: it avoids wrapping the
    counter, which could cause weird and spurious UAF bugs; this is even considered
    as a key security fix ([https://kernsec.org/wiki/index.php/Kernel_Protections/refcount_t](https://kernsec.org/wiki/index.php/Kernel_Protections/refcount_t)).'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计数器在`REFCOUNT_SATURATED`值（默认设置为`UINT_MAX`）处饱和，并且一旦到达那里就不会再移动。这很关键：它避免了计数器的包装，这可能会导致奇怪和偶发的UAF错误；这甚至被认为是一个关键的安全修复（[https://kernsec.org/wiki/index.php/Kernel_Protections/refcount_t](https://kernsec.org/wiki/index.php/Kernel_Protections/refcount_t)）。
- en: Several of the newer refcount APIs do provide **memory ordering** guarantees;
    in particular the `refcount_t` APIs – as compared to their older `atomic_t` cousins
    – and the memory ordering guarantees they provide are clearly documented at [https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t](https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t) (do
    have a look if you're interested in the low-level details).
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些较新的refcount API确实提供**内存排序**保证；特别是`refcount_t` API - 与其较老的`atomic_t`表亲相比 -
    以及它们提供的内存排序保证在[https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t](https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t)中有清楚的文档（如果您对底层细节感兴趣，请查看）。
- en: Also, realize that arch-dependent refcount implementations (when they exist;
    for example, x86 does have it, while ARM doesn't) can differ from the previously-mentioned
    generic one.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，要意识到与先前提到的通用实现不同，依赖于体系结构的refcount实现可能会有所不同（如果存在的话；例如，x86有，而ARM没有）。
- en: 'What exactly is *memory ordering* and how does it affect us? The fact is, it''s
    a complex topic and, unfortunately, the inner details on this are beyond the scope
    of this book. It''s worth knowing the basics: I suggest you read up on the **Linux-Kernel
    Memory Model** (**LKMM**), which includes coverage on processor memory ordering
    and more. We refer you to good documentation on this here: *Explanation of the
    Linux-Kernel Memory Model* ([https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/explanation.txt](https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/explanation.txt)).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '*内存排序*到底是什么，它如何影响我们？事实上，这是一个复杂的话题，不幸的是，关于这一点的内部细节超出了本书的范围。了解基础知识是值得的：我建议您阅读**Linux-Kernel
    Memory Model**（**LKMM**），其中包括处理器内存排序等内容。我们在这里为您提供了关于这方面的良好文档：*Linux-Kernel Memory
    Model解释*（[https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/explanation.txt](https://github.com/torvalds/linux/blob/master/tools/memory-model/Documentation/explanation.txt)）。'
- en: The simpler atomic_t and refcount_t interfaces
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更简单的atomic_t和refcount_t接口
- en: Regarding the `atomic_t` interfaces, we should mention that all the following
    `atomic_t` constructs are for 32-bit integers only; of course, with 64-bit integers
    now being commonplace, 64-bit atomic integer operators are available as well.
    Typically, they are semantically identical to their 32-bit counterparts with the
    difference being in the name (`atomic_foo()` becomes `atomic64_foo()`). So the
    primary data type for 64-bit atomic integers is called `atomic64_t` (AKA `atomic_long_t`).
    The `refcount_t` interfaces, on the other hand, cater to both 32 and 64-bit integers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 关于`atomic_t`接口，我们应该提到所有以下`atomic_t`构造仅适用于32位整数；当然，现在64位整数已经很常见，64位原子整数操作符也是可用的。它们通常在语义上与它们的32位对应物相同，不同之处在于名称（`atomic_foo()`变成`atomic64_foo()`）。因此，64位原子整数的主要数据类型称为`atomic64_t`（又名`atomic_long_t`）。另一方面，`refcount_t`接口适用于32位和64位整数。
- en: 'The following table shows how to declare and initialize an `atomic_t` and `refcount_t`
    variable, side by side so that you can compare and contrast them:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格显示了如何并排声明和初始化`atomic_t`和`refcount_t`变量，以便您可以进行比较和对比：
- en: '|  | **(Older) atomic_t (32-bit only)** | **(Newer) refcount_t (both 32- and
    64-bit)** |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| **（旧的）atomic_t（仅限32位）** | **（新的）refcount_t（32位和64位）** |'
- en: '| Header file to include | `<linux/atomic.h>` | `<linux/refcount.h>` |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: 要包含的头文件 | `<linux/atomic.h>` | `<linux/refcount.h>`
- en: '| Declare and initialize a variable | `static atomic_t gb = ATOMIC_INIT(1);`
    | `static refcount_t gb = REFCOUNT_INIT(1);` |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: 声明和初始化一个变量 | `static atomic_t gb = ATOMIC_INIT(1);` | `static refcount_t gb
    = REFCOUNT_INIT(1);`
- en: 'Table 17.1 – The older atomic_t versus the newer refcount_t interfaces for
    reference counting: header and init'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.1 - 旧的atomic_t与新的refcount_t接口用于引用计数：头文件和初始化
- en: 'The complete set of all the `atomic_t` and `refcount_t` APIs available within
    the kernel is pretty large; to help keep things simple and clear in this section,
    we only list some of the more commonly used (atomic 32-bit) and `refcount_t` interfaces
    in the following table (they operate upon a generic `atomic_t` or `refcount_t`
    variable, `v`):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '内核中可用的所有`atomic_t`和`refcount_t`API的完整集合非常庞大；为了在本节中保持简单和清晰，我们只列出了一些更常用的（32位原子）和`refcount_t`接口（它们操作于通用的`atomic_t`或`refcount_t`变量`v`）： '
- en: '| **Operation** | **(Older) atomic_t interface** | **(Newer) refcount_t interface
    [range: 0 to [U]INT_MAX]** |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '**操作** | **（旧的）atomic_t接口** | **（新的）refcount_t接口[范围：0到[U]INT_MAX]** |'
- en: '| Header file to include | `<linux/atomic.h>` | `<linux/refcount.h>` |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: 要包含的头文件 | `<linux/atomic.h>` | `<linux/refcount.h>` |
- en: '| Declare and initialize a variable | `static atomic_t v = ATOMIC_INIT(1);`
    | `static refcount_t v = REFCOUNT_INIT(1);` |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: 声明和初始化一个变量 | `static atomic_t v = ATOMIC_INIT(1);` | `static refcount_t v =
    REFCOUNT_INIT(1);` |
- en: '| Atomically read the current value of `v` | `int atomic_read(atomic_t *v)`
    | `unsigned int refcount_read(const refcount_t *v)` |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: 原子性地读取`v`的当前值 | `int atomic_read(atomic_t *v)` | `unsigned int refcount_read(const
    refcount_t *v)`
- en: '| Atomically set `v` to the value `i` | `void atomic_set(atomic_t *v, i)` |
    `void refcount_set(refcount_t *v, int i)` |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: 原子性地将`v`设置为值`i` | `void atomic_set(atomic_t *v, i)` | `void refcount_set(refcount_t
    *v, int i)`
- en: '| Atomically increment the `v` value by `1`  | `void atomic_inc(atomic_t *v)`
    | `void refcount_inc(refcount_t *v)` |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '原子性地将`v`值增加`1` | `void atomic_inc(atomic_t *v)` | `void refcount_inc(refcount_t
    *v)` '
- en: '| Atomically decrement the `v` value by `1`  | `void atomic_dec(atomic_t *v)`
    | `void refcount_dec(refcount_t *v)` |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: 原子性地将`v`的值减少`1` | `void atomic_dec(atomic_t *v)` | `void refcount_dec(refcount_t
    *v)`
- en: '| Atomically add the value of `i` to `v` | `void atomic_add(i, atomic_t *v)`
    | `void refcount_add(int i, refcount_t *v)` |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: 原子性地将`i`的值添加到`v` | `void atomic_add(i, atomic_t *v)` | `void refcount_add(int
    i, refcount_t *v)`
- en: '| Atomically subtract the value of `i` from `v` | `void atomic_sub(i, atomic_t
    *v)` | `void refcount_sub(int i, refcount_t *v)` |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: 原子性地从`v`中减去`i`的值 | `void atomic_sub(i, atomic_t *v)` | `void refcount_sub(int
    i, refcount_t *v)`
- en: '| Atomically add the value of `i` to `v` and return the result | `int atomic_add_return(i,
    atomic_t *v)` | `bool refcount_add_not_zero(int i, refcount_t *v)` (not a precise
    match; adds `i` to `v` unless it''s `0`.) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: 原子性地将`i`的值添加到`v`并返回结果 | `int atomic_add_return(i, atomic_t *v)` | `bool refcount_add_not_zero(int
    i, refcount_t *v)`（不是精确匹配；将`i`添加到`v`，除非它是`0`。）
- en: '| Atomically subtract the value of `i` from `v` and return the result | `int
    atomic_sub_return(i, atomic_t *v)` | `bool refcount_sub_and_test(int i, refcount_t
    *r)` (not a precise match; subtracts `i` from `v` and tests; returns `true` if
    resulting refcount is `0`, else `false`.) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: 原子性地从`v`中减去`i`的值并返回结果 | `int atomic_sub_return(i, atomic_t *v)` | `bool refcount_sub_and_test(int
    i, refcount_t *r)`（不是精确匹配；从`v`中减去`i`并测试；如果结果的引用计数为`0`，则返回`true`，否则返回`false`。）
- en: 'Table 17.2 – The older atomic_t versus the newer refcount_t interfaces for
    reference counting: APIs'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.2 - 旧的atomic_t与新的refcount_t接口用于引用计数：API
- en: You've now seen several `atomic_t` and `refcount_t` macros and APIs; let's quickly
    check out a few examples of their usage in the kernel.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到了几个`atomic_t`和`refcount_t`宏和API；让我们快速检查一下它们在内核中的使用示例。
- en: Examples of using refcount_t within the kernel code base
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在内核代码库中使用refcount_t的示例
- en: 'In one of our demo kernel modules regarding kernel threads (in `ch15/kthread_simple/kthread_simple.c`),
    we created a kernel thread and then employed the `get_task_struct()` inline function
    to mark the kernel thread''s task structure as being in use. As you can now guess,
    the `get_task_struct()` routine increments the task structure''s reference counter
    – a `refcount_t` variable named `usage` – via the `refcount_inc()` API:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们关于内核线程的演示内核模块中（在`ch15/kthread_simple/kthread_simple.c`），我们创建了一个内核线程，然后使用`get_task_struct()`内联函数来标记内核线程的任务结构正在使用中。正如您现在猜到的那样，`get_task_struct()`例程通过`refcount_inc()`API增加任务结构的引用计数器——一个名为`usage`的`refcount_t`变量：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The converse routine, `put_task_struct()`, performs the subsequent decrement
    on the reference counter. The actual routine employed by it internally, `refcount_dec_and_test()`,
    tests whether the new refcount value has dropped to `0`; if so, it returns `true`,
    and if this is the case, it implies that the task structure isn''t being referenced
    by anyone. The call to `__put_task_struct()` frees it up:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 相反的例程`put_task_struct()`对引用计数执行后续减量。它内部使用的实际例程`refcount_dec_and_test()`测试新的refcount值是否已经降至`0`；如果是，则返回`true`，如果是这种情况，则意味着任务结构没有被任何人引用。对`__put_task_struct()`的调用将其释放：
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Another example of the refcounting APIs in use within the kernel is found in
    `kernel/user.c` (which helps track the number of processes, files, and so on that
    a user has claimed via a per-user structure):'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 内核中另一个使用refcounting API的示例可以在`kernel/user.c`中找到（它有助于跟踪用户通过每个用户结构声明的进程、文件等的数量）：
- en: '![](img/52aff2e3-0b4e-4e2c-a5ff-a71048b50e91.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/52aff2e3-0b4e-4e2c-a5ff-a71048b50e91.png)'
- en: Figure 7.1 – Screenshot showing the usage of the refcount_t interfaces in kernel/user.c
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1 - 屏幕截图显示内核/user.c中refcount_t接口的使用
- en: Look up the `refcount_t` API interface documentation ([https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting](https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting));
    `refcount_dec_and_lock_irqsave()` returns `true` and withholds the spinlock with
    interrupts disabled if able to decrement the reference counter to `0`, and `false`
    otherwise.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 查阅`refcount_t` API接口文档（[https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting](https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting)）；`refcount_dec_and_lock_irqsave()`返回`true`，如果能够将引用计数减少到`0`，则在禁用中断的情况下保留自旋锁，否则返回`false`。
- en: As an exercise for you, convert our earlier `ch16/2_miscdrv_rdwr_spinlock/miscdrv_rdwr_spinlock.c` driver
    code to use refcount; it has the integers `ga` and `gb`, which, when being read
    or written, were protected via a spinlock. Now, make them refcount variables and
    use the appropriate `refcount_t` APIs when working on them.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 作为练习，将我们之前的`ch16/2_miscdrv_rdwr_spinlock/miscdrv_rdwr_spinlock.c`驱动程序代码转换为使用refcount；它具有整数`ga`和`gb`，在读取或写入时，通过自旋锁进行保护。现在，将它们变成refcount变量，并在处理它们时使用适当的`refcount_t`
    API。
- en: 'Careful! Don''t allow their values to go out of the allowed range, `[0..[U]INT_MAX]`!
    (Recall that the range is `[1..UINT_MAX-1]` for full refcount validation (`CONFIG_REFCOUNT_FULL`
    being on) and `[1..INT_MAX]` when it''s not full validation (the default)).Doing
    so typically leads to the `WARN()` macro being invoked (the code for this demo
    seen in *Figure 7.1* isn''t included in our GitHub repository):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 小心！不要让它们的值超出允许的范围，`[0..[U]INT_MAX]`！（请记住，当完整的refcount验证（`CONFIG_REFCOUNT_FULL`打开）时，范围为`[1..UINT_MAX-1]`，当不是完整验证（默认）时，范围为`[1..INT_MAX]`）。这样做通常会导致调用`WARN（）`宏（此演示中的代码在我们的GitHub存储库中未包含，*图7.1*中可见）：
- en: '![](img/24843ce0-e46c-41a2-bf1d-8c467aea70a3.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![](img/24843ce0-e46c-41a2-bf1d-8c467aea70a3.png)'
- en: Figure 7.2 – (Partial) screenshot showing the WARN() macro firing when we wrongly
    attempt to set a refcount_t variable to <= 0
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 - （部分）屏幕截图显示当我们错误地尝试将refcount_t变量设置为<= 0时，WARN（）宏触发
- en: The kernel has an interesting and useful test infrastructure called the **Linux
    Kernel Dump Test Module** (**LKDTM**); see `drivers/misc/lkdtm/refcount.c` for
    many test cases being run on the refcount interfaces, which you can learn from...
    FYI, you can also use LKDTM via the kernel's fault injection framework to test
    and evaluate the kernel's reaction to faulty scenarios (see the documentation
    here: *Provoking crashes with Linux Kernel Dump Test Module (LKDTM)* – [https://www.kernel.org/doc/html/latest/fault-injection/provoke-crashes.html#provoking-crashes-with-linux-kernel-dump-test-module-lkdtm](https://www.kernel.org/doc/html/latest/fault-injection/provoke-crashes.html#provoking-crashes-with-linux-kernel-dump-test-module-lkdtm)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 内核有一个有趣且有用的测试基础设施，称为**Linux内核转储测试模块**（**LKDTM**）；请参阅`drivers/misc/lkdtm/refcount.c`，了解在refcount接口上运行的许多测试用例，您可以从中学习...另外，您还可以通过内核的故障注入框架使用LKDTM来测试和评估内核对故障情况的反应（请参阅此处的文档：*使用Linux内核转储测试模块（LKDTM）引发崩溃*
    - [https://www.kernel.org/doc/html/latest/fault-injection/provoke-crashes.html#provoking-crashes-with-linux-kernel-dump-test-module-lkdtm](https://www.kernel.org/doc/html/latest/fault-injection/provoke-crashes.html#provoking-crashes-with-linux-kernel-dump-test-module-lkdtm)）。
- en: The atomic interfaces covered so far all operate on 32-bit integers; what about
    on 64-bit? That's what follows.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所有涵盖的原子接口都是针对32位整数进行操作的；那么64位整数呢？接下来就是。
- en: 64-bit atomic integer operators
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 64位原子整数运算符
- en: 'As mentioned at the start of this topic, the set of `atomic_t` integer operators
    we have dealt with so far all operate on traditional 32-bit integers (this discussion
    doesn''t apply to the newer `refcount_t` interfaces; they anyway operate upon
    both 32 and 64-bit quantities). Obviously, with 64-bit systems becoming the norm
    rather than the exception nowadays, the kernel community provides an identical
    set of atomic integer operators for 64-bit integers. The difference is as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本主题开头提到的，我们迄今为止处理的`atomic_t`整数运算符都是针对传统的32位整数进行操作的（这个讨论不适用于较新的`refcount_t`接口；它们无论如何都是针对32位和64位数量进行操作的）。显然，随着64位系统成为现在的常态而不是例外，内核社区为64位整数提供了一套相同的原子整数运算符。区别如下：
- en: Declare the 64-bit atomic integer as a variable of type `atomic64_t` (that is, `atomic_long_t`).
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将64位原子整数声明为`atomic64_t`类型的变量（即`atomic_long_t`）。
- en: For all operators, in place of the `atomic_` prefix, use the `atomic64_` prefix.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于所有运算符，使用`atomic64_`前缀代替`atomic_`前缀。
- en: 'So, take the following examples:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，采用以下示例：
- en: In place of `ATOMIC_INIT()`, use `ATOMIC64_INIT()`.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`ATOMIC64_INIT()`代替`ATOMIC_INIT()`。
- en: In place of `atomic_read()`, use `atomic64_read()`.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`atomic64_read()`代替`atomic_read()`。
- en: In place of `atomic64_dec_if_positive()`, use `atomic64_dec_if_positive()`.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`atomic64_dec_if_positive()`代替`atomic64_dec_if_positive()`。
- en: 'Recent C and C++ language standards – C11 and C++11 – provide an atomic operations
    library that helps developers implement atomicity in an easier fashion due to
    the implicit language support; we won''t delve into this aspect here. A reference
    can be found here (C11 also has pretty much the same equivalents): [https://en.cppreference.com/w/c/atomic](https://en.cppreference.com/w/c/atomic).'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的C和C++语言标准 - C11和C++11 - 提供了一个原子操作库，帮助开发人员实现原子性更容易，因为它有隐式的语言支持；我们不会在这里深入讨论这个方面。可以在这里找到参考（C11也有几乎相同的等价物）：[https://en.cppreference.com/w/c/atomic](https://en.cppreference.com/w/c/atomic)。
- en: Note that all these routines – both the 32- and 64-bit atomic ​`_operators` –
    are **arch-independent**. A key point worth repeating is that any and all operations
    performed upon an atomic integer must be done by declaring the variable as `atomic_t`
    and via the methods provided. This includes initialization and even a (integer)
    read operation.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所有这些例程 - 32位和64位的原子`_operators` - 都是**与架构无关**的。值得重申的关键一点是，对原子整数进行的任何操作都必须通过将变量声明为`atomic_t`并通过提供的方法来完成。这包括初始化甚至（整数）读取操作。
- en: 'In terms of internal implementation, a `foo()` atomic integer operator is typically
    a macro that becomes an inline function, which in turn invokes the arch-specific `arch_foo()` function. As
    usual, glancing through the official kernel documentation on atomic operators
    is always a good idea (within the kernel source tree, it''s here: `Documentation/atomic_t.txt`;
    go to [https://www.kernel.org/doc/Documentation/atomic_t.txt](https://www.kernel.org/doc/Documentation/atomic_t.txt)).
    It neatly categorizes the numerous atomic integer APIs into distinct sets. FYI,
    arch-specific *memory ordering issues* do affect the internal implementation.
    Here, we won''t delve into the internals. If interested, refer to this page on
    the official kernel documentation site at [https://www.kernel.org/doc/html/v4.16/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t](https://www.kernel.org/doc/html/v4.16/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t)
    (also, details on memory ordering go beyond the scope of this book; check out
    the kernel documentation at [https://www.kernel.org/doc/Documentation/memory-barriers.txt](https://www.kernel.org/doc/Documentation/memory-barriers.txt) for
    more on this).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 就内部实现而言，`foo()`原子整数操作通常是一个宏，变成内联函数，然后调用特定架构的`arch_foo()`函数。通常情况下，浏览官方内核文档中的原子操作符总是一个好主意（在内核源树中，它在这里：`Documentation/atomic_t.txt`；访问[https://www.kernel.org/doc/Documentation/atomic_t.txt](https://www.kernel.org/doc/Documentation/atomic_t.txt)）。它将众多原子整数API整齐地分类为不同的集合。值得一提的是，特定架构的*内存排序问题*会影响内部实现。在这里，我们不会深入探讨内部情况。如果感兴趣，请参考官方内核文档网站上的这个页面[https://www.kernel.org/doc/html/v4.16/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t](https://www.kernel.org/doc/html/v4.16/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t)（此外，关于内存排序的细节超出了本书的范围；请查看内核文档[https://www.kernel.org/doc/Documentation/memory-barriers.txt](https://www.kernel.org/doc/Documentation/memory-barriers.txt)了解更多）。
- en: 'We haven''t attempted to show all the atomic and refcount APIs here (it''s
    really not necessary); the official kernel documentation covers it:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有尝试在这里展示所有原子和引用计数API（这真的不必要）；官方内核文档涵盖了它：
- en: '`atomic_t` interfaces:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`atomic_t`接口：'
- en: S*emantics and Behavior of Atomic and Bitmask Operations* ([https://www.kernel.org/doc/html/v5.4/core-api/atomic_ops.html#semantics-and-behavior-of-atomic-and-bitmask-operations](https://www.kernel.org/doc/html/v5.4/core-api/atomic_ops.html#semantics-and-behavior-of-atomic-and-bitmask-operations))
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*原子和位掩码操作的语义和行为*（[https://www.kernel.org/doc/html/v5.4/core-api/atomic_ops.html#semantics-and-behavior-of-atomic-and-bitmask-operations](https://www.kernel.org/doc/html/v5.4/core-api/atomic_ops.html#semantics-and-behavior-of-atomic-and-bitmask-operations)）'
- en: API ref: Atomics ([https://www.kernel.org/doc/html/latest/driver-api/basics.html#atomics](https://www.kernel.org/doc/html/latest/driver-api/basics.html#atomics))
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API参考：原子操作（[https://www.kernel.org/doc/html/latest/driver-api/basics.html#atomics](https://www.kernel.org/doc/html/latest/driver-api/basics.html#atomics)）
- en: '(Newer) `refcount_t` interfaces for kernel object reference counting:'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （更新的）用于内核对象引用计数的`refcount_t`接口：
- en: '`refcount_t` API compared to `atomic_t` ([https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t](https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t))'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`refcount_t` API与`atomic_t` API的比较（[https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t](https://www.kernel.org/doc/html/latest/core-api/refcount-vs-atomic.html#refcount-t-api-compared-to-atomic-t)）'
- en: API ref: Reference counting ([https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting](https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting))
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: API参考：引用计数（[https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting](https://www.kernel.org/doc/html/latest/driver-api/basics.html#reference-counting)）
- en: Let's move on to the usage of a typical construct when working on drivers –
    **Read Modify Write** (**RMW**). Read on!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论在驱动程序上工作时使用的典型构造 - **读取修改写入**（**RMW**）。继续阅读！
- en: Using the RMW atomic operators
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用RMW原子操作符
- en: A more advanced set of atomic operators called the RMW APIs is available as
    well. Among its many uses (we show a list in the coming section) is that of performing
    atomic RMW operations on bits, in other words, performing bitwise operations atomically
    (safely, indivisibly). As a device driver author operating upon device or peripheral
    *registers*, this is indeed something you will find yourself using.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一组更高级的原子操作符称为RMW API也可用。在其许多用途中（我们将在接下来的部分中列出），是对位进行原子RMW操作，换句话说，安全地、不可分割地执行位操作。作为操作设备或外围*寄存器*的设备驱动程序作者，这确实是您将发现自己使用的东西。
- en: The material in this section assumes you have at least a basic understanding
    of accessing peripheral device (chip) memory and registers; we have covered this
    in detail in [Chapter 3](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml), *Working
    with Hardware I/O Memory*. Please ensure you understand it before moving further.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的材料假定您至少具有基本的访问外围设备（芯片）内存和寄存器的理解；我们在[第3章](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml)中详细介绍了这一点，请确保在继续之前理解它。
- en: 'Very often, you''ll need to perform bit operations (with the bitwise `AND &` and
    bitwise `OR |` being the most commonplace operators) on registers; this is done
    to modify its value, setting and/or clearing some bits within it. The thing is,
    merely performing some C manipulation to query or set device registers isn''t
    quite enough. No, sir: don''t forget about concurrency issues! Read on for the
    full story.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 经常需要对寄存器进行位操作（使用按位`AND &`和按位`OR |`是最常见的操作符），这是为了修改它的值，设置和/或清除其中的一些位。问题是，仅仅进行一些C操作来查询或设置设备寄存器是不够的。不，先生：不要忘记并发问题！继续阅读完整的故事。
- en: RMW atomic operations – operating on device registers
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RMW原子操作——对设备寄存器进行操作
- en: 'Let''s quickly go over some basics first: a byte consists of 8 bits, numbered
    from bit `0`, the **Least Significant Bit** (**LSB**), to bit `7`, the **Most
    Significant Bit** (**MSB**). (This is actually formally defined as the `BITS_PER_BYTE` macro in
    `include/linux/bits.h`, along with a few other interesting definitions.)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先快速复习一些基础知识：一个字节由8位组成，从位`0`，即**最低有效位**（**LSB**），到位`7`，即**最高有效位**（**MSB**）。（这实际上在`include/linux/bits.h`中以`BITS_PER_BYTE`宏的形式正式定义，还有一些其他有趣的定义。）
- en: A **register** is basically a small piece of memory within the peripheral device;
    typically, its size, the register bit width, is one of 8, 16, or 32 bits. The
    device registers provide control, status, and other information and are often
    programmable. This, in fact, is largely what you as a driver author will do –
    program the device registers appropriately to make the device do something, and
    query it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**寄存器**基本上是外围设备中的一个小片内存；通常，它的大小，寄存器位宽，是8、16或32位之一。设备寄存器提供控制、状态和其他信息，并且通常是可编程的。实际上，这在很大程度上是你作为驱动程序作者要做的事情——适当地编程设备寄存器以使设备执行某些操作，并查询它。
- en: 'To flesh out this discussion, let''s consider a hypothetical device that has
    two registers: a status register and a control register, each 8 bits wide. (In
    the real world, every device or chip has a *datasheet* that will provide a detailed
    specification of the chip and register-level hardware; this becomes an essential
    document for the driver author). Hardware folks usually design devices in such
    a way that several registers are sequentially clubbed together in a larger piece
    of memory; this is called register banking. By having the base address of the
    first register and the offset to each following one, it becomes easy to address any
    given register (here, we won''t delve into how exactly registers are "mapped"
    into the virtual address space on an OS such as Linux). For example, the (purely
    hypothetical) registers may be described like this in a header file:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充实这个讨论，让我们考虑一个假设的设备，它有两个寄存器：一个状态寄存器和一个控制寄存器，每个寄存器宽度为8位。（在现实世界中，每个设备或芯片都有一个*数据表*，其中提供了芯片和寄存器级硬件的详细规格；这对于驱动程序作者来说是一个必不可少的文档）。硬件人员通常设计设备的方式是将几个寄存器顺序地组合在一个更大的内存块中；这称为寄存器银行。通过拥有第一个寄存器的基地址和每个后续寄存器的偏移量，可以很容易地寻址任何给定的寄存器（在这里，我们不会深入探讨在诸如Linux等操作系统上寄存器如何被“映射”到虚拟地址空间）。例如，在头文件中可能像这样描述（纯粹是假设的）寄存器：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, say that in order to turn on our fictional device, the datasheet informs
    us we can do so by setting bit `7` (the MSB) of the control register to `1`. As
    every driver author quickly learns, there is a hallowed sequence for modifying
    registers:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设为了打开我们的虚构设备，数据表告诉我们可以通过将控制寄存器的第`7`位（MSB）设置为`1`来实现。正如每个驱动程序作者很快就会了解到的，修改寄存器有一个神圣的序列：
- en: '**Read** the register''s current value into a temporary variable.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**读取**寄存器的当前值到一个临时变量中。'
- en: '**Modify** the variable to the desired value.'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**修改**变量为所需的值。'
- en: '**Write** back the variable to the register.'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**将**变量写回寄存器。'
- en: 'This is often called the **RMW** **sequence**; so, great, we write the (pseudo)code
    like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这经常被称为**RMW** **序列**；所以，很好，我们像这样编写（伪）代码：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: (FYI, the actual routines used on Linux **MMIO** – **memory-mapped I/O** – are
    `ioread[8|16|32]()` and `iowrite[8|16|32]()`.)
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: （顺便说一句，在Linux上用于**MMIO**——**内存映射I/O**的实际例程是`ioread[8|16|32]()`和`iowrite[8|16|32]()`。）
- en: 'A key point here: *this isn''t good enough*; the reason is **concurrency, data
    races!** Think about it: a register (both CPU and device registers) is in fact
    a *global shared writable memory location*; thus, accessing it *constitutes a
    critical section*, which you have to take care to protect from concurrent access!
    The how is easy; we could just use a spinlock (for now at least). It''s trivial
    to modify the preceding pseudocode to insert the `spin_[un]lock()` APIs in the
    critical section – the RMW sequence.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个关键点：*这还不够好*；原因是**并发，数据竞争！**想想看：一个寄存器（无论是CPU还是设备寄存器）实际上是一个*全局共享的可写内存位置*；因此，访问它*构成了一个临界区*，你必须小心保护它免受并发访问！如何做到这一点很容易；我们可以简单地使用自旋锁（至少目前是这样）。修改前面的伪代码以在临界区中插入`spin_[un]lock()`API是微不足道的——RMW序列。
- en: 'However, there is an even better way to achieve data safety when dealing with
    small quantities such as integers; we have already covered it: *atomic operators*!
    Linux, however, goes further, providing a set of atomic APIs for both of the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一种更好的方法可以在处理整数等小量时实现数据安全；我们已经涵盖了它：*原子操作符*！然而，Linux更进一步，为以下两种情况提供了一组原子API：
- en: '**Atomic non-RMW operations** (the ones we saw earlier, in the *Using the atomic_t
    and refcount_t interfaces* section)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**非RMW原子操作**（我们之前看到的，在*使用atomic_t和refcount_t接口*部分）'
- en: '**Atomic RMW operations**; these include several types of operators that can
    be categorized into a few distinct classes: arithmetic, bitwise, swap (exchange),
    reference counting, miscellaneous, and barriers'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原子RMW操作**；这些包括几种类型的操作符，可以分为几个不同的类别：算术、按位、交换（交换）、引用计数、杂项和屏障'
- en: 'Let''s not reinvent the wheel; the kernel documentation ([https://www.kernel.org/doc/Documentation/atomic_t.txt](https://www.kernel.org/doc/Documentation/atomic_t.txt))
    has all the information required. We''ll show just a relevant portion of this
    document as follows, quoting directly from the `Documentation/atomic_t.txt` kernel
    code base:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们不要重复造轮子；内核文档（[https://www.kernel.org/doc/Documentation/atomic_t.txt](https://www.kernel.org/doc/Documentation/atomic_t.txt)）中包含了所有所需的信息。我们将仅显示这份文件的相关部分，直接引用自`Documentation/atomic_t.txt`内核代码库。
- en: '[PRE7]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Good; now that you're aware of these RMW (and non-RMW) operators, let's get
    practical – we'll check out how to use the RMW operators for bit operations next.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 好了；现在您已经了解了这些RMW（和非RMW）操作符，让我们实际操作一下 - 我们将看看如何在下一步使用RMW操作符进行位操作。
- en: Using the RMW bitwise operators
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用RMW位操作符
- en: 'Here, we''ll focus on employing the RMW bitwise operators; we''ll leave it
    to you to explore the others (refer to the kernel docs mentioned). So, let''s
    think again about how to more efficiently code our pseudocode example. We can
    set (to `1`) any given bit in any register or memory item using the `set_bit()`
    API:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将专注于使用RMW位操作符；其他操作留给您去探索（参考提到的内核文档）。因此，让我们再次考虑如何更有效地编写我们的伪代码示例。我们可以使用`set_bit()`
    API在任何寄存器或内存项中设置（为`1`）任何给定的位：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This atomically – safely and indivisibly – sets the `nr`th bit of `p` to `1`.
    (The reality is that the device registers (and possibly device memory) are mapped
    into kernel virtual address space and thus appear to be visible as though they
    are RAM locations – such as the address `p` here. This is called MMIO and is the
    common way by which driver authors map in and work with device memory.)
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这样原子地 - 安全地和不可分割地 - 将`p`的第`nr`位设置为`1`。（事实上，设备寄存器（可能还有设备内存）被映射到内核虚拟地址空间中，因此看起来就像是RAM位置
    - 就像这里的地址`p`一样。这称为MMIO，是驱动程序作者映射和处理设备内存的常见方式。）
- en: 'Thus, with the RMW atomic operators, we can safely achieve what we''ve (incorrectly)
    attempted previously – turning on our (fictional) device – with a single line
    of code:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，使用RMW原子操作符，我们可以安全地实现我们之前（错误地）尝试的操作 - 用一行代码打开我们的（虚构的）设备：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following table summarizes common RMW bitwise atomic APIs:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表总结了常见的RMW位原子API：
- en: '| **RMW bitwise atomic API** | **Comment** |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| **RMW位原子API** | **注释** |'
- en: '| `void set_bit(unsigned int nr, volatile unsigned long *p);` | Atomically set
    (set to `1`) the `nr`th bit of `p`. |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `void set_bit(unsigned int nr, volatile unsigned long *p);` | 原子地设置（设置为`1`）`p`的第`nr`位。
    |'
- en: '| `void clear_bit(unsigned int nr, volatile unsigned long *p)` | Atomically clear
    (set to `0`) the `nr`th bit of `p`. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `void clear_bit(unsigned int nr, volatile unsigned long *p)` | 原子地清除（设置为`0`）`p`的第`nr`位。
    |'
- en: '| `void change_bit(unsigned int nr, volatile unsigned long *p)` | Atomically toggle the `nr`th
    bit of `p`. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `void change_bit(unsigned int nr, volatile unsigned long *p)` | 原子地切换`p`的第`nr`位。
    |'
- en: '| *The following APIs return the previous value of the bit being operated upon
    (nr)* |  |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| *以下API返回正在操作的位（nr）的先前值* |  |'
- en: '| `int test_and_set_bit(unsigned int nr, volatile unsigned long *p)` | Atomically
    set the `nr`th bit of `p` returning the previous value (kernel API doc at [https://www.kernel.org/doc/htmldocs/kernel-api/API-test-and-set-bit.html](https://www.kernel.org/doc/htmldocs/kernel-api/API-test-and-set-bit.html)).
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `int test_and_set_bit(unsigned int nr, volatile unsigned long *p)` | 原子地设置`p`的第`nr`位，返回先前的值（内核API文档位于[https://www.kernel.org/doc/htmldocs/kernel-api/API-test-and-set-bit.html](https://www.kernel.org/doc/htmldocs/kernel-api/API-test-and-set-bit.html)）。
    |'
- en: '| `int test_and_clear_bit(unsigned int nr, volatile unsigned long *p)` | Atomically
    clear the `nr`th bit of `p` returning the previous value. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `int test_and_clear_bit(unsigned int nr, volatile unsigned long *p)` | 原子地清除`p`的第`nr`位，返回先前的值。
    |'
- en: '| `int test_and_change_bit(unsigned int nr, volatile unsigned long *p)` | Atomically
    toggle the `nr`th bit of `p` returning the previous value. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `int test_and_change_bit(unsigned int nr, volatile unsigned long *p)` | 原子地切换`p`的第`nr`位，返回先前的值。
    |'
- en: Table 17.3 – Common RMW bitwise atomic APIs
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.3 - 常见的RMW位原子API
- en: 'Careful: these atomic APIs are not just atomic with respect to the CPU core
    they''re running upon, but now with respect to all/other cores. In practice, this
    implies that if you''re performing atomic operations in parallel on multiple CPUs,
    that is, if they (can) race, then it''s a critical section and you must protect
    it with a lock (typically a spinlock)!'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：这些原子API不仅仅是相对于它们运行的CPU核心是原子的，而且现在也是相对于所有/其他核心是原子的。实际上，这意味着如果您在多个CPU上并行执行原子操作，也就是说，如果它们（可能）竞争，那么这是一个关键部分，您必须用锁（通常是自旋锁）来保护它！
- en: Trying out a few of these RMW atomic APIs will help build your confidence in
    using them; we do so in the section that follows.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试一些这些RMW原子API将有助于建立您对使用它们的信心；我们将在接下来的部分中这样做。
- en: Using bitwise atomic operators – an example
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用位原子操作符 - 一个例子
- en: 'Let''s check out a quick kernel module that demonstrates the usage of the Linux
    kernel''s RMW atomic bit operators ( `ch13/1_rmw_atomic_bitops`). You should realize
    that these operators can work on *any memory*, both a (CPU or device) register
    or RAM; here, we operate on a simple static global variable (named `mem`) within
    the example LKM. It''s very simple; let''s check it out:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个快速的内核模块，演示了Linux内核的RMW原子位操作符的用法（`ch13/1_rmw_atomic_bitops`）。您应该意识到这些操作符可以在*任何内存*上工作，无论是寄存器还是RAM；在这里，我们在示例LKM中操作一个简单的静态全局变量（名为`mem`）。很简单；让我们来看一下：
- en: '[PRE10]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We include the required headers and declare and initialize a few global variables
    (notice how our `MSB` variable uses `BIT_PER_BYTE`). We employ a simple macro, `SHOW()`,
    to display the formatted output with the printk. The `init` code path is where
    the actual work is done:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们包括所需的头文件，并声明和初始化了一些全局变量（请注意我们的`MSB`变量如何使用`BIT_PER_BYTE`）。我们使用一个简单的宏，`SHOW()`，来显示带有`printk`的格式化输出。`init`代码路径是实际工作所在的地方：
- en: '[PRE11]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The RMW atomic operators we use here are highlighted in bold font. A key part
    of this demo is to show that using the RMW bitwise atomic operators is not only
    much easier but also much faster than using the traditional approach where we
    manually perform the RMW operation within the confines of a spinlock. Here are
    the two functions for both of these approaches:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用的RMW原子操作符以粗体字突出显示。这个演示的一个关键部分是展示使用RMW位原子操作符不仅更容易，而且比在自旋锁的限制范围内手动执行RMW操作的传统方法更快。这是这两种方法的函数：
- en: '[PRE12]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We call these functions early in our `init` method; notice that we take timestamps
    (via the `ktime_get_real_ns()` routine) and display the time taken via our `SHOW_DELTA()`
    macro (defined in our `convenient.h` header). Right, here''s the output:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`init`方法中早期调用这些函数；注意我们通过`ktime_get_real_ns()`例程获取时间戳，并通过我们的`convenient.h`头文件中定义的`SHOW_DELTA()`宏显示所花费的时间。好了，这是输出：
- en: '![](img/5cc09eb6-4fc6-4857-9222-b4d1c51e833b.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5cc09eb6-4fc6-4857-9222-b4d1c51e833b.png)'
- en: Figure 7.3 – Screenshot of output from our ch13/1_rmw_atomic_bitops LKM, showing
    off some of the atomic RMW  operators at work
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3-来自我们的ch13/1_rmw_atomic_bitops LKM的输出截图，展示了一些原子RMW操作符的工作情况
- en: (I ran this demo LKM on my x86_64 Ubuntu 20.04 guest VM.) The modern approach
    – via the `set_bit()` RMW atomic bitwise API – took, in this sample run, just
    415 nanoseconds to execute; the traditional approach was about 265 times slower!
    The code (via `set_bit()`) is so much simpler as well...
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: （我在我的x86_64 Ubuntu 20.04虚拟机上运行了这个演示LKM。）现代方法-通过`set_bit()` RMW原子位API-在这个样本运行中只需要415纳秒来执行；传统方法慢了大约265倍！代码（通过`set_bit()`）也简单得多...
- en: On a somewhat related note to the atomic bitwise operators, the following section
    is a very brief look at the highly efficient APIs available within the kernel
    for searching a bitmask – a fairly common operation in the kernel, as it turns
    out.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在与原子位操作符有些相关的地方，以下部分是对内核中用于搜索位掩码的高效API的非常简要的介绍-事实证明这是内核中一个相当常见的操作。
- en: Efficiently searching a bitmask
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高效地搜索位掩码
- en: 'Several algorithms depend on performing a really fast search of a bitmask;
    several scheduling algorithms (such as `SCHED_FIFO` and `SCHED_RR`, which you
    learned about in the companion guide *Linux Kernel Programming -* *Chapter 10*, *The
    CPU Scheduler – Part 1*, and *Chapter 11*, *The CPU Scheduler – Part 2*) often
    internally require this. Implementing this efficiently becomes important (especially
    for OS-level performance-sensitive code paths). Hence, the kernel provides a few
    APIs to scan a given bitmask (these prototypes are found in `include/asm-generic/bitops/find.h`):'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种算法依赖于对位掩码进行快速搜索；几种调度算法（如`SCHED_FIFO`和`SCHED_RR`，你在伴随指南*Linux内核编程*-*第10章*，*CPU调度器-第1部分*和*第11章*，*CPU调度器-第2部分*中了解到）通常在内部需要这个。有效地实现这一点变得很重要（特别是对于操作系统级别的性能敏感代码路径）。因此，内核提供了一些API来扫描给定的位掩码（这些原型可以在`include/asm-generic/bitops/find.h`中找到）：
- en: '`unsigned long find_first_bit(const unsigned long *addr, unsigned long size)`:
    Finds the first set bit in a memory region; returns the bit number of the first
    set bit, else (no bits are set) returns `@size`.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unsigned long find_first_bit(const unsigned long *addr, unsigned long size)`:
    在内存区域中查找第一个设置的位；返回第一个设置的位的位数，否则（没有设置位）返回`@size`。'
- en: '`unsigned long find_first_zero_bit(const unsigned long *addr, unsigned long
    size)`: Finds the first cleared bit in a memory region; returns the bit number
    of the first cleared bit, else (no bits are cleared) returns `@size`.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unsigned long find_first_zero_bit(const unsigned long *addr, unsigned long
    size)`: 在内存区域中查找第一个清除的位；返回第一个清除的位的位数，否则（没有清除的位）返回`@size`。'
- en: Other routines include `find_next_bit()`, `find_next_and_bit()`, `find_last_bit()`.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他例程包括`find_next_bit()`、`find_next_and_bit()`、`find_last_bit()`。
- en: Looking through the <`linux/bitops.h>` header reveals other quite interesting
    macros as well, such as `for_each_{clear,set}_bit{_from}()`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看<`linux/bitops.h`>头文件，还可以发现其他非常有趣的宏，比如`for_each_{clear,set}_bit{_from}()`。
- en: Using the reader-writer spinlock
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用读写自旋锁
- en: Visualize a piece of kernel (or driver) code wherein a large, global, doubly
    linked circular list (with a few thousand nodes) is being searched. Now, since
    the data structure is global (shared and writable), accessing it constitutes a
    critical section that requires protection.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下内核（或驱动程序）代码的一部分，其中正在搜索一个大的全局双向循环链表（有几千个节点）。现在，由于数据结构是全局的（共享和可写），访问它构成了一个需要保护的临界区。
- en: Assuming a scenario where searching the list is a non-blocking operation, you'd
    typically use a spinlock to protect the critical section. A naive approach might
    propose not using a lock at all since we're *only reading data* within the list,
    not updating it. But, of course (as you have learned), even a read on shared writable
    data has to be protected to protect against an inadvertent write occurring simultaneously,
    thus resulting in a dirty or torn read.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 假设搜索列表是一个非阻塞操作的场景，你通常会使用自旋锁来保护临界区。一个天真的方法可能会建议根本不使用锁，因为我们*只是读取列表中的数据*，而不是更新它。但是，当然（正如你所学到的），即使是对共享可写数据的读取也必须受到保护，以防止同时发生的意外写入，从而导致脏读或不完整读取。
- en: 'So, we conclude that we require the spinlock; we imagine the pseudocode might
    look something like this:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得出结论，我们需要自旋锁；我们可以想象伪代码可能看起来像这样：
- en: '[PRE13]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: So, what's the problem? Performance, of course! Imagine several threads on a
    multicore system ending up at this code fragment more or less at the same time;
    each will attempt to take the spinlock, but only one winner thread will get it,
    iterate over the entire list, and then perform the unlock, allowing the next thread
    to proceed. In other words, as expected, execution is now *serialized*, dramatically
    slowing things down. But it can't be helped; or can it?
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 那么问题是什么？当然是性能！想象一下在多核系统上，几个线程几乎同时到达这段代码片段；每个线程都会尝试获取自旋锁，但只有一个获胜的线程会获取它，遍历整个列表，然后执行解锁，允许下一个线程继续。换句话说，执行现在是*串行化*的，显然会显著减慢速度。但是没办法；还是有办法吗？
- en: 'Enter the **reader-writer spinlock**. With this locking construct, it''s required
    that all threads performing reads on the protected data will ask for a **read
    lock**, whereas any thread requiring write access to the list will ask for an
    **exclusive write lock**. A read lock will be granted immediately to any thread
    that asks as long as no write lock is currently in play. In effect, this construct
    *allows all readers concurrent access to the data, meaning, in effect, no real locking
    at all*. This is fine, as long as there are only readers. The moment a writer
    thread comes along, it requests a write lock. Now, normal locking semantics apply:
    the writer **will have to wait** for all readers to unlock. Once that happens,
    the writer gets an exclusive write lock and proceeds. So now, if any readers or
    writers attempt access, they will be forced to wait to spin upon the writer''s
    unlock.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 进入**读-写自旋锁**。使用这种锁定结构，要求所有执行对受保护数据的读取的线程都会请求**读锁**，而任何需要对列表进行写访问的线程都会请求**独占写锁**。只要没有写锁在起作用，读锁将立即授予任何请求的线程。实际上，这种结构*允许所有读者并发访问数据，实际上根本不需要真正的锁定*。只要只有读者，这是可以的。一旦有写入线程出现，它就会请求写锁。现在，正常的锁定语义适用：写入者**必须等待**所有读者解锁。一旦发生这种情况，写入者就会获得独占的写锁并继续进行。因此，现在，如果任何读者或写者尝试访问，它们将被迫等待直到写者解锁。
- en: Thus, for those situations where the access pattern to data is such that reads
    are performed very often and writes are rare, and the critical section is a fairly
    long one, the reader-writer spinlock is a performance-enhancing one.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于那些数据访问模式中读取非常频繁而写入很少，并且关键部分是相当长的情况，读-写自旋锁是一种性能增强的锁。
- en: Reader-writer spinlock interfaces
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读-写自旋锁接口
- en: 'Having used spinlocks, using the reader-writer variant is straightforward;
    the lock data type is abstracted as the `rwlock_t` structure (in place of `spinlock_t`)
    and, in terms of API names, simply substitute `read` or `write` in place of `spin`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 使用自旋锁后，使用读-写变体是很简单的；锁数据类型被抽象为`rwlock_t`结构（而不是`spinlock_t`），在API名称方面，只需用`read`或`write`替换`spin`：
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The most basic APIs of the reader-writer spinlock are as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 读-写自旋锁的最基本API如下：
- en: '[PRE15]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'As an example, the kernel''s `tty` layer has code to handle a **Secure Attention
    Key** (**SAK**); the SAK is a security feature, a means to prevent a Trojan horse-type
    credentials hack by killing all processes associated with the TTY device. This
    will happen when the user presses the SAK ([https://www.kernel.org/doc/html/latest/security/sak.html](https://www.kernel.org/doc/html/latest/security/sak.html)).
    When this actually happens (that is, when the user presses the SAK, mapped to
    the `Alt-SysRq-k` sequence by default), within its code path, it has to iterate
    over all tasks, killing the entire session and any threads that have the TTY device
    open. To do so, it must take, in read mode, a reader-writer spinlock called `tasklist_lock`.
    The (truncated) relevant code is seen as follows, with `read_[un]lock()` on `tasklist_lock`
    highlighted:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，内核的`tty`层有处理**安全关注键**（**SAK**）的代码；SAK是一种安全功能，是一种防止特洛伊木马式凭证黑客攻击的手段，通过终止与TTY设备关联的所有进程来实现。当用户按下SAK时，这将发生（[https://www.kernel.org/doc/html/latest/security/sak.html](https://www.kernel.org/doc/html/latest/security/sak.html)）。在其代码路径中，它必须迭代所有任务，终止整个会话和打开TTY设备的任何线程。为此，它必须以读模式获取一个名为`tasklist_lock`的读写自旋锁。相关代码如下，其中`tasklist_lock`上的`read_[un]lock()`被突出显示：
- en: '[PRE16]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As an aside, in the companion guide *Linux Kernel Programming - Chapter 6, Kernel
    Internals Essentials* section *Processes and Threads* *Iterating over the task
    list*, we did something kind of similar: we wrote a kernel module ([https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c))
    that iterated over all threads in the task list, spewing out a few details about
    each thread. So, now that we understand the deal regarding concurrency, shouldn''t
    we have taken this very lock – `tasklist_lock` – the reader-writer spinlock protecting
    the task list? Yes, but it didn''t work (`insmod(8)` failed with the message `thrd_showall:
    Unknown symbol tasklist_lock (err -2)`). The reason, of course, is that this `tasklist_lock` variable is
    *not* exported and thus is unavailable to our kernel module.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '另外，在伴随指南*Linux内核编程-第6章，内核内部要点*的*进程和线程* *遍历任务列表*部分中，我们做了类似的事情：我们编写了一个内核模块（[https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c)），遍历了任务列表中的所有线程，并输出了每个线程的一些细节。因此，现在我们了解了并发处理的情况，难道我们不应该使用这个锁-`tasklist_lock`-保护任务列表的读-写自旋锁吗？是的，但它没有起作用（`insmod(8)`失败，并显示消息`thrd_showall:
    Unknown symbol tasklist_lock (err -2)`）。原因当然是，这个`tasklist_lock`变量*没有*被导出，因此对我们的内核模块不可用。'
- en: As another example of a reader-writer spinlock within the kernel code base,
    the `ext4` filesystem uses one when working with its extent status tree. We don't
    intend to delve into the details here; we will simply mention the fact that a
    reader-writer spinlock (within the inode structure, `inode->i_es_lock`) is quite heavily
    used here to protect the extent status tree against data races  (`fs/ext4/extents_status.c`).
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 作为内核代码库中读-写自旋锁的另一个示例，`ext4`文件系统在处理其范围状态树时使用了一个。我们不打算在这里深入讨论细节；我们只会简单提到一个事实，即读-写自旋锁（在inode结构中，`inode->i_es_lock`）在这里被广泛用于保护范围状态树免受数据竞争的影响（`fs/ext4/extents_status.c`）。
- en: There are many such examples within the kernel source tree; many places in the
    network stack including the ping code (`net/ipv4/ping.c`) use `rwlock_t`, routing
    table lookup, neighbor, PPP code, filesystems, and so on.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 内核源树中有许多类似的例子；网络堆栈中的许多地方，包括ping代码（`net/ipv4/ping.c`），都使用`rwlock_t`，路由表查找，邻居，PPP代码，文件系统等等。
- en: 'Just as with regular spinlocks, we have the typical variations on the reader-writer
    spinlock APIs: `{read,write}_lock_irq{save}()` paired with the corresponding `{read,write}_unlock_irq{restore}()`,
    as well as the `{read,write}_{un}lock_bh()` interfaces. Note that even the read
    IRQ lock disables kernel preemption.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 就像普通自旋锁一样，我们有典型的读写自旋锁API的变化：`{read,write}_lock_irq{save}()`与相应的`{read,write}_unlock_irq{restore}()`，以及`{read,write}_{un}lock_bh()`接口。请注意，即使是读取IRQ锁也会禁用内核抢占。
- en: A word of caution
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 谨慎一些。
- en: 'Issues do exist with reader-writer spinlocks. One typical issue with it is
    that, unfortunately, **writers can starve** when blocking on several readers.
    Think about it: let''s say that three reader threads currently have the reader-writer
    lock. Now, a writer comes along wanting the lock. It has to wait until all three
    readers perform the unlock. But what if, in the interim, more readers come along
    (which is entirely possible)? This becomes a disaster for the writer, who has
    to now wait even longer – in effect, starve. (Carefully instrumenting or profiling
    the code paths involved might be necessary to figure out whether this is indeed
    the case.)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 读写自旋锁存在问题。其中一个典型问题是，不幸的是，**写者可能会饿死**，当阻塞在多个读者上时。想想看：假设当前有三个读取线程持有读写锁。现在，一个写入者想要锁。它必须等到所有三个读者解锁。但如果在此期间，更多的读者出现了（这是完全可能的）？这对于写者来说是一场灾难，他现在必须等待更长的时间
    - 实际上是挨饿。（可能需要仔细地检查或分析涉及的代码路径，以弄清楚是否确实是这种情况。）
- en: 'Not only that, *cache effects* – known as cache ping-pong – can and do occur
    quite often when several reader threads on different CPU cores are reading the
    same shared state in parallel (while holding the reader-writer lock); we in fact
    discuss this in the *Cache effects and false sharing* section). The kernel documentation
    on spinlocks ([https://www.kernel.org/doc/Documentation/locking/spinlocks.txt](https://www.kernel.org/doc/Documentation/locking/spinlocks.txt))
    says pretty much the same thing. Here''s a quote directly from it: "*NOTE! reader-writer
    locks require more atomic memory operations than simple spinlocks. Unless the
    reader critical section is long, you are* *better* *off just using spinlocks*."
    In fact, the kernel community is working toward removing reader-writer spinlocks
    as far as is possible, moving them to superior lock-free techniques (such as **RCU
    - Read Copy Update**, an advanced lock-free technology). Thus, gratuitous use of
    reader-writer spinlocks is ill advised.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，*缓存效应* - 也称为缓存乒乓 - 当多个位于不同CPU核心上的读取线程并行读取相同的共享状态时（同时持有读写锁）时，经常会发生，实际上我们在*缓存效应和伪共享*部分讨论了这一点。自旋锁的内核文档([https://www.kernel.org/doc/Documentation/locking/spinlocks.txt](https://www.kernel.org/doc/Documentation/locking/spinlocks.txt))也说了差不多的事情。以下是其中的一句引用：“*注意！读写锁需要比简单自旋锁更多的原子内存操作。除非读取临界区很长，否则最好只使用自旋锁*。”实际上，内核社区正在努力尽可能地删除读写自旋锁，将它们移动到更高级的无锁技术（如**RCU
    - Read Copy Update**）中。因此，滥用读写自旋锁是不明智的。
- en: The neat and simple kernel documentation on the usage of spinlocks (written
    by Linus Torvalds himself), which is well worth reading, is available here: [https://www.kernel.org/doc/Documentation/locking/spinlocks.txt](https://www.kernel.org/doc/Documentation/locking/spinlocks.txt).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 内核文档中有关自旋锁用法的整洁简单的文档（由Linus Torvalds本人编写），非常值得一读，可以在这里找到：[https://www.kernel.org/doc/Documentation/locking/spinlocks.txt](https://www.kernel.org/doc/Documentation/locking/spinlocks.txt)。
- en: The reader-writer semaphore
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 读写信号量
- en: We earlier mentioned the semaphore object ([Chapter 6](f456f2ea-ca5f-4d0f-b9c0-55b9ae92f659.xhtml),
    *Kernel Synchronization – Part 1*, in the *The semaphore and the mutex* section),
    contrasting it with the mutex. There, you understood that it's preferable to simply
    use a mutex. Here, we point out that within the kernel, just as there exist reader-writer
    spinlocks, so do there exist *reader-writer semaphores*. The use cases and semantics
    are similar to that of the reader-writer spinlock. The relevant macros/APIs are
    (within `<linux/rwsem.h>`) `{down,up}_{read,write}_{trylock,killable}()`. A common
    example within the `struct mm_struct` structure (which is itself within the task
    structure) is that one of the members is a reader-writer semaphore: `struct rw_semaphore
    mmap_sem;`.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过信号量对象（[第6章](f456f2ea-ca5f-4d0f-b9c0-55b9ae92f659.xhtml)，*内核同步 - 第1部分*，在*信号量和互斥体*部分），将其与互斥体进行对比。在那里，您了解到最好只使用互斥体。在这里，我们指出，在内核中，就像存在读写自旋锁一样，也存在*读写信号量*。用例和语义与读写自旋锁类似。相关的宏/API（在`<linux/rwsem.h>`中）是`{down,up}_{read,write}_{trylock,killable}()`。在`struct
    mm_struct`结构（它本身在任务结构中）中的一个常见示例是读写信号量：`struct rw_semaphore mmap_sem;`。
- en: Rounding off this discussion, we'll merely mention a couple of other related
    synchronization mechanisms within the kernel. A synchronization mechanism that
    is heavily used in user space application development (we're thinking particularly
    of the Pthreads framework in Linux user space) is the **Condition Variable** (**CV**). In
    a nutshell, it provides the ability for two or more threads to synchronize with
    each other based on the value of a data item or some specific state. Its equivalent
    within the Linux kernel is called the *completion mechanism*. Please find details
    on its usage within the kernel documentation at [https://www.kernel.org/doc/html/latest/scheduler/completion.html#completions-wait-for-completion-barrier-apis](https://www.kernel.org/doc/html/latest/scheduler/completion.html#completions-wait-for-completion-barrier-apis).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 结束这个讨论，我们只会简单提到内核中的其他相关同步机制。在用户空间应用程序开发中广泛使用的同步机制（我们特别考虑的是Linux用户空间中的Pthreads框架）是**条件变量**（**CV**）。简而言之，它提供了两个或更多线程根据数据项的值或某些特定状态进行同步的能力。在Linux内核中，它的等效物被称为*完成机制*。请在内核文档中找到有关其用法的详细信息：[https://www.kernel.org/doc/html/latest/scheduler/completion.html#completions-wait-for-completion-barrier-apis](https://www.kernel.org/doc/html/latest/scheduler/completion.html#completions-wait-for-completion-barrier-apis)。
- en: The *sequence lock* is used in mostly write situations (as opposed to the reader-write
    spinlock/semaphore locks, which are suitable in mostly read scenarios), where
    the writes far exceed the reads on the protected variable. As you can imagine,
    this isn't a very common occurrence; a good example of using sequence locks is
    the update of the `jiffies_64` global.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '*序列锁*主要用于大部分写情况（与适用于大部分读情况的读写自旋锁/信号量锁相对），在受保护变量的写远远超过读的情况下。你可以想象，这并不是一个非常常见的情况；使用序列锁的一个很好的例子是更新`jiffies_64`全局变量。'
- en: For the curious, the `jiffies_64` global's update code begins here: `kernel/time/tick-sched.c:tick_do_update_jiffies64()`.
    This function figures out whether an update to jiffies is required, and if so, calls `do_timer(++ticks);` to
    actually update it. All the while, the `write_seq[un]lock(&jiffies_lock);` APIs
    provide protection over the mostly write-critical section.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 对于好奇的人，`jiffies_64`全局更新代码从这里开始：`kernel/time/tick-sched.c:tick_do_update_jiffies64()`。这个函数会判断是否需要更新jiffies，如果需要，就会调用`do_timer(++ticks);`来实际更新它。与此同时，`write_seq[un]lock(&jiffies_lock);`API提供了对大部分写关键部分的保护。
- en: Cache effects and false sharing
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 缓存效应和伪共享
- en: 'Modern processors make use of several levels of parallel cache memory within
    them, in order to provide a very significant speedup when working on memory (we
    briefly touched upon this in the companion guide *Linux Kernel Programming -* *Chapter
    8*, *Kernel Memory Allocation for Module Authors – Part 1*, in the *Allocating slab
    memory* section). We realize that modern CPUs do *not* really read and write RAM
    directly; no, when the software indicates that a byte of RAM is to be read starting
    at some address, the CPU actually reads several bytes – a whole **cacheline**
    of bytes (typically 64 bytes) from the starting address into all the CPU caches
    (say, L1, L2, and L3: levels 1, 2, and 3). This way, accessing the next few elements
    of sequential memory results in a tremendous speedup as it''s first checked for in
    the caches (first in L1, then L2, then L3, and a cache hit becomes likely). The
    reason it''s (much) faster is simple: accessing CPU cache memory takes typically
    one to a few (single-digit) nanoseconds, whereas accessing RAM can take anywhere
    between 50 and 100 nanoseconds (of course, this depends on the hardware system
    in question and the amount of money you''re willing to shell out!).'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现代处理器在内部使用多级并行缓存内存，以便在处理内存时提供非常显著的加速（我们在配套指南*Linux内核编程*-*第8章*-*模块作者的内核内存分配-第1部分*-*分配slab内存*部分简要提到了这一点）。我们意识到，现代CPU实际上并不直接读写RAM；当软件指示从某个地址开始读取RAM的一个字节时，CPU实际上会从起始地址读取多个字节
    - 整个**缓存行**的字节（通常为64字节）到所有CPU缓存（比如L1、L2和L3：1、2和3级）。这样，访问顺序内存的下几个元素会得到巨大的加速，因为首先会在缓存中检查（首先在L1中，然后在L2中，然后在L3中，缓存命中变得可能）。它之所以（要快得多）更快，原因很简单：访问CPU缓存内存通常需要1到几个（个位数）纳秒，而访问RAM可能需要50到100纳秒（当然，这取决于所涉及的硬件系统和你愿意花费的金额！）。
- en: 'Software developers take advantage of such phenomena by doing things such as
    the following:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发人员通过做以下事情来利用这种现象：
- en: Keeping important members of a data structure together (hopefully, within a
    single cacheline) and at the top of the structure
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据结构的重要成员放在一起（希望在一个缓存行内），并放在结构的顶部
- en: Padding a structure member such that we don't fall off a cacheline (again, these points
    have been covered in the companion guide *Linux Kernel Programming -* *Chapter
    8*, *Kernel Memory Allocation for Module Authors – Part 1*, in the *Data structures
    – a few design tips* section)
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 填充结构成员，以便我们不会超出缓存行（同样，这些点已经在配套指南*Linux内核编程*-*第8章*-*模块作者的内核内存分配-第1部分*-*数据结构-一些设计提示*部分中涵盖了）
- en: However, risks are involved and things do go wrong. As an example, consider
    two variables declared like so: `u16 ax = 1, bx = 2;` (`u16` denotes an unsigned
    16-bit integer value).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，存在风险，事情确实会出错。举个例子，考虑这样声明的两个变量：`u16 ax = 1, bx = 2;`（`u16`表示无符号16位整数值）。
- en: 'Now, as they have been declared adjacent to each other, they will, in all likelihood,
    occupy the same CPU cacheline at runtime. To understand what the issue is, let''s
    take an example: consider a multicore system with two CPU cores, with each core
    having two CPU caches, L1 and L2, as well as a common or unified L3 cache. Now, a
    thread, *T1*, is working on variable `ax` and another thread, *T2*, is concurrently
    (on another CPU core) working on variable `bx`. So, think about it: when thread
    *T1*, running on CPU `0`, accesses `ax` from main memory (RAM), its CPU caches
    will get populated with the current values of `ax` and `bx` (as they fall within
    the same cacheline!). Similarly, when thread *T2*, running on, say, CPU `1`, accesses
    `bx` from RAM, its CPU caches will get populated with the current values of both
    variables as well. *Figure 7.4* conceptually depicts the situation:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，因为它们被声明为相邻的，它们在运行时很可能会占用相同的CPU缓存行。为了理解问题是什么，让我们举个例子：考虑一个双核系统，每个核有两个CPU缓存，L1和L2，以及一个公共或统一的L3缓存。现在，一个线程*T1*正在处理变量`ax`，另一个线程*T2*正在并发地（在另一个CPU核心上）处理变量`bx`。所以，想一想：当运行在CPU`0`上的线程*T1*从主内存（RAM）中访问`ax`时，它的CPU缓存将被`ax`和`bx`的当前值填充（因为它们在同一个缓存行内！）。同样地，当运行在CPU`1`上的线程*T2*从RAM中访问`bx`时，它的CPU缓存也将被两个变量的当前值填充。*图7.4*在概念上描述了这种情况：
- en: '![](img/7eb6e6e6-512c-4d87-aed2-ca0f146ed57d.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7eb6e6e6-512c-4d87-aed2-ca0f146ed57d.png)'
- en: Figure 7.4 – Conceptual depiction of the CPU cache memory when threads T1 and
    T2 work in parallel on two adjacent variables, each on a distinct one
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 - 当线程T1和T2并行处理两个相邻变量时，CPU缓存内存的概念描述
- en: 'Fine so far; but what if *T1* performs an operation, say, `ax ++`, while concurrently,
    *T2* performs `bx ++`? Well, so what? (By the way, you might wonder: why aren''t
    they using a lock? The interesting thing is, it''s quite irrelevant to this discussion;
    there''s no data race as each thread is accessing a different variable. The issue
    is with the fact that they''re in the same CPU cacheline.)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止还好；但是如果*T1*执行一个操作，比如`ax ++`，与此同时，*T2*执行`bx ++`呢？那又怎样？（顺便说一句，您可能会想：为什么他们不使用锁？有趣的是，这与本讨论无关；因为每个线程正在访问不同的变量，所以不存在数据竞争。问题在于它们在同一个CPU高速缓存行中。）
- en: 'Here''s the issue: **cache coherency**. The processor and/or the OS in conjunction
    with the processor (this is all very arch-dependent stuff) will have to keep the
    caches and RAM synchronized or coherent with each other. Thus, the moment *T1* modifies
    `ax`, that particular cacheline of CPU `0` will have to be invalidated, that is,
    a CPU `0`-cache-to-RAM flush of the CPU cacheline will occur to update RAM to
    the new value, and then immediately, a RAM-to-CPU `1`-cache update must also occur
    to keep everything coherent!'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的问题是**高速缓存一致性**。处理器和/或处理器与操作系统（这都是与体系结构相关的东西）将必须保持高速缓存和RAM相互同步或一致。因此，一旦*T1*修改`ax`，CPU
    `0`的那个高速缓存行将被使无效，也就是说，CPU `0`的高速缓存行将被刷新到RAM以更新RAM到新值，然后立即，RAM到CPU `1`的高速缓存更新也必须发生以保持一切一致！
- en: But the cacheline contains `bx` as well, and, as we said, `bx` has also been
    modified on CPU `1` by *T2.* Thus, at about the same time, the CPU `1` cacheline
    will be flushed to RAM with the new value of `bx` and subsequently updated to
    CPU `0`'s caches (all the while, the unified L3 cache too will be read from/updated
    as well). As you can imagine, any updates on these variables will result in a
    whole lot of traffic over the caches and RAM; they will bounce. In fact, this
    is often referred to as **cache ping-pong**! This effect is very detrimental,
    significantly slowing down processing. This phenomenon is known as **false sharing**.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 但是高速缓存行也包含`bx`，正如我们所说，`bx`也已经在CPU `1`上由*T2*修改。因此，几乎同时，CPU `1`的高速缓存行将被刷新到RAM，带有`bx`的新值，并随后更新到CPU
    `0`的高速缓存（与此同时，统一的L3高速缓存也将被读取/更新）。您可以想象，对这些变量的任何更新都将导致大量的高速缓存和RAM流量；它们会反弹。事实上，这经常被称为**高速缓存乒乓**！这种效果非常有害，会显著减慢处理速度。这种现象被称为**错误共享**。
- en: Recognizing false sharing is the hard part; we must look for variables living
    on a shared cacheline that are updated by different contexts (threads or whatever
    else) simultaneously.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 识别错误共享是困难的部分；我们必须寻找在共享高速缓存行上的变量，这些变量由不同的上下文（线程或其他）同时更新。
- en: 'Interestingly, an earlier implementation of a key data structure in the memory
    management layer, `include/linux/mmzone.h:struct zone`, suffered from this very
    same false sharing issue: two spinlocks that were declared adjacent to each other!
    This has long been fixed (we briefly discussed *memory zones* in the companion
    guide *Linux Kernel Programming -* *Chapter 7*, *Memory Management Internals –
    Essentials*, in the *Physical RAM organization/zones* section).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，在内存管理层的一个关键数据结构的早期实现`include/linux/mmzone.h:struct zone`也遭受了同样的错误共享问题：两个相邻声明的自旋锁！这个问题已经被解决（我们在配套指南*Linux内核编程-第7章，内存管理内部-基础知识*的*物理RAM组织/区域*部分简要讨论了*内存区域*）。
- en: 'How do you fix this false sharing? Easy: just ensure that the variables are
    spaced far enough apart to guarantee that they *do not share the same cacheline*
    (dummy padding bytes are often inserted between variables for this purpose). Do
    refer to the references to false sharing in the *Further reading* section as well.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如何解决这个错误的共享？很简单：只需确保变量之间的间距足够大，以确保它们*不共享相同的高速缓存行*（通常在变量之间插入虚拟填充字节以实现此目的）。还可以参考*进一步阅读*部分中关于错误共享的参考资料。
- en: Lock-free programming with per-CPU variables
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无锁编程与每CPU变量
- en: 'As you have learned, when operating upon shared writable data, the critical
    section must be protected in some manner. Locking is perhaps the most common technology
    used to effect this protection. It''s not all rosy, though, as performance can
    suffer. To realize why, consider a few analogies to a lock: one would be a funnel,
    with the stem of the funnel just wide enough to allow one thread at a time to
    flow through, no more. Another is a single toll booth on a busy highway or a traffic
    light at a busy intersection. These analogies help us visualize and understand
    why locking can cause bottlenecks, slowing performance down to a crawl in some
    drastic cases. Worse, these adverse effects can be multiplied on high-end multicore
    systems with a few hundred cores; in effect, locking doesn''t scale well.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所了解的，当操作共享可写数据时，必须以某种方式保护临界区。锁定可能是实现此保护的最常见技术。然而，并非一切都很顺利，因为性能可能会受到影响。要了解原因，可以考虑一些与锁有关的类比：一个是漏斗，漏斗的茎口只宽到足以允许一个线程通过，不多。另一个是繁忙公路上的单个收费站或繁忙十字路口的交通灯。这些类比帮助我们可视化和理解为什么锁定可能导致瓶颈，在一些极端情况下会使性能变得非常缓慢。更糟糕的是，这些不利影响在高端多核系统上可能会被放大；实际上，锁定的扩展性并不好。
- en: 'Another issue is that of *lock contention*; how often is a particular lock
    being acquired? Increasing the number of locks within a system has the benefit
    of lowering the contention for a particular lock between two or more processes
    (or threads). This is called **lock proficiency**. However, again, this is not
    scalable to an enormous extent: after a while, having thousands of locks on a
    system (the case with the Linux kernel, in fact) is not good news – the chances
    of subtle deadlock conditions arising is multiplied significantly.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是*锁争用*;特定锁被获取的频率是多少？在系统中增加锁的数量有利于降低两个或多个进程（或线程）之间对特定锁的争用。这被称为**锁效率**。然而，同样地，这并不可扩展到极大的程度：过一段时间后，在系统上拥有数千个锁（实际上是Linux内核的情况）并不是好消息-产生微妙的死锁条件的机会显著增加。
- en: So, many challenges exist – performance issues, deadlocks, priority inversion
    risks, convoying (due to lock ordering, fast code paths might need to wait for
    the first slower one that's taken a lock that the faster ones also require), and
    so on. Evolving the kernel in a scalable manner a whole level further has mandated
    the use of *lock-free algorithms* and their implementation within the kernel.
    These have led to several innovative techniques, among them being per-CPU (PCP)
    data, lock-free data structures (by design), and RCU.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，存在许多挑战-性能问题、死锁、优先级反转风险、车队（由于锁定顺序，快速代码路径可能需要等待第一个较慢的代码路径，后者已经获取了快速代码路径也需要的锁），等等。在一个可扩展的内核中进一步发展，需要使用*无锁算法*及其在内核中的实现。这些已经导致了几种创新技术，其中包括每CPU（PCP）数据、无锁数据结构（按设计）和RCU。
- en: In this book, though, we elect to cover only per-CPU as a lock-free programming
    technique in some detail. The details regarding RCU (and its associated lock-free
    data structure by design) are beyond this book's scope. Do refer to the *Further
    reading *section of this chapter for several useful resources on RCU, its meaning,
    and its usage within the Linux kernel.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们选择仅详细介绍每CPU作为无锁编程技术。关于RCU（及其相关的按设计无锁数据结构）的细节超出了本书的范围。请参考本章的*进一步阅读*部分，了解有关RCU、其含义以及在Linux内核中的使用的几个有用资源。
- en: Per-CPU variables
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每CPU变量
- en: As the name suggests, **per-CPU variables** work by keeping *a copy* of the
    variable, the data item in question, assigned to each (live) CPU on the system.
    In effect, we get rid of the problem area for concurrency, the critical section,
    by avoiding the sharing of data between threads. With the per-CPU data technique,
    since every CPU refers to its very own copy of the data, a thread running on that
    processor can manipulate it without any worry of racing. (This is roughly analogous
    to local variables; as locals are on the private stack of each thread, they aren't
    shared between threads, thus there's no critical section and no need for locking.)
    Here, too, the need for locking is thus eliminated – making it a *lock-free *technology!
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，**每CPU变量**通过为系统上的每个（活动的）CPU分配*一个副本*来工作。实际上，通过避免在线程之间共享数据，我们摆脱了并发的问题领域，即临界区。使用每CPU数据技术，由于每个CPU都引用其自己的数据副本，运行在该处理器上的线程可以在没有竞争的情况下操纵它。
    （这在某种程度上类似于局部变量；由于局部变量位于每个线程的私有堆栈上，它们不在线程之间共享，因此没有临界区，也不需要锁定。）在这里，锁定的需求也被消除了-使其成为一种*无锁*技术！
- en: 'So, think of this: if you are running on a system with four live CPU cores,
    then a per-CPU variable on that system is essentially an array of four elements:
    element `0` represents the data value on the first CPU, element `1` the data value
    on the second CPU core, and so on. Understanding this, you''ll realize that per-CPU
    variables are also roughly analogous to the user space Pthreads **Thread Local
    Storage** (**TLS**) implementation where each thread automatically obtains a copy
    of the (TLS) variable marked with the `__thread` keyword. There, and here with
    per-CPU variables, it should be obvious: use per-CPU variables for small data
    items only. This is because the data item is reproduced (copied) with one instance
    per CPU core (on a high-end system with a few hundred cores, the overheads do
    climb). We mention some examples of per-CPU usage in the kernel code base (in
    the *Per-CPU usage within the kernel* section).'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，想象一下：如果您在一个具有四个活动CPU核心的系统上运行，那么该系统上的每CPU变量本质上是一个四个元素的数组：元素`0`表示第一个CPU上的数据值，元素`1`表示第二个CPU核心上的数据值，依此类推。了解这一点，您会意识到每CPU变量在某种程度上也类似于用户空间Pthreads
    **线程本地存储**（**TLS**）实现，其中每个线程自动获取标有`__thread`关键字的（TLS）变量的副本。在这里和每CPU变量中，显而易见：仅对小数据项使用每CPU变量。这是因为数据项会被复制，每个CPU核心有一个实例（在具有几百个核心的高端系统上，开销会增加）。我们在内核代码库中提到了一些每CPU使用的示例（在*内核中的每CPU使用*部分）。
- en: Now, when working with per-CPU variables, you must use the helper methods (macros and
    APIs) provided by the kernel and not attempt to directly access them (much like
    we saw with the refcount and atomic operators).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当使用每CPU变量时，您必须使用内核提供的辅助方法（宏和API），而不是直接访问它们（就像我们在引用计数和原子操作符中看到的那样）。
- en: Working with per-CPU
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用每CPU
- en: Let's approach the helper APIs and macros (methods) for per-CPU data by dividing
    the discussion into two portions. First, you will learn how to allocate, initialize,
    and subsequently free a per-CPU data item. Then, you will learn how to work with
    (read/write) it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过将讨论分为两部分来接近每CPU数据的辅助API和宏（方法）。首先，您将学习如何分配、初始化和随后释放每CPU数据项。然后，您将学习如何使用（读/写）它。
- en: Allocating, initialization, and freeing per-CPU variables
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 分配、初始化和释放每CPU变量
- en: 'There are broadly two types of per-CPU variables: statically and dynamically
    allocated ones. Statically allocated per-CPU variables are allocated at compile
    time itself, typically via one of these macros: `DEFINE_PER_CPU` or `DECLARE_PER_CPU`.
    Using the `DEFINE` one allows you to allocate and initialize the variable. Here''s
    an example of allocating a single integer as a per-CPU variable:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上有两种类型的每CPU变量：静态分配和动态分配。静态分配的每CPU变量是在编译时分配的，通常通过`DEFINE_PER_CPU`或`DECLARE_PER_CPU`宏之一来实现。使用`DEFINE`允许您分配和初始化变量。以下是一个分配单个整数作为每CPU变量的示例：
- en: '[PRE17]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, on a system with, say, four CPU cores, it would conceptually appear like
    this at initialization:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在一个具有四个CPU核心的系统上，初始化时概念上看起来是这样的：
- en: '![](img/eaad779b-7052-464c-8e37-a11bac841004.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eaad779b-7052-464c-8e37-a11bac841004.png)'
- en: Figure 7.5 – Conceptual representation of a per-CPU data item on a system with
    four live CPUs
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5-在具有四个活动CPU的系统上对每CPU数据项的概念表示
- en: (The actual implementation is quite a bit more complex than this, of course;
    please refer to the *Further reading* section of this chapter to see more on the
    internal implementation.)
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: （实际实现当然比这复杂得多；请参考本章的*进一步阅读*部分，了解更多内部实现。）
- en: 'In a nutshell, using per-CPU variables is good for performance enhancement
    on time-sensitive code paths because of the following:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，使用每个CPU变量对于性能敏感的代码路径是有益的，因为：
- en: We avoid using costly, performance-busting locks.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们避免使用昂贵的、性能破坏的锁。
- en: The access and manipulation of a per-CPU variable is guaranteed to remain on
    one particular CPU core; this eliminates expensive cache effects such as cache
    ping-pong and false sharing (covered in the *Cache effects and false sharing* section).
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问和操作每个CPU变量保证保持在一个特定的CPU核心上；这消除了昂贵的缓存效应，如缓存乒乓和伪共享（在“缓存效应和伪共享”部分中介绍）。
- en: 'Dynamically allocating per-CPU data can be achieved via the `alloc_percpu()` or
    `alloc_percpu_gfp()` wrapper macros, simply passing the data type of the object
    to allocate as per-CPU, and, for the latter, passing along the `gfp` allocation
    flag as well:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过`alloc_percpu()`或`alloc_percpu_gfp()`包装宏动态分配每个CPU数据，只需将要分配为每个CPU的对象的数据类型传递给它，对于后者，还要传递`gfp`分配标志：
- en: '[PRE18]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The underlying `__alloc_per_cpu[_gfp]()` routines are exported via `EXPORT_SYMBOL_GPL()`
    (and thus can be employed only when an LKM is released under a GPL-compatible
    license).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 底层的`__alloc_per_cpu[_gfp]()`例程通过`EXPORT_SYMBOL_GPL()`导出（因此只能在LKM以GPL兼容许可证发布时使用）。
- en: As you've learned, the resource-managed `devm_*()` API variants allow you (typically
    when writing drivers) to conveniently use these routines to allocate memory; the
    kernel will take care of freeing it, helping prevent leakage scenarios. The `devm_alloc_percpu(dev,
    type)` macro allows you to use this as a resource-managed version of `__alloc_percpu()`.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所学到的，资源管理的`devm_*()`API变体允许你（通常在编写驱动程序时）方便地使用这些例程来分配内存；内核将负责释放它，有助于防止泄漏情况发生。`devm_alloc_percpu(dev,
    type)`宏允许你使用这个作为`__alloc_percpu()`的资源管理版本。
- en: The memory allocated via the preceding routine(s) must subsequently be freed
    using the `void free_percpu(void __percpu *__pdata)` API.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 通过前面的例程分配的内存必须随后使用`void free_percpu(void __percpu * __pdata)` API释放。
- en: Performing I/O (reads and writes) on per-CPU variables
  id: totrans-212
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 对每个CPU变量执行I/O（读取和写入）
- en: 'A key question, of course, is how exactly can you access (read) and update
    (write) to per-CPU variables? The kernel provides several helper routines to do
    so; let''s take a simple example to understand how. We define a single integer
    per-CPU variable, and at a later point in time, we want to access and print its
    current value. You should realize that, being per-CPU, the value retrieved will
    be auto-calculated *based on the CPU core the code is currently running on*; in
    other words, if the following code is running on core `1`, then in effect, the
    `pcpa[1]` value is fetched (it''s not done exactly like this; this is just conceptual):'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一个关键的问题是你到底如何访问（读取）和更新（写入）每个CPU变量？内核提供了几个辅助例程来实现这一点；让我们举一个简单的例子来理解。我们定义一个单个整数每个CPU变量，然后在以后的某个时间点，我们想要访问并打印其当前值。你应该意识到，由于是每个CPU，所以检索到的值将根据代码当前运行的CPU核心自动计算；换句话说，如果以下代码在核心`1`上运行，那么实际上将获取`pcpa[1]`的值（实际操作并非完全如此；这只是概念上的）：
- en: '[PRE19]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The pair of `{get,put}_cpu_var()` macros allows us to safely retrieve or modify
    the per-CPU value of the given per-CPU variable (its parameter). It''s important
    to understand that the code between `get_cpu_var()` and `put_cpu_var()` (or equivalent)
    is, in effect, a critical section – an atomic context – *where kernel preemption
    is disabled and any kind of blocking (or sleeping) is disallowed*. If you do anything
    here that blocks (sleeps) in any manner, it''s a kernel bug. For example, see
    what happens if you try to allocate memory via `vmalloc()` within the `get_cpu_var()`/`put_cpu_var()`
    pair of macros:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`{get,put}_cpu_var()`宏对我们允许安全地检索或修改给定每个CPU变量（其参数）的每个CPU值。重要的是要理解`get_cpu_var()`和`put_cpu_var()`（或等效）之间的代码实际上是一个关键部分
    - 一个原子上下文 - *其中内核抢占被禁用，任何类型的阻塞（或睡眠）都是不允许的*。如果在这里做任何阻塞（睡眠）的操作，那就是内核错误。例如，看看如果你尝试通过`get_cpu_var()`/`put_cpu_var()`宏对内存进行分配会发生什么：'
- en: '[PRE20]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: (By the way, calling the `printk()` (or `pr_<foo>()`) wrappers as we do within
    the critical section is fine as they're non-blocking.) The issue here is that
    the `vmalloc()` API is possibly a blocking one; it might sleep (we discussed it
    in detail in the companion guide *Linux Kernel Programming -* *Chapter 9*, *Kernel
    Memory Allocation for Module Authors – Part 2*, in the *Understanding and using
    the kernel vmalloc() API *section), and the code between the `get_cpu_var()`/`put_cpu_var()` pair
    must be atomic and non-blocking.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: （顺便说一句，在关键部分内部调用`printk()`（或`pr_<foo>()`）包装器是可以的，因为它们是非阻塞的。）问题在于`vmalloc()`
    API可能是一个阻塞的；它可能会睡眠（我们在配套指南*Linux内核编程*的*第9章*，*模块作者的内核内存分配 - 第2部分*的*理解和使用内核vmalloc()
    API*部分中详细讨论过），而在`get_cpu_var()`/`put_cpu_var()`对之间的代码必须是原子的和非阻塞的。
- en: Internally, the `get_cpu_var()` macro invokes `preempt_disable()`, disabling
    kernel preemption, and `put_cpu_var()` undoes this by invoking `preempt_enable()`.
    As seen earlier (in the companion guide *Linux Kernel Programming* chapters on
    *CPU scheduling*), this can be nested and the kernel maintains a `preempt_count` variable
    to figure out whether kernel preemption is actually enabled or disabled.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在内部，`get_cpu_var()`宏调用`preempt_disable()`，禁用内核抢占，而`put_cpu_var()`通过调用`preempt_enable()`来撤消这一操作。正如之前所见（在配套指南*Linux内核编程*的*CPU调度*章节中），这可以嵌套，并且内核维护一个`preempt_count`变量来确定内核抢占是否实际上被启用或禁用。
- en: The upshot of all this is that you must carefully match the `{get,put}_cpu_var()`
    macros when using them (for example, if we call the `get` macro twice, we must
    also call the corresponding `put` macro twice).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，当使用这些宏时，你必须仔细匹配`{get,put}_cpu_var()`（例如，如果我们调用`get`宏两次，我们也必须调用相应的`put`宏两次）。
- en: 'The `get_cpu_var()` is an *lvalue* and can thus be operated upon; for example,
    to increment the per-CPU `pcpa` variable, just do the following:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_cpu_var()`是一个*lvalue*，因此可以进行操作；例如，要增加每个CPU的`pcpa`变量，只需执行以下操作：'
- en: '[PRE21]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can also (safely) retrieve the current per-CPU value via the macro:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以（安全地）通过宏检索当前每CPU值：
- en: '[PRE22]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'So, to retrieve the per-CPU `pcpa` variable for every CPU core on the system,
    use the following:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，要检索系统上每个CPU核心的每CPU`pcpa`变量，请使用以下内容：
- en: '[PRE23]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: FYI, you can always use the `smp_processor_id()` macro to figure out which CPU
    core you're currently running upon; in fact, this is precisely how our `convenient.h:PRINT_CTX()`
    macro does it.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，您可以始终使用`smp_processor_id()`宏来确定您当前运行的CPU核心；实际上，这正是我们的`convenient.h:PRINT_CTX()`宏的工作原理。
- en: In a similar manner, the kernel provides routines to work with pointers to variables
    that require to be per-CPU, the `{get,put}_cpu_ptr()` and `per_cpu_ptr()` macros.
    These macros are heavily employed when working with a per-CPU data structure (as
    opposed to just a simple integer); we safely retrieve the pointer to the structure
    of the CPU we're currently running upon, and use it (`per_cpu_ptr()`).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，内核提供了用于处理需要为每个CPU的变量指针的例程，`{get,put}_cpu_ptr()`和`per_cpu_ptr()`宏。当处理每个CPU数据结构时（而不仅仅是一个简单的整数），这些宏被广泛使用；我们安全地检索当前正在运行的CPU的结构的指针，并使用它（`per_cpu_ptr()`）。
- en: Per-CPU – an example kernel module
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 每CPU - 一个示例内核模块
- en: 'A hands-on session with our sample per-CPU demo kernel module will definitely
    help in using this powerful feature (code here: `ch13/2_percpu`). Here, we define
    and use two per-CPU variables:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的示例每CPU演示内核模块的实际操作会有所帮助，以使用这个强大的功能（代码在这里：`ch13/2_percpu`）。在这里，我们定义并使用两个每CPU变量：
- en: A statically allocated and initialized per-CPU integer
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个静态分配和初始化的每CPU整数
- en: A dynamically allocated per-CPU data structure
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个动态分配的每CPU数据结构
- en: 'As an interesting way to help demo per-CPU variables, let''s do this: we shall
    arrange for our demo kernel module to spawn off a couple of kernel threads. Let''s
    call them `thrd_0` and `thrd_1`. Furthermore, once created, we shall make use
    of the CPU mask (and API) to *affine* our `thrd_0` kernel thread on CPU `0` and
    our `thrd_1` kernel thread on CPU `1` (hence, they will be scheduled to run on
    only these cores; of course, we must test this code on a VM with at least two
    CPU cores).'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 作为演示每CPU变量的有趣方式，让我们这样做：我们将安排我们的演示内核模块产生一对内核线程。让我们称它们为`thrd_0`和`thrd_1`。此外，一旦创建，我们将利用CPU掩码（和API）将我们的`thrd_0`内核线程*关联*到CPU
    `0`，将我们的`thrd_1`内核线程*关联*到CPU `1`（因此，它们将被调度在这些核心上运行；当然，我们必须在至少有两个CPU核心的VM上测试这段代码）。
- en: 'The following code snippets illustrate how we define and use the per-CPU variables
    (we leave out the code that creates the kernel threads and sets up their CPU affinity
    masks, as they are not relevant to the coverage of this chapter; nevertheless,
    it''s key to browse through the full code and try it out!):'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段说明了我们如何定义和使用每CPU变量（我们省略了创建内核线程和设置它们的CPU亲和性掩码的代码，因为它们与本章的覆盖范围无关；然而，浏览完整代码并尝试它是非常重要的！）：
- en: '[PRE24]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Why not use the resource-managed `devm_alloc_percpu()` instead? Yes, you should
    when appropriate; here, though, as we're not writing a proper driver, we don't
    have a `struct device *dev` pointer handy, which is the required first parameter
    to `devm_alloc_percpu()`.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不使用资源管理的`devm_alloc_percpu()`呢？是的，在适当的时候你应该使用；然而，在这里，因为我们不是在编写一个合适的驱动程序，我们没有一个`struct
    device *dev`指针方便使用，这是`devm_alloc_percpu()`所需的第一个参数。
- en: 'By the way, I faced an issue when coding this kernel module; to set the CPU
    mask (to change the CPU affinity for each of our kernel threads), the kernel API
    is the `sched_setaffinity()` function, which, unfortunately for us, is *not exported*,
    thus preventing us from using it. So, we perform what is definitely considered
    a hack: obtain the address of the uncooperative function via `kallsyms_lookup_name()`
    (which works when `CONFIG_KALLSYMS` is defined) and then invoke it as a function pointer.
    It works, but is most certainly not the right way to code.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，我在编写这个内核模块时遇到了一个问题；要设置CPU掩码（为每个内核线程更改CPU亲和性），内核API是`sched_setaffinity()`函数，但不幸的是，这个函数对我们来说是*未导出*的，因此我们无法使用它。因此，我们执行了一个绝对被认为是黑客行为的操作：通过`kallsyms_lookup_name()`（在定义了`CONFIG_KALLSYMS`时有效）获取不合作函数的地址，然后将其作为函数指针调用。这样做是有效的，但绝对不是编码的正确方式。
- en: 'Our design idea is to create two kernel threads and have each of them differently
    manipulate the per-CPU data variables. If these were ordinary global variables,
    this would certainly constitute a critical section and we would of course require
    a lock; but here, precisely because they are *per-CPU* and because we guarantee
    that our threads run on separate cores, we can concurrently update them with differing
    data! Our kernel thread worker routine is as follows; the argument to it is the
    thread number (`0` or `1`). We accordingly branch off and manipulate the per-CPU
    data (we have our first kernel thread increment the integer three times, while
    our second kernel thread decrements it three times):'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的设计思想是创建两个内核线程，并让它们分别操作每CPU数据变量。如果这些是普通的全局变量，这肯定构成了一个关键部分，我们当然需要一个锁；但在这里，正是因为它们是*每CPU*，并且我们保证我们的线程在不同的核心上运行，我们可以同时使用不同的数据更新它们！我们的内核线程工作例程如下；它的参数是线程编号（`0`或`1`）。我们相应地分支并操作每CPU数据（我们的第一个内核线程将整数增加三次，而我们的第二个内核线程将其减少三次）：
- en: '[PRE25]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The effect at runtime is interesting; see the following kernel log:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 运行时的效果很有趣；请参阅以下内核日志：
- en: '![](img/0d0e4a40-1aa3-497e-b350-ea9980367d31.png)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0d0e4a40-1aa3-497e-b350-ea9980367d31.png)'
- en: Figure 7.6 – Screenshot showing the kernel log when our ch13/2_percpu/percpu_var
    LKM runs
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6 - 显示我们的ch13/2_percpu/percpu_var LKM运行时的内核日志的屏幕截图
- en: In the last three lines of output in *Figure 7.6*, you can see a summary of
    the values of our per-CPU data variables on CPU `0` and CPU `1` (we show it via
    our `disp_vars()` function). Clearly, for the per-CPU `pcpa` integer (as well
    as the `pcp_ctx` data structure), the values are *different* as expected, *without
    explicit locking*.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图7.6*的最后三行输出中，您可以看到我们的每CPU数据变量在CPU `0`和CPU `1`上的值的摘要（我们通过我们的`disp_vars()`函数显示）。显然，对于每CPU`pcpa`整数（以及`pcp_ctx`数据结构），值是*不同的*，正如预期的那样，*没有显式锁定*。
- en: 'The kernel module just demonstrated uses the `for_each_online_cpu(i)` macro
    to display the value of our per-CPU variables on each online CPU. Next, what if
    you have, say, six CPUs on your VM but want only two of them to be "live" at runtime?
    There are several ways to arrange this; one is to pass the `maxcpus=n` parameter to
    the VM''s kernel at boot – you can see if it''s there by looking up `/proc/cmdline`:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 刚刚演示的内核模块使用`for_each_online_cpu(i)`宏在每个在线CPU上显示每个CPU变量的值。接下来，如果您的虚拟机有6个CPU，但希望其中只有两个在运行时处于“活动”状态，该怎么办？有几种安排的方法；其中一种是在启动时向VM的内核传递`maxcpus=n`参数-您可以通过查找`/proc/cmdline`来查看是否存在：
- en: '`$ cat /proc/cmdline` `BOOT_IMAGE=/boot/vmlinuz-5.4.0-llkd-dbg root=UUID=1c4<...>
    ro console=ttyS0,115200n8 console=tty0  quiet splash 3 **maxcpus=2**` Also notice
    that we''re running on our custom `5.4.0-llkd-dbg` debug kernel.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ cat /proc/cmdline` `BOOT_IMAGE=/boot/vmlinuz-5.4.0-llkd-dbg root=UUID=1c4<...>
    ro console=ttyS0,115200n8 console=tty0  quiet splash 3 **maxcpus=2**` 还要注意我们正在运行我们自定义的`5.4.0-llkd-dbg`调试内核。'
- en: Per-CPU usage within the kernel
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内核中的每个CPU使用
- en: 'Per-CPU variables are quite heavily used within the Linux kernel; one interesting
    case is in the implementation of the `current` macro on the x86 architecture (we
    covered using the `current` macro in the companion guide *Linux Kernel Programming
    -* *Chapter 6*, *Kernel Internals Essentials – Processes and Threads*, in the *Accessing
    the task structure with current* section). The fact is that `current` is looked
    up (and set) every so often; keeping it as a per-CPU ensures that we keep its
    access lock-free! Here''s the code that implements it:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 每个CPU变量在Linux内核中被广泛使用；一个有趣的案例是在x86架构上实现`current`宏的情况（我们在伴随指南*Linux内核编程*的*第6章*，*内核内部要点-进程和线程*，*使用current访问任务结构*部分中介绍了使用`current`宏）。事实上，`current`经常被查找（和设置）；将其作为每个CPU变量可以确保我们保持其无锁访问！以下是实现它的代码：
- en: '[PRE26]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The `DECLARE_PER_CPU()` macro declares the variable named `current_task` as
    a per-CPU variable of type `struct task_struct *`. The `get_current()` inline
    function invokes the `this_cpu_read_stable()` helper on this per-CPU variable,
    thus reading the value of `current` on the CPU core that it''s currently running
    on (read the comment at [https://elixir.bootlin.com/linux/v5.4/source/arch/x86/include/asm/percpu.h#L383](https://elixir.bootlin.com/linux/v5.4/source/arch/x86/include/asm/percpu.h#L383) to
    see what this routine''s about). Okay, that''s fine, but an FAQ: where does this `current_task` per-CPU
    variable get updated? Think about it: the kernel must change (update) `current`
    *whenever its context switches* to another task.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '`DECLARE_PER_CPU()`宏声明名为`current_task`的变量为`struct task_struct *`类型的每个CPU变量。`get_current()`内联函数在这个每个CPU变量上调用`this_cpu_read_stable()`助手，从而读取当前正在运行的CPU核上的`current`的值（阅读[https://elixir.bootlin.com/linux/v5.4/source/arch/x86/include/asm/percpu.h#L383](https://elixir.bootlin.com/linux/v5.4/source/arch/x86/include/asm/percpu.h#L383)处的注释以了解这个例程的作用）。好吧，这很好，但一个常见问题：`current_task`每个CPU变量在哪里更新？想一想：内核必须在*每当其上下文切换*到另一个任务时更改（更新）`current`。'
- en: 'That''s exactly the case; it is indeed updated within the context-switching
    code (`arch/x86/kernel/process_64.c:__switch_to()`; at [https://elixir.bootlin.com/linux/v5.4/source/arch/x86/kernel/process_64.c#L504](https://elixir.bootlin.com/linux/v5.4/source/arch/x86/kernel/process_64.c#L504)):'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是这种情况；它确实在上下文切换代码（`arch/x86/kernel/process_64.c:__switch_to()`；在[https://elixir.bootlin.com/linux/v5.4/source/arch/x86/kernel/process_64.c#L504](https://elixir.bootlin.com/linux/v5.4/source/arch/x86/kernel/process_64.c#L504)）中更新：
- en: '[PRE27]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, a quick experiment to show per-CPU usage within the kernel code base
    via `__alloc_percpu()`: run `cscope -d` in the root of the kernel source tree
    (this assumes you''ve already built the `cscope` index via `make cscope`). In
    the `cscope` menu, under the `Find functions calling this function:` prompt, type `__alloc_percpu`.
    The result is as follows:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，一个快速实验来展示内核代码库中通过`__alloc_percpu()`使用每个CPU：在内核源代码根目录中运行`cscope -d`（这假设您已经通过`make
    cscope`构建了`cscope`索引）。在`cscope`菜单中，在`查找调用此函数的函数：`提示下，键入`__alloc_percpu`。结果如下：
- en: '![](img/73938e5c-c45f-4c4b-a974-213b2c3d03a9.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/73938e5c-c45f-4c4b-a974-213b2c3d03a9.png)'
- en: Figure 7.7 – (Partial) screenshot of the output of cscope -d showing kernel
    code that calls the __alloc_percpu() API
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7 - 显示调用__alloc_percpu() API的内核代码的（部分）cscope -d输出的屏幕截图
- en: This, of course, is just a partial list of per-CPU usage within the kernel code
    base, tracking only use via the `__alloc_percpu()` underlying API. Searching for
    functions calling `alloc_percpu[_gfp]()` (wrappers over `__alloc_percpu[_gfp]()`)
    reveals many more hits.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这只是内核代码库中每个CPU使用的部分列表，仅跟踪通过`__alloc_percpu()`底层API的使用。搜索调用`alloc_percpu[_gfp]()`（`__alloc_percpu[_gfp]()`的包装器）的函数会发现更多命中。
- en: 'With this, having completed our discussions on kernel synchronization techniques
    and APIs, let''s finish this chapter by learning about a key area: tools and tips
    when debugging locking issues within kernel code!'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些讨论，我们已经完成了关于内核同步技术和API的讨论，让我们通过学习一个关键领域来结束本章：在内核代码中调试锁定问题时的工具和提示！
- en: Lock debugging within the kernel
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内核中的锁调试
- en: The kernel has several means to help debug difficult situations with regard
    to kernel-level locking issues, *deadlock* being a primary one.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 内核有几种方法来帮助调试与内核级锁定问题有关的困难情况，*死锁*是主要问题之一。
- en: Just in case you haven't already, do ensure you've first read the basics on
    synchronization, locking, and deadlock guidelines from the previous chapter ([Chapter
    6](f456f2ea-ca5f-4d0f-b9c0-55b9ae92f659.xhtml), *Kernel Synchronization – Part
    1*, especially the *Exclusive execution and atomicity* and *Concurrency concerns
    within the Linux kernel* sections).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 以防您还没有，确保您首先从上一章（[第6章](f456f2ea-ca5f-4d0f-b9c0-55b9ae92f659.xhtml)，*内核同步-第1部分*）中阅读了有关同步、锁定和死锁指南的基础知识，特别是*独占执行和原子性*和*Linux内核中的并发问题*部分。
- en: 'With any debug scenario, there are different points at which debugging occurs,
    and thus perhaps differing tools and techniques that should/could be used. Very
    broadly speaking, a bug might be noticed at, and thus debugged at, a few different
    points in time (within the **Software Development Life Cycle** (**SDLC**), really):'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何调试场景中，都有不同的调试发生的时间点，因此可能需要使用不同的工具和技术。非常广义地说，bug可能会在**软件开发生命周期**（**SDLC**）中的几个不同时间点被注意到和调试（实际上）：
- en: During development
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发期间
- en: After development but before release (testing, **Quality Assurance** (**QA**),
    and so on)
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布前的开发（测试，**质量保证**（**QA**）等）
- en: After internal release
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部发布后
- en: After release, in the field
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布后，在现场
- en: 'A well-known and unfortunately true homily: the "further" a bug is exposed
    from development, the costlier it is to fix! So you really do want to try and
    find and fix them as early as possible!'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 一个众所周知且不幸的至理名言：bug从开发中暴露出来的越远，修复的代价就越高！所以您确实希望尽早找到并修复它们！
- en: As this book is focused squarely on kernel development, we shall focus here
    on a few tools and techniques for debugging locking issues at development time.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书专注于内核开发，我们将在这里专注于一些用于在开发时调试锁问题的工具和技术。
- en: '**Important**: We expect that by now, you''re running on a debug kernel, that
    is, a kernel deliberately configured for development/debug purposes. Performance
    will take a hit, but that''s okay – we''re out bug hunting now! We covered the
    configuration of a typical debug kernel in the companion guide *Linux Kernel Programming*
    *-* Chapter 5, *Writing Your First Kernel Module – LKMs Part 2*, in the *Configuring
    a debug kernel *section, and have even provided a sample kernel configuration
    file for debugging here: [https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch5/kconfigs/sample_kconfig_llkd_dbg.config](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch5/kconfigs/sample_kconfig_llkd_dbg.config).
    Specifics on configuring the debug kernel for lock debugging are in fact covered
    next.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要**：我们期望您现在正在运行调试内核，即故意配置为开发/调试目的的内核。性能会受到影响，但没关系-我们现在是在找bug！我们在伴随指南*Linux内核编程*第5章*编写您的第一个内核模块-LKMs第2部分*中介绍了典型调试内核的配置，并在这里提供了一个用于调试的示例内核配置文件：[https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch5/kconfigs/sample_kconfig_llkd_dbg.config](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch5/kconfigs/sample_kconfig_llkd_dbg.config)。关于为锁调试配置调试内核的具体信息实际上在下面介绍。'
- en: Configuring a debug kernel for lock debugging
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置调试内核以进行锁调试
- en: 'Due to its relevance and importance to lock debugging, we will take a quick
    look at a key point from the *Linux Kernel patch submission checklist* document
    ([https://www.kernel.org/doc/html/v5.4/process/submit-checklist.html](https://www.kernel.org/doc/html/v5.4/process/submit-checklist.html))
    that''s most relevant to our discussions here, on enabling a debug kernel (especially
    for lock debugging):'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 由于与锁调试的相关性和重要性，我们将快速查看*Linux内核补丁提交清单*文档（[https://www.kernel.org/doc/html/v5.4/process/submit-checklist.html](https://www.kernel.org/doc/html/v5.4/process/submit-checklist.html)）中与我们讨论最相关的一个关键点，即启用调试内核（特别是用于锁调试）：
- en: '[PRE28]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Though not covered in this book, I cannot fail to mention a very powerful dynamic
    memory error detector called **Kernel Address SANitizer** (**KASAN**). In a nutshell,
    it uses compile-time instrumentation-based dynamic analysis to catch common memory-related
    bugs (it works with both GCC and Clang). **ASan** (**Address Sanitizer**), contributed
    by Google engineers, is used to monitor and detect memory issues in user space
    apps (covered in some detail and compared with valgrind in the *Hands-On System
    Programming for Linux* book). The kernel equivalent, KASAN, has been available
    since the 4.0 kernel for both x86_64 and AArch64 (ARM64, from 4.4 Linux). Details
    (on enabling and using it) can be found within the kernel documentation ([https://www.kernel.org/doc/html/v5.4/dev-tools/kasan.html#the-kernel-address-sanitizer-kasan](https://www.kernel.org/doc/html/v5.4/dev-tools/kasan.html#the-kernel-address-sanitizer-kasan));
    I highly recommend you enable it in your debug kernel.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书未涉及，但我不能不提到一个非常强大的动态内存错误检测器，称为**内核地址SANitizer**（**KASAN**）。简而言之，它使用基于编译时的仪器化动态分析来捕获常见的与内存相关的bug（它适用于GCC和Clang）。**ASan**（**地址Sanitizer**）由Google工程师贡献，用于监视和检测用户空间应用程序中的内存问题（在*Linux的系统编程实践*书中详细介绍并与valgrind进行比较）。内核等效的KASAN自4.0内核以来已经适用于x86_64和AArch64（从4.4
    Linux开始）。可以在内核文档中找到有关详细信息（如何启用和使用它）（[https://www.kernel.org/doc/html/v5.4/dev-tools/kasan.html#the-kernel-address-sanitizer-kasan](https://www.kernel.org/doc/html/v5.4/dev-tools/kasan.html#the-kernel-address-sanitizer-kasan)）；我强烈建议您在调试内核中启用它。
- en: 'As covered in the companion guide *Linux Kernel Programming -* Chapter 2, *Building
    the 5.x Linux Kernel from Source – Part 1*, we can configure our Linux kernel
    specifically for our requirements. Here (within the root of the 5.4.0 kernel source
    tree), we perform `make menuconfig` and navigate to the `Kernel hacking / Lock
    Debugging (spinlocks, mutexes, etc...)` menu (see *Figure 7.8*, taken on our x86_64
    Ubuntu 20.04 LTS guest VM):'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 正如伴随指南*Linux内核编程*第2章*从源代码构建5.x Linux内核-第1部分*中所述，我们可以根据我们的需求配置我们的Linux内核。在这里（在5.4.0内核源代码树的根目录中），我们执行`make
    menuconfig`并导航到`Kernel hacking / Lock Debugging (spinlocks, mutexes, etc...)`菜单（见*图7.8*，在我们的x86_64
    Ubuntu 20.04 LTS虚拟机上拍摄）：
- en: '![](img/d401a93d-b5fc-4a84-ae7c-3990a73b3500.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d401a93d-b5fc-4a84-ae7c-3990a73b3500.png)'
- en: Figure 7.8 – (Truncated) screenshot of the kernel hacking / Lock Debugging (spinlocks,
    mutexes, etc...) menu with required items enabled for our debug kernel
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8-（截断）内核hacking / Lock Debugging（spinlocks，mutexes，等...）菜单的屏幕截图，启用了我们调试内核所需的项目
- en: '*Figure 7.8* is a (truncated) screenshot of the ` <Kernel hacking > Lock Debugging
    (spinlocks, mutexes, etc...)` menu with required items enabled for our debug kernel.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.8*是`<Kernel hacking> Lock Debugging（spinlocks，mutexes，等...）`菜单的（截断）屏幕截图，启用了我们调试内核所需的项目。'
- en: Instead of interactively having to go through each menu item and selecting the `<Help>` button
    to see what it's about, a much simpler way to gain the same help information is
    to peek inside the relevant Kconfig file (that describes the menu). Here, it's
    `lib/Kconfig.debug`, as all debug-related menus are there. For our particular
    case, search for the `menu "Lock Debugging (spinlocks, mutexes, etc...)"` string,
    where the `Lock Debugging` section begins (see the following table).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 与交互式地逐个浏览每个菜单项并选择`<帮助>`按钮以查看其内容相比，获得相同的帮助信息的一个更简单的方法是查看相关的Kconfig文件（描述菜单）。在这里，它是`lib/Kconfig.debug`，因为所有与调试相关的菜单都在那里。对于我们的特殊情况，搜索`menu
    "锁调试（自旋锁、互斥锁等...)"`字符串，其中`锁调试`部分开始（见下表）。
- en: 'The following table summarizes what each kernel lock debugging configuration
    option helps debug (we haven''t shown all of them and, for some of them, have
    directly quoted from the `lib/Kconfig.debug` file):'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表总结了每个内核锁调试配置选项帮助调试的内容（我们没有展示所有内容，对于其中一些内容，我们直接引用了`lib/Kconfig.debug`文件中的内容）：
- en: '| **Lock debugging menu title** | ** What it does** |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| **锁调试菜单标题** | **它的作用** |'
- en: '| Lock debugging: prove locking correctness (`CONFIG_PROVE_LOCKING`) | This
    is the `lockdep` kernel option – turn it on to get rolling proof of lock correctness
    at all times. Any possibility of locking-related deadlock *is reported even before
    it actually occurs*; very useful! (Explained shortly in more detail.) |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 锁调试：证明锁定正确性（`CONFIG_PROVE_LOCKING`） | 这是`lockdep`内核选项 - 打开它以始终获得锁正确性的滚动证明。任何与锁定相关的死锁的可能性*甚至在实际发生之前就报告*；非常有用！（稍后更详细地解释。）
    |'
- en: '| Lock usage statistics (`CONFIG_LOCK_STAT`) | Tracks lock contention points
    (explained shortly in more detail). |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 锁使用统计（`CONFIG_LOCK_STAT`） | 跟踪锁争用点（稍后更详细地解释）。 |'
- en: '| RT mutex debugging, deadlock detection (`CONFIG_DEBUG_RT_MUTEXES`) | "*This
    allows rt mutex semantics violations and rt mutex related deadlocks (lockups)
    to be detected and reported automatically*." |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| RT互斥锁调试，死锁检测（`CONFIG_DEBUG_RT_MUTEXES`） | “*这允许自动检测和报告rt互斥锁语义违规和rt互斥锁相关的死锁（锁死）*。”
    |'
- en: '| Spinlock and `rw-lock` debugging: basic checks (`CONFIG_DEBUG_SPINLOCK`)
    | Turning this on (along with `CONFIG_SMP`) helps catch missing spinlock initialization
    and other common spinlock errors. |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 自旋锁和`rw-lock`调试：基本检查（`CONFIG_DEBUG_SPINLOCK`） | 打开此选项（与`CONFIG_SMP`一起）有助于捕获缺少自旋锁初始化和其他常见自旋锁错误。
    |'
- en: '| Mutex debugging: basic checks (`CONFIG_DEBUG_MUTEXES`) | "*This feature allows
    mutex semantics violations to be detected and reported*." |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 互斥锁调试：基本检查（`CONFIG_DEBUG_MUTEXES`） | “*此功能允许检测和报告互斥锁语义违规*。” |'
- en: '| RW semaphore debugging: basic checks (`CONFIG_DEBUG_RWSEMS`) | Allows mismatched
    RW semaphore locks and unlocks to be detected and reported. |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| RW信号量调试：基本检查（`CONFIG_DEBUG_RWSEMS`） | 允许检测和报告不匹配的RW信号量锁定和解锁。 |'
- en: '| Lock debugging: detect incorrect freeing of live locks (`CONFIG_DEBUG_LOCK_ALLOC`)
    | "*This feature will check whether any held lock (spinlock, rwlock, mutex or
    rwsem) is incorrectly freed by the kernel, via any of the memory-freeing routines*
    (`kfree(), kmem_cache_free(), free_pages(), vfree()`*, etc.), whether a live lock
    is incorrectly reinitialized via* `spin_lock_init()/mutex_init()`*/etc., or whether
    there is any lock held during task exit*." |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 锁调试：检测错误释放活锁（`CONFIG_DEBUG_LOCK_ALLOC`） | “*此功能将检查内核是否通过任何内存释放例程（`kfree()，kmem_cache_free()，free_pages()，vfree()`等）错误释放任何持有的锁（自旋锁、读写锁、互斥锁或RW信号量），是否通过`spin_lock_init()/mutex_init()`等错误重新初始化活锁，或者是否在任务退出期间持有任何锁*。”
    |'
- en: '| Sleep inside atomic section checking (`CONFIG_DEBUG_ATOMIC_SLEEP`) | "*If
    you say Y here, various routines which may sleep will become very noisy if they
    are called inside atomic sections: when a spinlock is held, inside an rcu read
    side critical section, inside preempt disabled sections, inside an interrupt,
    etc...*" |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 原子段内睡眠检查（`CONFIG_DEBUG_ATOMIC_SLEEP`） | “*如果在这里选择Y，各种可能会睡眠的例程在自旋锁被持有时、在rcu读端关键段内、在禁止抢占的段内、在中断内等情况下将变得非常嘈杂...*”
    |'
- en: '| Locking API boot-time self-tests (`CONFIG_DEBUG_LOCKING_API_SELFTESTS`) |
    "*Say Y here if you want the kernel to run a short self-test during bootup. The
    self-test checks whether common types of locking bugs are detected by debugging
    mechanisms or not. (if you disable lock debugging then those bugs wont be detected
    of course.) The following locking APIs are covered: spinlocks, rwlocks,* *mutexes
    and rwsems*." |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 锁API启动时自检（`CONFIG_DEBUG_LOCKING_API_SELFTESTS`） | “*如果您希望内核在启动时运行简短的自检，请在此处选择Y。自检检查调试机制是否检测到常见类型的锁定错误。（如果禁用锁调试，则当然不会检测到这些错误。）以下锁定API包括：自旋锁、读写锁、互斥锁和RW信号量*。”
    |'
- en: '| Torture tests for locking (`CONFIG_LOCK_TORTURE_TEST`) | "*This option provides
    a kernel module that runs torture tests on kernel locking primitives. The kernel
    module may be built after the fact on the running kernel to be tested, if desired." (Can
    be built either inline with ''`Y`'' or externally as a module with ''*`M`*'')*."
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 锁的折磨测试（`CONFIG_LOCK_TORTURE_TEST`） | “*此选项提供一个在内核锁原语上运行折磨测试的内核模块。如果需要，可以在运行的内核上构建内核模块进行测试。”（可以内联构建为`Y`，也可以作为模块外部构建为`M`）*。”
    |'
- en: Table 17.4 – Typical kernel lock debugging configuration options and their meaning
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 表17.4 - 典型的内核锁调试配置选项及其含义
- en: 'As suggested previously, turning on all or most of these lock debug options
    within a debug kernel used during development and testing is a good idea. Of course,
    as expected, doing so might considerably slow down execution (and use more memory);
    as in life, this is a trade-off you have to decide on: you gain detection of common
    locking issues, errors, and deadlocks, at the cost of speed. It''s a trade-off
    you should be more than willing to make, especially when developing (or refactoring)
    the code.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 正如先前建议的，打开开发和测试过程中使用的调试内核中的所有或大部分锁调试选项是一个好主意。当然，预期的是，这样做可能会显著减慢执行速度（并使用更多内存）；就像生活中一样，这是一个你必须决定的权衡：你可以在速度的代价下获得常见锁定问题、错误和死锁的检测。这是一个你应该更愿意做出的权衡，特别是在开发（或重构）代码时。
- en: The lock validator lockdep – catching locking issues early
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 锁验证器lockdep - 及早捕捉锁定问题
- en: 'The Linux kernel has a tremendously useful feature begging to be taken advantage
    of by kernel developers: a runtime locking correctness or locking dependency validator;
    in short, **lockdep**. The basic idea is this: the `lockdep` runtime comes into
    play whenever any locking activity occurs within the kernel – the taking or the
    release of *any* kernel-level lock, or any locking sequence involving multiple
    locks.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核具有一个非常有用的功能，可以被内核开发人员充分利用：运行时锁定正确性或锁定依赖验证器；简而言之，**lockdep**。基本思想是：每当内核中发生任何锁定活动
    - 获取或释放*任何*内核级别的锁，或涉及多个锁的任何锁定序列时，`lockdep`运行时就会发挥作用。
- en: This is tracked or mapped (see the following paragraph for more on the performance
    impact and how it's mitigated). By applying well-known rules for correct locking
    (you got a hint of this in the previous chapter in the *Locking guidelines and
    deadlock* section), `lockdep` then makes a conclusion regarding the validity of
    the correctness of what was done.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 这是被跟踪或映射的（有关性能影响及其如何被缓解的更多信息，请参见下一段）。通过应用已知的正确锁定规则（在前一章的*锁定指南和死锁*部分中你已经得到了一些提示），`lockdep`然后对所做的正确性进行结论。
- en: 'The beauty of it is that `lockdep` achieves 100% mathematical proof (or closure)
    that a lock sequence is correct or not. The following is a direct quote from the
    kernel documentation on the topic ([https://www.kernel.org/doc/html/v5.4/locking/lockdep-design.html](https://www.kernel.org/doc/html/v5.4/locking/lockdep-design.html)):'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的美妙之处，`lockdep`实现了100%的数学证明（或闭合），证明了锁序列是正确的还是不正确。以下是来自内核文档对该主题的直接引用（https://www.kernel.org/doc/html/v5.4/locking/lockdep-design.html）：
- en: '"*The validator achieves perfect, mathematical ‘closure’ (proof of locking
    correctness) in the sense that for every simple, standalone single-task locking
    sequence that occurred at least once during the lifetime of the kernel, the validator
    proves it with a 100% certainty that no combination and timing of these locking
    sequences can cause any class of lock related deadlock.*"'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 验证器在数学上实现了完美的“闭合”（锁定正确性的证明），即对于内核生命周期中至少发生一次的每个简单的、独立的单任务锁定序列，验证器都能以100%的确定性证明，这些锁定序列的任何组合和时序都不会导致任何类型的锁相关死锁。
- en: 'Furthermore, `lockdep` warns you (by issuing the `WARN*()` macros) of any violation
    of the following classes of locking bugs: deadlocks/lock inversion scenarios,
    circular lock dependencies, and hard IRQ/soft IRQ safe/unsafe locking bugs. This
    information is precious; validating your code with `lockdep` can save hundreds
    of wasted hours of productivity by catching locking issues early. (FYI, `lockdep`
    tracks all locks and their locking sequence or "lock chains"; these can be viewed
    through `/proc/lockdep_chains`).'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`lockdep`通过发出`WARN*()`宏来警告您有关以下类别的锁定错误：死锁/锁倒置场景、循环锁依赖关系以及硬中断/软中断安全/不安全的锁定错误。这些信息非常宝贵；使用`lockdep`验证您的代码可以通过及早捕捉锁定问题来节省数百个被浪费的工作小时。（顺便说一下，`lockdep`跟踪所有锁及其锁定序列或“锁链”；这些可以通过`/proc/lockdep_chains`查看。）
- en: 'A word on *performance mitigation*: you might well imagine that, with literally
    thousands or more lock instances floating around, it would be absurdly slow to
    validate every single lock sequence (yes, in fact, it turns out to be a task of
    order `O(N^2)` algorithmic time complexity!). This would just not work; so, `lockdep`
    works by verifying any locking scenario (say, on a certain code path, lock A is
    taken, then lock B is taken – this is referred to as a *lock sequence* or *lock
    chain*) **only once**, the very first time it occurs. (It knows this by maintaining
    a 64-bit hash for every lock chain it encounters.)'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 关于*性能缓解*：你可能会想象，随着成千上万个锁实例在周围浮动，验证每个单个锁序列将会非常慢（实际上，它的算法时间复杂度是`O(N^2)`）。这根本行不通；因此，`lockdep`通过验证任何锁定场景（比如，在某个代码路径上，先获取锁A，然后获取锁B
    - 这被称为*锁序列*或*锁链*）**仅一次**，即第一次出现时。它通过维护每个锁链的64位哈希来实现这一点。
- en: 'Primitive user space approaches: A very primitive – and certainly not guaranteed
    – way to try and detect deadlocks is via user space by simply using GNU `ps(1)`;
    doing `ps -LA -o state,pid,cmd | grep "^D"` prints any threads in the `D` – *uninterruptible
    sleep *(`TASK_UNINTERRUPTIBLE`) – state. This could – but may not – be due to
    a deadlock; if it persists for a long while, chances are higher that it is a deadlock. Give
    it a try! Of course, `lockdep` is a far superior solution. (Note that this only
    works with GNU `ps`, not the lightweight ones such as `busybox ps`.)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 原始用户空间方法：一种非常原始的尝试检测死锁的方法是通过用户空间，只需使用GNU `ps(1)`；执行`ps -LA -o state,pid,cmd
    | grep "^D"`会打印出处于`D`（不可中断睡眠，`TASK_UNINTERRUPTIBLE`）状态的任何线程。这可能是由于死锁，但也可能不是；如果它持续了很长时间，那么它很可能是死锁。试一试！当然，`lockdep`是一个远远优越的解决方案。（请注意，这仅适用于GNU
    `ps`，而不适用于轻量级的`busybox ps`。）
- en: Other useful user space tools are `strace(1)` and `ltrace(1)` – they provide
    a detailed trace of every system and library call, respectively, issued by a process
    (or thread); you might be able to catch a hung process/thread and see where it
    got stuck (using `strace -p PID` might be especially useful on a hung process).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 其他有用的用户空间工具是`strace(1)`和`ltrace(1)` - 它们分别提供了由进程（或线程）发出的每个系统和库调用的详细跟踪；你可能能够捕捉到一个挂起的进程/线程，并查看它在哪里被卡住（使用`strace
    -p PID`对挂起的进程可能特别有用）。
- en: 'The other point that you need to be clear about is this: `lockdep` *will* issue
    warnings regarding (mathematically) incorrect locking *even if no deadlock actually
    occurs at runtime*! `lockdep` offers proof that there is indeed an issue that
    could conceivably cause a bug (deadlock, unsafe locking, and so on) at some point
    in the future if no corrective action is taken; it''s usually dead right; take
    it seriously and fix the issue. (Then again, typically, nothing in the software
    universe is 100% correct 100% of the time: what if a bug creeps into the `lockdep`
    code itself? There''s even a `CONFIG_DEBUG_LOCKDEP` config option. The bottom line
    is that we, the human developers, must carefully assess the situation, checking
    for false positives.)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要明确的要点是：`lockdep`*将*发出关于（数学上）不正确的锁定的警告，即使在运行时实际上没有发生死锁！`lockdep`提供了证据表明确实存在可能在将来某个时刻导致错误（死锁、不安全的锁定等）的问题；它通常是完全正确的；认真对待并修复问题。
    （再说一遍，通常情况下，软件世界中没有任何东西是100%正确的100%的时间：如果`lockdep`代码本身出现了错误怎么办？甚至还有一个`CONFIG_DEBUG_LOCKDEP`配置选项。最重要的是，我们作为人类开发人员必须仔细评估情况，检查是否存在错误的警告。）
- en: Next, `lockdep` works upon a *lock class*; this is simply a "logical" lock as
    opposed to "physical" instances of that lock. For example, the kernel's open file
    data structure, `struct file`, has two locks – a mutex and a spinlock – and each
    of them is considered a lock class by `lockdep`. Even if a few thousand instances
    of `struct file` exist in memory at runtime, `lockdep` will track it as a class
    only. For more detail on `lockdep`'s internal design, we refer you to the official
    kernel documentation on it ([https://www.kernel.org/doc/html/v5.4/locking/lockdep-design.html](https://www.kernel.org/doc/html/v5.4/locking/lockdep-design.html)).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`lockdep`基于*锁类*进行工作；这只是一个“逻辑”锁，而不是该锁的“物理”实例。例如，内核的打开文件数据结构`struct file`有两个锁——互斥锁和自旋锁——`lockdep`将每个锁都视为一个锁类。即使在运行时内存中存在几千个`struct
    file`实例，`lockdep`也只会将其跟踪为一个类。有关`lockdep`内部设计的更多细节，我们建议您参考官方内核文档（[https://www.kernel.org/doc/html/v5.4/locking/lockdep-design.html](https://www.kernel.org/doc/html/v5.4/locking/lockdep-design.html)）。
- en: Examples – catching deadlock bugs with lockdep
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例 - 使用lockdep捕获死锁错误
- en: 'Here, we shall assume that you''ve by now built and are running upon a debug
    kernel with `lockdep` enabled (as described in detail in the *Configuring a debug
    kernel for lock debugging* section). Verify that it is indeed enabled:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们假设您现在已经构建并正在运行一个启用了`lockdep`的调试内核（详细描述在*为锁调试配置调试内核*部分）。验证它确实已启用：
- en: '[PRE29]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Okay, good! Now, let's get hands-on with some deadlocks, seeing how `lockdep`
    will help you catch them. Read on!
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 好的！现在，让我们亲自体验一些死锁，看看`lockdep`将如何帮助您捕获它们。继续阅读！
- en: Example 1 – catching a self deadlock bug with lockdep
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例1 - 使用lockdep捕获自死锁错误
- en: 'As a first example, let''s travel back to one of our kernel modules from the
    companion guide *Linux Kernel Programming -* *Chapter 6*, *Kernel Internals Essentials
    – Processes and Threads*, in the *Iterating over the task list* section, here: [https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c).
    Here, we looped over each thread, printing some details from within its task structure;
    with regard to this, here''s a code snippet where we obtain the name of the thread
    (recall that it''s in a member of the task structure called `comm`):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 作为第一个例子，让我们回到我们的一个内核模块，这个模块是伴随指南*Linux Kernel Programming - Chapter 6*中*Kernel
    Internals Essentials – Processes and Threads*部分的，*Iterating over the task list*部分，这里：[https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/ch6/foreach/thrd_showall/thrd_showall.c)。在这里，我们循环遍历每个线程，从其任务结构中打印一些细节；关于这一点，这里有一个代码片段，我们从中获取线程的名称（记住它在任务结构的一个成员中叫做`comm`）：
- en: '[PRE30]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'This works, but there appears to be a better way to do it: instead of directly
    looking up the thread''s name with `t->comm` (as we do here), the kernel provides
    the `{get,set}_task_comm()` helper routines to both get and set the name of the
    task. So, we rewrite the code to use the `get_task_comm()` helper macro; the first
    parameter to it is the buffer to place the name into (it''s expected that you''ve
    allocated memory to it), and the second parameter is the pointer to the task structure
    of the thread whose name you are querying (the following code snippet is from
    here: `ch13/3_lockdep/buggy_thrdshow_eg/thrd_showall_buggy.c`):'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做是有效的，但似乎有更好的方法：与其直接使用`t->comm`查找线程的名称（就像我们在这里做的那样），内核提供了`{get,set}_task_comm()`辅助例程来获取和设置任务的名称。因此，我们重写代码以使用`get_task_comm()`辅助宏；它的第一个参数是放置名称的缓冲区（预期您已为其分配了内存），第二个参数是要查询其名称的线程的任务结构的指针（以下代码片段来自这里：`ch13/3_lockdep/buggy_thrdshow_eg/thrd_showall_buggy.c`）：
- en: '[PRE31]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: When compiled and inserted into the kernel on our test system (a VM, thank goodness),
    it can get weird, or even just simply hang! (When I did this, I was able to retrieve
    the kernel log via `dmesg(1)` before the system became completely unresponsive.).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 当编译并插入到我们的测试系统（一个虚拟机，谢天谢地）的内核中时，它可能会变得奇怪，甚至只是简单地挂起！（当我这样做时，我能够在系统完全无响应之前通过`dmesg(1)`检索内核日志。）
- en: What if your system just hangs upon insertion of this LKM? Well, that's a taste
    of the difficulty of kernel debugging! One thing you can try (which worked for
    me when trying this very example on a x86_64 Fedora 29 VM) is to reboot the hung
    VM and look up the kernel log by leveraging systemd's powerful `journalctl(1)`
    utility with the `journalctl --since="1 hour ago"` command; you should be able
    to see the printks from `lockdep` now. Again, unfortunately, it's not guaranteed
    that the key portion of the kernel log is saved to disk (at the time it hung)
    for `journalctl` to be able to retrieve. This is why using the kernel's **kdump**
    feature – and then performing postmortem analysis of the kernel dump image file
    with `crash(8)` – can be a lifesaver (see resources on using `kdump` and crash
    in the *Further reading *section for this chapter).
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的系统在插入此LKM时卡住了怎么办？嗯，这就是内核调试的困难所在！您可以尝试的一件事（在我在x86_64 Fedora 29 VM上尝试这个例子时对我有效）是重新启动卡住的VM，并使用`journalctl
    --since="1 hour ago"`命令查看内核日志，利用systemd强大的`journalctl(1)`实用程序；您应该能够看到`lockdep`的printk输出。不幸的是，不能保证内核日志的关键部分在卡住时保存到磁盘，以便`journalctl`能够检索。这就是为什么使用内核的**kdump**功能
    - 然后使用`crash(8)`对内核转储映像文件进行事后分析 - 可以成为救命稻草的原因（请参阅本章*进一步阅读*部分中有关使用`kdump`和`crash`的资源）。
- en: 'Glancing at the kernel log, it becomes clear: `lockdep` has caught a (self)
    deadlock (we show relevant parts of the output in the screenshot):'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 扫视内核日志，很明显：`lockdep`捕获到了（自身）死锁（我们在截图中展示了相关部分输出）。
- en: '![](img/adff4dda-3a9e-4c92-9c57-db9a988a0872.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![](img/adff4dda-3a9e-4c92-9c57-db9a988a0872.png)'
- en: Figure 7.9 – (Partial) screenshot showing the kernel log after our buggy module
    is loaded; lockdep catches the self deadlock!
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9 - 展示我们的有bug的模块加载后的内核日志的（部分）截图；lockdep捕获到了自身死锁！
- en: 'Though a lot more detail follows (including the stack backtrace of the kernel
    stack of `insmod(8)` – as it was the process context, in this case, register values, and
    so on), what we see in the preceding figure is sufficient to deduce what happened.
    Clearly, `lockdep` tells us `insmod/2367 is trying to acquire lock:`, followed
    by `but task is already holding lock:`. Next (look carefully at *Figure 7.9*),
    the lock that `insmod` is holding is `(p->alloc_lock)` (for now, ignore what follows
    it; we will explain it shortly) and the routine that actually attempts to acquire
    it (shown after `at:`) is `__get_task_comm+0x28/0x50`. Now, we''re getting somewhere:
    let''s figure out what exactly occurred when we called `get_task_comm()`; we find
    that it''s a macro, a wrapper around the actual worker routine, `__get_task_comm()`.
    Its code is as follows:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管接下来有更多的细节（包括`insmod(8)`的内核堆栈的堆栈回溯 - 因为它是进程上下文，在这种情况下，寄存器值等等），但是我们在前面的图中看到的足以推断出发生了什么。显然，`lockdep`告诉我们`insmod/2367正在尝试获取锁：`，接着是`但任务已经持有锁：`。接下来（仔细看*图7.9*），`insmod`持有的锁是`(p->alloc_lock)`（暂时忽略后面的内容；我们很快会解释），实际尝试获取它的例程（在`at:`后面显示）是`__get_task_comm+0x28/0x50`。现在我们有了进展：让我们弄清楚在调用`get_task_comm()`时到底发生了什么；我们发现它是一个宏，是实际工作例程`__get_task_comm()`的包装器。它的代码如下：
- en: '[PRE32]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Ah, there''s the problem: the `__get_task_comm()` function *attempts to reacquire
    the very same lock that we''re already holding, causing (self) deadlock*! Where
    did we acquire it? Recall that the very first line of code in our (buggy) kernel
    module after entering the loop is where we call `task_lock(t)`, and then just
    a few lines later, we invoke `get_task_comm()`, which internally attempts to reacquire
    the very same lock: the result is *self deadlock*:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，问题就在这里：`__get_task_comm()`函数*尝试重新获取我们已经持有的同一个锁，导致（自身）死锁*！我们在哪里获取它？回想一下，在我们（有bug的）内核模块进入循环后的第一行代码是我们调用`task_lock(t)`，然后几行后，我们调用`get_task_comm()`，它在内部尝试重新获取同一个锁：结果就是*自身死锁*！
- en: '[PRE33]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Furthermore, finding which particular lock this is easy; look up the code of
    the `task_lock()` routine:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，找到这个特定锁是很容易的；查找`task_lock()`例程的代码：
- en: '[PRE34]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: So, it all makes sense now; it's a spinlock within the task structure named `alloc_lock`,
    just as `lockdep` informs us.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在一切都说得通了；这是任务结构中名为`alloc_lock`的自旋锁，就像`lockdep`告诉我们的那样。
- en: '`lockdep`''s report has some amount of puzzling notations. Take the following
    lines:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '`lockdep`的报告中有一些令人困惑的标记。看看以下几行：'
- en: '[PRE35]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Ignoring the timestamp, the number in the leftmost column of the second line
    seen in the preceding code block is the 64-bit lightweight hash value used to
    identify this particular lock sequence. Notice it''s precisely the same as the
    hash in the following line; so, we know it''s the very same lock being acted upon!
    `{+.+.}` is lockdep''s notation for what state this lock was acquired in (the
    meaning: `+` implies lock acquired with IRQs enabled, `.` implies lock acquired
    with IRQs disabled and not in the IRQ context, and so on). These are explained
    in the kernel documentation ([https://www.kernel.org/doc/Documentation/locking/lockdep-design.txt](https://www.kernel.org/doc/Documentation/locking/lockdep-design.txt));
    we''ll leave it at that.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略时间戳，在前面的代码块中看到的第二行最左边列中的数字是用于标识这个特定锁序列的64位轻量级哈希值。请注意，它与下一行中的哈希值完全相同；因此，我们知道它是同一个锁！`{+.+.}`是lockdep对这个锁获取的状态的表示（含义是：`+`表示在启用IRQ的情况下获取锁，`.`表示在禁用IRQ并且不在IRQ上下文中获取锁，等等）。这些在内核文档中有解释（[https://www.kernel.org/doc/Documentation/locking/lockdep-design.txt](https://www.kernel.org/doc/Documentation/locking/lockdep-design.txt)）；我们就到此为止。
- en: 'A detailed presentation on interpreting `lockdep` output was given by Steve
    Rostedt at a Linux Plumber''s Conference (back in 2011); the relevant slides are
    informative, exploring both simple and complex deadlock scenarios and how `lockdep`
    can detect them:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: Steve Rostedt在2011年的Linux Plumber's Conference上做了一个关于解释`lockdep`输出的详细演示；相关幻灯片很有启发性，探讨了简单和复杂的死锁场景以及`lockdep`如何检测它们：
- en: '*Lockdep: How to read its cryptic output* ([https://blog.linuxplumbersconf.org/2011/ocw/sessions/153](https://blog.linuxplumbersconf.org/2011/ocw/sessions/153)).'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '*Lockdep: 如何阅读其神秘的输出* ([https://blog.linuxplumbersconf.org/2011/ocw/sessions/153](https://blog.linuxplumbersconf.org/2011/ocw/sessions/153))。'
- en: Fixing it
  id: totrans-327
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 修复它
- en: 'Now that we understand the issue here, how do we fix it? Seeing lockdep''s
    report (*Figure 7.9*) and interpreting it, it''s quite simple: (as mentioned)
    since the task structure spinlock named `alloc_lock` is already taken at the start
    of the `do-while` loop (via `task_lock(t)`), ensure that before calling the `get_task_comm()`
    routine (which internally takes and releases this same lock), you unlock it, then
    perform `get_task_comm()`, then lock it again.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们理解了这里的问题，我们该如何解决呢？看到lockdep的报告（*图7.9*）并解释它，很简单：（如前所述）由于在`do-while`循环的开始已经获取了名为`alloc_lock`的任务结构自旋锁（通过`task_lock(t)`），确保在调用`get_task_comm()`例程之前（它在内部获取并释放相同的锁），您解锁它，然后执行`get_task_comm()`，然后再次锁定它。
- en: 'The following screenshot (*Figure 7.10*) shows the difference (via the `diff(1)` utility)
    between the older buggy version (`ch13/3_lockdep/buggy_thrdshow_eg/thrd_showall_buggy.c`)
    and the newer fixed version of our code (`ch13/3_lockdep/fixed_lockdep/thrd_showall_fixed.c`):'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 以下屏幕截图（*图7.10*）显示了旧版本（`ch13/3_lockdep/buggy_thrdshow_eg/thrd_showall_buggy.c`）和我们代码的新版本之间的差异（通过`diff(1)`实用程序）：
- en: '![](img/a0ceead6-e333-44c6-81a6-cab46b8a29fe.png)'
  id: totrans-330
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a0ceead6-e333-44c6-81a6-cab46b8a29fe.png)'
- en: Figure 7.10 – (Partial) screenshot showing the key part of the difference between
    the buggy and fixed versions of our demo thrdshow LKM
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10 - （部分）屏幕截图显示了我们的演示thrdshow LKM的错误和修复版本之间的关键部分
- en: Great; another example follows – that of catching an AB-BA deadlock!
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 很好；接下来是另一个例子 - 捕获AB-BA死锁！
- en: Example 2 – catching an AB-BA deadlock with lockdep
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 示例2 - 使用lockdep捕获AB-BA死锁
- en: 'As one more example, let''s check out a (demo) kernel module that quite deliberately
    creates a **circular dependency**, which will ultimately result in a deadlock.
    The code is here: `ch13/3_lockdep/deadlock_eg_AB-BA`. We''ve based this module
    on our earlier one (`ch13/2_percpu`); as you''ll recall, we create two kernel
    threads and ensure (by using a hacked `sched_setaffinity()`) that each kernel
    thread runs on a unique CPU core (the first kernel thread on CPU core `0` and
    the second on core `1`).'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，让我们看一个（演示）内核模块，它故意创建了一个**循环依赖**，最终会导致死锁。 代码在这里：`ch13/3_lockdep/deadlock_eg_AB-BA`。
    我们基于之前的一个模块（`ch13/2_percpu`）创建了这个模块；正如您所记得的，我们创建了两个内核线程，并确保（通过使用一个被篡改的`sched_setaffinity()`）每个内核线程在唯一的CPU核心上运行（第一个内核线程在CPU核心`0`上运行，第二个在核心`1`上运行）。
- en: 'This way, we have concurrency. Now, within the threads, we have them work with
    two spinlocks, `lockA` and `lockB`. Understanding that we have a process context
    with two or more locks, we document and follow a lock ordering rule: *first take
    lockA, then lockB*. Great; so, one way it should *not* be done is like this:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就有了并发性。现在，在这些线程中，我们让它们使用两个自旋锁，`lockA`和`lockB`。 理解我们有一个进程上下文，有两个或更多锁，我们记录并遵循锁定顺序规则：*首先获取lockA，然后获取lockB*。
    很好；所以，一种不应该这样做的方式是：
- en: '[PRE36]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This, of course, is the classic AB-BA deadlock! Because the program (*kernel
    thread 1*, actually) ignored the lock ordering rule (when the `lock_ooo` module
    parameter is set to `1`), it deadlocks. Here''s the relevant code (we haven''t
    bothered showing the whole program here; please clone this book''s GitHub repository
    at [https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming) and
    try it out yourself):'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 当程序（*实际上是内核线程1*）忽略了锁定顺序规则（当`lock_ooo`模块参数设置为`1`时），这当然是经典的AB-BA死锁！ 它发生了死锁。 这里是相关的代码（我们没有在这里显示整个程序；请克隆本书的GitHub存储库[https://github.com/PacktPublishing/Linux-Kernel-Programming](https://github.com/PacktPublishing/Linux-Kernel-Programming)并自行尝试）：
- en: '[PRE37]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Our kernel thread `0` does it correctly, following the lock ordering rule;
    the code relevant to our kernel thread `1` (continued from the previous code)
    is as follows:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的内核线程`0`正确执行，遵循锁定顺序规则；与之前的代码相关的我们的内核线程`1`的代码如下：
- en: '[PRE38]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Build and run it with the `lock_ooo` kernel module parameter set to `0` (the
    default); we find that, obeying the lock ordering rule, all is well:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 构建并运行它，将`lock_ooo`内核模块参数设置为`0`（默认值）；我们发现，遵守锁定顺序规则，一切正常：
- en: '[PRE39]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, we run it with the `lock_ooo` kernel module parameter set to `1` and find
    that, as expected, the system locks up! We''ve disobeyed the lock ordering rule,
    and we pay the price as the system deadlocks! This time, rebooting the VM and
    doing `journalctl --since="10 min ago"` got me lockdep''s report:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将`lock_ooo`内核模块参数设置为`1`运行它，发现，如预期的那样，系统被锁定！ 我们违反了锁定顺序规则，因此系统陷入了死锁！ 这次，重新启动VM并执行`journalctl
    --since="10 min ago"`得到了lockdep的报告：
- en: '[PRE40]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'The `lockdep` report is quite amazing. Check out the lines after the sentence
    `Possible unsafe locking scenario:`; it pretty much precisely shows what actually
    occurred at runtime – the **out-of-order** (**ooo**) locking sequence on `CPU1
    : lock(lockB); --> lock(lockA);`! Since `lockA` is already taken by the kernel
    thread on CPU `0`, the kernel thread on CPU `1` spins forever – the root cause
    of this AB-BA deadlock.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`lockdep`报告非常惊人。 在句子“可能的不安全锁定场景：”之后，检查一下，它几乎精确地显示了运行时实际发生的情况 - `CPU1 : lock(lockB);
    --> lock(lockA);`的**out-of-order**（**ooo**）锁定顺序！由于`lockA`已经被CPU `0`上的内核线程占用，CPU
    `1`上的内核线程永远旋转 - 这是AB-BA死锁的根本原因。'
- en: 'Furthermore, quite interestingly, soon after module insertion (with `lock_ooo`
    set to `1`), the kernel also detected a soft lockup bug. The printk is directed
    to our console at log level `KERN_EMERG`, allowing us to see this even though
    the system appears to be hung. It even shows the relevant kernel threads where
    the issue originated (again, this output is on my x86_64 Ubuntu 20.04 LTS VM running
    the custom 5.4.0 debug kernel):'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，非常有趣的是，模块插入后不久（`lock_ooo`设置为`1`），内核还检测到了软锁定错误。 printk被定向到我们的控制台，日志级别为`KERN_EMERG`，这使我们能够看到这一点，尽管系统似乎已经挂起。
    它甚至显示了问题的起源（再次强调，这个输出是在我的x86_64 Ubuntu 20.04 LTS VM上运行自定义5.4.0调试内核）的相关内核线程：
- en: '[PRE41]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: (FYI, the code that detected this and spewed out the preceding messages is here: `kernel/watchdog.c:watchdog_timer_fn()`).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: （FYI，检测到这一点并喷出前面的消息的代码在这里：`kernel/watchdog.c:watchdog_timer_fn()`）。
- en: 'One additional note: the `/proc/lockdep_chains` output also "proves" the incorrect
    locking sequence was taken (or exists):'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个注意事项：`/proc/lockdep_chains`的输出也“证明”了错误的锁定顺序被采用（或存在）：
- en: '[PRE42]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Also, recall that `lockdep` reports only once – the first time – that a lock
    rule on any kernel lock is violated.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 还要记住，`lockdep`仅在第一次违反任何内核锁的锁规则时报告一次。
- en: lockdep – annotations and issues
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: lockdep - 注释和问题
- en: Let's wrap up this coverage with a couple more points on the powerful `lockdep`
    infrastructure.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用一些关于强大的`lockdep`基础设施的要点来总结这一覆盖范围。
- en: lockdep annotations
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: lockdep注释
- en: In user space, you will be familiar with using the very useful `assert()` macro.
    There, you assert a Boolean expression, a condition (for example, `assert(p ==
    5);`). If the assertion is true at runtime, nothing happens and execution continues;
    when the assertion is false, the process is aborted and a noisy `printf()` to
    `stderr` indicates which assertion and where it failed. This allows developers
    to check for runtime conditions that they expect. Thus, assertions can be very
    valuable – they help catch bugs!
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 在用户空间，您可能熟悉使用非常有用的`assert()`宏。在那里，您断言一个布尔表达式，一个条件（例如，`assert(p == 5);`）。如果断言在运行时为真，则什么也不会发生，执行会继续；当断言为假时，进程将被中止，并且一个嘈杂的`printf()`会指示哪个断言以及它失败的位置。这允许开发人员检查他们期望的运行时条件。因此，断言可能非常有价值-它们有助于捕获错误！
- en: 'In a similar manner, `lockdep` allows the kernel developer to assert that a
    lock is held at a particular point, via the `lockdep_assert_held()` macro. This
    is called a **lockdep annotation**. The macro definition is displayed here:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，`lockdep`允许内核开发人员通过`lockdep_assert_held()`宏在特定点断言锁已被持有。这称为**lockdep注释**。宏定义如下所示：
- en: '[PRE43]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The assertion failing results in a warning (via `WARN_ON()`). This is very valuable
    as it implies that though that lock `l` is supposed to be held now, it really
    isn't. Also notice that these assertions only come into play when lock debugging
    is enabled (this is the default when lock debugging is enabled within the kernel;
    it only gets turned off when an error occurs within `lockdep` or the other kernel
    locking infrastructure). The kernel code base, in fact, uses `lockdep` annotations
    all over the place, both in the core as well as the driver code. (There are a
    few variations on the `lockdep` assertion of the form `lockdep_assert_held*()`
    as well as the rarely used `lockdep_*pin_lock()` macros.)
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 断言失败会导致警告（通过`WARN_ON()`）。这非常有价值，因为它意味着尽管现在应该持有锁`l`，但实际上并没有。还要注意，这些断言只在启用锁调试时才起作用（这是内核内启用锁调试时的默认设置；只有在`lockdep`或其他内核锁定基础设施发生错误时才会关闭）。事实上，内核代码库在核心和驱动程序代码中都广泛使用`lockdep`注释。（还有一些形式为`lockdep_assert_held*()`的`lockdep`断言的变体，以及很少使用的`lockdep_*pin_lock()`宏。）
- en: lockdep issues
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: lockdep问题
- en: 'A couple of issues can arise when working with `lockdep`:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`lockdep`时可能会出现一些问题：
- en: Repeated module loading and unloading can cause `lockdep`'s internal lock class
    limit to be exceeded (the reason, as explained within the kernel documentation,
    is that loading a `x.ko` kernel module creates a new set of lock classes for all
    its locks, while unloading `x.ko` does not remove them; it's actually reused).
    In effect, either don't repeatedly load/unload modules or reset the system.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复加载和卸载模块可能导致`lockdep`的内部锁类限制超出（如内核文档中所解释的那样，加载`x.ko`内核模块会为其所有锁创建一组新的锁类，而卸载`x.ko`则不会删除它们；实际上是重用）。实际上，要么不要重复加载/卸载模块，要么重置系统。
- en: Especially in those cases where a data structure has an enormous number of locks
    (such as an array of structures), failing to properly initialize every single
    lock can result in `lockdep` lock-class overflow.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特别是在数据结构具有大量锁（例如结构数组）的情况下，未能正确初始化每个锁可能会导致`lockdep`锁类溢出。
- en: The `debug_locks` integer is set to `0` whenever lock debugging is disabled
    (even on a debug kernel); this can result in this message showing up: `*WARNING*
    lock debugging disabled!! - possibly due to a lockdep warning`. This could even
    happen due to `lockdep` issuing warnings earlier. Reboot your system and retry.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: '`debug_locks`整数在禁用锁调试时设置为`0`（即使在调试内核上也是如此）；这可能会导致出现以下消息：`*WARNING* lock debugging
    disabled!! - possibly due to a lockdep warning`。这甚至可能是由于`lockdep`之前发出警告而发生的。重新启动系统并重试。'
- en: 'Though this book is based on the 5.4 LTS kernel, a powerful feature was (very
    recently as of the time of writing) merged into the 5.8 kernel: the **Kernel Concurrency
    Sanitizer** (**KCSAN**). It''s a data race detector for the Linux kernel that
    works via compile-time instrumentation. You can find more details in these LWN
    articles: *Finding race conditions with KCSAN*, LWN, October 2019 ([https://lwn.net/Articles/802128/](https://lwn.net/Articles/802128/))
    and *Concurrency bugs should fear the big bad data-race detector (part 1)*, LWN,
    April 2020 ([https://lwn.net/Articles/816850/](https://lwn.net/Articles/816850/)).'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书是基于5.4 LTS内核的，但在撰写时最近合并到5.8内核中的一个强大功能是**内核并发性检查器**（**KCSAN**）。这是Linux内核的数据竞争检测器，通过编译时插装工作。您可以在这些LWN文章中找到更多详细信息：*使用KCSAN查找竞争条件*，LWN，2019年10月（[https://lwn.net/Articles/802128/](https://lwn.net/Articles/802128/)）和*并发错误应该害怕大坏数据竞争检测器（第1部分）*，LWN，2020年4月（[https://lwn.net/Articles/816850/](https://lwn.net/Articles/816850/)）。
- en: Also, FYI, several tools do exist for catching locking bugs and deadlocks in *user
    space apps*. Among them are the well-known `helgrind` (from the Valgrind suite),
    **TSan** (**Thread Sanitizer**), which provides compile-time instrumentation to
    check for data races in multithreaded applications, and lockdep itself; lockdep
    can be made to work in user space as well (as a library)! Moreover, the modern
    [e]BPF framework provides the `deadlock-bpfcc(8)` frontend. It's designed specifically
    to find potential deadlocks (lock order inversions) in a given running process
    (or thread).
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，值得一提的是，存在一些工具用于捕获*用户空间应用程序*中的锁定错误和死锁。其中包括著名的`helgrind`（来自Valgrind套件）、**TSan**（**线程检测器**），它提供了编译时的仪器来检查多线程应用程序中的数据竞争，以及lockdep本身；lockdep也可以在用户空间中使用（作为库）！此外，现代的[e]BPF框架提供了`deadlock-bpfcc(8)`前端。它专门设计用于在给定运行进程（或线程）中找到潜在的死锁（锁定顺序倒置）。
- en: Lock statistics
  id: totrans-366
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 锁定统计
- en: A lock can be *contended*, which is when, a context wants to acquire the lock
    but it has already been taken, so it must wait for the unlock to occur. Heavy
    contention can create severe performance bottlenecks; the kernel provides lock
    statistics with a view *to easily identifying heavily contended locks*. Enable
    lock statistics by turning on the `CONFIG_LOCK_STAT` kernel configuration option (without
    this, the `/proc/lock_stat` entry will not be present, the typical case on most
    distribution kernels).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 锁定可能会*争用*，这是指当一个上下文想要获取锁，但它已经被占用，因此必须等待解锁发生。严重的争用可能会导致严重的性能瓶颈；内核提供了锁定统计，以便*轻松识别严重争用的锁*。通过打开`CONFIG_LOCK_STAT`内核配置选项来启用锁定统计（如果没有这个选项，在大多数发行版内核上，`/proc/lock_stat`条目将不存在）。
- en: The lock stats code takes advantage of the fact that `lockdep` inserts hooks
    into the locking code path (the `__contended`, `__acquired`, and `__released`
    hooks) to gather statistics at these crucial points. The neatly written kernel
    documentation on lock statistics ([https://www.kernel.org/doc/html/latest/locking/lockstat.html#lock-statistics](https://www.kernel.org/doc/html/latest/locking/lockstat.html#lock-statistics))
    conveys this information (and a lot more) with a useful state diagram; do look
    it up.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 锁定统计代码利用了`lockdep`在锁定代码路径（`__contended`，`__acquired`和`__released`钩子）中插入钩子来在这些关键点收集统计信息。关于锁定统计的精心编写的内核文档（[https://www.kernel.org/doc/html/latest/locking/lockstat.html#lock-statistics](https://www.kernel.org/doc/html/latest/locking/lockstat.html#lock-statistics)）传达了这些信息（以及更多）以及有用的状态图；请查阅。
- en: Viewing lock stats
  id: totrans-369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看锁定统计
- en: 'A few quick tips and essential commands to view lock statistics are as follows
    (this assumes, of course, that `CONFIG_LOCK_STAT` is on):'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 一些快速提示和查看锁定统计信息的基本命令如下（当然，这假设`CONFIG_LOCK_STAT`已经打开）：
- en: '| **Do what?** | **Command** |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| **做什么？** | **命令** |'
- en: '| Clear lock stats | `sudo sh -c "echo 0 > /proc/lock_stat"` |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 清除锁定统计 | `sudo sh -c "echo 0 > /proc/lock_stat"` |'
- en: '| Enable lock stats | `sudo sh -c "echo 1 > /proc/sys/kernel/lock_stat"` |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 启用锁定统计 | `sudo sh -c "echo 1 > /proc/sys/kernel/lock_stat"` |'
- en: '| Disable lock stats | `sudo sh -c "echo 0 > /proc/sys/kernel/lock_stat"` |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 禁用锁定统计 | `sudo sh -c "echo 0 > /proc/sys/kernel/lock_stat"` |'
- en: 'Next, a simple demo to see locking statistics: we write a very simple Bash
    script, `ch13/3_lockdep/lock_stats_demo.sh` (check out its code in this book''s
    GitHub repo). It clears and enables locking statistics, then simply runs the `cat
    /proc/self/cmdline` command. This will actually trigger a chain of code to run
    deep within the kernel (within `fs/proc` mostly); several global – shared writable
    – data structures will need to be looked up. This will constitute a critical section
    and thus locks will be acquired. Our script will disable lock stats, and then
    grep the locking statistics to see a few locks, filtering out the rest:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，一个简单的演示来查看锁定统计信息：我们编写一个非常简单的Bash脚本，`ch13/3_lockdep/lock_stats_demo.sh`（在本书的GitHub存储库中查看其代码）。它清除并启用锁定统计，然后简单地运行`cat
    /proc/self/cmdline`命令。这实际上会触发内核深处的一系列代码运行（主要在`fs/proc`内）；需要查找几个全局的可写数据结构。这将构成一个关键部分，因此将会获取锁。我们的脚本将禁用锁定统计，然后使用grep命令查看一些锁定统计信息，过滤掉其余的部分：
- en: '[PRE44]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'On running it, the output we obtained is as follows (again, on our x86_64 Ubuntu
    20.04 LTS VM running our custom 5.4.0 debug kernel):'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 运行后，我们得到的输出如下（同样，在我们的x86_64 Ubuntu 20.04 LTS VM上运行我们的自定义5.4.0调试内核）：
- en: '![](img/20d96e77-c316-468f-b4d2-5eb8cd5cb015.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![](img/20d96e77-c316-468f-b4d2-5eb8cd5cb015.png)'
- en: Figure 7.11 – Screenshot showing our lock_stats_demo.sh script running, displaying
    some of the lock statistics
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11 - 屏幕截图显示我们的lock_stats_demo.sh脚本运行，显示一些锁定统计信息
- en: '(The output in *Figure 7.11* is pretty long horizontally and thus wraps.) The
    time displayed is in microseconds. The `class name` field is the lock class; we
    can see several locks associated with the task and memory structures (`task_struct`
    and `mm_struct`)! Instead of duplicating the material, we refer you to the kernel documentation
    on lock statistics, which explains each of the preceding fields (`con-bounces`,
    `waittime*`, and so on; hint: `con` is short for contended) and how to interpret
    the output. As expected, see, in *Figure 7.11*, in this simple case, the following:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: （*图7.11*中的输出在水平上相当长，因此换行。）显示的时间单位是微秒。`class name`字段是锁类；我们可以看到与任务和内存结构（`task_struct`和`mm_struct`）相关的几个锁！我们不会重复材料，而是建议您查阅锁定统计的内核文档，该文档解释了前述字段（`con-bounces`，`waittime*`等）以及如何解释输出。正如预期的那样，在*图7.11*中，在这种简单情况下，以下内容：
- en: The first field, `class_name`, is the lock class; the (symbolic) name of the
    lock is seen here.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个字段`class_name`是锁类；这里看到了锁的（符号）名称。
- en: There's really no contention for locks (fields 2 and 3).
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际上没有锁的争用（字段2和3）。
- en: The wait times (`waittime*`, fields 3 to 6) are 0.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待时间（`waittime*`，字段3到6）为0。
- en: The `acquisitions` field (#9) is the total number of times the lock was acquired
    (taken); it's positive (and even goes to over 300 for mm_struct semaphore `&mm->mmap_sem*`).
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acquisitions`字段（＃9）是锁定被获取（占用）的总次数；它是正数（甚至对于`mm_struct`信号量`&mm->mmap_sem*`，它甚至超过了300）。'
- en: The last four fields, 10 to 13, are the cumulative lock hold time statistics
    (`holdtime-{min|max|total|avg}`). Again, here, you can see that mm_struct `mmap_sem*` locks
    have the longest average hold time.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后的四个字段，10到13，是累积锁持有时间统计（`holdtime-{min|max|total|avg}`）。同样，在这里，您可以看到mm_struct
    `mmap_sem*` 锁的平均持有时间最长。
- en: (Notice the task structure's spinlock named `alloc_lock` is taken as well; we
    came across it in the *Example 1 – catching a self deadlock bug with lockdep* section).
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （请注意，任务结构的自旋锁命名为`alloc_lock`也被占用；我们在*示例1 - 使用lockdep捕获自死锁错误*部分遇到了它）。
- en: The most contended locks on the system can be looked up via `sudo grep ":" /proc/lock_stat
    | head`. Of course, you should realize that this is from when the locking statistics
    were last reset (cleared).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过 `sudo grep ":" /proc/lock_stat | head` 查找系统上争用最激烈的锁。当然，您应该意识到这是上次重置（清除）锁统计信息时的情况。
- en: 'Note that lock statistics can get disabled due to lock debugging being disabled;
    for example, you might come across this:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于锁调试被禁用，锁统计信息可能会被禁用；例如，您可能会遇到这种情况：
- en: '[PRE45]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This warning might necessitate you rebooting the system.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 这个警告可能需要您重新启动系统。
- en: All right, you're almost there! Let's finish this chapter with some brief coverage
    of memory barriers.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，您离成功不远了！让我们以对内存屏障的简要介绍结束本章。
- en: Memory barriers – an introduction
  id: totrans-392
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存屏障 - 介绍
- en: Last but not least, let's briefly address another concern – that of the **memory
    barrier**. What does it mean? Sometimes, a program flow becomes unknown to the
    human programmer as the microprocessor, the memory controllers, and the compiler *can
    reorder* memory reads and writes. In the majority of cases, these "tricks" remain
    benign and optimized. But there are cases – typically across hardware boundaries,
    such as CPU cores on multicore systems, CPU to peripheral device, and vice versa
    on **UniProcessor** (**UP**) – where this reordering *should not occur*; the original
    and intended memory load and store sequences must be honored. The *memory barrier* (typically
    machine-level instructions embedded within the `*mb*()` macros) is a means to
    suppress such reordering; it's a way to force both the CPU/memory controllers
    and the compiler to order instruction/data in a desired sequence.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，让我们简要讨论另一个问题 - **内存屏障**。这是什么意思？有时，程序流对人类程序员来说变得不可知，因为微处理器、内存控制器和编译器*可以重新排序*内存读取和写入。在大多数情况下，这些“技巧”保持良性并且被优化。但是有些情况
    - 通常跨硬件边界，例如多核系统上的CPU核心、CPU到外围设备，以及反之亦然的**UniProcessor**（**UP**） - 在这些情况下，这种重新排序*不应该发生*；必须遵守原始和预期的内存加载和存储顺序。*内存屏障*（通常是嵌入在`*mb*()`宏中的机器级指令）是一种抑制这种重新排序的方法；它是一种强制CPU/内存控制器和编译器按照所需的顺序对指令/数据进行排序的方法。
- en: 'Memory barriers can be placed into the code path by using the following macros: `#include
    <asm/barrier.h>`:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用以下宏将内存屏障放入代码路径中：`#include <asm/barrier.h>`：
- en: '`rmb()`: Inserts a read (or load) memory barrier into the instruction stream'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rmb()`: 将读（或加载）内存屏障插入指令流中'
- en: '`wmb()`: Inserts a write (or store) memory barrier into the instruction stream'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wmb()`: 将写（或存储）内存屏障插入指令流中'
- en: '`mb()`: A general memory barrier; quoting directly from the kernel documentation
    on memory barriers ([https://www.kernel.org/doc/Documentation/memory-barriers.txt](https://www.kernel.org/doc/Documentation/memory-barriers.txt)), "*A
    general memory barrier gives a guarantee that all the LOAD and STORE operations
    specified before the barrier will appear to happen before all the LOAD and STORE
    operations specified after the barrier with respect to the other components of
    the system*."'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mb()`: 通用内存屏障；直接引用内存屏障的内核文档（[https://www.kernel.org/doc/Documentation/memory-barriers.txt](https://www.kernel.org/doc/Documentation/memory-barriers.txt)）上的话，"*通用内存屏障保证在屏障之前指定的所有LOAD和STORE操作将在系统的其他组件方面发生在屏障之后指定的所有LOAD和STORE操作之前*。"'
- en: The memory barrier ensures that unless the preceding instruction or data access
    executes, the following ones will not, thus maintaining the ordering. On some
    (rare) occasions, DMA being the likely one, driver authors use memory barriers.
    When using DMA, it's important to read the kernel documentation ([https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt](https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt)).
    It mentions where memory barriers are to be used and the perils of not using them;
    see the example that follows for more on this.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 内存屏障确保在执行前面的指令或数据访问之前，后续的指令不会执行，从而保持顺序。在某些（罕见）情况下，DMA可能是其中之一，驱动程序作者使用内存屏障。在使用DMA时，重要的是阅读内核文档（[https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt](https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt)）。它提到了内存屏障的使用位置以及不使用它们的危险；有关此内容的更多示例，请参见以下内容。
- en: As the placement of memory barriers is typically a fairly perplexing thing to
    get right for many of us, we urge you to refer to the relevant technical reference
    manual for the processor or peripheral you're writing a driver for, for more details.
    For example, on the Raspberry Pi, the SoC is the Broadcom BCM2835 series; referring
    to its peripherals manual – the *BCM2835 ARM Peripherals* manual ([https://www.raspberrypi.org/app/uploads/2012/02/BCM2835-ARM-Peripherals.pdf](https://www.raspberrypi.org/app/uploads/2012/02/BCM2835-ARM-Peripherals.pdf)), section 1.3,
    *Peripheral access precautions for correct memory ordering* – is helpful to sort
    out when and when not to use memory barriers.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 由于内存屏障的放置通常对我们中的许多人来说是一个相当令人困惑的事情，我们建议您参考为您编写驱动程序的处理器或外围设备的相关技术参考手册，以获取更多详细信息。例如，在树莓派上，SoC是Broadcom
    BCM2835系列；参考其外围设备手册 - *BCM2835 ARM Peripherals* 手册（[https://www.raspberrypi.org/app/uploads/2012/02/BCM2835-ARM-Peripherals.pdf](https://www.raspberrypi.org/app/uploads/2012/02/BCM2835-ARM-Peripherals.pdf)），第1.3节，*正确内存排序的外围设备访问注意事项*
    - 有助于弄清何时以及何时不使用内存屏障。
- en: An example of using memory barriers in a device driver
  id: totrans-400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在设备驱动程序中使用内存屏障的示例
- en: 'As one example, take the Realtek 8139 "fast Ethernet" network driver. In order
    to transmit a network packet via DMA, it must first set up a DMA (transmit) descriptor
    object. For this particular hardware (NIC chip), the DMA descriptor object is
    defined as follows:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，以Realtek 8139“快速以太网”网络驱动程序为例。为了通过DMA传输网络数据包，必须首先设置DMA（传输）描述符对象。对于这个特定的硬件（NIC芯片），DMA描述符对象定义如下：
- en: '[PRE46]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The DMA descriptor object, christened `struct cp_desc`, has three "words."
    Each of them has to be initialized. Now, to ensure that the descriptor is correctly
    interpreted by the DMA controller, it''s often critical that the writes to the
    DMA descriptor are seen in the same order as the driver author intends. To guarantee
    this, memory barriers are used. In fact, the relevant kernel documentation – the
    *Dynamic DMA mapping Guide* ([https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt](https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt))
    – tells us to ensure that this is indeed the case. So, for example, when setting
    up the DMA descriptor, you must code it as follows to get correct behavior on
    all platforms:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: DMA描述符对象，被命名为`struct cp_desc`，有三个“单词”。每个单词都必须初始化。现在，为了确保DMA控制器正确解释描述符，通常至关重要的是看到对DMA描述符的写入与驱动程序作者的意图相同的顺序。为了保证这一点，使用了内存屏障。事实上，相关的内核文档
    - *动态DMA映射指南*（[https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt](https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt)）告诉我们确保这确实是这种情况。因此，例如，当设置DMA描述符时，您必须将其编码如下，以在所有平台上获得正确的行为：
- en: '[PRE47]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Thus, check out how the DMA transmit descriptor is set up in practice (by the
    Realtek 8139 driver code, as follows):'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，看看实践中如何设置DMA传输描述符（由Realtek 8139驱动程序代码，如下）：
- en: '[PRE48]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: The driver, acting upon what the chip's datasheet requires, requires that the
    words `txd->opts2` and `txd->addr` are stored to memory, followed by the storage
    of the `txd->opts1` word. As *the order in which these writes go through is important*, the
    driver makes use of the `wmb()` write memory barrier. (Also, FYI, RCU is certainly
    a user of appropriate memory barriers to enforce memory ordering.)
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 根据芯片的数据表要求，驱动程序要求将单词`txd->opts2`和`txd->addr`存储到内存中，然后存储`txd->opts1`单词。由于*这些写入的顺序很重要*，驱动程序使用`wmb()`写内存屏障。
    （另外，FYI，RCU当然是适当内存屏障的用户，以强制执行内存排序。）
- en: Furthermore, using the `READ_ONCE()` and `WRITE_ONCE()` macros on individual
    variables *absolutely guarantees that the compiler and the CPU will do what you
    mean*. It will preclude compiler optimizations as required, use memory barriers
    as required, and guarantee cache coherency when multiple threads on different
    cores simultaneously access the variable in question.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对于单个变量，使用`READ_ONCE()`和`WRITE_ONCE()`宏*绝对保证编译器和CPU会执行你的意图*。它将排除所需的编译器优化，使用所需的内存屏障，并在多个核上的多个线程同时访问所涉及的变量时保证缓存一致性。
- en: For details, do refer to the kernel documentation on memory barriers ([https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt](https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt)).
    It has a detailed section entitled *WHERE ARE MEMORY BARRIERS NEEDED?*. The good
    news is that it's mostly taken care of under the hood; for a driver author, it's
    only when performing operations such as setting up DMA descriptors or initiating
    and ending CPU-to-peripheral (and vice versa) communication that you might require
    a barrier.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 有关详细信息，请参阅内核文档中关于内存屏障的部分（[https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt](https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt)）。大部分情况下，这些都是在幕后处理的；对于驱动程序作者来说，只有在执行操作，如设置DMA描述符或启动和结束CPU到外围设备（反之亦然）的通信时，才可能需要内存屏障。
- en: 'One last thing – an (unfortunate) FAQ: will using the `volatile` keyword magically
    make concurrency concerns disappear? Of course not. The `volatile` keyword merely
    instructs the compiler to disable common optimizations around that variable (things
    outside this code path could also modify the variable marked as `volatile`), that''s
    all. This is often required and useful when working with MMIO. With regard to
    memory barriers, interestingly, the compiler won''t reorder reads or writes on
    a variable marked as `volatile` with respect to other volatile variables. Still,
    atomicity is a separate construct, *not* guaranteed by using the `volatile` keyword.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一件事 - 一个（不幸的）常见问题：使用`volatile`关键字会神奇地使并发问题消失吗？当然不会。`volatile`关键字只是指示编译器禁用围绕该变量的常见优化（此代码路径之外的事物也可能修改标记为`volatile`的变量），仅此而已。在处理MMIO时，这通常是必需的和有用的。关于内存屏障，有趣的是，编译器不会重新排序对于其他`volatile`变量标记的变量的读取或写入。然而，原子性是一个单独的构造，*不能*通过使用`volatile`关键字来保证。
- en: Summary
  id: totrans-411
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Well, what do you know!? Congratulations, you have done it, you have completed
    this book!
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，你知道吗！恭喜你，你做到了，你完成了这本书！
- en: In this chapter, we continued from the previous chapter in our quest to learn
    more about kernel synchronization. Here, you learned how to more efficiently and
    safely perform locking on integers, via both `atomic_t` and the newer `refcount_t`
    interface. Within this, you learned how the typical RMW sequence can be atomically
    and safely employed in a common activity for driver authors – updating a device's
    registers. The reader-writer spinlock, interesting and useful, though with several
    caveats, was then covered. You saw how easy it is to mistakenly create adverse
    performance issues caused by unfortunate caching side effects, including looking
    at the false sharing problem and how to avoid it.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们继续了上一章的内容，继续学习有关内核同步的知识。在这里，您学会了如何通过`atomic_t`和更新的`refcount_t`接口更有效地和安全地对整数进行锁定。在其中，您了解了典型的RMW序列如何在驱动程序作者的常见活动中被原子化和安全地使用
    - 更新设备的寄存器。然后介绍了读者-写者自旋锁，这是一个有趣且有用的内容，尽管有一些注意事项。您将看到，由于不幸的缓存副作用，很容易错误地产生性能问题，包括查看伪共享问题以及如何避免它。
- en: A boon to developers – lock-free algorithms and programming techniques – was
    then covered in some detail, with a focus on per-CPU variables within the Linux
    kernel. It's important to learn how to use these carefully (especially the more
    advanced forms such as RCU). Finally, you learned what memory barriers are and
    where they are typically used.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者的福音——无锁算法和编程技术——然后详细介绍了Linux内核中的每CPU变量。重要的是要学会如何谨慎地使用这些技术（尤其是更高级的形式，如RCU）。最后，您将了解内存屏障是什么，它们通常在哪里使用。
- en: Your long journey in working within the Linux kernel (and related areas, such
    as device drivers) has begun in earnest now. Do realize, though, that without
    constant hands-on practice and actually working on these materials, the fruits
    quickly fade away... I urge you to stay in touch with these topics and others.
    As you grow in knowledge and experience, contributing to the Linux kernel (or
    any open source project for that matter) is a noble endeavor, one you would do
    well to undertake.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 您在Linux内核（以及相关领域，如设备驱动程序）中的长期工作之旅现在已经认真开始了。请注意，没有不断的动手实践和实际操作这些材料，成果很快就会消失……我敦促您与这些主题和其他主题保持联系。随着您的知识和经验的增长，为Linux内核（或任何开源项目）做出贡献是一项高尚的努力，您最好能够承担起这项任务。
- en: Questions
  id: totrans-416
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: As we conclude, here is a list of questions for you to test your knowledge regarding
    this chapter's material: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions).
    You will find some of the questions answered in the book's GitHub repo: [https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn).
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这里有一些问题供您测试对本章材料的了解：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/questions)。您会发现一些问题的答案在书的GitHub存储库中：[https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming/tree/master/solutions_to_assgn)。
- en: Further reading
  id: totrans-418
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: To help you delve deeper into the subject with useful materials, we provide
    a rather detailed list of online references and links (and at times, even books)
    in a Further reading document in this book's GitHub repository. The *Further reading*
    document is available here: [https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md).
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助您深入学习这个主题，我们在本书的GitHub存储库中提供了一个相当详细的在线参考和链接列表（有时甚至包括书籍）。*进一步阅读*文档在这里可用：[https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md](https://github.com/PacktPublishing/Linux-Kernel-Programming/blob/master/Further_Reading.md)。
