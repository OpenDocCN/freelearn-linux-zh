- en: Multithreading with Pthreads Part II - Synchronization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Pthreads进行多线程编程第二部分-同步
- en: One of the key reasons that multithreading is powerful and makes a big impact
    performance-wise is that it lends itself to the notion of parallelism or concurrency;
    from what we learned in the previous [Chapter 14](586f3099-3953-4816-8688-490c9cf2bfd7.xhtml),
    *Multithreading with Pthreads Part I - Es**sential**s*, we understand that multiple
    threads of a process can (and indeed do) execute in parallel. On large multicore
    systems (multicore is pretty much the norm now, even in embedded systems), the
    effect is magnified.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 多线程强大并且在性能上产生巨大影响的一个关键原因是它适用于并行或并发的概念；根据我们在之前的[第14章]中学到的，*使用Pthreads进行多线程编程第一部分-基础*，我们了解到一个进程的多个线程可以（而且确实）并行执行。在大型多核系统上（多核现在几乎是标准，即使在嵌入式系统中），效果会被放大。
- en: However, as experience teaches us, there's always a trade-off. With parallelism
    comes the ugly potential for races and the subsequent defects. Not only that,
    situations like this typically become extremely hard to debug, and therefore,
    fix.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，正如经验告诉我们的那样，总是存在权衡。并行性带来了丑陋的竞争和随后的缺陷的潜在可能。不仅如此，这种情况通常变得极其难以调试，因此也难以修复。
- en: 'In this chapter, we shall attempt to:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将尝试：
- en: Make the reader aware as to where and what exactly these concurrency (race)
    defects are
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让读者了解并发（竞争）缺陷的位置和具体内容
- en: How to avoid them with good design and coding practices in multithreaded applications
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何通过良好的设计和编码实践在多线程应用程序中避免这些问题
- en: 'Again, this chapter divides itself into two broad areas:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，本章分为两个广泛的领域：
- en: In the first part, we clearly explain the problem(s), such as how atomicity matters
    and deadlock issues.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一部分中，我们清楚地解释了问题，比如原子性的重要性和死锁问题。
- en: in the latter part of this chapter, we present the locking (and other) mechanisms
    that the pthreads API set makes available to the application developer to help
    tackle and avoid these issues altogether.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本章的后半部分，我们将介绍pthread API集提供给应用程序开发人员的锁定（和其他）机制，以帮助解决和完全避免这些问题。
- en: The racing problem
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 竞争问题
- en: First and foremost, let's attempt to understand what and where exactly the problem we
    are trying to resolve is. In the previous chapter, we learned that all threads
    of a process share everything except for the stack; each thread has its own private
    stack memory space.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们尝试理解我们试图解决的问题是什么以及问题的确切位置。在上一章中，我们了解到一个进程的所有线程除了堆栈之外都共享一切；每个线程都有自己的私有堆栈内存空间。
- en: 'Look carefully again at [Chapter 14](586f3099-3953-4816-8688-490c9cf2bfd7.xhtml),
    *Multithreading with Pthreads Part I-Essentials: Fig 2*, (leaving out the kernel
    stuff); the virtual address space—the text and data segments, but not the stack
    segment—are shared between all threads of a process. The data segment, of course,
    is where global and static variables reside.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细再看一下[第14章]，*使用Pthreads进行多线程编程第一部分-基础：图2*（省略内核内容）；虚拟地址空间-文本和数据段，但不包括堆栈段-在一个进程的所有线程之间共享。数据段当然是全局和静态变量所在的地方。
- en: 'At the risk of overstating these facts, this implies that all the threads of
    a given process truly (if not poss, then make COW also normal font not **Copy
    On Write** (**COW**)) share the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 冒着过分强调这些事实的风险，这意味着给定进程的所有线程真正（如果不可能，则使COW也成为正常字体而不是**写时复制**（COW））共享以下内容：
- en: The text segment
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本段
- en: The data segments—initialized data, uninitialized data (earlier referred to
    as the BSS), and the heap segment
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据段-初始化数据，未初始化数据（之前称为BSS）和堆段
- en: 'Pretty much all the kernel-level objects and data maintained for the process
    by the OS (again, refer to [Chapter 14](586f3099-3953-4816-8688-490c9cf2bfd7.xhtml), *Multithreading
    with Pthreads Part I-Essentials* *: Fig 2*)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 几乎所有由操作系统维护的进程的内核级对象和数据（再次参考[第14章]，*使用Pthreads进行多线程编程第一部分-基础*：图2*）
- en: 'A really important point to understand is that sharing the text segment is not
    a problem at all. Why? Text is code; the machine code—the opcodes and operands
    that make up what we call the machine language — reside in these memory pages.
    Recall from [Chapter 2](976fc2af-8bb4-4060-96cd-3b921682ed75.xhtml), *Virtual
    Memory*, that all pages of text (code) have the same permissions: **read-execute**
    (**r-x**). This is important, since multiple threads executing text (code) in
    parallel is not only fine—it''s encouraged! This is what parallelism is all about,
    after all. Think about it; if we only read and execute code, we do not modify
    it in any manner whatsoever; therefore, it''s completely safe, even when being
    executed in parallel.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常重要的理解点是共享文本段根本不是问题。为什么？文本是代码；机器代码-构成我们所谓的机器语言的操作码和操作数-驻留在这些内存页中。回想一下[第2章]，*虚拟内存*，所有文本（代码）的页面都具有相同的权限：**读-执行**（r-x）。这很重要，因为多个线程并行执行文本（代码）不仅是可以的-而且是鼓励的！毕竟，这就是并行性的全部意义。想想看；如果我们只读取和执行代码，我们不以任何方式修改它；因此，即使在并行执行时，它也是完全安全的。
- en: 'On the other hand, data pages have permissions of **read-write** (**rw**). This
    implies that a thread, A, working on a page of data in parallel—concurrently with
    another thread, B,—is inherently dangerous. Why? It''s fairly intuitive: they
    can end up clobbering the memory values within the page. (One can imagine both
    threads writing to, for example, a global linked list simultaneously.) The key
    point is that shared writable memory has to be protected against concurrent access
    so that data integrity is preserved at all times.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，数据页的权限为**读-写**（rw）。这意味着一个线程A与另一个线程B并行工作在一个数据页上时是固有的危险。为什么？这是相当直观的：它们可能会破坏页面内的内存值。（可以想象两个线程同时写入全局链表，例如。）关键点是，共享的可写内存必须受到保护，以防止并发访问，以便始终保持数据完整性。
- en: To really understand why we care so much about these issues, please read on.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要真正理解为什么我们如此关心这些问题，请继续阅读。
- en: Concurrency and atomicity
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并发和原子性
- en: Concurrent execution implies that multiple threads can run truly in parallel
    on multiple CPU cores. When this happens on text (code), it's good; we get higher
    throughput. However, the moment we run concurrently while working on shared writable
    data, we will have a problem with data integrity. This is because text is read-only
    (and executable), whereas data is read-write.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 并发执行意味着多个线程可以在多个CPU核心上真正并行运行。当这在文本（代码）上发生时，这是好事；我们获得了更高的吞吐量。然而，一旦我们在处理共享可写数据时并发运行，我们将遇到数据完整性的问题。这是因为文本是只读的（和可执行的），而数据是可读写的。
- en: 'What we would really like, of course, is to be greedy and have the best of
    both worlds: execute code concurrently via multiple threads, but the moment we
    must work on shared data, stop the concurrency (parallelism), and have just one
    thread run through the data section sequentially until it''s done, then resume
    parallel execution.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们真正想要的是贪婪地同时拥有两全其美的情况：通过多个线程并发执行代码，但是在必须处理共享数据的时候停止并发（并行），并且只有一个线程按顺序运行数据部分，直到完成，然后恢复并行执行。
- en: The pedagogical bank account example
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教学银行账户示例
- en: A classic (pedagogical) example is that of the faulty bank account software
    application. Imagine that Kaloor (needless to say, fictional names and figures
    have been employed here), a freelance sculptor, has an account with his bank;
    his current balance is $12,000.00\. Two transactions, deposits of $3,000 and $8,000,
    which are payments for work he has successfully completed, are issued simultaneously. It
    does not take a genius to see that (assuming that there are no other transactions),
    very soon, his account balance should reflect an amount of $23,000.00.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个经典（教学）例子是有缺陷的银行账户软件应用。想象一下，卡卢尔（不用说，这里使用了虚构的名字和数字），一个自由职业的雕塑家，有一个银行账户；他目前的余额是12000.00美元。同时发生了两笔交易，分别是3000美元和8000美元的存款，这是他成功完成工作的付款。毫无疑问，很快，他的账户余额应该反映出23000.00美元的金额（假设没有其他交易）。
- en: For the purpose of this example, let's visualize that the banking software application
    is a multithreaded process; to keep things very simple, we consider that a thread
    is spawned off to handle a transaction. The server system that the software runs
    upon is a powerful multicore machine—it has, say, 12 CPU cores. This, of course,
    implies that threads can run in parallel on different cores simultaneously.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了这个例子，让我们想象银行软件应用是一个多线程进程；为了保持简单，我们考虑一个线程被分派来处理一个交易。软件运行的服务器系统是一台强大的多核机器——它有12个CPU核心。当然，这意味着线程可以同时在不同的核心上并行运行。
- en: 'So, let''s visualize that for each of Kaloor''s transactions we have a thread
    running to perform it—thread A and thread B. Thread A (running on, say, CPU #0)
    works upon the first deposit of $3,000 and thread B (running on, say, CPU #1)
    works upon the (almost immediate) second deposit of $8,000.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们想象一下，对于卡卢尔的每一笔交易，我们都有一个线程在运行来执行它——线程A和线程B。线程A（在CPU＃0上运行）处理3000美元的第一笔存款，而线程B（在CPU＃1上运行）处理（几乎立即的）8000美元的第二笔存款。
- en: 'We consider two cases here:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里考虑两种情况：
- en: 'The case where, by chance, the transactions go through successfully. The following
    diagram clearly shows this case:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偶然情况下，交易成功进行。下图清楚地显示了这种情况：
- en: '![](img/d972a362-4cc9-438d-b07a-427fa3231681.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d972a362-4cc9-438d-b07a-427fa3231681.png)'
- en: 'Figure 1: The bank account; correct, by chance'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：银行账户；由于偶然而正确
- en: 'The case where, again by chance, the transactions do not go through successfully.
    The following diagram shows this case:'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再次偶然情况下，交易不成功进行。下图显示了这种情况：
- en: '![](img/286e0061-b9fd-4086-b167-6d94cd2df5c1.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](img/286e0061-b9fd-4086-b167-6d94cd2df5c1.png)'
- en: 'Figure 2: The bank account; incorrect, by chance'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：银行账户；由于偶然而不正确
- en: 'The problem area is highlighted in the preceding tables: It''s quite clear
    that thread B has performed an invalid read on the balance—it has read a stale
    value of $12,000 (the value as of time **t4**) instead of fetching the actual
    current value of $15,000—resulting in an effective loss of $3,000 for poor Kaloor.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的表格中，问题区域已经被突出显示：很明显，线程B已经对余额进行了无效读取——它读取了12000美元的陈旧值（**t4时刻**的值），而不是获取实际的当前值15000美元，导致卡卢尔损失了3000美元。
- en: 'How did this happen? In a nutshell, a race condition has caused the problem.
    To understand the race, look carefully at the preceding table and visualize the
    activity:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是怎么发生的？简而言之，竞争条件导致了问题。要理解这场竞赛，请仔细看前面的表格并想象活动：
- en: 'The variable representing the current balance in the account; balance is global:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代表账户当前余额的变量；余额是全局的：
- en: It is residing in the data segment
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它位于数据段中
- en: It is shared by all threads of the process
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它被进程的所有线程共享
- en: '**At time t3**, **thread A on CPU #0**: A deposit of $3,000 is made; the `balance`
    is still $12,000 (not updated yet)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在t3时刻**，**CPU＃0上的线程A**：存款3000美元；`余额`仍然是12000美元（尚未更新）'
- en: '**At time t4**, **thread B on CPU #1**: A deposit of $8,000 is made; the balance
    is still $12,000 (not updated yet)'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在t4时刻**，**CPU＃1上的线程B**：存款8000美元；余额仍然是12000美元（尚未更新）'
- en: '**At time t5**:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在t5时刻**：'
- en: 'Thread A on CPU #0: update the balance'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU＃0上的线程A：更新余额
- en: 'Simultaneously, but on the other core:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同时，但在另一个核心上：
- en: 'Thread B on CPU #1: update the balance'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU＃1上的线程B：更新余额
- en: 'By chance, what if thread B ran on CPU #1 a few microseconds before thread
    A on CPU #0 could update the balance variable!?'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 偶然情况下，如果线程B在CPU＃1上比线程A在CPU＃0上更新`余额`变量早了几微秒！？
- en: Then, thread B reads the balance as $12,000 ($3,000 short!) This is called a
    dirty readand is at the heart of the problem. This very situation is called a
    race; a race being a situation in which the outcome is undefined and unpredictable. In
    most cases, this will be a problem (as it is here); in some rare cases where it
    does not matter, it's referred to as a benign race.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，线程B读取余额为12000美元（少了3000美元！）这被称为脏读，是问题的核心。这种情况被称为竞争；竞争是一种结果不确定和不可预测的情况。在大多数情况下，这将是一个问题（就像这里一样）；在一些罕见的情况下，这并不重要，被称为良性竞争。
- en: The fact to be emphasized is that the operation of depositing funds and updating
    the balance (or the converse, withdrawing funds and updating the balance) has
    to be guaranteed to be atomic. They cannot race, as that would be a defect (a
    bug).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 需要强调的事实是，存款和更新余额（或相反，取款和更新余额）的操作必须保证是原子的。它们不能竞争，因为那将是一个缺陷（错误）。
- en: The phrase atomic operation (or atomicity) in a software programming context
    implies that the operation, once begun, will run to completion without interruption.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 短语原子操作（或原子性）在软件编程上下文中意味着一旦开始，操作将在没有中断的情况下完成。
- en: Critical sections
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 临界区
- en: 'How do we fix the preceding race? It''s quite straightforward, really: we have
    to ensure that, as stated earlier, the banking operations—deposits, withdrawals,
    and so on—are guaranteed to do two things:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何修复前面的竞争？这实际上非常简单：我们必须确保，如前所述，银行操作 - 存款、取款等 - 被保证执行两件事：
- en: Be the only thread running the code at that point in time
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成为在那个时间点上运行代码的唯一线程
- en: Be atomic — run to completion, without interruption
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原子性 - 完成，不中断
- en: Once this is achieved, the shared data will be safe from corruption. The section
    of code that must run in the fashion described previously is called a critical
    section.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦实现了这一点，共享数据将不受损坏。必须以前述方式运行的代码部分称为临界区。
- en: 'In our fictional banking application, the threads running the code to perform
    a banking operation (a deposit or a withdrawal) must do so in a critical section,
    shown as follows:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们虚构的银行应用程序中，运行执行银行操作（存款或取款）的线程必须在临界区中执行，如下所示：
- en: '![](img/4f210b98-b336-46d2-b12e-96597699f140.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/4f210b98-b336-46d2-b12e-96597699f140.png)
- en: 'Figure 3: The critical section'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：临界区
- en: 'So, now, let''s say that the banking application is corrected to take these
    facts into account; the vertical timeline execution path of thread A and thread
    B would now be as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设银行应用程序已经根据这些事实进行了更正；线程A和线程B的垂直时间线执行路径现在如下：
- en: '![](img/6e4698e1-51d8-4dec-914b-66b6eaf8efd4.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/6e4698e1-51d8-4dec-914b-66b6eaf8efd4.png)
- en: 'Fig 4: Correct banking application—critical section'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：正确的银行应用程序 - 临界区
- en: Here, both thread A and thread B, once they begin their (deposit) operations,
    run it alone and to completion (without interruption); hence, sequentially and
    atomically.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，一旦线程A和线程B开始它们的（存款）操作，它们就会独自完成（不中断）；因此，按顺序和原子方式。
- en: 'To sum this up:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下：
- en: 'A critical section is code that must:'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 临界区是必须的代码：
- en: Run without interference from other threads in the process (as it works upon
    some shared resource such as global data)
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在处理一些共享资源（如全局数据）时，不受其他线程的干扰运行
- en: Run atomically (to completion, without interruption)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原子地运行（完成，不中断）
- en: If the code of the critical section can run in parallel with other threads,
    this is a defect (a bug), called a race
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果临界区的代码可以与其他线程并行运行，这是一个缺陷（错误），称为竞争。
- en: To prevent races, we have to guarantee that the code of the critical section
    runs alone and atomically
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了防止竞争，我们必须保证临界区的代码独立和原子地运行
- en: To do so, we must synchronize critical sections
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为此，我们必须同步临界区
- en: 'Now, the question is: how do we synchronize a critical section? Read on.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，问题是：我们如何同步临界区？继续阅读。
- en: Locking concepts
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁定概念
- en: There are several forms of synchronization in software; one of the commonly
    encountered ones, and indeed one that we shall be working with quite a bit, is
    called **locking**. A lock, in programming terms, and as seen by the application
    developer, is ultimately a data structure instantiated as a variable.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 软件中有几种形式的同步；其中一种常见的形式，也是我们将要大量使用的一种，称为**锁定**。在编程术语中，锁，如应用程序开发人员所见，最终是作为变量实例化的数据结构。
- en: When one requires a critical section, just encapsulate the code of the critical
    section between a lock and a corresponding unlock operation. (For now, don't worry
    about the code-level API details; we shall cover that later. Here, we are just
    focusing on getting the concepts right.)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要临界区时，只需将临界区的代码封装在锁和相应的解锁操作之间。（现在，不要担心代码级API细节；我们稍后会涵盖。在这里，我们只关注正确理解概念。）
- en: 'Let''s represent the critical section, along with the synchronization mechanism—a
    lock— using a diagram (a superset of the preceding* Figure 3*):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们表示临界区，以及同步机制 - 锁 - 使用图表（前述*图3*的超集）：
- en: '![](img/6889d1bb-3e14-4d0c-9c7a-12ca130fe2ea.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/6889d1bb-3e14-4d0c-9c7a-12ca130fe2ea.png)
- en: 'Fig 5: Critical section with locking'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：带锁的临界区
- en: 'The basic premise of a lock is as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 锁的基本前提如下：
- en: Only one thread can hold or own a lock at any given point in time; that thread
    is the owner of the lock.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何给定时间点，只有一个线程可以持有或拥有锁；该线程是锁的所有者。
- en: Upon the unlock, when more than one thread attempts to get or take the lock, the
    kernel will guarantee that exactly one thread will get the lock.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在解锁时，当多个线程尝试获取或获取锁时，内核将保证只有一个线程会获取锁。
- en: The thread that gets the lock is called the winner (or the lock owner); the
    threads that tried for but did not get the lock are called the losers.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获得锁的线程称为赢家（或锁的所有者）；尝试但未获得锁的线程称为失败者。
- en: 'So, visualize this: say that we have three threads, A, B, and C, running in
    parallel on different CPU cores, all attempting to take a lock. The guarantee
    of the lock is that exactly one thread gets it—let''s say that thread C  wins,
    taking the lock (thus thread C is the winner or owner of the lock); threads A
    and B are the losers. What happens after that?'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，想象一下：假设我们有三个线程A、B和C，在不同的CPU核心上并行运行，都试图获取锁。锁的保证是确切地有一个线程得到它 - 假设线程C获胜，获取锁（因此线程C是锁的赢家或所有者）；线程A和B是失败者。之后会发生什么？
- en: The winner thread sees the lock operation as a non-blocking call; it continues
    into the critical section (probably working on some shared writable resource,
    such as global data).
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 赢家线程将锁操作视为非阻塞调用；它继续进入临界区（可能在处理一些共享可写资源，如全局数据）。
- en: The loser threads see the lock operation as a blocking call; they now block
    (wait), but on what exactly? (Recall that a blocking call is one in which we wait
    upon an event occurring and get unblocked once it occurs.) Well, the unlock operation,
    of course!
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 失败的线程将锁操作视为阻塞调用；他们现在阻塞（等待），但究竟在等待什么？（回想一下，阻塞调用是指我们等待事件发生并在事件发生后解除阻塞。）嗯，当然是解锁操作！
- en: The winner thread, upon (atomically) completing the critical section, performs
    the unlock operation.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获胜的线程在（原子地）完成临界区后执行解锁操作。
- en: Either thread A or B will now get the lock, and the whole sequence repeats.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在线程A或B将获得锁，整个序列重复。
- en: 'In a more generic manner, we can now understand it as: if N threads are in
    competition for a lock, the guarantee of the lock operation (by the OS) is that exactly
    one thread—the winner—will get the lock. So, we shall have one winner and N-1 losers.
    The winner thread proceeds into the code of the critical section; in the interim,
    all the N-1 loser threads wait (block) upon the unlock operation. At some point
    in the future (hopefully soon), the winner performs the unlock; this re-triggers
    the whole sequence again: the N-1 losers again compete for the lock; we shall
    have one winner and N-2 losers; the winner thread proceeds into the code of the critical
    section. In the interim, all the N-2 loser threads wait (block) upon the unlock operation
    and so on, until all the loser threads have become winners and have hence run
    the code of the critical section.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 更一般地说，我们现在可以理解为：如果有N个线程竞争一个锁，那么锁操作（由操作系统）的保证是只有一个线程——获胜者——会获得锁。因此，我们将有一个获胜者和N-1个失败者。获胜的线程进入临界区的代码；与此同时，所有N-1个失败者线程等待（阻塞）解锁操作。在将来的某个时刻（希望很快），获胜者执行解锁操作；这将重新触发整个序列：N-1个失败者再次竞争锁；我们将有一个获胜者和N-2个失败者；获胜的线程进入临界区的代码。与此同时，所有N-2个失败者线程等待（阻塞）解锁操作，依此类推，直到所有失败者线程都成为获胜者并因此运行了临界区的代码。
- en: Is it atomic?
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 它是原子的吗？
- en: 'The preceding discussion on the necessity for atomic execution of a critical
    section might make you, the programmer, apprehensive: perhaps you are wondering,
    how does one recognize a critical section? Well, that''s easy: if you have the
    potential for parallelism (multiple threads can run through the code path in parallel) and
    the code path is working on some shared resource (usually global or static data),
    then you have a critical section, implying that you will protect it via locking.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 关于对临界区进行原子执行的必要性的前述讨论可能会让您，程序员，感到担忧：也许您正在想，如何才能识别临界区？嗯，这很容易：如果您有并行性的潜力（多个线程可以并行运行通过代码路径）并且代码路径正在处理某些共享资源（通常是全局或静态数据），那么您就有一个临界区，这意味着您将通过锁定来保护它。
- en: 'A quick thumb rule: in the majority of cases, multiple threads will be running
    through code paths. Thus, in a general sense, the mere presence of some writable shared
    resource of any sort—a global, a static, an IPC shared-memory region, (even) a
    data item representing a hardware register in a device driver— makes the code
    path into a critical section. The rule is this: just protect it.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 一个快速的经验法则：在大多数情况下，多个线程将通过代码路径运行。因此，从一般意义上讲，任何一种可写的共享资源的存在——全局变量、静态变量、IPC共享内存区域，甚至是表示设备驱动程序中硬件寄存器的数据项——都会使代码路径成为临界区。规则是：保护它。
- en: 'The fictional bank account example we saw in the previous section makes it
    amply clear that we had a critical section which required protection (via locking).
    However, one does come across cases in which it is perhaps not as apparent whether
    we indeed require locking. Take this example: we have a global integer `g` in
    a multithreaded C application program; at some point, we increment its value,
    such as: `g ++;`'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中看到的虚构的银行账户示例清楚地表明，我们有一个需要保护的临界区（通过锁定）。然而，有些情况下，我们可能并不清楚是否确实需要锁定。举个例子：在一个多线程的C应用程序中，我们有一个全局整数`g`；在某个时刻，我们增加它的值，比如：`g++`。
- en: It looks simple, but wait! It's a writeable shared resource—global data; multiple
    threads might run through this code in parallel, thus rendering it a critical
    section which requires protection (via a lock). Yes? Or no?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来很简单，但等等！这是一个可写的共享资源——全局数据；多个线程可能会并行运行这段代码，因此它成为一个需要保护的临界区（通过锁）。是的？还是不是？
- en: On the face of it, a simple increment (or decrement) operation might appear
    to be atomic (recall that atomic runs to completion without interruption) in and
    of itself, thus requiring no special protection via locks or any other form of
    synchronization. But is this really the case?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，简单的增量（或减量）操作可能看起来是原子的（回想一下，原子操作是指在没有中断的情况下完成），因此不需要通过锁或任何其他形式的同步进行特殊保护。但事实真的是这样吗？
- en: Before we go any further, there is (yet) another key fact to be aware of which
    is, the only thing guaranteed to be atomic on a modern microprocessor in a single
    machine language instruction. After every machine instruction completes, the control
    unit on the CPU checks whether it has to service anything else, typically a hardware
    interrupt or (software) exception condition; if so, it sets the program counter
    (IP or PC) to that address and branches off; if not, execution continues sequentially
    with the PC register being appropriately incremented.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续之前，还有一个关键事实需要注意，那就是，现代微处理器上唯一保证原子性的是单个机器语言指令。每当一个机器指令完成后，CPU上的控制单元会检查是否需要处理其他事情，通常是硬件中断或（软件）异常条件；如果需要，它会将程序计数器（IP或PC）设置为该地址并进行分支；如果不需要，执行将继续顺序进行，PC寄存器将适当递增。
- en: 'So, think carefully about this: whether or not an increment operation `g++` is
    atomic or not really depends on two factors:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，请仔细考虑这一点：增量操作`g++`是否原子取决于两个因素：
- en: The **Instruction Set Architecture** (**ISA**) of the microprocessor being used
    (in simpler terms, it depends on the CPU itself)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正在使用的微处理器的指令集架构（ISA）（更简单地说，这取决于CPU本身）
- en: How the C compiler for that processor generates code
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该处理器的C编译器如何生成代码
- en: If the compiler generates a single machine language instruction for the `g++` C
    code, then execution will indeed be atomic. But will it? Let's find out! (the
    importance of being empirical - experimenting, trying things out—is a critical
    feature; our [Chapter 19](b6b41870-c02e-4379-af86-b5e501799c31.xhtml), *Troubleshooting
    and Best Practices*, covers more on such points).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 如果编译器为`g++` C代码生成了单个机器语言指令，那么执行确实是原子的。但是真的吗？让我们找出来！（实证的重要性——实验，尝试事物——是一个关键特征；我们的[第19章](b6b41870-c02e-4379-af86-b5e501799c31.xhtml)，*故障排除和最佳实践*，涵盖了更多这样的要点）。
- en: A very interesting website, [https://godbolt.org](https://godbolt.org) (screenshots
    will follow),allows one to see how various compilers compile a given piece of
    high-level language code (at the time of writing this book, it supports 14 languages,
    including C and C++, and various compilers, including, of course, gcc(1) and clang(1).
    Interestingly, with the language drop-down set to C++, one can also compile via
    gcc for ARM!).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常有趣的网站，[https://godbolt.org](https://godbolt.org)（屏幕截图将随后出现），允许我们看到各种编译器如何编译给定的高级语言代码（在撰写本书时，它支持14种语言，包括C和C++，以及各种编译器，当然包括gcc(1)和clang(1)。有趣的是，将语言下拉菜单设置为C++后，还可以通过gcc为ARM进行编译！）。
- en: 'Let''s begin by visiting this website and then doing the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从访问这个网站开始，然后进行以下操作：
- en: Select C as the language via the drop-down
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过下拉菜单选择C作为语言
- en: Select, in the right window pane, the compiler as x86_64 gcc 8.2
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在右窗格中，选择编译器为x86_64 gcc 8.2
- en: 'In the left window pane, key in the following program:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左窗格中，输入以下程序：
- en: '[PRE0]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following is the output:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是输出：
- en: '![](img/f940d6e7-d28a-428c-9dcf-8d4dc50c6c5c.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f940d6e7-d28a-428c-9dcf-8d4dc50c6c5c.png)'
- en: 'Figure 6: g++ increment via gcc 8.2 on x86_64, no optimization'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：通过x86_64上的gcc 8.2进行g++增量，无优化
- en: Look at the right window pane—one can see the assembly language generated by
    the compiler (which, of course, will subsequently become machine code corresponding
    to the processor ISA). So? Note that the `g++` C high-level language statement
    is highlighted in a pale yellow color in its left window pane; the same color
    is used in the right window to highlight the corresponding assembly. What does
    one, quite glaringly, notice? The single line of C code, `g++`; , has become four
    assembly language instructions. Thus, by virtue of our preceding learning, this
    code cannot be considered to be atomic in and of itself (but we can certainly force
    it to be atomic by using a lock).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 看看右窗格——可以看到编译器生成的汇编语言（当然，随后将成为与处理器ISA相对应的机器代码）。那么呢？请注意，`g++` C高级语言语句在其左窗格中以淡黄色突出显示；右窗格中使用相同的颜色突出显示相应的汇编。有什么明显的发现吗？单行C代码`g++`已经变成了四条汇编语言指令。因此，根据我们之前的学习，这段代码本身不能被认为是原子的（但我们当然可以使用锁来强制它成为原子）。
- en: 'The next experiment: leave everything the same, except notice that in the right
    window pane there is a text widget into which you are allowed to type in option
    switches to pass on to the compiler; we type `-O2`, implying that we would like
    the compiler to use optimization level 2 (a fairly high optimization level). Now,
    for the output:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个实验：保持一切不变，只是注意到在右窗格中有一个文本小部件，你可以在其中输入传递给编译器的选项开关；我们输入`-O2`，表示我们希望编译器使用优化级别2（一个相当高的优化级别）。现在，输出为：
- en: '![](img/78e01152-0b99-40e6-a4d1-0271a63ff19b.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](img/78e01152-0b99-40e6-a4d1-0271a63ff19b.png)'
- en: 'Figure 7: g++ increment via gcc 8.2 on x86_64, optimization level 2'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：通过x86_64上的gcc 8.2进行g++增量，优化级别2
- en: The `g++` C code now boils down to just one assembly instruction, thus indeed
    becoming atomic.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`g++` C代码现在只剩下一个汇编指令，因此确实变成了原子的。'
- en: 'With the ARM compiler, and no optimization, `g++` translates to several lines
    of assembly— clearly, non-atomic:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用ARM编译器，没有优化，`g++`转换为几行汇编——显然不是原子的：
- en: '![](img/9e172c33-992a-4810-9189-6d1ea542a5ca.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9e172c33-992a-4810-9189-6d1ea542a5ca.png)'
- en: 'Fig 8: g++ increment via gcc 7.2.1 on ARM, no optimization'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：通过ARM上的gcc 7.2.1进行g++增量，无优化
- en: 'Our conclusion? It is usually important for applications that the code we write
    remains portable across (CPU) architectures. In the preceding example, we clearly
    find that the code generated by the compiler for the simple `g++`operation is
    sometimes atomic and sometimes not. (It will depend on several factors: the CPU''s
    ISA, the compiler, and the optimization level `-On` that it''s compiled at, and
    so on.) Hence, the only safe conclusion one can make is this: be safe, and wherever
    there exists a critical section, protect it(with locks, or other means).'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结论？对于应用程序来说，我们编写的代码通常很重要，要跨（CPU）架构保持可移植性。在前面的例子中，我们清楚地发现，编译器为简单的`g++`操作生成的代码有时是原子的，有时不是。（这将取决于几个因素：CPU的ISA，编译器，以及它编译的优化级别`-On`等等。）因此，我们唯一可以得出的安全结论是：要安全，并且无论何时存在关键部分，都要保护它（使用锁或其他手段）。
- en: Dirty reads
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 脏读
- en: 'Many programmers new to these topics make a fatal assumption, and think something
    like this: Okay, I understand that when modifying a shared resource—like a global
    data structure — I will be required to treat the code as a critical section and
    protect it with locking, but, my code is only iterating over a global linked list;
    it''s only reading it and never writing to it and hence, this is not a critical
    section and does not require protection (I''ll even get brownie points for high
    performance).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 许多对这些主题新手的程序员会做出一个致命的假设，认为类似这样：好吧，我明白了，当修改共享资源——比如全局数据结构——时，我将需要将代码视为关键部分，并用锁来保护它，但是，我的代码只是在全局链表上进行迭代；它只是读取它而不是写入它，因此，这不是一个关键部分，不需要保护（我甚至会因高性能而得到好处）。
- en: 'Burst the bubble, please! It is a critical section. Why? Visualize this: while
    your code is iterating over the global linked list (only reading it), precisely
    because you have not taken a lock or synchronized in some other manner, another
    writer thread can very well be writing to the data structure while you are reading
    it. Think about it: this is a recipe for disaster; it''s entirely possible that
    your code will end up reading stale or half-written inconsistent data. This is
    called a *dirty read*, and it can happen when you do not protect the critical
    section. In fact, this is precisely the defect in our fictional banking application
    example.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请打破这个泡泡！这是一个关键部分。为什么？想象一下：当您的代码在全局链表上进行迭代（仅读取它）时，正因为您没有采取锁定或以其他方式进行同步，另一个写入线程很可能正在写入数据结构，而您正在读取它。想一想：这是一场灾难的预兆；您的代码很可能最终会读取过时或不一致的数据。这就是所谓的*脏读*，当您不保护关键部分时，它可能发生。实际上，这正是我们虚构的银行应用示例中的缺陷。
- en: 'Once again, we (re)stress these facts:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调这些事实：
- en: If the code is accessing a writable shared resource of any sort and there is
    the potential for parallelism, then it's a critical section. Protect it.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果代码正在访问任何类型的可写共享资源，并且存在并行性的潜力，那么它就是一个关键部分。保护它。
- en: 'Some side effects of this include the following:'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些的一些副作用包括：
- en: 'If your code does have parallelism but works only on local variables, there
    is no issue and it''s not a critical section. (Remember: each thread has its own
    private stack, and so using local variables without explicit protection is fine.)'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果您的代码确实具有并行性，但仅适用于局部变量，则没有问题，这不是关键部分。（记住：每个线程都有自己的私有堆栈，因此在没有显式保护的情况下使用局部变量是可以的。）
- en: If a global variable is marked as `const`, then of course it's fine—it's read-only,
    in any case.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果全局变量标记为`const`，那当然没问题——它是只读的，在任何情况下。
- en: (Note though, that the const keyword in C does not actually guarantee that the
    value is indeed constant (as one typically understands it)! It just means that
    the variable is read-only, but the data it refers to can still be changed if another
    pointer has access to it from underneath using a macro instead might help).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: （尽管在C语言中，const关键字实际上并不保证值确实是常量（通常理解的常量）！它只意味着变量是只读的，但它所引用的数据仍然可以在另一个指针从下面访问时被更改，使用宏而不是const关键字可能有所帮助）。
- en: Using locks correctly has a learning curve, perhaps a bit steeper than other
    programming constructs; this is because, one has to first learn to recognize critical
    sections, and therefore the need for locks (covered in the previous section),
    then learn and use good design locking guidelines, and third, understand and avoid
    nasty deadlocks!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正确使用锁定有一个学习曲线，可能比其他编程结构陡峭一些；这是因为，首先必须学会识别关键部分，因此需要锁定（在前一节中介绍），然后学习和使用良好的设计锁定指南，第三，理解并避免令人讨厌的死锁！
- en: Locking guidelines
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁定指南
- en: In this section, we will present a small but important set of heuristics or
    guidelines for the developer to keep in mind while designing and implementing
    multithreaded code that makes use of locks. These may or may not apply in a given
    situation; with experience, one learns to apply the right guidelines at the appropriate
    times.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将提出一组小而重要的启发式或指导原则，供开发人员在设计和实现使用锁的多线程代码时牢记。这些可能适用于特定情况，也可能不适用；通过经验，人们学会在适当的时候应用正确的指导原则。
- en: 'Without further ado, here they are:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 话不多说，它们在这里：
- en: '**Keep locking granularity fine enough**: lock data, not code.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保持锁定粒度足够细**：锁定数据，而不是代码。'
- en: '**Simplicity is key**: Complex locking scenarios involving multiple locks and
    threads lead to not just performance issues (the extreme case being deadlock),
    but also to other defects. Keeping the design as simple as it can be is always
    good practice.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单是关键**：涉及多个锁和线程的复杂锁定方案不仅会导致性能问题（极端情况是死锁），还会导致其他缺陷。保持设计尽可能简单始终是一个好的实践。'
- en: '**Prevent Starvation**: Holding a lock for an arbitrarily long amount of time
    leads to the loser threads starving; one has to design—and indeed test—to ensure
    that, as a rule of thumb, every critical section (the code between the lock and
    the unlock operations) completes as soon as possible. Good design ensures that
    there is no possibility of a critical section of code taking far too long; using
    a timeout in conjunction with the lock is one way to alleviate this issue (more
    on this later).'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预防饥饿**：持有锁定的时间任意长会导致失败者线程饿死；必须设计——并确实测试——以确保，作为一个经验法则，每个关键部分（在lock和unlock操作之间的代码）尽快完成。良好的设计确保代码关键部分不会花费太长时间；在锁定中使用超时是缓解这个问题的一种方法（稍后详细介绍）。'
- en: 'It’s really important to also understand that locking creates bottlenecks. Good
    physical analogies for locking are as follows:'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还要了解锁定会产生瓶颈。锁定的良好物理类比如下：
- en: 'A funnel: Think of the stem of the funnel as the critical section—it’s only
    wide enough to allow one thread to go through at a time (the winner); the loser threads
    remain blocked in the mouth of the funnel'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 漏斗：将漏斗的茎视为关键部分——它只宽到足够容纳一个线程通过（赢家）；失败者线程则保持阻塞在漏斗口
- en: A single toll booth on a multi-lane busy highway
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多车道繁忙公路上的一个收费站
- en: 'Thus, avoiding long critical sections is key:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，避免长时间的关键部分是关键：
- en: Build synchronization into the design, and avoid the temptation that goes something
    like, okay, I'll first write the code and then come back and look at locking. It
    typically does not go well; locking is a complex business as it is; trying to
    postpone its correct design and implementation only aggravates the issue.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将同步构建到设计中，并避免诱惑，比如，好吧，我先写代码，然后再回来看锁定。通常情况下效果不佳；锁定本身就很复杂；试图推迟其正确的设计和实现只会加剧问题。
- en: Let's examine the first of these points in a bit more detail.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地检查这些观点中的第一个。
- en: Locking granularity
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 锁定粒度
- en: 'While working on an application, let''s say there are several places which
    require data protection via locking—in other words, several critical sections:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用程序中工作时，假设有几个地方需要通过锁定来保护数据，换句话说，有几个关键部分：
- en: '![](img/58bff04b-3089-46aa-99d8-fc7cbb9fa098.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58bff04b-3089-46aa-99d8-fc7cbb9fa098.png)'
- en: 'Fig 9: Timeline with several critical sections'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：具有几个关键部分的时间线
- en: 'We have shown the critical sections (the places that, as we have learned, require
    synchronization—locking) with the solid red rectangles on the timeline. The developer
    might well realize, why not simplify this? Just take a single lock at time **t1**
    and unlock it at time **t6**:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在时间线上用实心红色矩形显示了关键部分（正如我们所学到的，需要同步锁定）。开发人员可能会意识到，为什么不简化一下呢？只需在t1时刻获取一个锁，然后在t6时刻解锁它：
- en: '![](img/ca5dea18-639b-404e-91db-dda609ef947a.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ca5dea18-639b-404e-91db-dda609ef947a.png)'
- en: 'Figure 10: Coarse granularity locking'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：粗粒度锁定
- en: This will work in protecting all the critical sections. But this is at the cost
    of performance. Think about it; each time a thread runs through the preceding
    code path, it must take the lock, perform the work, and then unlock. That's fine,
    but what about parallelism? It's effectively defeated; the code from **t1** to
    **t6** is now serialized. This kind of over-amplified locking-of-all-critical-sections-with-one-big-fat-lock
    is called coarse granularity locking.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这将保护所有的关键部分。但这是以性能为代价的。想想看；每次一个线程运行前面的代码路径时，它必须获取锁，执行工作，然后解锁。这没问题，但并行性呢？它实际上被打败了；从t1到t6的代码现在被序列化了。这种过度放大的锁定所有关键部分的行为被称为粗粒度锁定。
- en: 'Recall our earlier discussion: code (text) is never an issue—there is no need
    at all to lock here; just lock the places where writable shared data of any sort
    is being accessed. These are the critical sections! This gives rise to fine granularity
    locking—we only take the lock at the point in time where a critical section begins
    and unlock where it ends; the following diagram reflects this:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 回想我们之前的讨论：代码（文本）从来不是问题——根本不需要在这里锁定；只需锁定可写共享数据的地方。这些就是关键部分！这就产生了细粒度锁定——我们只在关键部分开始的时候获取锁，并在结束的时候解锁；以下图表反映了这一点：
- en: '![](img/0bc4c06e-a618-4dad-8f18-263f0b664697.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0bc4c06e-a618-4dad-8f18-263f0b664697.png)'
- en: 'Figure 11: Fine granularity locking'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：细粒度锁定
- en: As we stated previously, a good rule of thumb to keep in mind is to lock data,
    not code.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所述，一个好的经验法则是锁定数据，而不是代码。
- en: Is super-fine granularity locking always best? Perhaps not; locking is a complex
    business. Practical work has shown that, sometimes, holding a lock while even
    working on code (pure text—the code between the critical sections), is okay. It
    is a balancing act; the developer must ideally use experience and trial-and-error
    to judge locking granularity and efficiency, constantly testing and re-evaluating
    the code paths for robustness and performance as one goes along.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 超细粒度锁定总是最好的吗？也许不是；锁定是一个复杂的业务。实际工作表明，有时即使在代码上工作（纯文本——关键部分之间的代码），持有锁也是可以的。这是一个平衡的行为；开发人员理想情况下应该利用经验和试错来判断锁定的粒度和效率，不断测试和重新评估代码路径的健壮性和性能。
- en: Straying too far in either direction might be a mistake; too coarse a locking
    granularity yields poor performance, but too fine a granularity can too.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何方向上走得太远都可能是一个错误；锁定粒度太粗会导致性能不佳，但粒度太细也是如此。
- en: Deadlock and its avoidance
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 死锁及其避免
- en: A deadlock is the undesirable situation wherein it is impossible for the threads
    in question to make further progress. The typical symptom of deadlock is that
    the application (or device driver or whatever software it is) appears to hang.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 死锁是一种不希望发生的情况，其中相关线程无法再取得进展。死锁的典型症状是应用程序（或设备驱动程序或任何其他软件）似乎“挂起”。
- en: Common deadlock types
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常见的死锁类型
- en: Thinking about a couple of typical deadlock scenarios will help the reader understand
    it better. Recall that the basic premise of a lockis that there can only be one winner (the
    thread that obtained the lock) and N-1 losers. Another key point is that only
    the winnerthread can perform the unlock operation—no other thread can do so.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 思考一些典型的死锁场景将有助于读者更好地理解。回想一下，锁的基本前提是只能有一个赢家（获得锁的线程）和N-1个输家。另一个关键点是只有赢家线程才能执行解锁操作，没有其他线程可以这样做。
- en: Self deadlock (relock)
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自死锁（重新锁定）
- en: 'Knowing the aforementioned information, visualize this scenario: there is one
    lock (we just call it L1) and three threads in competition for it (let''s just
    call them threads A, B, and C); let''s say thread B is the winner. That''s fine,
    but what happens if thread B, within its critical section, again attempts to take
    the same lock, L1? Well, think about it: lock L1 is currently in the locked state,
    thus forcing thread B to block (wait) upon it getting unlocked. However, no thread
    but thread B itself can possibly perform the unlock operation, so thread B will
    end up waiting forever! There we have it: deadlock. This type of deadlock is termed
    the self deadlock, or the relock error.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 了解了上述信息，想象一下这种情况：有一个锁（我们称之为L1）和三个竞争它的线程（我们称它们为A、B和C）；假设线程B是赢家。这没问题，但是如果线程B在其关键部分内再次尝试获取相同的锁L1会发生什么呢？嗯，想想看：锁L1当前处于锁定状态，因此迫使线程B在其解锁时阻塞（等待）。然而，除了线程B本身，没有其他线程可能执行解锁操作，因此线程B最终将永远等待下去！这就是死锁。这种类型的死锁被称为自死锁，或重新锁定错误。
- en: One might argue, and indeed the case does exist, can't a lock be taken recursively? Yes,
    as we shall see later that this can be done within the pthreads API. However,
    good design often argues against using recursive locks; indeed, the Linux kernel
    does not allow it.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可能会争辩，实际上确实存在这种情况，锁能够递归地被获取吗？是的，正如我们将在后面看到的，这可以在pthread API中完成。然而，良好的设计通常会反对使用递归锁；事实上，Linux内核不允许这样做。
- en: The ABBA deadlock
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ABBA死锁
- en: 'A more complex form of deadlock can emerge in a scenario which involves nested
    locking: two or more competing threads and two or more locks. Here, let''s take
    the simplest case: a scenario with two threads (A and B) working with two locks
    (L1 and L2).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '在涉及嵌套锁定的情况下，可能会出现更复杂的死锁形式：两个或更多竞争线程和两个或更多锁。在这里，让我们以最简单的情况为例：两个线程（A和B）与两个锁（L1和L2）一起工作。 '
- en: 'Let''s say that this is what unfolds over the vertical timeline, as the following
    table reveals:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这是在垂直时间线上展开的情况，如下表所示：
- en: '| **Time** | **Thread A** | **Thread B** |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| **时间** | **线程A** | **线程B** |'
- en: '| t1 | Attempt to take lock L1 | Attempt to take lock L2 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| t1 | 尝试获取锁L1 | 尝试获取锁L2 |'
- en: '| t2 | Gets lock L1 | Gets lock L2 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| t2 | 获取锁L1 | 获取锁L2 |'
- en: '| t3 | <--- In critical section of L1 ---> |  <--- In critical section of L2
    ---> |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| t3 | <--- 在L1的临界区中 ---> |  <--- 在L2的临界区中 ---> |'
- en: '| t4 | Attempt to take lock L2 | Attempt to take lock L1 |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| t4 | 尝试获取锁L2 | 尝试获取锁L1 |'
- en: '| t5 | Block on L2 being unlocked | Block on L1 being unlocked |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| t5 | 阻塞，等待L2解锁 | 阻塞，等待L1解锁 |'
- en: '|  | <waits forever: deadlock> |  <waits forever: deadlock> |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  | <永远等待：死锁> |  <永远等待：死锁> |'
- en: It's quite clear that each thread waits for the other to unlock the lock it
    wants; thus, each thread waits forever, guaranteeing a deadlock. This kind of
    deadlock is often called the deadly embrace or the ABBA deadlock.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，每个线程都在等待另一个解锁它想要的锁；因此，每个线程都永远等待，保证了死锁。这种死锁通常被称为致命拥抱或ABBA死锁。
- en: Avoiding deadlock
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 避免死锁
- en: Avoiding deadlock is obviously something we would want to ensure. In addition
    to the points covered in the *Locking guidelines* section,there is one more key
    point, which is that the order in which multiple locks are taken matters; keeping
    the lock ordering consistent throughout will provide protection against deadlocks.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，避免死锁是我们希望确保的事情。除了*锁定指南*部分涵盖的要点之外，还有一个关键点，那就是获取多个锁的顺序很重要；始终保持锁定顺序一致将提供对抗死锁的保护。
- en: 'To understand why, let''s re-look at the ABBA deadlock scenario we just covered
    (refer to the preceding table). Look at the table again: notice that thread A
    takes lock L1 and then attempts to take lock L2, while thread B does the opposite.
    We shall now represent this scenario, but with a key caveat: lock ordering! This
    time, we shall have a lock ordering rule; it could be as simple as this: first,
    take lock L1, and then take lock L2:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解原因，让我们重新看一下刚才讨论过的ABBA死锁场景（参考上表）。再次看表格：注意线程A获取锁L1，然后尝试获取锁L2，而线程B则相反。现在我们将表示这种情况，但有一个关键的警告：锁定顺序！这一次，我们将有一个锁定顺序规则；它可能很简单，比如：首先获取锁L1，然后获取锁L2：
- en: lock L1 --> lock L2
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 锁L1 --> 锁L2
- en: 'With this lock ordering in mind, we find the scenario could play out as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这种锁定顺序，我们发现情况可能会如下展开：
- en: '| **Time** | **Thread A** | **Thread B** |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| **时间** | **线程A** | **线程B** |'
- en: '| t1 | Attempt to take lock L1 | Attempt to take lock L1 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| t1 | 尝试获取锁L1 | 尝试获取锁L1 |'
- en: '| t2 |  | Gets lock L1 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| t2 |  | 获取锁L1 |'
- en: '| t3 | <Waits for L1 to be unlocked> | <--- In critical section of L1 --->
    |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| t3 | <等待L1解锁> | <--- 在L1的临界区中 ---> |'
- en: '| t4 |  | Unlock L1 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| t4 |  | 解锁L1 |'
- en: '| t5 | Gets lock L1 |  |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| t5 | 获取锁L1 |  |'
- en: '| t6 | <--- In critical section of L1 ---> | Attempt to take lock L2 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| t6 | <--- 在L1的临界区中 ---> | 尝试获取锁L2 |'
- en: '| t7 | Unlock L1 | Gets locks L2 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| t7 | 解锁L1 | 获取锁L2 |'
- en: '| t8 | Attempt to take lock L2 | <--- In critical section of L2  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| t8 | 尝试获取锁L2 | <--- 在L2的临界区中  |'
- en: '| t9 | <Waits for L2 to be unlocked> |                                    
                            ---> |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| t9 | <等待L2解锁> |                                                          
      ---> |'
- en: '| t10 |  | Unlock L2 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| t10 |  | 解锁L2 |'
- en: '| t11 | Gets lock L2 | <Continues with other work> |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| t11 | 获取锁L2 | <继续其他工作> |'
- en: '| t12 |  <--- In critical section of L2 ---> | ... |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| t12 | <--- 在L2的临界区中 ---> | ... |'
- en: '| t13 | Unlock L2 | ... |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| t13 | 解锁L2 | ... |'
- en: The key point here is that both threads attempt to take locks in a given order;
    first L1, and then L2\. In the preceding table, we can visualize a case in which
    thread B obtains the locks first, forcing thread A to wait. This is completely
    fine and expected; no deadlock occurring is the whole point.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 关键点在于两个线程尝试按照给定顺序获取锁；首先是L1，然后是L2。在上表中，我们可以想象一种情况，即线程B首先获取锁，迫使线程A等待。这是完全正常和预期的；不发生死锁是整个重点。
- en: The precise ordering itself does not really matter; what does matter is the
    fact that the designers and developers document the lock ordering to be followed
    and stick to it.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 确切的顺序本身并不重要；重要的是设计者和开发者记录并遵守要遵循的锁定顺序。
- en: The lock ordering semantics, and indeed developer comments regarding this key
    point, can be often found within the source tree of the Linux kernel (ver 4.19,
    as of this writing). Here's one example: `virt/kvm/kvm_main.c``...`
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 锁定顺序语义，实际上开发者关于这一关键点的评论，通常可以在Linux内核源代码树（截至本文撰写时的版本4.19）中找到。以下是一个例子：`virt/kvm/kvm_main.c``...`
- en: '`/*`'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`/*`'
- en: '` * Ordering of locks:`'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '` * 锁的顺序：`'
- en: '` *`'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '` *`'
- en: '` * kvm->lock --> kvm->slots_lock --> kvm->irq_lock`'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '` * kvm->lock --> kvm->slots_lock --> kvm->irq_lock`'
- en: '` */`'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '` */`'
- en: '`...`'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`...`'
- en: 'So, looking back at our first table, we can now clearly see that the deadlock
    occurred because the lock ordering rule was violated: thread B took lock L2 before taking
    lock L1!'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，回顾我们的第一个表格，我们现在可以清楚地看到，死锁发生是因为违反了锁定顺序规则：线程B在获取锁L1之前获取了锁L2！
- en: Using the pthread APIs for synchronization
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用pthread API进行同步
- en: 'Now that we have covered the required theoretical background information, let''s
    move on with the actual practice: for the remainder of this chapter, we shall
    focus on how to use the pthreads API to perform synchronization, thus avoiding
    races.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经涵盖了所需的理论背景信息，让我们继续进行实际操作：在本章的其余部分，我们将专注于如何使用pthread API进行同步，从而避免竞争。
- en: We have learned that to protect writable shared data of any kind in a critical
    section, we require locking. The pthreads API provides the mutex lock for exactly
    this use case; we intend to hold the lock for a short while only—the duration
    of the critical section.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解到，为了保护任何类型的可写共享数据，我们需要在临界区域进行锁定。pthread API为这种情况提供了互斥锁；我们打算只在临界区域内短暂持有锁。
- en: There are scenarios, though, in which we require a different kind of synchronization—we
    require to synchronize based on a certain data element's value; the pthreads API
    provides the **condition variable** (**CV**) for this use case.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些情况下，我们需要一种不同类型的同步 - 我们需要根据某个数据元素的值进行同步；pthread API为这种情况提供了条件变量（CV）。
- en: Let's cover these in turn.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们依次来看看这些。
- en: The mutex lock
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁
- en: The word **mutex** is really an abbreviation for **mutual exclusion**; to the
    mutual exclusion of all other (loser) threads, one thread—the winner—holds (or
    owns) the mutex lock. Only when it is unlocked can another thread take the lock.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**互斥锁**一词实际上是**互斥排斥**的缩写；对于所有其他（失败的）线程的互斥排斥，一个线程 - 赢家 - 持有（或拥有）互斥锁。只有在它被解锁时，另一个线程才能获取锁。'
- en: 'An FAQ: What really is the difference between the semaphore and the mutex lock? Firstly,
    the semaphore can be used in two ways—one, as a counter (with the counting semaphore
    object), and two (relevant to us here), essentially as a mutex lock—the binary
    semaphore.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见问题：信号量和互斥锁之间的真正区别是什么？首先，信号量可以以两种方式使用 - 一种是作为计数器（使用计数信号量对象），另一种（我们这里关注的）基本上是作为互斥锁
    - 二进制信号量。
- en: 'Between the binary semaphore and the mutex lock, there exists two primary differences:
    one, the semaphore is meant to be used to synchronize between processes and not
    the threads internal to a single process (it is indeed a well-known IPC facility);
    the mutex lock is meant to synchronize between the threads of a given (single)
    process. (Having said that, it is possible to create a process-shared mutex, but
    it''s never the default).'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制信号量和互斥锁之间存在两个主要区别：一是信号量用于在进程之间进行同步，而不是单个进程内部的线程（它确实是一个众所周知的IPC设施）；互斥锁用于同步给定（单个）进程的线程。
    （话虽如此，可以创建一个进程共享的互斥锁，但这并不是默认值）。
- en: 'Two, the SysV IPC implementation of the semaphore provides the possibility
    of having the kernel unlock the semaphore (via the `semop(2)` `SEM_UNDO` flag) if
    the owner process is abruptly killed (always possible via signal #9); no such
    possibility even exists for the mutex—the winner must unlock it (we shall cover
    how the developer can ensure this later).'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，信号量的SysV IPC实现提供了这样的可能性，即内核可以在所有者进程被突然终止时（总是可能通过信号#9）解锁信号量（通过`semop(2)` `SEM_UNDO`标志）；对于互斥锁，甚至不存在这样的可能性
    - 获胜者必须解锁它（我们稍后将介绍开发人员如何确保这一点）。
- en: Let's get started with a simple example of initializing, using, and destroying
    a mutex lock. In this program, we shall create three threads and merely increment
    three global integers, once each within the worker routine of the threads.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的示例开始，初始化、使用和销毁互斥锁。在这个程序中，我们将创建三个线程，仅在线程的工作例程中每次增加三个全局整数。
- en: For readability, only key parts of the source code are displayed; to view the
    complete source code, build, and run it. The entire tree is available for cloning
    from GitHub here: [https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux)*.*
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可读性，只显示了源代码的关键部分；要查看完整的源代码，请构建并运行它。整个树可在GitHub上克隆：[https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux)。
- en: 'Code: `ch15/mutex1.c`:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 代码：`ch15/mutex1.c`：
- en: '[PRE1]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In order to use a mutex lock, one must first initialize it to the unlocked
    state; this can be done as follows:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用互斥锁，必须首先将其初始化为未锁定状态；可以这样做：
- en: '[PRE2]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alternatively, we could perform the initialization as a declaration, such as:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以将初始化作为声明来执行，例如：
- en: '[PRE3]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In fact, there are a few mutex attributes that can be specified for the mutex
    lock (via the `pthread_mutexattr_init(3)` API); we shall get to this later in
    this chapter. For now, the attributes will be the system defaults.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，有一些可以为互斥锁指定的互斥属性（通过`pthread_mutexattr_init(3)` API）；我们将在本章后面介绍这一点。现在，属性将是系统默认值。
- en: 'Also, once we are done, we must destroy the mutex lock(s):'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，一旦完成，我们必须销毁互斥锁：
- en: '[PRE4]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As usual, we then create the (three) worker threads in a loop (we do not show
    this code here as it is repetitious). Here is the thread''s worker routine:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，我们在循环中创建（三个）工作线程（我们不在这里显示这段代码，因为它是重复的）。这是线程的工作例程：
- en: '[PRE5]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Because the data we are working on with each thread is a writable shared (it's
    in the data segment!) resource, we recognize that this is a critical section!
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们正在使用每个线程的可写共享（它在数据段中！）资源进行操作，我们意识到这是一个临界区域！
- en: Thus, we must protect it—here, we do so with a mutex lock. So, just prior to
    entering the critical section, we first take the mutex lock and then work on the
    global data, and then unlock our lock, rendering the operation safe against races.
    (Notice that in the preceding code we only perform the locking and unlocking if the
    variable called `locking` is true; this is a deliberate way to test our code.
    In production, of course, please do away with the if condition and just perform
    the locking!) The attentive reader will also notice that we have kept the critical
    section quite short—it only encapsulates the global update and subsequent `printf(3)`,
    nothing more. (This is important for good performance; recall what we learned
    in the earlier section on *Locking granularity*.)
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们必须保护它 - 在这里，我们使用互斥锁。因此，在进入临界区域之前，我们首先获取互斥锁，然后处理全局数据，然后解锁我们的锁，使操作安全地抵御竞争。（请注意，在前面的代码中，我们只在变量称为`locking`为真时才执行锁定和解锁；这是一种测试代码的故意方式。在生产中，当然，请取消`if`条件并执行锁定！）细心的读者还会注意到，我们将临界区域保持得相当短
    - 它只包含全局更新和随后的`printf(3)`，没有更多的内容。（这对于良好的性能很重要；回想一下我们在前一节关于*锁定粒度*中学到的内容）。
- en: 'As mentioned previously, we deliberately provide an option to the user to avoid using
    locking altogether—this of course will, or rather, could, result in buggy behavior.
    Let''s try it out:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们故意为用户提供了一个选项，可以完全避免使用锁定，这当然会导致错误行为。让我们试一试：
- en: '[PRE6]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'It does work as expected. Even if we pass the parameter as zero—thus turning
    locking off— the program does (usually) seem to work correctly:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 它确实按预期工作。即使我们将参数传递为零，从而关闭锁定，程序（通常）似乎也能正常工作：
- en: '[PRE7]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Why? Ah, this is important to understand: recall what we learned in the earlier
    section Is it atomic? With a simple integer increment and compiler optimization
    set to a high level (`-O2` in fact, here), it''s quite possible that the integer
    increments are atomic and thus do not really require locking. However, this may
    not always be the case, especially when we do something more complex than mere
    increments or decrements on an integer variable. (Think about reading/writing
    a large global linked list, and so on)! The bottom line: we must always recognize
    critical section(s) and ensure that we protect them.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么？啊，这很重要要理解：回想一下我们在前一节“它是原子的吗？”中学到的内容。对于一个简单的整数增量和编译器优化设置为高级别（实际上是`-O2`），整数增量很可能是原子的，因此不真正需要锁定。然而，这并不总是情况，特别是当我们对整数变量进行比简单的增量或减量更复杂的操作时（考虑读取/写入一个大的全局链表等）！最重要的是：我们必须始终识别关键部分并确保我们保护它们。
- en: Seeing the race
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 看到竞争
- en: 'To demonstrate exactly this issue (actually seeing the data race), we will
    write another demo program. In this one, we will calculate the factorial of a
    given number (a quick reminder: 3! = 3 x 2 x 1 = 6; recall from your school days—the
    notation N! means factorial of N). Here''s the relevant code:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确切地演示这个问题（实际上看到数据竞争），我们将编写另一个演示程序。在这个程序中，我们将计算给定数字的阶乘（一个快速提醒：3！= 3 x 2 x 1
    = 6；从学校时代记得的符号N！表示N的阶乘）。以下是相关代码：
- en: For readability, only key parts of the source code are displayed; to view the
    complete source code, build, and run it. The entire tree is available for cloning
    from GitHub here: [https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux)*.*
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于阅读，只显示了源代码的关键部分；要查看完整的源代码，构建并运行它。整个树可以从GitHub克隆到这里：[https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux)*.*
- en: 'Code: `ch15/facto.c`:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 代码：`ch15/facto.c`：
- en: 'In `main()`, we initialize our mutex lock (and create two worker threads; we
    do not show the code to create the threads, destroy them, as well as the mutex):'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main()`中，我们初始化我们的互斥锁（并创建两个工作线程；我们没有显示创建线程、销毁线程以及互斥锁的代码）：
- en: '[PRE8]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The thread''s worker routine is as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 线程的`worker`例程如下：
- en: '[PRE9]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Recognizing the critical section, we take (and subsequently unlock) our mutex
    lock. The code of the `factorize` function is as follows:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 识别临界区，我们获取（然后解锁）我们的互斥锁。`factorize`函数的代码如下：
- en: '[PRE10]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Read the preceding comment carefully; it''s key to this demo. Let''s try it
    out:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细阅读前面的评论；这对这个演示很关键。让我们试一试：
- en: '[PRE11]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The results are correct (verify this for yourself). Now we rerun it with locking
    off and verbose mode on:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是正确的（自行验证）。现在我们关闭锁定并打开详细模式重新运行它：
- en: '[PRE12]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Aha! In this case, `10!` works, but `12!` is wrong! We can literally see from
    the preceding output that a dirty read has occurred (at the i==2 iteration of
    the calculation for 12!), causing the defect. Well, of course: we did not protect
    the critical section here (locking was turned off); it''s really no wonder that
    it went wrong.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 啊哈！在这种情况下，`10！`是正确的，但`12！`是错误的！我们可以从前面的输出中清楚地看到发生了脏读（在计算12！时的i==2迭代中），导致了缺陷。当然：我们在这里没有保护关键部分（锁定被关闭）；难怪出错了。
- en: What we would like to stress, again, is that these races are delicate timing
    coincidences; in a buggy implementation, your test cases might still succeed,
    but of course that does not guarantee anything (it will likely fail in the field,
    as Murphy's Law tells us!). (An unfortunate truth is that testing can reveal the
    presence of errors but not their absence.  Importantly, [Chapter 19](b6b41870-c02e-4379-af86-b5e501799c31.xhtml),
    *Troubleshooting and Best Practices*, covers such points).
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次要强调的是，这些竞争是微妙的时间巧合；在一个有错误的实现中，你的测试用例可能仍然会成功，但这并不能保证任何事情（它很可能在实际应用中失败，正如墨菲定律告诉我们的那样！）。（一个不幸的事实是测试可以揭示错误的存在，但不能保证它们的不存在。重要的是，[第19章](b6b41870-c02e-4379-af86-b5e501799c31.xhtml)，*故障排除和最佳实践*，涵盖了这些要点）。
- en: The reader will realize that, as these data races are delicate timing coincidences, they
    may or may not occur exactly as shown here on your test systems. Retrying the
    app a few times may help reproduce these scenarios.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 读者会意识到，由于这些数据竞争是微妙的时间巧合，它们可能会或可能不会在您的测试系统上完全如此发生。多次重试应用程序可能有助于重现这些情况。
- en: We leave it to the reader to try out the use case with locking mode on and verbose
    mode on; it should work, of course.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们留给读者尝试在锁定模式和详细模式下使用用例；当然它应该工作。
- en: Mutex attributes
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁属性
- en: A mutex lock can have several attributes associated with it. Furthermore, we
    enumerate several of them.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 互斥锁可以有几个与之关联的属性。此外，我们列举了其中的几个。
- en: Mutex types
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁类型
- en: A mutex can be one of four types, the default usually—but not always (it depends
    upon the implementation)—being the normal mutex. The type of mutex used affects
    the behavior of the lock and unlock. The types are: PTHREAD_MUTEX_NORMAL, PTHREAD_MUTEX_ERRORCHECK,
    PTHREAD_MUTEX_RECURSIVE, and PTHREAD_MUTEX_DEFAULT.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 互斥锁可以是四种类型之一，默认情况下通常是正常互斥锁，但并不总是（这取决于实现）。使用的互斥锁类型会影响锁定和解锁的行为。这些类型是：PTHREAD_MUTEX_NORMAL，PTHREAD_MUTEX_ERRORCHECK，PTHREAD_MUTEX_RECURSIVE和PTHREAD_MUTEX_DEFAULT。
- en: The system man page on `pthread_mutex_lock(3)` describes the behavior depending
    on the mutex type with a table; for the reader's convenience, we have reproduced
    the same here.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 系统手册中关于`pthread_mutex_lock(3)`的行为取决于互斥锁类型的表格；为了读者方便，我们在这里重复了相同的内容。
- en: 'If a thread attempts to relock a mutex that it has already locked, `pthread_mutex_lock(3)`
    shall behave as described in the relock column of the following table. If a thread
    attempts to unlock a mutex that it has not locked or a mutex which is unlocked,
    `pthread_mutex_unlock(3)` shall behave as described in the **Unlock When Not Owner**
    column of the following table:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如果线程尝试重新锁定已经锁定的互斥锁，则`pthread_mutex_lock(3)`将按照以下表格中的重新锁定列中描述的行为进行。如果线程尝试解锁未锁定或已解锁的互斥锁，则`pthread_mutex_unlock(3)`将按照以下表格中的**非所有者解锁**列中描述的行为进行：
- en: '![](img/2dfc4139-4ba1-47be-a5fe-8d878fbb3a0c.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2dfc4139-4ba1-47be-a5fe-8d878fbb3a0c.png)'
- en: If the mutex type is PTHREAD_MUTEX_DEFAULT, the behavior of `pthread_mutex_lock(3)`
    may correspond to one of the three other standard mutex types, as described in
    the preceding table. If it does not correspond to one of those three, the behavior
    is undefined for the cases marked †.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果互斥锁类型为PTHREAD_MUTEX_DEFAULT，则`pthread_mutex_lock(3)`的行为可能对应于前表中描述的三种其他标准互斥锁类型之一。如果它不对应于这三种中的任何一种，对于标记为†的情况，行为是未定义的。
- en: The relock column directly corresponds to what we described earlier in this
    chapter as the self-deadlock scenario, such as, what effect attempting to re-lock
    an already-locked lock (poetic wording, perhaps?) will have. Clearly, except for
    the recursive and error check mutex case, the end result is either undefined (which
    means that anything can happen!) or a deadlock indeed.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 重新锁定列直接对应于我们在本章前面描述的自死锁场景，比如，尝试重新锁定已经锁定的锁（或许是诗意的措辞？）会产生什么影响。显然，除了递归和错误检查互斥锁的情况，最终结果要么是未定义的（这意味着任何事情都可能发生！），要么确实是死锁。
- en: Similarly, attempting to unlock a mutex by any thread except the owner either
    results in an undefined behavior or an error.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，除了拥有者之外的任何线程尝试解锁互斥锁都会导致未定义行为或错误。
- en: 'One might wonder: why does the locking API behave differently—in terms of error
    return or failures—depending on the type of the mutex? Why not just have one standard
    behavior for all types and thus simplify the situation? Well, it''s the usual
    trade-off between simplicity and performance: the way it''s implemented allows,
    for example, a well-written, programmatically proven correct real-time embedded
    application to forgo extra error checking and thus gain speed (which is especially
    important on critical code paths). On the other hand, in a development or debug
    environment, the developer might choose to allow extra checking to catch defects
    before shipping. (The man page on `pthread_mutex_destroy(3)` has a section entitled *Tradeoff
    Between Error Checks and Performance Supported* that describes this aspect in
    some detail.)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 人们可能会想：为什么锁定API的行为会根据互斥锁的类型而有所不同——在错误返回或失败方面？为什么不为所有类型都设定一个标准行为，从而简化情况？嗯，这是简单性和性能之间的通常权衡：实现的方式允许，例如，一个编写良好、在程序上经过验证正确的实时嵌入式应用程序放弃额外的错误检查，从而获得速度（这在关键代码路径上尤为重要）。另一方面，在开发或调试环境中，开发人员可能选择允许额外的检查，以便在发货前捕捉缺陷。（`pthread_mutex_destroy(3)`的man页面有一个名为*错误检查和性能支持之间的权衡*的部分，其中对这个方面进行了比较详细的描述。）
- en: 'The pair of APIs to `get` and `set` a mutex''s type attribute (the first column
    in the preceding table) are quite straightforward:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '`get`和`set`互斥锁类型属性的一对API（在上表的第一列）非常直接：'
- en: '[PRE13]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The robust mutex attribute
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 鲁棒互斥锁属性
- en: 'Glancing at the preceding table, one spies the robustness column; what does
    it mean? Recall that only the owner thread of a mutex lock can possibly unlock
    the mutex; now, we ask, what if, by some chance, the owner thread dies? (Well,
    firstly, good design will ensure this never happens; secondly, even if it does, 
    there are ways to protect against thread cancellation, a topic we will cover in
    the next chapter.) On the face of it, there is no help for it; any other threads
    waiting on the lock will now just deadlock (effectively, they will just hang).
    This behavior is in fact the default; it''s also the behavior that''s set up by
    the robust attribute known as PTHREAD_MUTEX_STALLED. To the (possible) rescue
    in such a situation, there does exist another value for the robust mutex attribute: PTHREAD_MUTEX_ROBUST.
    One can always query and set these attributes upon the mutex via the following
    pair of APIs:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下上表，人们会注意到鲁棒性列；这是什么意思？回想一下，只有互斥锁的拥有者线程可能解锁互斥锁；现在，我们问，如果拥有者线程碰巧死亡会怎么样？（首先，良好的设计将确保这种情况永远不会发生；其次，即使发生了，也有方法来保护线程取消，这是我们将在下一章中讨论的一个主题。）从表面上看，没有帮助；任何其他等待锁的线程现在都将陷入死锁（实际上，它们将被挂起）。这实际上是默认行为；这也是由称为PTHREAD_MUTEX_STALLED的鲁棒属性设置的行为。在这种情况下，可能的救援存在于另一个鲁棒互斥锁属性的值：PTHREAD_MUTEX_ROBUST。可以通过以下一对API查询和设置这些属性：
- en: '[PRE14]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'If this attribute (the value PTHREAD_MUTEX_ROBUST) is set upon the mutex lock,
    then if the owner thread dies while holding the mutex, a subsequent `pthread_mutex_lock(3)` upon
    the lock will succeed,  returning the value `EOWNERDEAD`. Hang on, though! Even
    though the call returns a (so-called) successful return, it''s important to understand
    that the lock in question is now considered to be in an inconsistent state and
    has to be reset into a consistent state via the `pthread_mutex_consistent(3)` API:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在互斥锁上设置了此属性（值为PTHREAD_MUTEX_ROBUST），那么如果拥有者线程在持有互斥锁时死亡，随后对锁的`pthread_mutex_lock(3)`将成功返回值`EOWNERDEAD`。不过，即使调用返回了（所谓的）成功返回，重要的是要理解，相关的锁现在被认为处于不一致状态，并且必须通过`pthread_mutex_consistent(3)`API将其重置为一致状态：
- en: '`int pthread_mutex_consistent(pthread_mutex_t *mutex);`'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '`int pthread_mutex_consistent(pthread_mutex_t *mutex);`'
- en: A return value of zero here indicates success; the mutex is now back in a consistent
    (stable) state and can be used normally (use it, and at some point, you must of
    course unlock it).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这里返回值为零表示成功；互斥锁现在恢复到一致（稳定）状态，并且可以正常使用（使用它，当然在某个时候，你必须解锁它）。
- en: 'To sum this up, to use the robust attribute mutex, use the following:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，要使用鲁棒属性互斥锁，请使用以下方法：
- en: 'Initialize the mutex lock:'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化互斥锁：
- en: '`pthread_mutexattr_t attr`;'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '`pthread_mutexattr_t attr`;'
- en: '`pthread_mutexattr_init(&attr)`;'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '`pthread_mutexattr_init(&attr)`；'
- en: 'Set the robust attribute on it: `pthread_mutexattr_setrobust(&attr, PTHREAD_MUTEX_ROBUST)`;'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在它上面设置robust属性：`pthread_mutexattr_setrobust(&attr, PTHREAD_MUTEX_ROBUST)`；
- en: Owner thread
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有者线程
- en: 'Lock it: `pthread_mutex_lock(&mylock)`'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁定它：`pthread_mutex_lock(&mylock)`。
- en: Now, assume that the thread owner abruptly dies (while holding the mutex lock)
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，假设线程所有者突然死亡（同时持有互斥锁）
- en: 'Another thread (perhaps main) can assume ownership:'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个线程（可能是主线程）可以假定所有权：
- en: 'First, detect the case:'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，检测情况：
- en: '`ret = pthread_mutex_lock(&mylock);`'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ret = pthread_mutex_lock(&mylock)`；'
- en: '`if (ret == EOWNERDEAD) {`'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '`if (ret == EOWNERDEAD) {`'
- en: 'Then, make it consistent:'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，使其一致：
- en: '`pthread_mutex_consistent(&mylock)`'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '`pthread_mutex_consistent(&mylock)`；'
- en: Use it (or just unlock it)
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用它（或解锁它）
- en: Unlock it: `pthread_mutex_unlock(&mylock)`
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解锁它：`pthread_mutex_unlock(&mylock)`；
- en: Instead of duplicating the wheel, we point the reader to a simple, readable
    example of using the robust mutex attribute feature described previously. Find
    it within the man page of `pthread_mutexattr_setrobust(3)`.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不打算重复造轮子，我们将读者指向一个简单易读的示例，该示例使用了之前描述的robust互斥锁属性功能。在`pthread_mutexattr_setrobust(3)`的man页面中可以找到它。
- en: Under the hood, the Linux pthreads mutex lock is implemented via the `futex(2)` system
    call (and thus by the OS). The futex (fast user mutex) provides a fast, robust,
    atomic-only instructions locking implementation. Links with more details can be
    found in the *Further reading *section on the GitHub repository.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，Linux pthreads互斥锁是通过`futex(2)`系统调用（因此由操作系统）实现的。`futex（快速用户互斥锁）`提供了快速、健壮、仅原子指令的锁定实现。更多详细信息的链接可以在GitHub存储库的*进一步阅读*部分中找到。
- en: IPC, threads, and the process-shared mutex
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: IPC、线程和进程共享的互斥锁
- en: Visualize a large application that consists of several independent multithreaded
    processes. Now, if the processes want to communicate with each other (and they
    often will want to), how can this be achieved? The answer, of course, is **Inter
    -process Communication** (**IPC**)—mechanisms that exist for this very purpose.
    Broadly speaking, there are several IPC mechanisms available on the typical Unix/Linux
    platforms; these include shared memory (as well as the `mmap(2)`), message queues,
    semaphores (typically for synchronization), named (FIFO) and unnamed pipes, sockets
    (Unix and internet domain), and, to some extent, signals.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个由几个独立的多线程进程组成的大型应用程序。现在，如果这些进程想要相互通信（他们通常会想要这样做），这该如何实现？答案当然是**进程间通信**（IPC）——为此目的存在的机制。广义上说，在典型的Unix/Linux平台上有几种IPC机制可用；这些包括共享内存（以及`mmap(2)`）、消息队列、信号量（通常用于同步）、命名（FIFO）和无名管道、套接字（Unix和互联网域），在一定程度上还有信号。
- en: Unfortunately, due to space constraints, we do not cover process IPC mechanisms
    in this book; we urge the interested reader to look into the links (and books)
    provided on IPC in the *Further reading *section on the GitHub repository.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，由于空间限制，我们在本书中没有涵盖进程IPC机制；我们敦促感兴趣的读者查看IPC部分在GitHub存储库的*进一步阅读*部分中提供的链接（和书籍）。
- en: 'The thing to stress here is that all of these IPC mechanisms are meant for
    communication between VM-isolated processes. So, our discussion here being focused
    on multithreading, how do the threads within a given process communicate with
    each other? Well, that''s quite simple, really: just as one can set up and use
    a shared memory region to effectively and efficiently communicate between processes
    (writing and reading into that region, synchronizing access via a semaphore),
    threads can simply and effectively use a global memory buffer (or any appropriate
    data structure) as a medium within which to communicate with each other, and,
    of course, synchronize access to the global memory region via a mutex lock.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要强调的是，所有这些IPC机制都是用于在VM隔离的进程之间进行通信。因此，我们在这里讨论的重点是多线程，那么给定进程内的线程如何相互通信呢？实际上很简单：就像可以设置并使用共享内存区域来有效和高效地在进程之间进行通信（写入和读取该区域，通过信号量同步访问），线程可以简单有效地使用全局内存缓冲区（或任何适当的数据结构）作为彼此通信的媒介，并且当然，通过互斥锁同步访问全局内存区域。
- en: 'Interestingly, it is possible to use a mutex lock as a synchronization primitive
    between threads belonging to different processes. This is achieved by setting
    up the mutex attribute called pshared, or process-shared. The pair of APIs to
    get and set the pshared mutex attribute are as follows:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，可以使用互斥锁作为不同进程的线程之间的同步原语。这是通过设置名为pshared或进程共享的互斥锁属性来实现的。获取和设置pshared互斥锁属性的一对API如下：
- en: '[PRE15]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The second parameter, `pshared`, can be set to one of the following:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个参数pshared可以设置为以下之一：
- en: '**PTHREAD_PROCESS_PRIVATE** : The default; here, the mutex is only visible
    to threads within the process in which the mutex has been created.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PTHREAD_PROCESS_PRIVATE**：默认值；在这里，互斥锁只对创建互斥锁的进程内的线程可见。'
- en: '**PTHREAD_PROCESS_SHARED**: Here, the mutex is visible to any threads that
    have access to the memory region in which the mutex is created, including threads
    of different processes.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PTHREAD_PROCESS_SHARED**：在这里，互斥锁对在创建互斥锁的内存区域中具有访问权限的任何线程可见，包括不同进程的线程。'
- en: 'But how does one actually ensure that the memory region in which the mutex
    exists is shared between processes (without which it will not be possible for
    the processes in question to use the mutex)? Well, it''s really back to basics:
    we must make use of one of the IPC mechanisms we mentioned—shared memory turns
    out to be the right one to use. So, we have the application set up a shared memory
    region (via either the traditional SysV IPC `shmget(2)` or the newer POSIX IPC `shm_open(2)` system
    calls), and have our process-shared mutex lock instantiated in this shared memory.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如何确保互斥锁存在的内存区域在进程之间是共享的（如果没有，将无法让相关进程使用互斥锁）？嗯，这实际上是基本的：我们必须使用我们提到的IPC机制之一——共享内存原来是正确的。因此，我们让应用程序设置一个共享内存区域（通过传统的SysV
    IPC `shmget(2)`或较新的POSIX IPC `shm_open(2)`系统调用），并且在这个共享内存中实例化我们的进程共享的互斥锁。
- en: 'So, let''s tie all this together with a simple application: we will write an application
    that creates two shared memory regions:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们用一个简单的应用程序将所有这些联系在一起：我们将编写一个应用程序，创建两个共享内存区域：
- en: One, a small shared memory region to act as a shared space for a process-shared
    mutex lock and an once-only initialization control (more on this in a minute)
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一、一个小的共享内存区域，用作进程共享互斥锁和一次性初始化控制的共享空间（稍后详细介绍）
- en: Two, a shared memory region to act as a simple buffer to store IPC messages
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二、一个共享内存区域，用作存储IPC消息的简单缓冲区
- en: We will initialize a mutex with the process-shared attribute so that it can be
    used between threads of differing processes to synchronize access; here, we fork
    and have a thread of the original parent process and the newly born child process
    compete for the mutex lock. Once they (sequentially) obtain it, they write a message
    into the second shared memory segment. At the end of the app, we destroy the resources
    and display the shared memory buffer (as a simple proof-of-concept).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用进程共享属性初始化互斥锁，以便在不同进程的线程之间同步访问；在这里，我们fork并让原始父进程和新生的子进程的线程竞争互斥锁。一旦它们（顺序地）获得它，它们将向第二个共享内存段写入消息。在应用程序结束时，我们销毁资源并显示共享内存缓冲区（作为一个简单的概念验证）。
- en: 'Let''s just try out our app (`ch15/pshared_mutex_demo.c`):'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一下我们的应用程序（`ch15/pshared_mutex_demo.c`）：
- en: We have added some blank lines in the following code for readability.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于阅读，我们在下面的代码中添加了一些空行。
- en: '[PRE16]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In the real world, things are not quite as simple as this; there does exist
    an additional synchronization issue to think about: how can one ensure that the
    mutex lock is initialized correctly and atomically (by only one process or thread),
    and, only initialized once, should other threads attempt to use it? In our demo
    program, we have used the `pthread_once(3)` API to achieve guaranteed once-only
    initialization of the mutex object (but have ignored the have-threads-wait-and-only-use-it-once-initialized
    issue). issue). (An interesting Q&A on Stack Overflow highlights this very concern;
    take a look:  [https://stackoverflow.com/questions/42628949/using-pthread-mutex-shared-between-processes-correctly#](https://stackoverflow.com/questions/42628949/using-pthread-mutex-shared-between-processes-correctly#)*.)* 
    However, the reality is that the `pthread_once(3)` API is meant to be used between
    the threads of a process. Also, POSIX requires that the initialization of the
    `once_control` is done statically; here, we have performed it at run time, so
    it''s not perfect.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，事情并不像这样简单；还存在一个额外的同步问题需要考虑：如何确保互斥锁正确且原子地初始化（只由一个进程或线程），并且只初始化一次，其他线程应该如何使用它？在我们的演示程序中，我们使用了`pthread_once(3)`
    API来实现互斥对象的一次性初始化（但忽略了线程等待并且只在初始化后使用的问题）。 （Stack Overflow上的一个有趣的问答突出了这个问题；请看：[https://stackoverflow.com/questions/42628949/using-pthread-mutex-shared-between-processes-correctly#](https://stackoverflow.com/questions/42628949/using-pthread-mutex-shared-between-processes-correctly#)*。）然而，事实是`pthread_once(3)`
    API是用于在一个进程的线程之间使用的。此外，POSIX要求`once_control`的初始化是静态完成的；在这里，我们在运行时执行了它，所以并不完美。
- en: 'In the main function, we set up and initialize the (IPC) shared memory segments;
    we urge the reader to carefully go through the source code (reading all the comments)
    and try it out for themselves as well:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main`函数中，我们设置并初始化（IPC）共享内存段；我们敦促读者仔细阅读源代码（阅读所有注释），并自行尝试：
- en: For readability, only key parts of the source code are displayed; to view the
    complete source code, build, and run it. The entire tree is available for cloning
    from GitHub here: [https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux)*.*
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于阅读，只显示了源代码的关键部分；要查看完整的源代码，请构建并运行它。整个树可以在GitHub上克隆：[https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux)*.*
- en: '[PRE17]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The `init_mutex`function which initializes the mutex with the process-shared
    attribute is shown as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`init_mutex`函数用于使用进程共享属性初始化互斥锁，如下所示：'
- en: '[PRE18]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The code of the worker thread—the worker routine—is shown in the following
    code. Here, we need to operate upon the second shared memory segment, implying
    of course that this is a critical section. Hence, we take the process-shared lock,
    perform the work, and subsequently unlock the mutex:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 工作线程的代码——`worker`例程——如下所示。在这里，我们需要操作第二个共享内存段，这意味着这是一个关键部分。因此，我们获取进程共享锁，执行工作，然后解锁互斥锁：
- en: '[PRE19]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Notice that the lock and unlock operations are carried out by macros; here
    they are:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，锁定和解锁操作是通过宏执行的；这里它们是：
- en: '[PRE20]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We leave it to the reader to look at the code where we fork and have the newly
    born child process essentially do the same thing as the preceding worker thread—operate
    upon the (same) second shared memory segment; being a critical section, it too
    attempts to take the process-shared lock, and once it gets it, performs the work,
    and subsequently unlocks the mutex.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们留给读者查看代码，在那里我们fork并让新生的子进程基本上做与前面的工作线程相同的事情——操作（相同的）第二个共享内存段；作为关键部分，它也尝试获取进程共享锁，一旦获取，执行工作，然后解锁互斥锁。
- en: Unless there is some compelling reason not to do so, when setting up IPC between processes,
    we suggest that you use one (or some) of the numerous IPC mechanisms that have
    been explicitly designed for this very purpose. Using the process-shared mutex
    as a synchronization mechanism between the threads of two or more processes is
    possible, but ask yourself if it is really required.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 除非有令人信服的理由不这样做，在设置进程之间的IPC时，我们建议您使用专门为此目的设计的众多IPC机制之一（或其中一些）。使用进程共享互斥锁作为两个或多个进程的线程之间的同步机制是可能的，但请问自己是否真的需要。
- en: Having said that, there are some advantages to using a mutex over the traditional
    (binary) semaphore object; these include the fact that the mutex is always associated
    with an owner thread, and only the owner can operate upon it (preventing some
    illegal or defective scenarios), and that mutexes can be set up to use nested
    (recursive) locking, and deal with the priority inversion problem effectively
    (via the inheritance protocol and/or priority ceiling attributes).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，使用互斥锁而不是传统的（二进制）信号量对象也有一些优点；其中包括互斥锁始终与一个所有者线程相关联，只有所有者才能对其进行操作（防止一些非法或有缺陷的情况），互斥锁可以设置为使用嵌套（递归）锁定，并有效地处理**优先级反转**问题（通过继承协议和/或优先级天花板属性）。
- en: Priority inversion, watchdogs, and Mars
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优先级反转，看门狗和火星
- en: An **Real Time Operating System **(**RTOS**) often has time-critical multithreaded
    applications running on it. Very simplistically, but nevertheless true, the primary
    rule for the RTOS scheduler to decide which thread to run next is the highest
    priority runnable thread must be the thread that is running. (By the way, we shall
    cover CPU scheduling with regard to the Linux OS in [Chapter 17](36229bac-c402-4d2f-b876-d1eb4aba8051.xhtml),
    *CPU Scheduling on Linux*; don't worry about the details for now.)
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '**实时操作系统**（RTOS）通常在其上运行时间关键的多线程应用程序。非常简单地说，但仍然是真的，RTOS调度程序决定下一个要运行的线程的主要规则是最高优先级的可运行线程必须是正在运行的线程。（顺便说一下，我们将在[第17章](36229bac-c402-4d2f-b876-d1eb4aba8051.xhtml)中涵盖有关Linux操作系统的CPU调度，*Linux上的CPU调度*；现在不用担心细节。）'
- en: Priority inversion
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优先级反转
- en: 'Let''s visualize an application that contains three threads; one of them is
    a high priority thread (let''s calls it thread A with priority 90), the other
    is a low priority thread (let''s calls it thread B with priority 10) and finally
    a medium priority thread, C. (The priority range for the SCHED_FIFO scheduling
    policy is 1 to 99, with 99 being the highest possible priority; more on this in
    a later chapter.) So, we can imagine that we have these three threads within a
    process at differing priorities:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一个包含三个线程的应用程序；其中一个是高优先级线程（让我们称其为优先级为90的线程A），另一个是低优先级线程（让我们称其为优先级为10的线程B），最后是一个中等优先级线程C。（SCHED_FIFO调度策略的优先级范围是1到99，99是最高可能的优先级；稍后的章节中会详细介绍。）因此，我们可以想象我们在一个进程中有这三个不同优先级的线程：
- en: 'Thread A: high priority, 90'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程A：高优先级，90
- en: 'Thread B: low priority, 10'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程B：低优先级，10
- en: 'Thread C: medium priority, 45'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程C：中等优先级，45
- en: Furthermore, let's consider that we have some shared resource, X, which is coveted
    by threads A and B; this, of course, constitutes a critical section, and thus,
    we will need to synchronize access to it for correctness. We shall use a mutex
    lock to do so.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，让我们考虑一下我们有一些共享资源X，线程A和B都渴望拥有它；这当然构成了一个关键部分，因此，我们需要同步访问它以确保正确性。我们将使用**互斥锁**来做到这一点。
- en: 'The normal case might well work like this (let''s ignore thread C for now):
    thread B is on the CPU running some code; thread A is working on something else
    on another CPU core. Neither thread is in the critical section; thus, the mutex
    is in the unlocked state.'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 正常情况可能是这样的（现在先忽略线程C）：线程B正在CPU上运行一些代码；线程A正在另一个CPU核心上处理其他事情。两个线程都不在关键部分；因此，互斥锁处于未锁定状态。
- en: 'Now (at time **t1**), thread B hits the code of the critical section and takes
    the mutex lock, thus becoming the owner. It now runs the code within the critical
    section (working on X). In parallel, what if—at time **t2**— thread A too happens
    to hit the critical section and thus attempts to take the mutex lock? Well, we
    know that it''s already locked, and thus thread A will have to wait (block) upon
    the unlock that will be performed (hopefully, soon) by thread B. Once thread B
    unlocks the mutex (at time **t3**), thread A takes it (at time **t4**; we consider
    that the delay **t4**-**t3** is very tiny), and life (quite happily) continues.
    This seems fine:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 现在（在时间**t1**），线程B进入关键部分的代码并获取互斥锁，从而成为**所有者**。它现在运行关键部分的代码（处理X）。与此同时，如果—在时间**t2**—线程A也碰巧进入关键部分，因此尝试获取互斥锁呢？嗯，我们知道它已经被锁定，因此线程A将不得不等待（阻塞），直到线程B执行（希望很快）解锁。一旦线程B解锁互斥锁（在时间**t3**），线程A获取它（在时间**t4**；我们认为延迟**t4**-**t3**非常小），生活（非常愉快地）继续。这看起来很好：
- en: '![](img/ebe8bb6c-fdc5-4d88-ae4a-6769f82daea6.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebe8bb6c-fdc5-4d88-ae4a-6769f82daea6.png)'
- en: 'Fig 12: Mutex locking: the normal good case'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：互斥锁定：正常情况
- en: However, a potential bad case exists as well! Read on.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，也存在潜在的不良情况！继续阅读。
- en: Watchdog timer in brief
  id: totrans-324
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简要介绍看门狗定时器
- en: A watchdog is a mechanism which is used to periodically detect that the system
    is in a healthy state, and, if it is deemed not to be, to reboot it. This is achieved
    by setting up a (kernel) timer (to say, a 60 second timeout). If all's well, a
    watchdog daemon process (a daemon is nothing but a system background process)
    will consistently cancel the timer (before it expires, of course) and subsequently
    re-enable it; this is known as **petting the dog**. If the daemon does not (due
    to something having gone badly wrong), the watchdog is annoyed and reboots the
    system! A pure software watchdog implementation will not be protected against
    kernel bugs and faults; a hardware watchdog (which latches into the board reset
    circuitry) will always be able to reboot the system as and when required.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 看门狗是一种用于定期检测系统是否处于健康状态的机制，如果被认为不是，就会重新启动系统。这是通过设置（内核）定时器（比如，60秒超时）来实现的。如果一切正常，看门狗守护进程（守护进程只是系统后台进程）将始终取消定时器（在其到期之前，当然），然后重新启用它；这被称为**抚摸狗**。如果守护进程没有这样做（由于某些事情出了大问题），看门狗就会生气并重新启动系统！纯软件看门狗实现将无法防止内核错误和故障；硬件看门狗（它连接到板复位电路）将始终能够在需要时重新启动系统。
- en: Often, the high priority threads of embedded applications are designed to have
    very real deadlines within which they must complete some work; otherwise, the
    system is considered to have failed. One wonders, what if at run time the OS itself—due
    to an unfortunate bug— simply crashes or hangs (panics)? The application thread(s)
    then cannot continue; we need a way to detect and get out of this mess. Embedded
    designers often make use of **watchdog timer** (**WDT**) hardware circuitry (and
    an associated device driver) to achieve precisely this. If the system or a critical
    thread does not meet its deadline (fails to pet the dog), the system is rebooted.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，嵌入式应用的高优先级线程被设计为在其中必须完成一些工作的非常真实的截止日期；否则，系统被认为已经失败。人们不禁想，如果操作系统本身在运行时由于不幸的错误而崩溃或挂起（恐慌）会怎么样？然后应用线程就无法继续；我们需要一种方法来检测并摆脱这种困境。嵌入式设计人员经常利用**看门狗定时器**（**WDT**）硬件电路（以及相关的设备驱动程序）来精确实现这一点。如果系统或关键线程未能在截止日期前完成其工作（未能喂狗），系统将重新启动。
- en: 'So, back to our scenarios. Let''s say we have a deadline for the high priority
    thread A of 100 ms; repeat the preceding locking scenario in your mind, but with
    this difference (refer to *Fig 13*: as well):'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，回到我们的场景。假设我们对线程A的截止日期为100毫秒；在你的脑海中重复前面的锁定场景，但有一个区别（参考*图13*：）：
- en: '**Thread B** (the low priority thread), obtains the mutex lock at time **t1**.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线程B**（低优先级线程）在时间**t1**获得互斥锁。'
- en: '**Thread A** also requests the mutex lock at time **t2** (but has to wait upon
    the unlock by thread B).'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线程A**也在时间**t2**请求互斥锁（但必须等待线程B的解锁）。'
- en: Before thread B can complete the critical section, another medium priority thread
    C (running on the same CPU core and at priority 45) wakes up! It will immediately preempt thread
    B as its priority is higher (recall that the highest priority runnable thread
    must be the thread that is running).
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在线程B完成关键部分之前，另一个中等优先级的线程C（在同一CPU核心上运行，并且优先级为45）醒来了！它会立即抢占线程B，因为它的优先级更高（请记住，可运行的最高优先级线程必须是正在运行的线程）。
- en: Now, until thread C gets off the CPU, thread B cannot complete the critical
    section, and therefore cannot perform the unlock.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，在线程C离开CPU之前，线程B无法完成关键部分，因此无法执行解锁。
- en: 'This, in turn, can significantly delay thread A, which is blocking upon the
    yet-to-happen unlock by thread B:'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这反过来会显著延迟线程A，它正在等待线程B尚未发生的解锁：
- en: However, thread B has been preempted by thread C, hence it cannot perform the
    unlock.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，线程B已被线程C抢占，因此无法执行解锁。
- en: What if the time to unlock exceeds the deadline for thread A (at time **t4**)?
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果解锁的时间超过了线程A的截止日期（在时间**t4**）会怎么样？
- en: 'Then the watchdog timer will expire, forcing a system reboot:'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后看门狗定时器将会过期，强制系统重新启动：
- en: '![](img/5d1e63a3-f58b-49e8-abf4-80d9eed4a655.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5d1e63a3-f58b-49e8-abf4-80d9eed4a655.png)'
- en: 'Fig 13: Priority inversion'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：优先级反转
- en: Interesting, and unfortunate; did you notice that the highest priority thread
    (A) was in effect forced to wait upon the lowest priority thread (B) on the system?
    This phenomenon is in fact a documented software risk , formally called priority
    inversion.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣而不幸的是；你是否注意到最高优先级的线程（A）实际上被迫等待系统中优先级最低的线程（B）？这种现象实际上是一种已记录的软件风险，正式称为优先级反转。
- en: Not only that, consider what might happen if several medium priority threads
    woke up while thread B was in its critical section (and thus holding the lock)?
    The potential time wait for thread A can now become very large; such situations
    are known as unbounded priority inversion.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，想象一下，如果在线程B处于其关键部分（因此持有锁）时，有几个中等优先级的线程醒来会发生什么？线程A的潜在等待时间现在可能会变得非常长；这种情况被称为无界优先级反转。
- en: The Mars Pathfinder mission in brief
  id: totrans-340
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 火星探路者任务简介
- en: 'Very interestingly, this precise scenario priority inversion  played out quite
    dramatically in a literally out of this world setting: on the surface of Mars!
    NASA successfully landed a robot spacecraft (the Pathfinder Lander) on the Martian
    surface on July 4, 1997; it then proceeded to unload and deploy a smaller robot—the Sojourner
    Rover—onto the surface. However, controllers found that the lander ran into problems—every
    so often it would reboot. Detailed analysis of the live telemetry feed ultimately
    revealed the underlying issue—it was the software, which had hit a priority inversion
    issue! To their immense credit, NASA''s **Jet Propulsion Laboratory** (**JPL**)
    team, along with engineers from Wind River, the company that supplied a custom VxWorks
    RTOS to NASA, diagnosed and debugged the situation from Earth, determined the
    root cause defect as a priority inversion issue, fixed it, uploaded the new firmware
    to the rover, and it all worked:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 非常有趣的是，这种精确的优先级反转场景在一个真正超凡脱俗的环境中发生了：在火星表面！美国宇航局成功地在1997年7月4日将一艘机器人飞船（探路者着陆器）降落在火星表面；然后它继续卸载并部署了一个更小的机器人——Sojourner
    Rover——到表面上。然而，控制器发现着陆器遇到了问题——每隔一段时间就会重新启动。对实时遥测数据的详细分析最终揭示了潜在问题——是软件，它遇到了优先级反转问题！值得赞扬的是，美国宇航局的**喷气推进实验室**（**JPL**）团队，以及Wind
    River公司的工程师，他们为美国宇航局提供了定制的VxWorks RTOS，他们从地球上诊断和调试了这种情况，确定了根本原因是优先级反转问题，修复了它，上传了新的固件到探路者，一切都正常运行了：
- en: '![](img/e0ce7e31-9f76-42ff-8936-e9358bb67eca.png)'
  id: totrans-342
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e0ce7e31-9f76-42ff-8936-e9358bb67eca.png)'
- en: 'Figure 14: Photo from the Mars Pathfinder Lander'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：火星探路者着陆器的照片
- en: The news spread (in a viral fashion) when an MS engineer, Mike Jones, at an
    IEEE Real-Time Symposium, wrote an interesting email about what occurred with
    NASA's Pathfinder mission; this was ultimately, and in detail, responded to by
    the team leader of NASA's JPL, Glenn Reeves, with a now quite famous article entitled *What
    Really Happened on Mars?*. Many interesting insights were captured in this and
    subsequent articles written on the topic. In my opinion, all software engineers
    would do themselves a favor by reading these! (Do look up the links provided in
    the *Further reading* section on the GitHub repository under Mars Pathfinder and
    Priority Inversion.)
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 当微软工程师迈克·琼斯在IEEE实时研讨会上写了一封有趣的电子邮件，讲述了NASA的Pathfinder任务发生了什么事情时，这一消息以病毒式传播。这封电子邮件最终得到了NASA的JPL团队负责人格伦·里夫斯的详细回复，题为《火星上到底发生了什么？》。这和后续文章中捕捉到了许多有趣的见解。在我看来，所有软件工程师都应该读一读这些文章！（在GitHub存储库的*进一步阅读*部分查找提供的链接，标题为火星Pathfinder和优先级倒置。）
- en: 'Glenn Reeves stresses a few important lessons learned and the reasons why they
    were able to reproduce and fix the issue, and one of them is this: We strongly
    believe in the test what you fly and fly what you test philosophy. In effect,
    because of the design decisions to keep relevant detailed diagnostic and debug
    information in trace/log ring buffers, which could be dumped at will (and sent
    to Earth), they were able to debug the root issue at hand.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: Glenn Reeves强调了一些重要的教训和他们能够重现和解决问题的原因，其中之一是：我们坚信测试你所飞行的东西，飞行你所测试的哲学。实际上，由于设计决策将相关的详细诊断和调试信息保留在跟踪/日志环形缓冲区中，这些信息可以随意转储（并发送到地球），他们能够调试手头的根本问题。
- en: Priority inheritance – avoiding priority inversion
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优先级继承-避免优先级倒置
- en: Okay, great; but how does one fix such an issue as priority inversion? Interestingly,
    this is a known risk, and the design of the mutex includes a built-in solution. Two
    mutex attributes exist with regard to helping address the priority inversion issue—**priority
    inheritance** (**PI**) and priority ceiling.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 好的；但是如何解决优先级倒置这样的问题呢？有趣的是，这是一个已知的风险，互斥锁的设计包括了一个内置的解决方案。关于帮助解决优先级倒置问题的互斥锁属性存在两个——优先级继承（PI）和优先级上限。
- en: 'PI is an interesting solution. Think about it, the key issue is the way in
    which the OS schedules threads. In an OS (and especially on an RTOS), the scheduling
    of a real-time thread—deciding who runs—is essentially directly proportional to
    the priority of the competing threads: the higher your priority, the better the
    chance you will run. So, let''s take a quick relook at our preceding scenario
    example. Recall that we have these three threads at differing priorities:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: PI是一个有趣的解决方案。想想看，关键问题是操作系统调度线程的方式。在操作系统（尤其是在实时操作系统上），实时线程的调度——决定谁运行——基本上与竞争线程的优先级成正比：你的优先级越高，你运行的机会就越大。所以，让我们快速重新看一下我们之前的场景示例。回想一下，我们有这三个不同优先级的线程：
- en: 'Thread A: high priority, 90'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程A：高优先级，90
- en: 'Thread B: low priority, 10'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程B：低优先级，10
- en: 'Thread C: medium priority, 45'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程C：中等优先级，45
- en: The priority inversion occurred when thread B held the mutex lock for a long
    while, thus forcing thread A to block on the unlock for perhaps far too long (over
    the deadline). So, think about this: what if, the moment thread B grabs the mutex
    lock, we increase its priority to that of the highest priority thread on the system
    which is also waiting on the same mutex lock. Then, of course, thread B will get
    priority 90 and thus cannot be preempted (by thread C or any other thread for
    that matter)! This ensures that it completes its critical section quickly and
    unlocks the mutex; the moment it unlocks it, it goes back to its original priority.
    This solves the problem; this approach is termed PI.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 优先级倒置发生在线程B长时间持有互斥锁时，从而迫使线程A在解锁时可能要等待太久（超过截止日期）。所以，想想这个：如果线程B一抓住互斥锁，我们就把它的优先级提高到系统上等待相同互斥锁的最高优先级线程的优先级。然后，当然，线程B将获得优先级90，因此不能被抢占（无论是被线程C还是其他任何线程）！这确保了它快速完成临界区并解锁互斥锁；一旦解锁，它就会恢复到原来的优先级。这解决了问题；这种方法被称为PI。
- en: 'The pthreads API set provides a pair of APIs to query and set the protocol mutex
    attribute, upon which you can make use of PI:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: pthreads API集提供了一对API来查询和设置协议互斥锁属性，你可以利用PI：
- en: '[PRE21]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The value that the protocol parameter can take is one of the following:  PTHREAD_PRIO_INHERIT,
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 协议参数可以取以下值之一：PTHREAD_PRIO_INHERIT，
- en: PTHREAD_PRIO_NONE, or PTHREAD_PRIO_PROTECT (the default being PTHREAD_PRIO_NONE).
    When a mutex has one of the INHERIT or PROTECT protocols, its owner thread is
    affected in terms of scheduling priority.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: PTHREAD_PRIO_NONE，或PTHREAD_PRIO_PROTECT（默认为PTHREAD_PRIO_NONE）。当互斥锁具有INHERIT或PROTECT协议之一时，其所有者线程在调度优先级方面会受到影响。
- en: A thread that holds the lock (owns it) on any mutexes initialized with the PTHREAD_PRIO_INHERIT protocol
    will inherit the highest priority (and therefore execute at that priority) of
    any thread that is blocked upon (waiting) on any of these mutexes (robust or non-robust)
    that also uses this protocol.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用PTHREAD_PRIO_INHERIT协议初始化的任何互斥锁，持有锁（拥有它）的线程将继承任何线程的最高优先级（因此以该优先级执行），这些线程在任何使用此协议的互斥锁（鲁棒或非鲁棒）上阻塞（等待）。
- en: A thread that holds the lock (owns it) on any mutexes initialized with the  PTHREAD_PRIO_PROTECT protocol
    will inherit the highest priority ceiling (and therefore execute at that priority)
    of any thread that also uses this protocol, regardless of whether or not they
    are currently blocking upon (waiting) on any of these mutexes (robust or non-robust).
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用PTHREAD_PRIO_PROTECT协议初始化的任何互斥锁，持有锁（拥有它）的线程将继承任何使用此协议的线程的最高优先级上限（因此以该优先级执行），无论它们当前是否在任何这些互斥锁（鲁棒或非鲁棒）上阻塞（等待）。
- en: If a thread uses mutexes initialized with differing protocols, it will execute
    at the highest priority defined among them.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个线程使用了使用不同协议初始化的互斥锁，它将以它们中定义的最高优先级执行。
- en: On the Pathfinder mission, the RTOS used was the well-known VxWorks by Wind
    River. The mutex (or semaphores) certainly had the PI attribute; it's just that
    the JPL software team missed turning on the PI attribute of a mutex lock, resulting
    in the priority inversion issue! (Actually, the software team was well aware of
    it and used it in several places, but not the one place that struck — Murphy's
    Law at work!)
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在“开拓者”任务中，RTOS 使用的是著名的 VxWorks，由风河公司提供。互斥锁（或信号量）肯定具有 PI 属性；只是 JPL 软件团队忘记打开互斥锁的
    PI 属性，导致了优先级反转问题！（实际上，软件团队对此非常清楚，并在几个地方使用了它，但没有在发生问题的地方使用 —— 这就是墨菲定律在起作用！）
- en: Furthermore, the developer can make use of priority ceiling—this is the minimum
    priority at which the owner thread will execute the code of the critical section.
    Thus, being able to specify this, one can ensure that it's at a sufficiently high
    value to guarantee that the owner thread does not get preempted while in the critical
    section. The pthreads `pthread_mutexattr_getprioceiling(3)` and `pthread_mutexattr_setprioceiling(3)` API's
    can be used to query and set the priority ceiling attribute of a mutex. (It must
    fall within the valid SCHED_FIFO priority range, typically 1 to 99 on the Linux
    platform).
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，开发人员可以利用优先级上限——这是所有者线程执行临界区代码的最低优先级。因此，通过能够指定这一点，可以确保它具有足够高的值，以确保所有者线程在临界区时不会被抢占。Pthreads
    `pthread_mutexattr_getprioceiling(3)` 和 `pthread_mutexattr_setprioceiling(3)`
    API 可以用于查询和设置互斥锁的优先级上限属性。（它必须在有效的 SCHED_FIFO 优先级范围内，通常在 Linux 平台上为 1 到 99）。
- en: 'Again, in practice, there are some challenges in using priority inheritance
    and ceiling attributes, which are, mostly, performance overheads:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，在实践中，使用优先级继承和上限属性存在一些挑战，主要是性能开销：
- en: Heavier task/context switching can result
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更重的任务/上下文切换可能会导致
- en: Priority propagation can add overhead
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优先级传播会增加开销
- en: With many threads and many locks, there is performance overhead, as well the
    potential for deadlock climbs
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有许多线程和许多锁时，会有性能开销，同时也会有死锁的潜在风险
- en: Summary of mutex attribute usage
  id: totrans-366
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥属性使用摘要
- en: 'In effect, if you would like to thoroughly test and debug your application
    and don''t really care about performance (right now, at least), then set up your
    mutex as follows:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，如果您想彻底测试和调试您的应用程序，并且现在并不真的关心性能，那么请设置您的互斥锁如下：
- en: Set the robust attribute on it (allowing one to catch the owner-dies-without-unlocking case): `pthread_mutexattr_setrobust(&attr, PTHREAD_MUTEX_ROBUST)`
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在其上设置 robust 属性（允许捕获所有者死亡而不解锁的情况）：`pthread_mutexattr_setrobust(&attr, PTHREAD_MUTEX_ROBUST)`
- en: 'Set the type to error checking (allowing one to catch the self-deadlock / relock case):'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将类型设置为错误检查（允许捕获自死锁/重新锁定的情况）：
- en: '`pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_ERRORCHECK)`'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '`pthread_mutexattr_settype(&attr, PTHREAD_MUTEX_ERRORCHECK)`'
- en: On the other hand, a well-designed and proven application that requires you
    to squeeze out performance would use the normal (default) mutex type and attributes.
    The preceding cases will not be caught (and will instead result in undefined behavior),
    but then, they should never occur!
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，一个设计良好且经过验证的应用程序，需要您挤出性能，将使用正常（默认）的互斥锁类型和属性。前面的情况不会被捕捉到（而是导致未定义的行为），但是它们本来就不应该发生！
- en: If one requires a recursive lock, (obviously) set the mutex type to PTHREAD_MUTEX_RECURSIVE. With
    the recursive mutex, it's important to realize that if the mutex lock is performed `n` times,
    it must also be unlocked `n` times in order for it be considered to be truly in
    the unlocked state (and therefore lockable again).
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要递归锁定，（显然）将互斥锁类型设置为 PTHREAD_MUTEX_RECURSIVE。对于递归互斥锁，重要的是要意识到，如果互斥锁被锁定 `n`
    次，则为了被认为真正处于解锁状态（因此可以再次锁定），它也必须被解锁 `n` 次。
- en: In a multiprocess and multithreaded application, if there is a need to use a
    mutex lock between threads of different processes, this can be achieved via the process-shared
    attribute of the mutex object. Note that, in this case, the memory that contains
    the mutex must itself be shared between the processes (we usually use a shared
    memory segment).
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在多进程和多线程应用程序中，如果需要在不同进程的线程之间使用互斥锁，可以通过互斥对象的进程共享属性来实现。请注意，在这种情况下，包含互斥锁的内存本身必须在进程之间共享（通常使用共享内存段）。
- en: 'The PI and the priority ceiling attributes allow the developer to safeguard
    the application against a well-understood software risk: priority inversion.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: PI 和优先级上限属性使开发人员能够保护应用程序免受众所周知的软件风险：优先级反转。
- en: Mutex locking – additional variants
  id: totrans-375
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁定 - 附加变体
- en: This section helps one understand additional—slightly different semantics—to
    mutex locking. We will cover the timeout mutex variant, the "busy-waiting" use
    case, and the reader-writer lock.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 本节帮助理解互斥锁的附加变体，稍微不同的语义。我们将涵盖超时互斥锁变体、"忙等待"用例和读者-写者锁。
- en: Timing out on a mutex lock attempt
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 争取互斥锁超时
- en: 'In the earlier section, *Locking guidelines*, under the label prevent starvation,
    we understood that holding a mutex lock for a long-ish time leads to performance
    issues; noticeably, the loser threads will starve. A way to ward off this issue
    (although, of course, fixing the underlying root cause of any starvation is the
    important thing to do!) is to have the loser threads wait upon the mutex lock
    for only a certain amount of time; if it takes longer to be unlocked, forget it.
    This is precisely the functionality that the `pthread_mutex_timedlock(3)` API
    provides:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的“锁定指南”部分中，在防止饥饿的标签下，我们了解到长时间持有互斥锁会导致性能问题；显然，失败的线程会饿死。避免这个问题的一种方法（尽管，当然，修复任何饥饿的根本原因才是重要的！）是让失败的线程等待一定时间后再等待互斥锁；如果等待时间超过一定时间，就放弃。这正是
    `pthread_mutex_timedlock(3)` API 提供的功能：
- en: '[PRE22]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'It''s quite obvious: all locking semantics remains the same as they do for
    the usual `pthread_mutex_lock(3)`, except that if the time spent blocking (waiting)
    upon the lock exceeds the second parameter—the time specified as an absolute value,
    where the API returns failure—the value returned will be `ETIMEDOUT`. (We have
    already programmed timeouts in detail in [Chapter 13](1f621f72-e067-42db-b2eb-b82e20161dec.xhtml),
    *Timers*.)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显：所有锁定语义与通常的`pthread_mutex_lock(3)`一样，只是如果在锁上花费的阻塞时间（等待）超过第二个参数——作为绝对值指定的时间，API返回失败——返回的值将是`ETIMEDOUT`。（我们已经在[第13章](1f621f72-e067-42db-b2eb-b82e20161dec.xhtml)中详细编程了超时，*定时器*。）
- en: Note, though, that other error return values are possible (for example, `EOWNERDEAD`
    for a robust mutex in which the previous owner terminates, `EDEADLK` for a deadlock
    being detected on an error-checking mutex, and so on.). Please refer to the man
    page on `pthread_mutex_timedlock(3)` for details.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，其他错误返回值也是可能的（例如，对于先前所有者终止的鲁棒互斥锁，可能返回`EOWNERDEAD`，对于检查错误的互斥锁检测到死锁，等等）。有关详细信息，请参阅`pthread_mutex_timedlock(3)`的手册页。
- en: Busy-waiting (non-blocking variant) for the lock
  id: totrans-382
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 忙等待（非阻塞变体）锁
- en: We understand how a mutex lock works normally: if a lock is already locked,
    then attempting to take the lock will cause that thread to block (wait upon) the
    unlock occurring. What if one wants a design which goes something like this: if
    the lock is locked, don't make me wait; I'll do some other work and retry? This
    semantic is often referred to as busy-waiting or non-blocking, and is provided
    by the trylock variant. As the name suggests, we try for the lock and if we get
    it, great; if not, it's okay—we do not force the thread to wait. The lock might
    be taken by any thread within the process (or even outside if it's a process-shared
    mutex) including the same thread—if it's marked as recursive. But hold on; if
    the mutex lock is indeed a recursive lock, then taking it will succeed immediately and
    the call will return straight away.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道互斥锁的正常工作方式：如果锁已经被锁定，那么尝试获取锁将导致该线程阻塞（等待）解锁事件发生。如果有人想要一个设计，大致如下：如果锁已被锁定，不要让我等待；我会做一些其他工作然后重试？这种语义通常被称为忙等待或非阻塞，并由trylock变体提供。顾名思义，我们尝试获取锁，如果成功，很好；如果没有，没关系——我们不会强迫线程等待。锁可以被进程内的任何线程（甚至是外部线程，如果它是进程共享的互斥锁）获取，包括相同的线程——如果它被标记为递归。但是等等；如果互斥锁确实是递归锁，那么获取它将立即成功，并且调用将立即返回。
- en: 'The API for this is as follows:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 其API如下：
- en: '`​int pthread_mutex_trylock(pthread_mutex_t *mutex);`.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '`int pthread_mutex_trylock(pthread_mutex_t *mutex);`。'
- en: 'While this busy-waiting semantic is useful on occasion—specifically, it is
    used to detect and prevent certain types of deadlock—be careful when using it.
    Think about it: for a lightly contented lock (one which is not being used often,
    in which the thread attempting to take the lock will very likely get it straight
    away), using this busy-wait semantic might be useful. But for a heavily contented lock
    (a lock on a hot code path, taken and released often), this can actually hurt
    one''s chances of obtaining the lock! Why? Because you are not willing to wait
    for it. (Funny how software mimics life sometimes, yes?)'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这种忙等待语义偶尔会很有用——具体来说，它用于检测和防止某些类型的死锁——但在使用时要小心。想一想：对于一个轻度争用的锁（很少被使用的锁，在这种情况下，尝试获取锁的线程很可能会立即获得锁），使用这种忙等待语义可能是有用的。但对于一个严重争用的锁（在热代码路径上的锁，经常被获取和释放），这实际上可能会损害获得锁的机会！为什么？因为你不愿意等待它。（有时软件模仿生活，是吧？）
- en: The reader-writer mutex lock
  id: totrans-387
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 读者-写者互斥锁
- en: 'Visualize a multithreaded application with some ten worker threads; let''s
    say that, most of the time (say 90% of the time), eight of the workers are busy
    scanning a global linked list (or similar data structure). Now, of course, since
    it''s global, we know that it''s a critical section; failing to protect it with
    a mutex can easily result in a dirty read bug. But, this is at a major performance
    cost: as each worker thread wants to search the list, it is forced to wait upon
    the unlock event from the owner.'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一个多线程应用程序，有十个工作线程；假设大部分时间（比如90%的时间），八个工作线程都在忙于扫描全局链表（或类似的数据结构）。现在，当然，由于它是全局的，我们知道它是一个临界区；如果没有用互斥锁保护它，很容易导致脏读错误。但是，这会带来很大的性能成本：因为每个工作线程都想要搜索列表，它被迫等待来自所有者的解锁事件。
- en: 'Computer scientists have come up with quite an innovate alternative for situations
    like this (also referred to as the reader-writer problem), wherein the data accesses
    are such that for the majority of time (shared) data is only being read and not
    written to. We use a special variant of the mutex lock called the reader-writer lock:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学家已经提出了一种创新的替代方案，用于这种情况（也称为读者-写者问题），其中数据访问的大部分时间（共享）数据只被读取而不被写入。我们使用了一种特殊的互斥锁变体，称为读者-写者锁：
- en: '[PRE23]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Notice that it''s a new type of lock altogether: the `pthread_wrlock_t`.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这是一种全新的锁类型：`pthread_wrlock_t`。
- en: 'If a thread obtains a read lock for itself, the key point is this: the implementation
    now trusts that this thread will only read and never write; thus, no actual locking
    is done and the API will just return success! This way, readers actually run in
    parallel, thus keeping performance high; there is no safety issue or race, as
    they guarantee they will only read.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个线程为自己获取了读锁，关键点在于：实现现在信任这个线程只会读取而不会写入；因此，不会进行实际的锁定，API将直接返回成功！这样，读者实际上是并行运行的，从而保持了性能；没有安全问题或竞争，因为他们保证只会读取。
- en: However, the moment a thread wishes to write data, it must obtain a write lock: when
    this happens, normal locking semantics apply. The writer thread must now wait
    for all readers to perform the unlock, and then the writer gets the write lock
    and proceeds. While it's within the critical section, no thread—reader nor writer—will
    be able to intervene; they will have to, as is usual, block (wait) upon the writer's
    unlock. Thus, both scenarios are now optimized.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一旦一个线程希望写入数据，它必须获得写锁：当这发生时，正常的锁定语义适用。写入线程现在必须等待所有读者执行解锁，然后写入者获得写锁并继续。在临界区内，没有线程——读者也不是写者——能够干预；它们将像通常一样阻塞（等待）写入者的解锁。因此，现在两种情况都得到了优化。
- en: 'The usual suspects—the APIs—for setting up the reader-writer mutex lock attributes
    exist (in alphabetical order):'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的嫌疑犯——用于设置读写互斥锁属性的API存在（按字母顺序排列）：
- en: '`pthread_rwlockattr_destroy(3P)`'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlockattr_destroy(3P)`'
- en: '`pthread_rwlockattr_getpshared(3P)`'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlockattr_getpshared(3P)`'
- en: '`pthread_rwlockattr_setkind_np(3P)`'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlockattr_setkind_np(3P)`'
- en: '`pthread_rwlockattr_getkind_np(3P)`'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlockattr_getkind_np(3P)`'
- en: '`pthread_rwlockattr_init(3P)`'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlockattr_init(3P)`'
- en: '`pthread_rwlockattr_setpshared(3P)`'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlockattr_setpshared(3P)`'
- en: Note that the APIs suffixed with `_np` imply they are non-portable, and Linux-only.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，以`_np`结尾的API意味着它们是非便携的，仅适用于Linux。
- en: 'Similarly, the reader-writer locking APIs follow the usual pattern—the timeout
    and try variants are present as well:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，读写锁定的API遵循通常的模式——超时和尝试变体也存在。
- en: '`pthread_rwlock_destroy(3P)`'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_destroy(3P)`'
- en: '`pthread_rwlock_init(3P)`'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_init(3P)`'
- en: '`pthread_rwlock_timedrdlock(3P)`'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_timedrdlock(3P)`'
- en: '`pthread_rwlock_tryrdlock(3P)`'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_tryrdlock(3P)`'
- en: '`pthread_rwlock_unlock(3P)`'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_unlock(3P)`'
- en: '`pthread_rwlock_rdlock(3P)`'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_rdlock(3P)`'
- en: '`pthread_rwlock_timedwrlock(3P)`'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_timedwrlock(3P)`'
- en: '`pthread_rwlock_trywrlock(3P)`'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_trywrlock(3P)`'
- en: '`pthread_rwlock_wrlock(3P)`'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_rwlock_wrlock(3P)`'
- en: We expect the programmer to set up in a normal manner—initialize the rwlock attribute
    object, initialize the rwlock itself (with `pthread_rwlock_init(3P)`), destroy
    the attribute structure once done with it, and then perform the actual locking
    as required.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望程序员按照正常的方式设置——初始化读写锁属性对象，初始化读写锁本身（使用`pthread_rwlock_init(3P)`），在完成后销毁属性结构，然后根据需要执行实际的锁定。
- en: 'Note, though, that when using reader-writer locks, the application should be
    carefully tested for performance; it has been noted to be a slower implementation
    than the usual mutex lock. Also, there is the additional worry that, under load,
    the reader-writer locking semantics might result in writer starvation. Think:
    if readers keep coming up, the writer thread might have to wait for a long time
    before it gets the lock.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当使用读写锁时，应该仔细测试性能；已经注意到它比通常的互斥锁实现要慢。此外，还有一个额外的担忧，在负载下，读写锁的语义可能导致写入者饥饿。想象一下：如果读者不断出现，写入线程可能要等很长时间才能获得锁。
- en: 'Apparently, with the reader-writer lock, the opposite dynamic can also occur:
    the readers could be starved. Interestingly, Linux provides a non-portable API,
    allowing the programmer to specify which kind of starvation to prevent—reader
    or writer—with the default being that the writers starve. The API to invoke to
    set this up is `pthread_rwlockattr_setkind_np(3)`. This allows some degree of
    tuning based on your specific workload. (However, the implementation apparently
    still suffers from a bug wherein, in effect, writer starvation remains the reality.
    We do not attempt to go into this further; the reader is referred to the man page
    if further aid is required.)'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，使用读写锁也可能出现相反的动态：读者可能被饥饿。有趣的是，Linux提供了一个非便携的API，允许程序员指定要防止哪种类型的饥饿——读者还是写者，其中默认是写者被饥饿。调用此API进行设置的方法是`pthread_rwlockattr_setkind_np(3)`。这允许根据特定的工作负载进行一定程度的调整。（然而，实现显然仍然存在一个bug，实际上，写者饥饿仍然是现实。我们不打算进一步讨论这一点；如有需要，读者可以参考手册页以获得进一步的帮助。）
- en: Nevertheless, the reader-writer lock variant is often useful; think of applications
    that need to often scan some key-value map data structure and perform a table
    lookup of some sort. (For example, an OS often has network code paths that often
    look up the routing table but rarely update it.) The invariant is that the global
    shared data in question is often read from but rarely written to.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，读写锁变体通常是有用的；想想那些经常需要扫描某些键值映射数据结构并执行某种表查找的应用程序。（例如，操作系统经常有网络代码路径经常查找路由表但很少更新它。）不变的是，所讨论的全局共享数据通常被读取，但很少被写入。
- en: The spinlock variant
  id: totrans-416
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自旋锁变体
- en: 'A bit of repetition here: we already understand how a mutex lock works normally;
    if a lock is already locked, then attempting to take the lock will cause that
    thread to block (wait upon) the unlock occurring. Let''s dig a little deeper; how
    exactly do the loser threads block—wait upon — the unlock of the mutex? The answer
    is that, for the mutex lock, they do so by sleeping (being scheduled off CPU by
    the OS). This, in fact, is one of the defining properties of the mutex lock.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一点重复：我们已经了解了互斥锁的正常工作方式；如果锁已经被锁定，那么尝试获取锁将导致该线程阻塞（等待解锁）。让我们深入一点；失败的线程究竟如何阻塞——等待——互斥锁的解锁？答案是，对于互斥锁，它们通过睡眠（被操作系统调度下CPU）来实现。事实上，这是互斥锁的一个定义属性。
- en: 'On the other hand, there exists a different kind of lock altogether—the spinlock (very
    commonly used within the Linux kernel) whose behavior is quite the opposite: it
    works by having the loser threads wait upon the unlock operation by spinning (polling)—well,
    the reality is that the actual spinlock implementation is a lot more refined 
    and efficient than it''s made to sound here; this discussion is well beyond the
    scope of this book, though. At first glance, polling seems to be a poor way to
    have the loser threads wait on the unlock; the reason it works well with the spinlock
    is that the time taken within the critical section is guaranteed to be very small
    (technically, less than the time required to perform two context switches), thus
    making the spinlock much more efficient to use than the mutex when the critical
    section tiny.'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，还存在一种完全不同的锁——spinlock（在Linux内核中非常常用），其行为恰恰相反：它通过让失败的线程等待解锁操作来工作（旋转/轮询）——实际上，实际的spinlock实现要比这里描述的更加精细和高效；不过，这个讨论已经超出了本书的范围。乍一看，轮询似乎是让失败的线程等待解锁的一种不好的方式；它能够与spinlock很好地配合工作的原因在于临界区内所需的时间保证非常短（从技术上讲，小于执行两次上下文切换所需的时间），因此在临界区很小的情况下，使用spinlock比互斥锁更加高效。
- en: 'Though the pthreads implementation does provide the spinlock, one should be
    clear on these points:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管pthread实现确实提供了自旋锁，但应明确以下几点：
- en: The spinlock is only meant to be used by extreme performance real-time threads
    that employ a real-time OS scheduling policy (SCHED_FIFO, and possibly SCHED_RR;
    we discuss these in [Chapter 17](36229bac-c402-4d2f-b876-d1eb4aba8051.xhtml),
    *CPU Scheduling on Linux*).
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自旋锁只应该由使用实时操作系统调度策略（SCHED_FIFO，可能还有SCHED_RR；我们在[第17章](36229bac-c402-4d2f-b876-d1eb4aba8051.xhtml)中讨论这些，*Linux上的CPU调度*）的极端性能实时线程使用。
- en: The default scheduling policy on the Linux platform is never a real-time one; it's
    the non-real-time SCHED_OTHER policy, which is well-suited to non-deterministic
    applications; using the mutex lock is the way to go.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linux平台上的默认调度策略从不是实时的；它是非实时的SCHED_OTHER策略，非常适合非确定性应用程序；使用互斥锁是正确的方法。
- en: Using spinlocks in user space is not considered the right design approach; moreover,
    the code will be a lot more susceptible to deadlock and (unbounded) priority inversion
    scenarios.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在用户空间使用自旋锁不被认为是正确的设计方法；此外，代码将更容易受到死锁和（无限）优先级反转的影响。
- en: 'For the preceding reasons, we refrain from delving into the following pthreads spinlock
    APIs:'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 出于上述原因，我们不深入研究以下pthread spinlock API：
- en: '`pthread_spin_init(3)`'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_spin_init(3)`'
- en: '`pthread_spin_lock(3)`'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_spin_lock(3)`'
- en: '`pthread_spin_trylock(3)`'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_spin_trylock(3)`'
- en: '`pthread_spin_unlock(3)`'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_spin_unlock(3)`'
- en: '`pthread_spin_destroy(3)`'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pthread_spin_destroy(3)`'
- en: If required, do look them up within their respective manual pages (but also
    be doubly careful if employing them!).
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，确保在各自的手册页中查找它们（但在使用时要格外小心！）。
- en: A few more mutex usage guidelines
  id: totrans-430
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一些互斥锁使用指南
- en: 'In addition to the tips and guidelines that were provided earlier (refer to
    the *Locking Guidelines* section), think upon this as well:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前提供的提示和指南（参考*锁定指南*部分）之外，也要考虑这一点：
- en: How many locks should one use?
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该使用多少个锁？
- en: With many lock instances, how to know which lock variable to use and when?
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有了许多锁实例，如何知道何时使用哪个锁变量？
- en: Test whether a mutex is locked or not.
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试互斥锁是否被锁定。
- en: Let's take these points up one by one.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 我们逐一来看这些要点。
- en: 'In small applications (like the kind shown here), perhaps using just a single
    lock to protect critical sections is enough; it has the advantage of keeping things
    simple (which is a big deal). However, in a large project, using just one lock
    to perform locking on every critical section one might encounter has the potential
    to become a major performance breaker! Think about why exactly this is: the moment
    that one mutex lock is hit anywhere in the code, all parallelism stops, and the
    code runs in a serialized fashion; if this happens often enough, performance will
    rapidly degrade.'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 在小型应用程序中（如此处所示的类型），也许只使用一个锁来保护临界区就足够了；这样做的好处是保持简单（这很重要）。然而，在大型项目中，只使用一个锁来对可能遇到的每个临界区进行锁定可能会成为一个主要的性能瓶颈！思考一下为什么会这样：一旦代码中的任何地方遇到一个互斥锁，所有的并行性都会停止，代码将以串行方式运行；如果这种情况经常发生，性能将迅速下降。
- en: Interestingly, the Linux kernel, for years, had a major performance headache
    precisely because of one lock that was being used throughout large cross sections
    of the codebase—so much so, that it was nicknamed the **big kernel lock** (**BKL**)
    (a giant lock). It was finally gotten rid of only in the 2.6.39 version of the
    Linux kernel (see the *Further reading* section on the GitHub repository for a
    link to more on the BKL).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，Linux内核多年来一直因为在代码库的大部分区域中使用了一把锁而导致了严重的性能问题——以至于它被昵称为**大内核锁**（**BKL**）（一个巨大的锁）。它最终在Linux内核的2.6.39版本中才被彻底摆脱（在GitHub存储库的*进一步阅读*部分中有关于BKL的更多链接）。
- en: So, while there is no rule to decide exactly how many locks one should use,
    the heuristic is to think about the simplicity versus performance trade off. As
    a tip, in large production-quality projects (like the Linux kernel), we often
    use a single lock to protect a single datum— a data object; typically, this is a
    data structure. This would ensure that the global data is protected while accessed,
    but only by the code paths that actually access it and not every code path, thus
    ensuring both data safety as well as parallelism (performance).
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然没有规则可以准确决定应该使用多少个锁，但启发式方法是考虑简单性与性能之间的权衡。在大型生产质量项目（如Linux内核）中，我们经常使用单个锁来保护单个数据——数据对象；通常，这是一种数据结构。这将确保在访问时保护全局数据，但只有实际访问它的代码路径，从而确保数据安全和并行性（性能）。
- en: 'Okay, great. Now, if we do follow this guideline, what if we end up with a
    few hundred locks!? (Yes, this is entirely possible in large projects that have
    a few hundred global data structures.) Now, we have another practical problem:
    the developer must ensure that they use the correct lock to protect a given data
    structure (of what use is using lock X meant for data structure X while accessing
    data structure Y? That would be a serious defect). So, a practical issue is how
    do I know for sure which data structure is protected by which lock or, another
    way to state it: how (how do I know for sure which lock variable protects which
    data structure?) The naive solution is to name each lock appropriately, perhaps
    something like `lock_<DataStructureName>`. Hmm, not as simple as it appears!'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。现在，如果我们遵循这个指南，如果最终有几百个锁怎么办？（是的，在有几百个全局数据结构的大型项目中，这是完全可能的。）现在，我们有另一个实际问题：开发人员必须确保他们使用正确的锁来保护给定的数据结构（使用为数据结构X设计的锁X来访问数据结构Y有什么用呢？那将是一个严重的缺陷）。因此，一个实际的问题是我怎么确定哪个数据结构由哪个锁保护，或者另一种陈述方式是：我怎么确定哪个锁变量确实保护哪个数据结构？天真的解决方案是适当地命名每个锁，也许像`lock_<DataStructureName>`这样。嗯，这并不像看起来那么简单！
- en: Informal polls have revealed that, often, one of the hardest things a programmer
    does is variable naming! (See the *Further reading* section on the GitHub repository
    for a link to this.)
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 非正式的调查显示，程序员经常做的最困难的事情之一是变量命名！（请参阅GitHub存储库上的*进一步阅读*部分，以获取相关链接。）
- en: 'So, here''s a tip: embed the lock that protects a given data structure inside
    the data structure itself; in other words, make it a member of the data structure
    it protects! (Again, the Linux kernel often uses this approach.)'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这里有一个提示：将保护给定数据结构的锁嵌入到数据结构本身中；换句话说，将其作为保护它的数据结构的成员！（再次，Linux内核经常使用这种方法。）
- en: Is the mutex locked?
  id: totrans-442
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 互斥锁被锁定了吗？
- en: 'In certain situations, the developer might be tempted to ask: given a mutex,
    can I find out if it''s in the locked or unlocked state? Perhaps the reasoning
    is: if locked, let''s unlock it.'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，开发人员可能会想问：给定一个互斥锁，我能否找出它是锁定还是未锁定状态？也许推理是：如果锁定了，让我们解锁它。
- en: 'There is a way to test this: with the `pthread_mutex_trylock(3)` API. If it
    returns `EBUSY`, it implies that the mutex is currently locked (otherwise, it
    should return `0`, implying it''s unlocked). But wait! There is an inherent race
    condition here; just think about this:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种方法可以测试这个问题：使用`pthread_mutex_trylock(3)`API。如果它返回`EBUSY`，这意味着互斥锁当前被锁定（否则，它应该返回`0`，表示它是未锁定的）。但等等！这里存在一个固有的竞争条件；想一想：
- en: '[PRE24]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: By the time we reach time t2, there is no guarantee that another thread has
    not, by now, locked the mutex in question! So, this approach is incorrect. (The
    only realistic way to do this kind of synchronization is to abandon doing this
    via mutex locks and use condition variables instead; that's what we cover in the
    next section.)
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们到达时间t2时，没有保证另一个线程现在没有锁定该互斥锁！因此，这种方法是不正确的。（这种同步的唯一现实方法是放弃使用互斥锁，而是使用条件变量；这是我们在下一节中讨论的内容。）
- en: 'This concludes our (rather long) coverage on mutex locking. Before we are done,
    we would like to point out another point of interest: we stated earlier that being atomic implies
    being able to run the critical code section to completion without interruption.
    But the reality is that our modern systems do interrupt us with (alarming) regularity—hardware
    interruptions and exceptions being the norm! Thus, one should realize that:'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们对互斥锁的（相当长的）覆盖。在我们结束之前，我们想指出另一个有趣的地方：我们之前说过，原子意味着能够完整地运行临界代码段而不被中断。但现实是，我们的现代系统确实经常中断我们——硬件中断和异常是常态！因此，人们应该意识到：
- en: In user space, with it being impossible to mask hardware interrupts, processes
    and threads will get interrupted at any point in time due to them. Thus, it's
    essentially impossible to be truly atomic with user space code. (But so what if
    we're interrupted by hardware interrupts/faults/exceptions? They will perform
    their work and hand control back to us, all very quickly. It's highly unlikely
    we race, sharing global writable data with these code entities).
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在用户空间中，由于无法屏蔽硬件中断，进程和线程随时可能因此而中断。因此，使用用户空间代码实际上不可能真正地原子化。（但如果我们被硬件中断/故障/异常中断，那又怎样呢？它们会执行它们的工作并迅速将控制权交还给我们。我们几乎不可能与这些代码实体共享全局可写数据而发生竞争。）
- en: In kernel space, though, we run with OS privilege, actually making it possible
    to mask even hardware interrupts, and thus allowing us to run in a truly atomic fashion
    (how do you think the well-known Linux kernel spinlock works?).
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在内核空间中，我们以操作系统特权运行，实际上可以屏蔽甚至硬件中断，从而使我们能够以真正的原子方式运行（你认为著名的Linux内核自旋锁是如何工作的？）。
- en: Now that we have covered the typical APIs used for locking, we encourage the
    reader to, one, work on trying out examples in a hands-on manner; and two, revisit
    the sections covered earlier in sections, *Locking guidelines* and *Deadlock*.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了用于锁定的典型API，我们鼓励读者一方面以实际操作的方式尝试示例；另一方面，重新访问之前涵盖的部分，*锁定指南*和*死锁*。
- en: Condition variables
  id: totrans-451
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 条件变量
- en: A  CV is an inter-thread event notification mechanism. Where we use the mutex
    lock to synchronize (serialize) access to a critical section, thus protecting
    it, we use condition variables to facilitate efficient communication—in terms
    of synchronizing based on the value of a data item—between the threads of a process.
    The following discussion will make this clearer.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: CV是一种线程间的事件通知机制。在我们使用互斥锁来同步（串行化）对临界区的访问，从而保护它时，我们使用条件变量来促进有效的通信——根据数据项的值来同步进程的线程之间的通信。以下讨论将使这一点更清晰。
- en: 'Often, in multithreaded application design and implementation, one is faced
    with this type of situation: a thread, B, is performing some work and another
    thread, A, is awaiting the completion of that work. Only when thread B completes
    the work should thread A continue; how can we efficiently implement this in code?'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 在多线程应用程序的设计和实现中，经常会面临这种情况：一个线程B正在执行一些工作，另一个线程A正在等待该工作的完成。只有当线程B完成工作时，线程A才能继续；我们如何在代码中高效地实现这一点？
- en: No CV – the naive approach
  id: totrans-454
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 没有CV - 幼稚的方法
- en: 'One might recall that the exit status of a thread (via `pthread_exit(3)`) is
    passed back to the thread that calls `pthread_join(3)`; could we make use of this
    feature? Well, no: for one thing, it''s not necessarily the case that thread B
    will terminate once the designated work is complete (it might only be a milestone
    and not all of the job it has to perform), and two, even if it does terminate,
    perhaps some other thread besides the one invoking `pthread_join(3)` might need
    to know.'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会记得线程的退出状态（通过`pthread_exit(3)`）会传递回调用`pthread_join(3)`的线程；我们能利用这个特性吗？好吧，不行：首先，并不一定线程B一旦指定的工作完成就会终止（它可能只是一个里程碑，而不是它要执行的所有工作），其次，即使它终止了，也许除了调用`pthread_join(3)`的线程之外，可能还有其他线程需要知道。
- en: 'Okay; why not have thread A poll upon the completion by the simple technique
    of having thread B set a global integer (call it `gWorkDone`) to 1 when the work
    is complete (and having thread A poll on it, of course), perhaps something like
    the following in pseudocode:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，为什么不让线程A通过简单的技术来轮询完成工作，即当工作完成时，线程B将一个全局整数（称为`gWorkDone`）设置为1（当然线程A会轮询它），也许就像伪代码中的以下内容：
- en: '| **Time** | **Thread B** | **Thread A** |'
  id: totrans-457
  prefs: []
  type: TYPE_TB
  zh: '| **时间** | **线程B** | **线程A** |'
- en: '| t0 | Initialize: `gWorkDone = 0` |  < common > |'
  id: totrans-458
  prefs: []
  type: TYPE_TB
  zh: '| t0 | 初始化：`gWorkDone = 0` |  <通用> |'
- en: '| t1 | Perform the work ... | `while (!gWorkDone) ;` |'
  id: totrans-459
  prefs: []
  type: TYPE_TB
  zh: '| t1 | 执行工作... | `while (!gWorkDone) ;` |'
- en: '| t2 | ... | ... |'
  id: totrans-460
  prefs: []
  type: TYPE_TB
  zh: '| t2 | ... | ... |'
- en: '| t3 | Work done; `gWorkDone = 1` | ... |'
  id: totrans-461
  prefs: []
  type: TYPE_TB
  zh: '| t3 | 工作完成；`gWorkDone = 1` | ... |'
- en: '| t4 |  | Detected; break out of the loop and continue |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| t4 |  | 检测到；跳出循环并继续 |'
- en: 'It might work, but it doesn''t. Why not?:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 它可能有效，但实际上并不是。为什么呢？：
- en: One, polling on a variable for unbounded periods of time is very expensive in
    CPU terms (and is just bad design).
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，对变量进行无限期的轮询在CPU方面非常昂贵（而且设计不好）。
- en: Two, notice that we are operating upon a shared writable global variable without
    protecting it;  this is exactly the way to introduce data races, and thus bugs,
    into the application.
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，注意我们在没有保护的情况下操作共享可写全局变量；这正是引入数据竞争和bug的方法。
- en: Hence, the approach shown in the preceding table is considered to be a naive,
    inefficient, and even possibly buggy (racy).
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，前表中显示的方法被认为是幼稚、低效甚至可能有bug（竞争条件）。
- en: Using the condition variable
  id: totrans-467
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用条件变量
- en: The correct approach is to use a  CV. A condition variable is a way for threads to
    synchronize upon the value of data in an efficient manner. It achieves the same
    end result as the naive polling approach does, but in a far more efficient and,
    even more importantly, correct manner.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的方法是使用CV。条件变量是线程以高效的方式同步数据值的一种方式。它实现了与幼稚的轮询方法相同的最终结果，但以一种更高效、更重要的正确方式。
- en: 'Check out the following table:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下表格：
- en: '| **Time** | **Thread B** | **Thread A** |'
  id: totrans-470
  prefs: []
  type: TYPE_TB
  zh: '| **时间** | **线程B** | **线程A** |'
- en: '| t0 | Initialize: gWorkDone = 0 ; init the {CV, mutex} pair |  < common >
    |'
  id: totrans-471
  prefs: []
  type: TYPE_TB
  zh: '| t0 | 初始化：gWorkDone = 0；初始化{CV，互斥锁}对 |  <通用> |'
- en: '| t1 |  | Wait upon signal from thread B : lock the associated mutex; `pthread_cond_wait()`
    |'
  id: totrans-472
  prefs: []
  type: TYPE_TB
  zh: '| t1 |  | 等待来自线程B的信号：锁定相关的互斥锁；`pthread_cond_wait()` |'
- en: '| t2 | Perform the work ... |  < ... blocking ... > |'
  id: totrans-473
  prefs: []
  type: TYPE_TB
  zh: '| t2 | 执行工作... |  <...阻塞...> |'
- en: '| t3 | Work  done; lock the associated mutex; signal thread A : `pthread_cond_signal(`)
    ; unlock the associated mutex |  ... |'
  id: totrans-474
  prefs: []
  type: TYPE_TB
  zh: '| t3 | 工作完成；锁定相关的互斥锁；向线程A发出信号：`pthread_cond_signal()`；解锁相关的互斥锁 | ... |'
- en: '| t4 |  | Unblocked; check to see that the work is really done, and if so,
    unlock the associated mutex, and continue... |'
  id: totrans-475
  prefs: []
  type: TYPE_TB
  zh: '| t4 |  | 解除阻塞；检查工作是否真的完成，如果是，解锁相关的互斥锁，然后继续... |'
- en: Though the preceding table shows us the sequence of steps, some explanation
    is required. In the naive approach, we saw that one of the (serious) shortcomings
    is the fact that the global shared data variable was being manipulated without
    protection! The condition variable solves this by requiring that a condition variable
    be always associated with a mutex lock; we can think of it as a **{CV, mutex}
    pair**.
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前表显示了步骤的顺序，但需要一些解释。在幼稚的方法中，我们看到一个（严重的）缺点是全局共享数据变量在没有保护的情况下被操纵！条件变量通过要求条件变量始终与互斥锁相关联来解决了这个问题；我们可以将其视为**{CV，互斥锁}对**。
- en: 'The idea is simple: every time we intend to use the global predicate that tells
    us whether or not the work has been completed (`gWorkDone`, in our example), we
    lock the mutex, read/write the global, unlock the mutex, thus—importantly!—protecting
    it.'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法很简单：每当我们打算使用全局谓词来告诉我们工作是否已经完成（在我们的例子中是`gWorkDone`），我们会锁定互斥锁，读/写全局变量，解锁互斥锁，从而重要的是保护它。
- en: 'The beauty of the CV is that we do not require polling at all: the thread awaiting
    work completion uses `pthread_cond_wait(3)` to block (wait) upon that event occurring, and
    the thread that has completed work "signals" its counterpart via the `pthread_cond_signal(3)` API:'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: CV的美妙之处在于我们根本不需要轮询：等待工作完成的线程使用`pthread_cond_wait(3)`来阻塞（等待）事件发生，完成工作的线程通过`pthread_cond_signal(3)`API向其对应的线程发出“信号”：
- en: '[PRE25]'
  id: totrans-479
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Though we use the word signal here, this has nothing to do with Unix/Linux signals
    and signaling that we covered in earlier [Chapters 11](99fafa09-8972-4d9f-b241-46caf9de98f3.xhtml),
    *Signaling - Part I*, and [Chapter 12](657b6be0-ebc8-40dd-81b6-4741b04602b1.xhtml),
    *Signaling - II*.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在这里使用了“信号”这个词，但这与我们在之前的[第11章](99fafa09-8972-4d9f-b241-46caf9de98f3.xhtml)和[第12章](657b6be0-ebc8-40dd-81b6-4741b04602b1.xhtml)中讨论的Unix/Linux信号和信号毫无关系。
- en: '(Notice how the {CV, mutex} pair go together). Of course, just as with threads,
    we must first initialize the CV and its associated mutex lock; the CV is initialized
    either statically via:'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: （注意{CV，mutex}对是如何一起使用的）。当然，就像线程一样，我们必须首先初始化CV及其关联的互斥锁；CV可以通过静态方式进行初始化：
- en: '`pthread_cond_t cond = PTHREAD_COND_INITIALIZER; `'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: '`pthread_cond_t cond = PTHREAD_COND_INITIALIZER; `'
- en: 'Or dynamically (at runtime) via the following API:'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 或者在运行时动态地通过以下API进行初始化：
- en: '[PRE26]'
  id: totrans-484
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'If specific, non-default attributes of the CV are to be set up, one can do
    so via the `pthread_condattr_set*(3P)` APIs, or just set the CV to default by
    first invoking the `pthread_condattr_init(3P)` API and passing the initialized
    CV attribute object as the second parameter to `pthread_cond_init(3P)`:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要设置CV的特定非默认属性，可以通过`pthread_condattr_set*(3P)`API来设置，或者通过首先调用`pthread_condattr_init(3P)`API并将初始化的CV属性对象作为第二个参数传递给`pthread_cond_init(3P)`来将CV设置为默认值：
- en: '`int pthread_condattr_init(pthread_condattr_t *attr);`'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '`int pthread_condattr_init(pthread_condattr_t *attr);`'
- en: 'Conversely, when done, use the following APIs to destroy the CV attribute object
    and the CV itself:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，当完成时，使用以下API来销毁CV属性对象和CV本身：
- en: '[PRE27]'
  id: totrans-488
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: A simple CV usage demo application
  id: totrans-489
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个简单的CV使用演示应用程序
- en: 'Too many inits/destroys? Looking at the following simple code (`ch15/cv_simple.c`) will
    clarify their usage; we write a small program to demonstrate the usage of a condition
    variable and its associated mutex lock. Here, we create two threads, A and B.
    We then have thread B perform some work and thread A synchronize upon completion
    of that work by using the {CV, mutex} pair:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 太多的初始化/销毁？查看下面的简单代码（`ch15/cv_simple.c`）将澄清它们的用法；我们编写一个小程序来演示条件变量及其关联互斥锁的用法。在这里，我们创建两个线程A和B。然后，线程B执行一些工作，线程A在完成该工作后使用{CV，mutex}对进行同步：
- en: For readability, only key parts of the source code are displayed; to view the
    complete source code, build and run it. The entire tree is available for cloning
    from GitHub here: [https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux).
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 为了便于阅读，只显示了源代码的关键部分；要查看完整的源代码，请构建并运行它。整个树可以从GitHub克隆到这里：[https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux](https://github.com/PacktPublishing/Hands-on-System-Programming-with-Linux)。
- en: '[PRE28]'
  id: totrans-492
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: In the preceding code, we again show the macros that implement the mutex lock
    and unlock, the global predicate (Boolean) variable `gWorkDone`, and of course,
    the {CV, mutex} pair of variables.
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，我们再次显示了实现互斥锁和解锁的宏，全局谓词（布尔）变量`gWorkDone`，当然还有{CV，mutex}对变量。
- en: 'In the following code, in main, we initialize the CV attribute object and the
    CV itself:'
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，在main函数中，我们初始化了CV属性对象和CV本身：
- en: '[PRE29]'
  id: totrans-495
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The worker threads A and B are created and start their work (we do not repeat
    the code showing thread creation here). Here, you will find the worker routine
    for thread A— it must wait until thread B completes the work. We use the {CV,
    mutex} pair to easily and efficiently achieve this.
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 工作线程A和B被创建并开始他们的工作（我们这里不重复显示线程创建的代码）。在这里，你会找到线程A的工作例程 - 它必须等待直到线程B完成工作。我们使用{CV，mutex}对来轻松高效地实现这一点。
- en: The library does, however, require the application to guarantee that prior to
    invoking the `pthread_cond_wait(3P)` API, the associated mutex lock is taken (locked);
    otherwise, this will result in undefined behavior (or an actual failure when the
    mutex type is `PTHREAD_MUTEX_ERRORCHECK` or a robust mutex). Once the thread is
    blocking upon the CV, the mutex lock is auto-released.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，该库要求应用程序在调用`pthread_cond_wait(3P)`API之前保证关联的互斥锁被获取（锁定）；否则，这将导致未定义的行为（或者当互斥锁类型为`PTHREAD_MUTEX_ERRORCHECK`或者鲁棒互斥锁时会导致实际失败）。一旦线程在CV上阻塞，互斥锁会自动释放。
- en: 'Also, if a signal is delivered while the thread is blocked upon the wait condition,
    it shall be processed and the wait will be resumed; it could also cause a return
    value of zero for a spurious wake up (more on this in a minute):'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果在线程在等待条件上阻塞时传递了信号，它将被处理并且等待将会恢复；这也可能导致虚假唤醒的返回值为零（稍后会详细介绍）：
- en: '[PRE30]'
  id: totrans-499
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'It''s very important to understand this: merely returning from the `pthread_cond_wait(3P)` does not necessarily
    imply that the condition we were waiting (blocking) upon — in this case, thread
    B completing the work—actually occurred! In software, receiving a spurious wakeup (a
    false wakeup due to some other event — perhaps a signal) can occur; robust software
    will literally recheck the condition in a loop to determine that the reason we
    were awoken is the right one—in our case here, that the work has indeed been completed.
    This is why we run in an infinite loop and, once unblocked from `pthread_cond_wait(3P)`,
    check whether the global integer `gWorkDone` is actually having the value we expect
    (1, in this case, signifying completion of the work).'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 非常重要的是要理解：仅仅从`pthread_cond_wait(3P)`返回并不一定意味着我们等待（阻塞）的条件 - 在这种情况下，线程B完成工作 -
    实际发生了！在软件中，可能会发生虚假唤醒（由于其他事件 - 也许是信号而导致的虚假唤醒）；健壮的软件将会在循环中重新检查条件，以确定我们被唤醒的原因是正确的
    - 在我们这里，工作确实已经完成。这就是为什么我们在一个无限循环中运行，并且一旦从`pthread_cond_wait(3P)`中解除阻塞，就会检查全局整数`gWorkDone`是否确实具有我们期望的值（在这种情况下为1，表示工作已经完成）。
- en: 'All right, but think about this too: even reading a shared global becomes a
    critical section (otherwise a dirty read could result); hence, we need to take
    the mutex before doing so. Ah, this is where the {CV, mutex} pair idea has a built-in
    automatic mechanism that really helps us out—the moment we call `pthread_cond_wait(3P)`, the
    associated mutex lock is automatically and atomically released (unlocked), and
    then we block upon the condition variable signal. The moment the other thread
    (B, here) signals us (on the same CV, obviously), we are unblocked from `pthread_cond_wait(3P)` and
    the associated mutex lock is automatically and atomically locked, allowing us
    to recheck the global (or whatever). So, we do our work and then unlock it.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，但也要考虑这一点：即使是读取共享全局变量也会成为一个临界区（否则会导致脏读）；因此，在这之前我们需要获取互斥锁。啊，这就是{CV，mutex}对的一个内置自动机制，真的帮助了我们——一旦调用`pthread_cond_wait(3P)`，关联的互斥锁会自动原子释放（解锁），然后我们会阻塞在条件变量信号上。当另一个线程（这里是B）向我们发出信号（显然是在同一个CV上），我们就会从`pthread_cond_wait(3P)`中解除阻塞，并且关联的互斥锁会自动原子锁定，允许我们重新检查全局变量（或其他内容）。所以，我们完成工作然后解锁它。
- en: 'Here''s the code for the worker routine for thread B, which performs some sample
    work and then signals thread A:'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: 这是线程B的工作例程的代码，它执行一些示例工作然后向线程A发出信号：
- en: '[PRE31]'
  id: totrans-503
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Notice the comment detailing why we again take the mutex lock just prior to
    the signal. Okay, let''s try it out (we suggest you build and run the debug version
    as then, the delay loop shows up correctly):'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 注意注释详细说明了为什么我们在信号之前再次获取互斥锁。好的，让我们试一下（我们建议您构建和运行调试版本，因为这样延迟循环才能正确显示）：
- en: '[PRE32]'
  id: totrans-505
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The API also provides a timeout variant of the blocking call:'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: API还提供了阻塞调用的超时变体：
- en: '[PRE33]'
  id: totrans-507
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The semantics are identical to that of `pthread_cond_wait`, except that the
    API returns (with a failure value of `ETIMEDOUT`) if the time specified in the
    third parameter, abstime, has (already) passed. The clock used to measure the
    time that's elapsed is an attribute of the CV and can be set via the `pthread_condattr_setclock(3P)`
    API.
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 语义与`pthread_cond_wait`相同，只是如果第三个参数abstime中指定的时间已经过去，API会返回（失败值为`ETIMEDOUT`）。用于测量经过的时间的时钟是CV的属性，并且可以通过`pthread_condattr_setclock(3P)`API进行设置。
- en: (Both `pthread_cond_wait` and the `pthread_cond_timedwait` are cancellation
    points; this topic is dealt with in the next chapter.)
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: （`pthread_cond_wait`和`pthread_cond_timedwait`都是取消点；这个主题将在下一章中讨论。）
- en: CV broadcast wakeup
  id: totrans-510
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CV广播唤醒
- en: 'As we saw previously, the `pthread_cond_signal(3P)` API is used to unblock
    a thread that is blocked upon a particular CV. A variant of this API is as follows:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，`pthread_cond_signal(3P)` API用于解除阻塞在特定CV上的线程。这个API的变体如下：
- en: '`int pthread_cond_broadcast(pthread_cond_t *cond);`'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: '`int pthread_cond_broadcast(pthread_cond_t *cond);`'
- en: This API allows you to unblock multiple threads that are blocking on the same
    CV. So, for example, what if we have three threads blocking on the same CV; when
    the application calls the `pthread_cond_broadcast(3P)`, which thread will run
    first? Well, this is like asking, when threads are created, which one will run
    first (recall these discussions from the previous chapter). The answer, of course,
    is that, in the absence of particular scheduling policies, it is indeterminate.
    The same answer holds for the question when applied to the CV unblock and run
    on CPU.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API允许你解除阻塞在同一个CV上的多个线程。例如，如果有三个线程在同一个CV上阻塞；当应用程序调用`pthread_cond_broadcast(3P)`时，哪个线程会首先运行？嗯，这就像问，当线程被创建时，哪一个会首先运行（回想一下前一章中的讨论）。答案当然是，在没有特定调度策略的情况下，这是不确定的。当应用到CV解除阻塞并在CPU上运行时，也是同样的答案。
- en: To continue, once the waiting threads are unblocked, recall that the associated
    mutex will be taken, but of course only one of the unblocked threads will get
    it first. Again, this depends on scheduling policy and priority. With all defaults,
    it remains indeterminate which thread gets it first. In any case, in the absence
    of real-time characteristics, this should not matter to the application (if the
    application is real-time, then read our [Chapter 17](36229bac-c402-4d2f-b876-d1eb4aba8051.xhtml),
    *CPU Scheduling on Linux*, and setting up real-time scheduling policies and priorities
    first on each application thread).
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 继续，一旦等待的线程解除阻塞，要记住关联的互斥锁会被获取，但当然只有一个解除阻塞的线程会首先获取它。同样，这取决于调度策略和优先级。在所有默认情况下，无法确定哪个线程会首先获取它。无论如何，在没有实时特性的情况下，这对应用程序不应该有影响（如果应用程序是实时的，那么首先在每个应用程序线程上阅读我们的[第17章](36229bac-c402-4d2f-b876-d1eb4aba8051.xhtml)，*Linux上的CPU调度*，并设置实时调度策略和优先级）。
- en: Also, the manual page on these APIs clearly states that although the threads
    invoking the preceding APIs (`pthread_cond_signal` and the `pthread_cond_broadcast`)
    do not require that you hold the associated mutex lock when doing so (recall,
    we always have a {CV, mutex} pair), pedantically correct semantics demand that
    they do hold the mutex, perform the signal or broadcast, and then unlock the mutex
    (our example app, `ch15/cv_simple.c`, does follow this guideline).
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些API的手册页面清楚地指出，尽管调用前面的API（`pthread_cond_signal`和`pthread_cond_broadcast`）的线程在这样做时不需要持有关联的互斥锁（请记住，我们总是有{CV，mutex}对），但严谨的正确语义要求他们持有互斥锁，执行信号或广播，然后解锁互斥锁（我们的示例应用程序`ch15/cv_simple.c`遵循了这一准则）。
- en: 'To round off this discussion on CVs, here are a few tips:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束对CV的讨论，这里有一些建议：
- en: Do not use the condition variable approach from within a signal handler; the
    code is not considered to be async signal-safe (recall our earlier [Chapter 11](99fafa09-8972-4d9f-b241-46caf9de98f3.xhtml),
    *Signaling - Part I*, and [Chapter 12](657b6be0-ebc8-40dd-81b6-4741b04602b1.xhtml),
    *Signaling - Part II*).
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不要在信号处理程序中使用条件变量方法；该代码不被认为是异步信号安全的（回想我们之前的[第11章](99fafa09-8972-4d9f-b241-46caf9de98f3.xhtml)，*信号-第一部分*和[第12章](657b6be0-ebc8-40dd-81b6-4741b04602b1.xhtml)，*信号-第二部分*）。
- en: 'Using the well-known Valgrind suite (recall that we covered Valgrind''s Memcheck tool
    in [Chapter 6](406956b7-38f0-40c1-a76b-366ab36db17b.xhtml), *Debugging Tools for
    Memory Issues*), specifically the tool named helgrind, is useful (sometimes) to
    detect synchronization errors (data races) in pthreads multithreaded applications.
    The usage is simple:'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用众所周知的Valgrind套件（回想一下，我们在[第6章](406956b7-38f0-40c1-a76b-366ab36db17b.xhtml)中介绍了Valgrind的Memcheck工具，*内存问题的调试工具*），特别是名为helgrind的工具，有时可以检测到pthread多线程应用程序中的同步错误（数据竞争）。使用方法很简单：
- en: '`$ valgrind --tool=helgrind [-v] <app_name> [app-params ...]`:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: '`$ valgrind --tool=helgrind [-v] <app_name> [app-params ...]`：'
- en: helgrind, though, like many tools of this type, can quite often raise many false
    positives. For example, we find that eliminating `printf(3)` in the `cv_simple` application
    we wrote previously removes plenty of (false positive) errors and warnings from helgrind!
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，像这种类型的许多工具一样，helgrind经常会引发许多错误警报。例如，我们发现在我们之前编写的`cv_simple`应用程序中消除`printf(3)`会消除helgrind中的许多（错误的）错误和警告！
- en: Prior to invoking the `pthread_cond_signal` and/or the `pthread_cond_broadcast` APIs,
    if the associated mutex lock is not first acquired (it's not required), helgrind complains.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在调用`pthread_cond_signal`和/或`pthread_cond_broadcast` API之前，如果未首先获取相关的互斥锁（不是必需的），helgrind会抱怨。
- en: Do try helgrind out (again, the *Further reading* section on the GitHub repository
    has a link to its (really good) documentation).
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 请尝试使用helgrind（再次提醒，GitHub存储库的*进一步阅读*部分有链接到其（非常好的）文档）。
- en: Summary
  id: totrans-523
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: We began this chapter by focusing on the key concepts of concurrency, atomicity,
    and the need to recognize critical sections and protect them. Locking is a typical
    way to achieve this; the pthreads API set provides the powerful mutex lock to
    do so. However, using locks, especially on large projects, is fraught with hidden
    problems and dangers—we discussed useful *Locking guidelines*, *Deadlock* *and
    its avoidance*.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始本章时，重点关注并发性、原子性的关键概念，以及识别和保护关键部分的必要性。锁定是实现这一点的典型方式；pthread API集提供了强大的互斥锁来实现。然而，在大型项目中使用锁定，尤其是隐藏的问题和危险，我们讨论了有用的*锁定指南*、*死锁*及其避免。
- en: This chapter then went on to guide the reader in the usage of the pthreads mutex
    lock. A lot of ground was covered here, including various mutex attributes, the
    importance of recognizing and avoiding the priority inversion issue, and variations
    on the mutex lock. Finally, we covered the need for and usage of the condition
    variable (CV) and how it can be used to efficiently facilitate inter-thread event
    notification.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 本章随后指导读者使用pthread互斥锁。这里涵盖了很多内容，包括各种互斥锁属性，识别和避免优先级反转问题的重要性，以及互斥锁的变化。最后，我们介绍了条件变量（CV）的需求和用法，以及如何有效地促进线程间事件通知。
- en: The next chapter is the final one in this trilogy of chapters on multithreading;
    in it, we shall focus on the important issues of thread safety (and thread-safe
    APIs), thread cancellation and cleanup, mixing signals with MT, a few FAQs and
    tips, and look at the pros and cons of the multiprocess vs the  multithreaded
    model.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章是这个关于多线程的三部曲的最后一章；在其中，我们将专注于线程安全的重要问题（和线程安全的API），线程取消和清理，将信号与MT混合，一些常见问题和提示，并看看多进程与多线程模型的利弊。
