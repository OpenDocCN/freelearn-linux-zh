["```\nsudo lttng create <session-name> --output=<dir>\n```", "```\nsudo lttng enable-event --kernel --all\n\n```", "```\nsudo lttng start\n```", "```\nsudo lttng stop\n```", "```\nsudo lttng destroy\n```", "```\n$ sudo trace-cmd record -o trace_ps.dat -r 99 -p function_graph -F ps -LA\nplugin 'function_graph'\nPID     LWP TTY         TIME CMD\n 1        1   ?     00:01:42 systemd\n 2        2   ?     00:00:00 kthreadd\n[ ... ]\n32701   734 tty2   00:00:00 ThreadPoolForeg\nCPU 2: 48176 events lost\nCPU0 data recorded at offset=0x761000\n[ ... ]\nCPU3 data recorded at offset=0xf180000\n114688 bytes in size\n$ ls -lh trace_ps.dat\n-rw-r--r-- 1 root root 242M Jun 25 11:23 trace_ps.dat\n$\n```", "```\ntrace-cmd report -i ./trace_ps.dat -l > report_tc_ps.txt \n```", "```\n$ kernelshark ./trace_ps.dat\n```", "```\n#define _GNU_SOURCE\n#include <sched.h>\n\nint sched_getaffinity(pid_t pid, size_t cpusetsize,\n                        cpu_set_t *mask);\nint sched_setaffinity(pid_t pid, size_t cpusetsize,\n                        const cpu_set_t *mask);\n```", "```\n// ch11/cpu_affinity/userspc_cpuaffinity.c\n\nstatic int query_cpu_affinity(pid_t pid)\n{\n    cpu_set_t cpumask;\n\n    CPU_ZERO(&cpumask);\n    if (sched_getaffinity(pid, sizeof(cpu_set_t), &cpumask) < 0) {\n        perror(\"sched_getaffinity() failed\");\n        return -1;\n    }\n    disp_cpumask(pid, &cpumask, numcores);\n    return 0;\n}\n```", "```\n// ch11/cpu_affinity/userspc_cpuaffinity.c\nstatic int set_cpu_affinity(pid_t pid, unsigned long bitmask)\n{\n    cpu_set_t cpumask;\n    int i;\n\n    printf(\"\\nSetting CPU affinity mask for PID %d now...\\n\", pid);\n    CPU_ZERO(&cpumask);\n\n    /* Iterate over the given bitmask, setting CPU bits as required */\n    for (i=0; i<sizeof(unsigned long)*8; i++) {\n        /* printf(\"bit %d: %d\\n\", i, (bitmask >> i) & 1); */\n        if ((bitmask >> i) & 1)\n            CPU_SET(i, &cpumask);\n    }\n\n    if (sched_setaffinity(pid, sizeof(cpu_set_t), &cpumask) < 0) {\n        perror(\"sched_setaffinity() failed\");\n        return -1;\n    }\n    disp_cpumask(pid, &cpumask, numcores);\n    return 0;\n}\n```", "```\n$ taskset -p 1\npid 1's current affinity mask: f \n$\n```", "```\n$ taskset 03 gcc userspc_cpuaffinity.c -o userspc_cpuaffinity -Wall \n```", "```\n  /* ch17/6_percpuvar/6_percpuvar.c */\n  /* WARNING! This is considered a hack.\n   * As sched_setaffinity() isn't exported, we don't have access to it\n   * within this kernel module. So, here we resort to a hack: we use\n   * kallsyms_lookup_name() (which works when CONFIG_KALLSYMS is defined)\n   * to retrieve the function pointer, subsequently calling the function\n   * via it's pointer (with 'C' what you do is only limited by your\n   * imagination :).\n   */\n  ptr_sched_setaffinity = (void *)kallsyms_lookup_name(\"sched_setaffinity\");\n```", "```\n    cpumask_clear(&mask);\n    cpumask_set_cpu(cpu, &mask); // 1st param is the CPU number, not bitmask\n    /* !HACK! sched_setaffinity() is NOT exported, we can't call it\n     *   sched_setaffinity(0, &mask); // 0 => on self \n     * so we invoke it via it's function pointer */\n    ret = (*ptr_sched_setaffinity)(0, &mask);   // 0 => on self\n```", "```\n// kernel/sched/core.c\n/**\n * sched_setscheduler_nocheck - change the scheduling policy and/or RT priority of a thread from kernelspace.\n * @p: the task in question.\n * @policy: new policy.\n * @param: structure containing the new RT priority.\n *\n * Just like sched_setscheduler, only don't bother checking if the\n * current context has permission. For example, this is needed in\n * stop_machine(): we create temporary high priority worker threads,\n * but our caller might not have that capability.\n *\n * Return: 0 on success. An error code otherwise.\n */\nint sched_setscheduler_nocheck(struct task_struct *p, int policy,\n                   const struct sched_param *param)\n{\n    return _sched_setscheduler(p, policy, param, false);\n}\nEXPORT_SYMBOL_GPL(sched_setscheduler_nocheck);\n```", "```\n// kernel/irq/manage.c\nstatic int\nsetup_irq_thread(struct irqaction *new, unsigned int irq, bool secondary)\n{ \n    struct task_struct *t;\n    struct sched_param param = {\n        .sched_priority = MAX_USER_RT_PRIO/2,\n    };\n    [ ... ]\n    sched_setscheduler_nocheck(t, SCHED_FIFO, &param);\n    [ ... ]\n```", "```\n$ mount | grep cgroup2 \ncgroup2 on /sys/fs/cgroup/unified type cgroup2 \n   (rw,nosuid,nodev,noexec,relatime,nsdelegate) \n$ sudo cat /sys/fs/cgroup/unified/cgroup.controllers \n$ \n```", "```\n$ cat /proc/cmdline\n BOOT_IMAGE=/boot/vmlinuz-4.15.0-118-generic root=UUID=<...> ro console=ttyS0,115200n8 console=tty0 ignore_loglevel quiet splash cgroup_no_v1=all 3\n$\n```", "```\n$ cat /sys/fs/cgroup/cgroup.controllers\ncpu io memory pids \n```", "```\necho \"+cpu\" > /sys/fs/cgroup/cgroup.subtree_control\n```", "```\nmkdir /sys/fs/cgroup/test_group\n```", "```\ncpu.max\nA read-write two value file which exists on non-root cgroups. The default is \u201cmax 100000\u201d. The maximum bandwidth limit. It\u2019s in the following format: \n$MAX $PERIOD\nwhich indicates that the group may consume upto $MAX in each $PERIOD duration. \u201cmax\u201d for $MAX indicates no limit. If only one number is written, $MAX is updated.\n```", "```\n$ sudo ./cgv2_cpu_ctrl.sh\n[sudo] password for <username>: \nUsage: cgv2_cpu_ctrl.sh max-to-utilize(us)\n This value (microseconds) is the max amount of time the processes in the sub-control\n group we create will be allowed to utilize the CPU; it's relative to the period,\n which is the value 1000000;\n So, f.e., passing the value 300,000 (out of 1,000,000) implies a max CPU utilization\n of 0.3 seconds out of 1 second (i.e., 30% utilization).\n The valid range for the $MAX value is [1000-1000000].\n$ \n```", "```\n$ sudo ./cgv2_cpu_ctrl.sh 1000 [+] Checking for cgroup v2 kernel support\n[+] Adding a 'cpu' controller to the cgroups v2 hierarchy\n[+] Create a sub-group under it (here: /sys/fs/cgroup/test_group)\n\n***\nNow allowing 1000 out of a period of 1000000 by all processes (j1,j2) in this\nsub-control group, i.e., .100% !\n***\n\n[+] Launch processes j1 and j2 (slinks to /home/llkd/Learn-Linux-Kernel-Development/ch11/cgroups_v2_cpu_eg/simp.sh) now ...\n[+] Insert processes j1 and j2 into our new CPU ctrl sub-group\nVerifying their presence...\n0::/test_group\nJob j1 is in our new cgroup v2 test_group\n0::/test_group\nJob j2 is in our new cgroup v2 test_group\n\n............... sleep for 5 s ................\n\n[+] killing processes j1, j2 ...\n./cgv2_cpu_ctrl.sh: line 185: 10322 Killed ./j1 1 > ${OUT1}\ncat 1stjob.txt\n1 2 3 \ncat 2ndjob.txt\n900 901 \n[+] Removing our cpu sub-group controller\nrmdir: failed to remove '/sys/fs/cgroup/test_group': Device or resource busy\n./cgv2_cpu_ctrl.sh: line 27: 10343 Killed ./j2 900 > ${OUT2}\n$  \n```", "```\n$ ls -lh\ntotal 106M\ndrwxrwxr-x 24 kaiwan kaiwan 4.0K Oct  1 16:49 linux-5.4.69/\n-rw-rw-r--  1 kaiwan kaiwan 105M Oct 13 16:35 linux-5.4.69.tar.xz\n-rw-rw-r--  1 kaiwan kaiwan 836K Oct 13 16:33 patch-5.4.69-rt39.patch\n$ \n```", "```\n$ cd linux-5.4.69\n$ patch -p1 --dry-run < ../patch-5.4.69-rt39.patch \nchecking file Documentation/RCU/Design/Expedited-Grace-Periods/Expedited-Grace-Periods.html\nchecking file Documentation/RCU/Design/Requirements/Requirements.html\n[ ... ]\nchecking file virt/kvm/arm/arm.c\n$ echo $?\n0\n```", "```\n$ patch -p1 < ../patch-5.4.69-rt39.patch patching file Documentation/RCU/Design/Expedited-Grace-Periods/Expedited-Grace-Periods.html\npatching file Documentation/RCU/Design/Requirements/Requirements.html\n[ ... ] \n```", "```\n$ lsmod > /tmp/mylsmod \n$ make LSMOD=/tmp/mylsmod localmodconfig\n```", "```\n$ grep PREEMPT_RT .config\nCONFIG_PREEMPT_RT=y\n```", "```\nmake -j4 && sudo make modules_install install \n```", "```\n$ uname -r\n5.4.69-rt39-rtl-llkd1\n```", "```\nmax_latency = CLK_WAVELENGTH x 105 s\n```", "```\n$ head -n4 linux/Makefile \n# SPDX-License-Identifier: GPL-2.0\nVERSION = 5\nPATCHLEVEL = 4\nSUBLEVEL = 70\n```", "```\ncd linux\npatch -p1 < ../patch-5.4.70-rt40.patch\n```", "```\nmake ARCH=arm bcm2709_defconfig\n```", "```\nmake -j4 ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- zImage modules dtbs\n```", "```\nsudo env PATH=$PATH make ARCH=arm CROSS_COMPILE=arm-linux-gnueabihf- INSTALL_MOD_PATH=/media/${USER}/rootfs modules_install\n```", "```\nrpi ~ $ uname -a \nLinux raspberrypi 5.4.70-rt40-v7-llkd-rtl+ #1 SMP PREEMPT_RT Thu Oct 15 07:58:13 IST 2020 armv7l GNU/Linux\nrpi ~ $ zcat /proc/config.gz |grep PREEMPT_RT\nCONFIG_PREEMPT_RT=y\n```", "```\nsudo apt install coreutils build-essential stress gnuplot libnuma-dev\n```", "```\ngit clone git://git.kernel.org/pub/scm/utils/rt-tests/rt-tests.git\n```", "```\ngit checkout -b stable/v1.0 origin/stable/v1.0\nmake\n```", "```\nstress --cpu 6 --io 2 --hdd 4 --hdd-bytes 1MB --vm 2 --vm-bytes 128M --timeout 1h\n```", "```\nsudo cyclictest --duration=1h -m -Sp90 -i200 -h400 -q >output\n```"]