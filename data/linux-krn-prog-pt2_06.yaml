- en: Working with Kernel Timers, Threads, and Workqueues
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 使用内核定时器、线程和工作队列
- en: What if the low-level specification for your device driver demands that, between
    the execution of `func_a()` and `func_b()`, there should be a 50-millisecond delay?
    Furthermore, depending on your circumstances, the delay should work when you're
    running in either process or interrupt contexts. What if, in another part of the
    driver, you require a monitoring function of some sort to be executed asynchronously
    and periodically (say, every second)? Or do you need to have a thread (or several
    threads) silently performing work in the background but within the kernel?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的设备驱动的低级规范要求在执行`func_a()`和`func_b()`之间应该有50毫秒的延迟呢？此外，根据你的情况，当你在进程或中断上下文中运行时，延迟应该起作用。在驱动的另一部分，如果你需要异步定期执行某种监控功能（比如，每秒一次）怎么办？或者你需要在内核中静默执行工作的线程（或多个线程）？
- en: These are very common requirements in all kinds of software, including our corner
    of the universe – Linux kernel module (and driver) development! In this chapter,
    you will learn how to set up, understand, and use delays while running in kernel
    space, as well as how to work with kernel timers, kernel threads, and workqueues.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是各种软件中非常常见的要求，包括我们所在的领域- Linux内核模块（和驱动）开发！在本章中，你将学习如何在内核空间中设置、理解和使用延迟，以及如何使用内核定时器、内核线程和工作队列。
- en: 'In this chapter, you will learn how to optimally perform these tasks. In a
    nutshell, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何最优地执行这些任务。简而言之，我们将涵盖以下主题：
- en: Delaying for a given time in the kernel
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在内核中延迟一段时间
- en: Setting up and using kernel timers
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置和使用内核定时器
- en: Creating and working with kernel threads
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和使用内核线程
- en: Using kernel workqueues
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用内核工作队列
- en: Let's get started!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'I assume that you have gone through the Preface section To get the most out
    of this book and have appropriately prepared a guest VM running Ubuntu 18.04 LTS
    (or a later stable release) and installed all the required packages. If not, I
    highly recommend you do this first. To get the most out of this book, I strongly
    recommend you first set up the workspace environment, including cloning this book''s
    GitHub repository for the code, and work on it in a hands-on fashion. The repository
    can be found here: [https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/ch5).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我假设你已经阅读了前言部分，以便充分利用本书，并已经准备好运行Ubuntu 18.04 LTS（或更高版本的稳定发布版）的虚拟机，并安装了所有必需的软件包。如果没有，我强烈建议你首先这样做。为了充分利用本书，我强烈建议你首先设置好工作环境，包括克隆本书的GitHub代码库，并以实际操作的方式进行工作。代码库可以在这里找到：[https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/ch5)。
- en: Delaying for a given time in the kernel
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在内核中延迟一段时间
- en: 'Often, your kernel or driver code will need to wait for a given time before
    moving on to the next instruction. This can be achieved within the Linux kernel
    space via a set of delay APIs. Right from the outset, a key point to understand
    is that you can enforce a delay in two broad ways:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，你的内核或驱动代码需要在继续执行下一条指令之前等待一段时间。在Linux内核空间中，可以通过一组延迟API来实现这一点。从一开始，需要理解的一个关键点是，你可以通过两种广泛的方式强制延迟：
- en: Delay via non-blocking or atomic APIs that will never cause a sleep process
    to occur (in other words, it will never schedule out)
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过永远不会导致进程休眠的非阻塞或原子API进行延迟（换句话说，它永远不会调度出）
- en: Delay via blocking APIs that cause the current process context to sleep (in
    other words, by scheduling out)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过导致当前进程上下文休眠的阻塞API进行延迟（换句话说，通过调度出）
- en: (As we covered in detail in the companion guide *Linux Kernel Programming,*
    our chapters on CPU scheduling  *Chapter 10,* *The CPU Scheduler – Part 1*, and
    *Chapter 11*, *The CPU Scheduler – Part 2*), putting a process context to sleep
    internally implies that the kernel's core `schedule()` function is invoked at
    some point, ultimately causing a context switch to occur. This leads up to a really
    important point (one we've mentioned previously!): you must never, ever invoke
    `schedule()` while running in an atomic or interrupt context of any sort.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: （正如我们在《Linux内核编程》的配套指南中详细介绍的那样，我们在CPU调度的章节中涵盖了这一点，《第10章- CPU调度器-第1部分》和《第11章-
    CPU调度器-第2部分》），将进程上下文内部休眠意味着内核的核心`schedule()`函数在某个时刻被调用，最终导致上下文切换发生。这引出了一个非常重要的观点（我们之前提到过！）：在任何原子或中断上下文中运行时，绝对不能调用`schedule()`。
- en: Often, as is our case here with inserting delays, you have to figure out what
    context the code where you intend to insert a delay is running in. We covered
    this in the companion guide *Linux Kernel Programming -* *Chapter 6*, *Kernel
    Internals Essentials – Processes and Threads*, in the *Determining the context* section;
    please refer back to it if you're unclear. (We went into even more detail on this
    in [*Chapter 4*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling Hardware
    Interrupts*.)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，就像我们在插入延迟的情况下一样，你必须弄清楚你打算插入延迟的代码所在的上下文是什么。我们在配套指南《Linux内核编程-第6章-内核内部要点-进程和线程》的“确定上下文”部分中涵盖了这一点；如果你不清楚，请参考一下。（我们在《第4章-处理硬件中断》中对此进行了更详细的讨论。）
- en: 'Next, think about this carefully: if you are indeed in an atomic (or interrupt)
    context, is there really a need to delay? The whole point of an atomic or interrupt
    context is that the execution within it is limited to an as-brief-as-possible
    duration; it is strongly recommended that you design it in this way. This implies
    that you don''t insert delays into atomic code unless you can''t avoid doing so.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，请仔细考虑一下：如果你确实处于原子（或中断）上下文中，是否真的需要延迟？原子或中断上下文的整个目的是，其中的执行时间应尽可能短暂；强烈建议你以这种方式设计。这意味着除非你无法避免，否则不要在原子代码中插入延迟。
- en: '**Use the first type**: These are the non-blocking or atomic APIs that will
    never cause a sleep to occur. You should use this when your code is in an atomic
    (or interrupt) context and you really do require a non-blocking delay with a short
    duration; but how short is that? As a rule of thumb, use these APIs for non-blocking
    atomic delays that are 1 millisecond or less. Even if you need to delay for longer
    than a millisecond in an atomic context – say, within the code of an interrupt
    handler (*but why delay in an interrupt!?*) – use these `*delay()` APIs (the `*` character
    implies a wildcard; here, as you will see, it implies the `ndelay()`, `delay()`,
    and `mdelay()` routines).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用第一种类型**：这些是永远不会导致休眠发生的非阻塞或原子API。当您的代码处于原子（或中断）上下文中，并且您确实需要一个短暂的非阻塞延迟时，您应该使用这些API；但是多短呢？作为一个经验法则，对于1毫秒或更短的非阻塞原子延迟使用这些API。即使您需要在原子上下文中延迟超过一毫秒
    - 比如，在中断处理程序的代码中（*但为什么要在中断中延迟！？*） - 使用这些`*delay()`API（`*`字符表示通配符；在这里，您将看到它表示`ndelay()`、`delay()`和`mdelay()`例程）。'
- en: '**Use the second type**: These are the blocking APIs that cause the current
    process context to sleep. You should use this when your code is in a process (or
    task) context, for delays that are blocking in nature and of a longer duration;
    in effect, for delays over a millisecond. These kernel APIs follow the form `*sleep()`.
    (Again, without going into too much detail, think about this: if you are in a
    process context *but* within the critical section of a spinlock, it''s an atomic
    context – if you must incorporate a delay, then you must use the `*delay()` APIs!
    We''ll cover spinlocks and much more in the last two chapters of this book.)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用第二种类型**：这些是导致当前进程上下文休眠的阻塞API。当您的代码处于进程（或任务）上下文中，需要阻塞性较长时间的延迟时，您应该使用这些；实际上，对于超过一毫秒的延迟。这些内核API遵循`*sleep()`的形式。（再次，不详细讨论，想想这个：如果您在进程上下文中，但在自旋锁的临界区内，那就是一个原子上下文
    - 如果您必须加入延迟，那么您必须使用`*delay()`API！我们将在本书的最后两章中涵盖自旋锁等更多内容。）'
- en: Now, let's look at these kernel APIs and see how they're used. We'll begin by
    looking at `*delay()` atomic APIs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看这些内核API，看看它们是如何使用的。我们将首先看一下`*delay()`原子API。
- en: Understanding how to use the *delay() atomic APIs
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解如何使用*delay()原子API
- en: 'Without further ado, let''s take a look at a table that quickly summarizes
    the available (to us module authors) non-blocking or atomic `*delay()` kernel
    APIs; *they''re meant to be used in any kind of atomic or interrupt context where
    you cannot block or sleep* (or invoke `schedule()`):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 话不多说，让我们来看一张表，快速总结一下可用的（对于我们模块作者来说）非阻塞或原子`*delay()`内核API；*它们旨在用于任何类型的原子或中断上下文，其中您不能阻塞或休眠*（或调用`schedule()`）：
- en: '| **API** | **Comment** |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| **API** | **注释** |'
- en: '| `ndelay(ns);` | Delay for `ns` nanoseconds. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| `ndelay(ns);` | 延迟`ns`纳秒。 |'
- en: '| `udelay(us);` | Delay for `us` microseconds. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| `udelay(us);` | 延迟`us`微秒。 |'
- en: '| `mdelay(ms);` | Delay for `ms` milliseconds. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| `mdelay(ms);` | 延迟`ms`毫秒。 |'
- en: Table 5.1 – The *delay() non-blocking APIs
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.1 - *delay()非阻塞API
- en: 'There are a few points to note regarding these APIs, their internal implementation,
    and their usage:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些API、它们的内部实现和使用，有一些要注意的地方：
- en: Always include the `<linux/delay.h>` header when using these macros/APIs.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用这些宏/API时，始终包括`<linux/delay.h>`头文件。
- en: You are expected to call an appropriate routine based on the time you must delay
    for; for example, if you need to perform an atomic non-blocking delay of, say,
    30 milliseconds, you should call `mdelay(30)` and not`udelay(30*1000)`. The kernel
    code mentions this very point: `linux/delay.h` – *"Using udelay() for intervals
    greater than a few milliseconds can risk overflow for high loops_per_jiffy (high
    bogomips) machines ...".*
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你应该根据你需要延迟的时间调用适当的例程；例如，如果你需要执行一个原子非阻塞延迟，比如30毫秒，你应该调用`mdelay(30)`而不是`udelay(30*1000)`。内核代码提到了这一点：`linux/delay.h`
    - *"对于大于几毫秒的间隔使用udelay()可能会在高loops_per_jiffy（高bogomips）的机器上出现溢出风险...".*
- en: 'The internal implementation of these APIs, like many on Linux, is nuanced:
    there is a higher-level abstracted implementation for these functions (or macros,
    as the case may be) in the `<linux/delay.h>` header; there is often a low-level
    arch-specific implementation within an arch-specific header (`<asm-<arch>/delay.h>`
    *or *`<asm-generic/delay.h>`; where `arch`, of course, means CPU) that will automatically
    override the high-level version at call time (the linker will ensure this).'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些API的内部实现，就像Linux上的许多API一样，是微妙的：在`<linux/delay.h>`头文件中，这些函数（或宏）有一个更高级的抽象实现；在特定于体系结构的头文件中（`<asm-<arch>/delay.h>`或`<asm-generic/delay.h>`；其中`arch`当然是CPU），通常会有一个特定于体系结构的低级实现，它会在调用时自动覆盖高级版本（链接器会确保这一点）。
- en: 'In the current implementation, these APIs ultimately boil down to wrappers
    over `udelay()`; this function itself boils down to a tight assembly loop that
    performs what''s called "busy looping"! (for x86, the code can be found in `arch/x86/lib/delay.c:__const_udelay()`).
    Without going into the gory details, early in the boot process, the kernel calibrates
    a couple of values: the so-called **bogomips –** bogus MIPS – and **loops per
    jiffy** (**lpj**) values. Essentially, the kernel figures out, on that particular
    system, how many times a loop must be iterated over in order for 1 timer tick
    or a jiffy to elapse. This value is known as the system''s bogomips value and
    can be seen in the kernel log. For example, on my Core-i7 laptop, it''s as follows:'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在当前的实现中，这些API最终都会转换为对`udelay()`的包装；这个函数本身会转换为一个紧凑的汇编循环，执行所谓的“忙循环”！（对于x86，代码可以在`arch/x86/lib/delay.c:__const_udelay()`中找到）。不详细讨论，早期在引导过程中，内核会校准一些值：所谓的**bogomips
    -**虚假MIPS - 和**每个jiffy的循环**（**lpj**）值。基本上，内核会在那个特定系统上找出，为了使一个定时器滴答或一个jiffy经过多少次循环。这个值被称为系统的bogomips值，并且可以在内核日志中看到。例如，在我的Core-i7笔记本上，它是这样的：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: For delays over `MAX_UDELAY_MS` (set to 5 ms), the kernel will internally call
    the `udelay()` function in a loop.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于超过`MAX_UDELAY_MS`（设置为5毫秒）的延迟，内核将在循环中内部调用`udelay()`函数。
- en: 'Remember the `*delay()` APIs must be used when you require a delay in any type
    of atomic context, such as an interrupt handler (top or bottom half), as they
    guarantee that no sleep – and thus no call to `schedule()` – ever occurs. A reminder
    (we mentioned this point in [*Chapter 4*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling
    Hardware Interrupts*): `might_sleep()` is used as a debug aid; the kernel (and
    drivers) internally uses the `might_sleep()` macro in places in the code base
    where the code runs in the process context; that is, where it can sleep. Now,
    if `might_sleep()` is ever invoked within an atomic context, that''s just plain
    wrong – a noisy printk stack trace is then emitted, thus helping you catch these
    issues early and fix them. You can use these `*delay()` APIs in the process context
    as well.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，`*delay()` APIs必须在任何类型的原子上下文中使用，例如中断处理程序（顶部或底部），因为它们保证不会发生睡眠 - 因此也不会调用`schedule()`。提醒一下（我们在[*第4章*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml)中提到过这一点，*处理硬件中断*）：`might_sleep()`用作调试辅助工具；内核（和驱动程序）在代码库中的某些地方内部使用`might_sleep()`宏，即代码在进程上下文中运行时；也就是说，它可以睡眠。现在，如果`might_sleep()`在原子上下文中被调用，那就是完全错误的
    - 然后会发出一个嘈杂的`printk`堆栈跟踪，从而帮助您及早发现并修复这些问题。您也可以在进程上下文中使用这些`*delay()` APIs。
- en: In these discussions, you will often come across the `jiffies` kernel variable;
    essentially, think of `jiffies` as a global unsigned 64-bit value that is incremented
    on every timer interrupt (or timer tick; it's internally protected against overflow).
    Thus, the continually incrementing variable is used as a way to measure uptime,
    as well as a means of implementing simple timeouts and delays.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些讨论中，您经常会遇到`jiffies`内核变量；基本上，将`jiffies`视为一个全局的无符号64位值，它在每次定时器中断（或定时器滴答）时递增（它在内部受到溢出的保护）。因此，这个不断递增的变量被用作测量正常运行时间的一种方式，以及实现简单超时和延迟的手段。
- en: Now, let's look at the second type of delay APIs available – the blocking type.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看可用的第二种类型的延迟APIs - 阻塞类型。
- en: Understanding how to use the *sleep() blocking APIs
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解如何使用*sleep*() 阻塞APIs
- en: 'Let''s look at another table that quickly summarizes the available (to us module
    authors) blocking `*sleep*()` kernel APIs; these are *only meant to be used in
    the process context when it''s safe to sleep*; that is, where the invocation of
    `schedule()` is not a problem. In other words, the delay is implemented by the
    process context actually going to sleep for the duration of the delay and is then
    woke up when it''s done:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再看一个表，它快速总结了可用的（对我们模块作者来说）阻塞`*sleep*()`内核APIs；这些只能在进程上下文中使用，当安全睡眠时；也就是说，在进程上下文实际上进入睡眠状态的延迟期间，然后在完成时唤醒：
- en: '| **API** | **Internally "backed by"** | **Comment** |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| **API** | **内部“支持”** | **评论** |'
- en: '| `usleep_range(umin, umax);` | `hrtimers` (high-resolution timers) | Sleep
    for between `umin` and `umax` microseconds. Use where the wakeup time is flexible.
    This is the **recommended API** to use. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '`usleep_range(umin, umax);` | `hrtimers`（高分辨率定时器） | 睡眠介于`umin`和`umax`微秒之间。在唤醒时间灵活的情况下使用。这是**推荐的API**。'
- en: '| `msleep(ms);` | `jiffies`/`legacy_timers` | Sleep for `ms` milliseconds.
    Typically meant for a sleep with a duration of 10 ms or more. |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '`msleep(ms);` | `jiffies`/`legacy_timers` | 睡眠`ms`毫秒。通常用于持续时间为10毫秒或更长的睡眠。'
- en: '| `msleep_interruptible(ms);` | `jiffies`/`legacy_timers` | An interruptible
    variant of `msleep(ms);`. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '`msleep_interruptible(ms);` | `jiffies`/`legacy_timers` | `msleep(ms);`的可中断变体。'
- en: '| `ssleep(s);` | `jiffies`/`legacy_timers` | Sleep for `s` seconds. This is meant
    for sleeps > 1 s (wrapper over `msleep()`). |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '`ssleep(s);` | `jiffies`/`legacy_timers` | 睡眠`s`秒。这是用于睡眠时间大于1秒的情况（对`msleep()`的封装）。'
- en: Table 5.2 – The *sleep*() blocking APIs
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2 - *sleep*() 阻塞APIs
- en: 'There''s a few points to note regarding these APIs, their internal implementation,
    and their usage:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些API、它们的内部实现和使用，有一些要注意的地方：
- en: Ensure you include the `<linux/delay.h>` header when using these macros/APIs.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在使用这些宏/ API时，请确保包含`<linux/delay.h>`头文件。
- en: All these `*sleep()` APIs are internally implemented in such a manner that they *cause
    the current process context to sleep *(that is, by internally invoking `schedule()`);
    thus, of course, they must only ever be invoked in the process context when it's
    "safe to sleep". Again, just because your code is in the process context does
    not necessarily mean it's safe to sleep; for example, the critical section of
    a spinlock is atomic; thus, you must not invoke the aforementioned `*sleep()`
    APIs there!
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有这些`*sleep()` API都是以这样一种方式内部实现的，即它们会使当前进程上下文进入睡眠状态（也就是通过内部调用`schedule()`）；因此，当进程上下文“安全睡眠”时，它们必须只能被调用。再次强调，仅仅因为您的代码在进程上下文中，并不一定意味着它是安全的睡眠；例如，自旋锁的临界区是原子的；因此，在那里您不能调用上述的`*sleep()`
    API！
- en: We mentioned that `usleep_range()` is the **preferred/recommended API** to use
    when you want a short sleep – but why? This will become clearer in the *Let's
    try it – how long do delays and sleeps really take?* section.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们提到`usleep_range()`是**首选/推荐的API**，当您需要短暂的睡眠时使用它 - 但是为什么？这将在*让我们试试 - 延迟和睡眠实际需要多长时间？*部分中变得更清晰。
- en: 'As you are aware, sleeps on Linux can be of two types: interruptible and uninterruptible.
    The latter means that no signal task can "disturb" the sleep. So, when you invoke
    `msleep(ms);`,i t puts the current process context to sleep for `ms` by internally
    invoking the following:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所知，Linux上的睡眠可以分为两种类型：可中断和不可中断。后者意味着没有信号任务可以“打扰”睡眠。因此，当您调用`msleep(ms);`时，它会通过内部调用以下内容将当前进程上下文置于睡眠状态，持续`ms`：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The `schedule_timeout()` routine works by setting up a kernel timer (our next
    topic!) that will expire in the desired time, then immediately putting the process
    to sleep by calling `schedule()`! (For the curious, have a peek at its code here: `kernel/time/timer.c:schedule_timeout()`.)
    The `msleep_interruptible()` implementation is very similar, except that it calls `__set_current_state(TASK_INTERRUPTIBLE);`.
    As a design heuristic, follow the UNIX paradigm of *provide mechanism, not policy*;
    this way, calling `msleep_interruptible()` might be a good idea in situations
    where, if the userspace app aborts the work (by the user pressing `^C` perhaps),
    the kernel or driver obediently releases the task: its process context is awoken,
    it runs the appropriate signal handler, and life continues. In situations where
    it''s important that the kernel space is not disturbed by user-generated signals,
    use the `msleep()` variant.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`schedule_timeout()`例程通过设置一个内核定时器（我们下一个话题！）来工作，该定时器将在所需的时间内到期，然后立即通过调用`schedule()`将进程置于睡眠状态！（对于好奇的人，可以在这里查看它的代码：`kernel/time/timer.c:schedule_timeout()`。）`msleep_interruptible()`的实现非常类似，只是调用了`__set_current_state(TASK_INTERRUPTIBLE);`。作为设计启发，遵循*提供机制，而不是策略*的UNIX范式；这样，调用`msleep_interruptible()`可能是一个好主意，因为在用户空间应用程序中终止工作（例如用户按下`^C`）时，内核或驱动程序会顺从地释放任务：它的进程上下文被唤醒，运行适当的信号处理程序，生活继续。在内核空间不受用户生成的信号干扰很重要的情况下，使用`msleep()`变体。'
- en: 'Again, as a rule of thumb, use the following APIs, depending on the duration
    of the delay:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，作为一个经验法则，根据延迟的持续时间使用以下API：
- en: '**For delays of over 10 milliseconds**: `msleep()` or `msleep_interruptible()`'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超过10毫秒的延迟**：`msleep()`或`msleep_interruptible()`'
- en: '**For delays of over 1 second**: `ssleep()`'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超过1秒的延迟**：`ssleep()`'
- en: As you might expect, `ssleep()` is a simple wrapper over `msleep();` and becomes `msleep(seconds
    * 1000);`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所期望的，`ssleep()`是`msleep()`的简单包装；并且变成了`msleep(seconds * 1000);`。
- en: 'One simple way to implement the (approximate) equivalent of the user space
    `sleep(3)` API can be seen in our `convenient.h` header; at heart, it employs
    the `schedule_timeout()` API:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 实现（近似）等效于用户空间`sleep(3)`API的一种简单方法可以在我们的`convenient.h`头文件中看到；本质上，它使用了`schedule_timeout()`API：
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now that you''ve learned how to delay (yes, smile please), let''s move on and
    learn a useful skill: timestamping kernel code. This allows you to quickly calculate
    how long a particular piece of code takes to execute.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何延迟（是的，请微笑），让我们继续学习一个有用的技能：给内核代码加上时间戳。这样可以快速计算特定代码执行所需的时间。
- en: Taking timestamps within kernel code
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在内核代码中获取时间戳
- en: 'It''s important to be able to take an accurate timestamp as kernels open employ
    this facility. For example, the `dmesg(1)` utility shows the time since the system
    booted in `seconds.microseconds` format; Ftrace traces typically show the time
    a function takes to execute. When in user mode, we often employ the `gettimeofday(2)`
    system call to take a timestamp. Within the kernel, several interfaces exist;
    commonly, the `ktime_get_*()` family of routines is employed for the purpose of
    obtaining accurate timestamps. For our purposes, the following routine is useful:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 能够获取准确的时间戳对内核开放使用这一设施非常重要。例如，`dmesg(1)`实用程序以`seconds.microseconds`格式显示系统启动以来的时间；Ftrace跟踪通常显示函数执行所需的时间。在用户模式下，我们经常使用`gettimeofday(2)`系统调用来获取时间戳。在内核中，存在多个接口；通常使用`ktime_get_*()`系列例程来获取准确的时间戳。对于我们的目的，以下例程很有用：
- en: '[PRE3]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This routine internally queries the wall (clock) time via the `ktime_get_real()`
    API and then converts the result into a nanosecond quantity. We won't bother with
    the internal details here. Also, several variants of this API are available; for
    example, `ktime_get_real_fast_ns()`, `ktime_get_real_ts64()`, and so on. The former
    is both fast and NMI-safe.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例程通过`ktime_get_real()`API内部查询墙（时钟）时间，然后将结果转换为纳秒数量。我们不会在这里烦恼内部细节。此外，这个API还有几个变体；例如，`ktime_get_real_fast_ns()`，`ktime_get_real_ts64()`等。前者既快速又NMI安全。
- en: 'Now that you know how to get a timestamp, you can calculate how long some code
    takes to execute to a good degree of accuracy, with nanosecond resolution no less!
    You can use the following pseudocode to achieve this:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道如何获取时间戳，你可以计算一段代码执行所需的时间，而且精度相当高，甚至可以达到纳秒级别的分辨率！你可以使用以下伪代码来实现这一点：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, the time taken for the (fictional) `foo()` and `bar()` functions to execute
    is calculated, and the result – in nanoseconds – is available in the `time_taken_ns` variable.
    The `<linux/ktime.h>` kernel header itself includes the `<linux/timekeeping.h>`
    header, which is where the `ktime_get_*()` family of routines is defined.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，计算了（虚构的）`foo()`和`bar()`函数执行所需的时间，并且结果（以纳秒为单位）存储在`time_taken_ns`变量中。`<linux/ktime.h>`内核头文件本身包括了`<linux/timekeeping.h>`头文件，其中定义了`ktime_get_*()`系列例程。
- en: A macro to help you calculate the time taken between two timestamps has been
    provided in our `convenient.h` header file: `SHOW_DELTA(later, earlier);`. Ensure
    that you pass the later timestamp as the first parameter and the first timestamp
    as the second parameter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`convenient.h`头文件中提供了一个宏来帮助你计算两个时间戳之间的时间：`SHOW_DELTA(later, earlier);`。确保将后一个时间戳作为第一个参数，第一个时间戳作为第二个参数。
- en: The code example in the next section will help us employ this kind of approach.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节的代码示例将帮助我们采用这种方法。
- en: Let's try it – how long do delays and sleeps really take?
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们来试试看-延迟和睡眠实际上需要多长时间？
- en: By now, you know how to use the `*delay()` and `*sleep()` APIs to construct
    delays and sleeps (non-blocking and blocking, respectively). Hang on, though –
    we haven't really tried it out in a kernel module. Not only that, are the delays
    and sleeps as accurate as we have been led to believe? Let's, as usual, be *empirical*
    (this is important!) and not make any assumptions. Let's actually try it out for
    ourselves!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经知道如何使用`*delay()`和`*sleep()`API来构建延迟和睡眠（非阻塞和阻塞）。不过，我们还没有真正在内核模块中尝试过。而且，延迟和睡眠是否像我们所相信的那样准确呢？让我们像往常一样*经验主义*（这很重要！）而不是做任何假设。让我们亲自尝试一下！
- en: 'The demo kernel module we''ll be looking at in this subsection performs two
    kinds of delays, in order:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本小节中查看的演示内核模块执行两种延迟，顺序如下：
- en: First, it employs the `*delay()` routines (which you learned about in the *Understanding
    how to use the *delay() atomic **APIs* section) to implement atomic non-blocking
    delays of 10 ns, 10 us, and 10 ms.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，它使用`*delay()`例程（您在*理解如何使用*delay()原子**API*部分中了解到）来实现10纳秒、10微秒和10毫秒的原子非阻塞延迟。
- en: Next, it employs the `*sleep()` routines (which you learned about in the *Understanding
    how to use the *sleep() blocking **APIs* section) to implement blocking delays
    of 10 us, 10 ms, and 1 second.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，它使用`*sleep()`例程（您在*理解如何使用*sleep()阻塞**API*部分中了解到）来实现10微秒、10毫秒和1秒的阻塞延迟。
- en: 'We call the code for this like so:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这样调用这段代码：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Here, `DILLY_DALLY()` is a custom macro. Its implementation is as follows:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`DILLY_DALLY()`是一个自定义宏。其实现如下：
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we have implemented the time delta calculation trivially; a good implementation
    will involve checking that the value of `t2` is greater than `t1`, that no overflow
    occurs, and so on.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们以简单的方式实现了时间差计算；一个良好的实现将涉及检查`t2`的值是否大于`t1`，是否发生溢出等。
- en: 'We invoke it, for various delays and sleeps, within our kernel module''s `init`
    function, like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在内核模块的`init`函数中调用它，用于各种延迟和睡眠，如下所示：
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here''s some sample output when the kernel module is run on our trusty x86_64
    Ubuntu VM:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的可靠的x86_64 Ubuntu VM上运行内核模块时，这是一些示例输出：
- en: '![](img/f9d48d06-517c-4f1c-8883-91e2d9d6f34e.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f9d48d06-517c-4f1c-8883-91e2d9d6f34e.png)'
- en: Figure 5.1 – A partial screenshot showing the output of our delays_sleeps.ko
    kernel module
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 - 部分截图显示我们的delays_sleeps.ko内核模块的输出
- en: 'Carefully study the preceding output; it''s peculiar that both the `udelay(10)` and
    `mdelay(10)` routines seem to complete their execution *before *the desired delay
    period has expired (in our sample output, in `9 us` and `9 ms`, respectively)!
    How come? The reality is that **the `*delay()` routines tend to finish earlier**.
    This fact is documented within the kernel source. Let''s take a look at the relevant
    portion of code here (it''s self-explanatory):'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细研究前面的输出；奇怪的是，`udelay(10)`和`mdelay(10)`例程似乎在所需的延迟期间*之前*完成了执行（在我们的示例输出中，分别为`9微秒`和`9毫秒`）！为什么？事实是**`*delay()`例程往往会提前完成**。这个事实在内核源代码中有记录。让我们来看看这里的相关代码部分（这是不言自明的）：
- en: '[PRE8]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `*sleep()` routines have the reverse characteristic; they pretty much always
    tend to **sleep for *longer *than asked**. Again, these are expected issues in
    a non-real-time OS such as standard Linux.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`*sleep()`例程具有相反的特性；它们几乎总是**比要求的时间*睡眠更长**。同样，这些是标准Linux等非实时操作系统中预期的问题。'
- en: 'You can **mitigate these issues** in a few ways:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过几种方式**减轻这些问题**：
- en: 'On standard Linux, in user mode, do the following:'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在标准Linux中，用户模式下，执行以下操作：
- en: First of all, it's best to use the **High-Resolution Timer (HRT)** interfaces
    for high accuracy. This, again, is code that's been merged from the RTL project
    into mainstream Linux (way back in 2006). It supports timers that require a resolution
    of less than a single *jiffy *(which, as you know, is tightly coupled to the timer
    "tick", the kernel `CONFIG_HZ` value); for example, with the `HZ` value being
    100, a jiffy is 1000/100 = 10 ms; with `HZ` being 250, a jiffy is 4 ms, and so
    on.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，最好使用**高分辨率定时器（HRT）**接口以获得高精度。这又是从RTL项目合并到主流Linux（早在2006年）的代码。它支持需要小于单个*jiffy*（您知道，这与定时器“tick”、内核`CONFIG_HZ`值紧密耦合）的分辨率的定时器；例如，当`HZ`值为100时，一个jiffy为1000/100
    = 10毫秒；当`HZ`为250时，一个jiffy为4毫秒，依此类推。
- en: Once you've done this, why not employ the soft RT scheduling features of Linux?
    Here, you can specify a scheduling policy of `SCHED_FIFO` or `SCHED_RR` and a
    high priority for your user mode thread (the range is `1` to `99`; we covered
    these details in the companion guide *Linux Kernel Programming -* *Chapter 10,*
    *The CPU Scheduler – Part 1*).
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成后，为什么不使用Linux的软实时调度功能呢？在这里，您可以指定`SCHED_FIFO`或`SCHED_RR`的调度策略，并为用户模式线程设置高优先级（范围为1到99；我们在配套指南*Linux内核编程*的*第10章*
    *CPU调度器-第1部分*中介绍了这些细节）。
- en: 'Most modern Linux systems will have HRT support. However, how do you exploit
    it? This is simple: you''re recommended to write your timer code *in user space* and
    employ standard POSIX timer APIs (such as the `timer_create(2)` and `timer_settime(2)` system
    calls). Since this book is concerned with kernel development, we won''t delve
    into these user space APIs here. In fact, this topic was covered in some detail
    in my earlier book, *Hands-On System Programming with Linux*, in *Chapter 13,
    Timers*, in the *The newer POSIX (interval) timers mechanism* section.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现代Linux系统都支持HRT。但是，如何利用它呢？这很简单：建议您在*用户空间*编写您的定时器代码，并使用标准的POSIX定时器API（例如`timer_create(2)`和`timer_settime(2)`系统调用）。由于本书关注内核开发，我们不会在这里深入探讨这些用户空间API。实际上，这个主题在我的早期著作*Linux系统编程实践*的*第13章*
    *定时器*的*较新的POSIX（间隔）定时器*部分有详细介绍。
- en: The kernel developers have taken the trouble to clearly document some excellent
    recommendations for when you're using these delay and sleep APIs within the kernel.
    It's really important that you browse through this document within the official
    kernel documentation: [https://www.kernel.org/doc/Documentation/timers/timers-howto.rst](https://www.kernel.org/doc/Documentation/timers/timers-howto.rst).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核开发人员已经费心清楚地记录了一些关于在内核中使用这些延迟和睡眠API时的出色建议。非常重要的是，您浏览一下官方内核文档中的这份文件：[https://www.kernel.org/doc/Documentation/timers/timers-howto.rst](https://www.kernel.org/doc/Documentation/timers/timers-howto.rst)。
- en: Configure and build the Linux OS as an RTOS; this will significantly reduce
    scheduling "jitter" (we covered this topic in detail in the companion guide *Linux
    Kernel Programming -* *Chapter 11,* *The CPU Scheduler – Part 2*, in the *Converting
    mainline Linux into an RTOS *section).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Linux OS配置为RTOS并构建；这将显著减少调度“抖动”（我们在配套指南*Linux内核编程*的*第11章* *CPU调度器-第2部分*的*将主线Linux转换为RTOS*部分中详细介绍了这个主题）。
- en: 'Interestingly, using our "better" Makefile''s checkpatch target can be a real
    boon. Let''s take a look at what it (the kernel''s checkpatch Perl script) has
    caught (first ensure you''re in the correct source directory):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，使用我们“更好”的Makefile的checkpatch目标可能会带来真正的好处。让我们看看它（内核的checkpatch Perl脚本）已经捕捉到了什么（首先确保你在正确的源目录中）：
- en: '[PRE9]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: That's really good! Ensure that you use the targets in our "better" `Makefile` (we
    covered this in detail in the companion guide *Linux Kernel Programming -* *Chapter
    5, Writing Your First Kernel Module LKMs – Part 2*, in the *A "better" Makefile
    template for your kernel modules* section).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的很好！确保你使用我们“更好”的`Makefile`中的目标（我们在伴随指南*Linux内核编程*的*第5章，编写你的第一个内核模块LKM - 第2部分*中详细介绍了这一点，在*为你的内核模块提供一个“更好”的Makefile模板*部分）。
- en: With that, we've finished looking at kernel delays and sleeping within the kernel.
    With this as a base, you shall now learn how to set up and use kernel timers,
    kernel threads, and workqueues in the remaining sections of this chapter.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们已经完成了对内核延迟和内核内睡眠的研究。有了这个基础，你现在将学习如何在本章的其余部分设置和使用内核定时器、内核线程和工作队列。
- en: The "sed" drivers – to demo kernel timers, kthreads, and workqueues
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: “sed”驱动程序——演示内核定时器、内核线程和工作队列
- en: To make this chapter more interesting and hands-on, we shall begin evolving
    a miscellaneous class character "driver" called a **simple encrypt decrypt** –
    or **sed** for short – driver (not to be confused with the well-known `sed(1)`
    utility). No, you won't get a grand prize for guessing that it provides some kind
    of – very simplistic – text encryption/decryption support.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本章更有趣和实用，我们将开始演变一个名为**简单加密解密**的杂项字符“驱动程序”（简称**sed**驱动程序）（不要与著名的`sed(1)`实用程序混淆）。不，你猜对了也不会得到大奖，它提供了一些非常简单的文本加密/解密支持。
- en: The point here is that we shall imagine that in the specification for this driver,
    one clause demands that the work (practically speaking, the encryption/decryption
    functionality) is carried out within a given time interval – in effect, *within
    a given deadline*. In order to check this, we shall design our driver so that
    it has a kernel timer that will expire in the given time interval; the driver
    will check that the functionality does indeed complete within this time constraint!
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重点是，我们应该想象在这个驱动程序的规范中，有一个条款要求工作（实际上是加密/解密功能）在给定的时间间隔内完成——实际上是*在给定的截止日期内*。为了检查这一点，我们将设计我们的驱动程序，使其具有一个内核定时器，在给定的时间间隔内到期；驱动程序将检查功能确实在这个时间限制内完成！
- en: 'We shall evolve a series of `sed` drivers and their user space counterparts
    (apps):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演变一系列`sed`驱动程序及其用户空间对应程序（应用程序）：
- en: 'The first driver – the `sed1` driver and user mode app (`ch5/sed1`) – will
    perform what we just described: the demo user mode app will employ `ioctl` system
    calls to interface with the driver and get the encrypt/decrypt message functionality
    going. The driver will focus on a kernel timer that we will set up to expire by
    the given deadline. If it does expire, we deem the operation to have failed; if
    not, the timer is canceled and the operation is a success.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个驱动程序——`sed1`驱动程序和用户模式应用程序（`ch5/sed1`）——将执行我们刚才描述的操作：演示用户模式应用程序将使用`ioctl`系统调用与驱动程序进行接口，并启动加密/解密消息功能。驱动程序将专注于一个内核定时器，我们将设置它在给定的截止日期前到期。如果它到期了，我们认为操作失败；如果没有，定时器被取消，操作就成功了。
- en: The second version, `sed2` (`ch5/sed2`), will do the same as `sed1`, except
    that the actual encrypt/decrypt message functionality here will be carried out
    in the context of a separately created kernel thread! This changes the design
    of the project.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个版本，`sed2`（`ch5/sed2`），将执行与`sed1`相同的操作，只是这里实际的加密/解密消息功能将在一个单独创建的内核线程的上下文中执行！这改变了项目的设计。
- en: The third version, `sed3` (`ch5/sed3`), will again do the same as `sed1` and
    `sed2`, except that this time the actual encrypt/decrypt message functionality
    will be carried out by a kernel workqueue!
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个版本，`sed3`（`ch5/sed3`），将再次执行与`sed1`和`sed2`相同的操作，只是这次实际的加密/解密消息功能将由内核工作队列执行！
- en: Now that you have learned how to perform delays (both atomic and blocking) and
    capture timestamps, let's learn how to set up and use kernel timers.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经学会了如何执行延迟（原子和阻塞）和捕获时间戳，让我们学习如何设置和使用内核定时器。
- en: Setting up and using kernel timers
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置和使用内核定时器
- en: A **timer** provides software with a means of being asynchronously notified
    when a designated amount of time has passed. All kinds of software, both in user
    and kernel space, require timers; this commonly includes network protocol implementations,
    block layer code, device drivers, and various kernel subsystems. This timer provides
    a means of asynchronous notification, thus allowing the driver to execute work
    in parallel with the running timer. An important question that arises is, *how
    will I know when the timer expires?* In user space apps, typically, the kernel
    sends a signal to the relevant process (the signal is typically `SIGALRM`).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**定时器**提供了软件在指定时间过去时异步通知的手段。各种软件，无论是在用户空间还是内核空间，都需要定时器；这通常包括网络协议实现、块层代码、设备驱动程序和各种内核子系统。这个定时器提供了异步通知的手段，从而允许驱动程序与运行的定时器并行执行工作。一个重要的问题是，*我怎么知道定时器何时到期？*在用户空间应用程序中，通常情况下，内核会向相关进程发送一个信号（信号通常是`SIGALRM`）。'
- en: In kernel space, it's a bit nuanced. As you will know from our discussion on
    top and bottom halves for hardware interrupts (see *Chapter 4, Handling Hardware
    Interrupts*, the *Understanding and using top and bottom halves* section), after
    the timer interrupt's top half (or ISR) completes, the kernel will ensure it runs
    the timer interrupt bottom half or timer softirq (as we showed in the table in [Chapter
    4](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling Hardware Interrupts*
    section* Available softirqs and what they are for*). This is a very high priority
    softirq called `TIMER_SOFTIRQ`. This softirq is what consumes expired timers!
    In effect – and this is very important to understand – your timer's "callback"
    function – the function that will run when the timer expires – is run by the timer
    softirq *and thus runs in atomic (interrupt) context*. Thus, it's limited in what
    it can and cannot do (again, this was explained in detail in *Chapter 4*, *Handling
    Hardware Interrupts*).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在内核空间中，这有点微妙。正如您从我们对硬件中断的上半部分和下半部分的讨论中所了解的（请参阅*第4章，处理硬件中断*，*理解和使用上半部分和下半部分*部分），在定时器中断的上半部分（或ISR）完成后，内核将确保运行定时器中断的下半部分或定时器softirq（正如我们在[第4章](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml)中所示，*处理硬件中断*部分*可用的softirq及其用途*）。这是一个非常高优先级的softirq，称为`TIMER_SOFTIRQ`。这个softirq就是消耗已到期的定时器！实际上-这一点非常重要-您的定时器的“回调”函数-定时器到期时将运行的函数-由定时器softirq运行*因此在原子（中断）上下文中运行*。因此，它在能够和不能做的方面受到限制（同样，这在*第4章*，*处理硬件中断*中有详细解释）。
- en: In the following section, you will learn how to set up and use a kernel timer.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习如何设置和使用内核定时器。
- en: Using kernel timers
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用内核定时器
- en: 'In order to use a kernel timer, you must follow a few steps. Here''s what to
    do in a nutshell (we''ll discuss this in more detail afterward):'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用内核定时器，您必须遵循一些步骤。简而言之，要做的是（我们稍后会详细讨论）：
- en: 'Initialize the timer metadata structure (`struct timer_list`) with the `timer_setup()`
    macro. The key items that get initialized here are as follows:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`timer_setup()`宏初始化定时器元数据结构（`struct timer_list`）。这里初始化的关键项目如下：
- en: The time to expire by (that value that `jiffies` should reach for the timer
    to expire)
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 到期时间（`jiffies`应达到的值，定时器才会到期）
- en: The function to invoke when the timer expires – in effect, the timer "callback"
    function
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定时器到期时要调用的函数-实际上是定时器的“回调”函数
- en: Write the code for your timer callback routine.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写定时器回调例程的代码。
- en: When appropriate, "arm" the timer – that is, have it start – by invoking the
    `add_timer()` (or `mod_timer()`) function.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在适当的时候，“启动”定时器-也就是，通过调用`add_timer()`（或`mod_timer()`）函数来启动。
- en: When the timer times out (expires), the OS will automatically invoke your timer's
    callback function (the one you set up in *step 2*); remember, it will be running
    in the timer softirq or an atomic or interrupt context.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当定时器超时（到期）时，操作系统将自动调用您的定时器回调函数（在*步骤2*中设置的函数）；请记住，它将在定时器softirq或原子或中断上下文中运行。
- en: (Optional) *Timers are not cyclic, they are one-time by default*. To have your
    timer run again, you will have to invoke the `mod_timer()` API; this is how you
    can set up an interval timer – one that times out at a given fixed time interval.
    If you don't perform this step, your timer will be a one-shot timer - it will
    count down and expire exactly once.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （可选）*定时器默认不是循环的，它们默认是一次性的*。要使定时器再次运行，您将需要调用`mod_timer()` API；这是如何设置间隔定时器-在给定的固定时间间隔后超时。如果不执行此步骤，您的定时器将是一次性定时器-它将倒计时并到期一次。
- en: When you are done, delete the timer with `del_timer[_sync]()`; this can also
    be used to cancel the timeout. It returns a value denoting whether a pending timer
    has been deactivated or not; that is, it returns `1` for an active timer or `0`
    for an inactive timer being canceled.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，使用`del_timer[_sync]()`删除定时器；这也可以用于取消超时。它返回一个值，表示是否已停用挂起的定时器；也就是说，对于活动定时器返回`1`，对于被取消的非活动定时器返回`0`。
- en: 'The `timer_list` data structure is the one that''s relevant to our work here;
    within it, the relevant members (the module/driver authors) are shown:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`timer_list`数据结构是我们这里相关的；其中，相关成员（模块/驱动程序作者）如下所示：'
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Use the `timer_setup()` macro to initialize it:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`timer_setup()`宏进行初始化：
- en: '[PRE11]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The parameters of `timer_setup()` are as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`timer_setup()`的参数如下：'
- en: '`@timer`: The pointer to the `timer_list` data structure (this should be allocated
    memory first; also, prefixing the formal parameter name with an `@` is a common
    convention).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@timer`：指向`timer_list`数据结构的指针（这应该首先分配内存；另外，用`@`作为形式参数名的前缀是一种常见的约定）。'
- en: '`@callback`: The pointer to the callback function. This is the function that
    the OS invokes (in the softirq context) when the timer expires. Its signature
    is `void (*function)(struct timer_list *);`. The parameter you receive in the
    callback function is the pointer to the `timer_list` data structure. So, how can
    we pass and access some arbitrary data within our timer callback? We''ll answer
    this question shortly.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@callback`：回调函数的指针。这是操作系统在定时器到期时调用的函数（在softirq上下文中）。它的签名是`void (*function)(struct
    timer_list *);`。回调函数中接收的参数是指向`timer_list`数据结构的指针。那么，我们如何在定时器回调中传递和访问一些任意数据呢？我们很快就会回答这个问题。'
- en: '`@flags`: These are the timer flags. We typically pass this as `0` (implying
    no special behavior). The flags you can specify are `TIMER_DEFERRABLE`, `TIMER_PINNED`, and `TIMER_IRQSAFE`.
    Let''s look at both in the kernel source code:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@flags`：这些是定时器标志。我们通常将其传递为`0`（意味着没有特殊行为）。您可以指定的标志是`TIMER_DEFERRABLE`、`TIMER_PINNED`和`TIMER_IRQSAFE`。让我们在内核源代码中看一下：'
- en: '[PRE12]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Using the `TIMER_DEFERRABLE` flag is useful when power consumption must be watched
    (such as on a battery-backed device). The third flag, `TIMER_IRQSAFE`, is special-purpose
    only; avoid using it.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在必要时，使用`TIMER_DEFERRABLE`标志是有用的，当需要监视功耗时（例如在备电设备上）。第三个标志`TIMER_IRQSAFE`只是特定目的；避免使用它。
- en: 'Next, use the `add_timer()` API to arm, or start, the timer. Once called, the
    timer is "live" and starts counting down:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用`add_timer()` API来启动定时器。一旦调用，定时器就是“活动的”并开始倒计时：
- en: '[PRE13]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Its parameter is the pointer to the `timer_list` structure that you just initialized
    (via the `timer_setup()` macro).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 它的参数是你刚刚初始化的`timer_list`结构的指针（通过`timer_setup()`宏）。
- en: Our simple kernel timer module – code view 1
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们的简单内核定时器模块-代码视图1
- en: 'Without further ado, let''s dive into the code of a simple kernel timer, written
    using the **Loadable Kernel Module** (**LKM**) framework (this can be found at `ch5/timer_simple`).
    As with most drivers, we keep a context or private data structure containing the
    information required while running; here, we call it `st_ctx`. We instantiate
    it as the `ctx` variable. We also specify the time to expire (as 420 ms) in a
    global named `exp_ms`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 不多说了，让我们来看一下使用**可加载内核模块**（**LKM**）框架编写的简单内核定时器代码的第一部分（可以在`ch5/timer_simple`找到）。和大多数驱动程序一样，我们保留一个包含在运行时所需的信息的上下文或私有数据结构；在这里，我们称之为`st_ctx`。我们将其实例化为`ctx`变量。我们还在一个名为`exp_ms`的全局变量中指定了过期时间（为420毫秒）。
- en: '[PRE14]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, let''s check out the first portion of our *init *code:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下我们*init*代码的第一部分：
- en: '[PRE15]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This is pretty straightforward. First, we initialize the `ctx` data structure,
    setting a `data` member to the value `3`. The one key point here is that the `timer_list`
    structure is within our `ctx` structure, so we must initialize it. Now, setting
    the timer callback function (the `function` parameter) and the `flags` parameter values
    is simple; what about setting the time to expire? You must set the `timer_list.expires`
    member to the value that the `jiffies` variable (macro, actually) in the kernel
    must reach; at that point, the timer will expire! So, we prime it to have the
    timer expire 420 milliseconds in the future by adding the current value of jiffies
    to the jiffies value that the 420 ms elapsed time will take, like this:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常简单。首先，我们初始化`ctx`数据结构，将`data`成员设置为值`3`。这里的一个关键点是`timer_list`结构在我们的`ctx`结构内部，所以我们必须初始化它。现在，设置定时器回调函数（`function`参数）和`flags`参数的值很简单；那么设置过期时间呢？你必须将`timer_list.expires`成员设置为内核中`jiffies`变量（实际上是宏）必须达到的值；在那一点，定时器将会过期！所以，我们设置它在未来420毫秒后过期，方法是将当前的jiffies值加到420毫秒经过的jiffies值上，就像这样：
- en: '[PRE16]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The `msecs_to_jiffies()` convenience routine helps us out here as it converts
    the millisecond value that's passed to `jiffies`. Adding this result to the current
    value of `jiffies` will give us the value that `jiffies` will be in the future,
    in 420 ms from now, which is when we want our kernel timer to expire.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`msecs_to_jiffies()`方便的例程在这里帮了我们一个忙，因为它将传递给`jiffies`的毫秒值转换了一下。将这个结果加到当前的`jiffies`值上将会给我们一个`jiffies`在未来的值，在420毫秒后，也就是我们希望内核定时器过期的时间。'
- en: This code is an inline function in `include/linux/jiffies.h:msecs_to_jiffies()`;
    the comments help us understand how it works. In a similar fashion, the kernel
    contains the `usecs_to_jiffies()`, `nsecs_to_jiffies()`, `timeval_to_jiffies()`,
    and `jiffies_to_timeval()` (inline) function helper routines.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码是在`include/linux/jiffies.h:msecs_to_jiffies()`中的一个内联函数；注释帮助我们理解它是如何工作的。同样地，内核包含了`usecs_to_jiffies()`、`nsecs_to_jiffies()`、`timeval_to_jiffies()`和`jiffies_to_timeval()`（内联）函数辅助例程。
- en: 'The next portion of the *init *code is as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*init*代码的下一部分如下：'
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As we can see, by invoking the `add_timer()` API, we have armed (start) our
    kernel timer. It''s now live and counting down... in (approximately) 420 ms, it
    will expire. (Why approximately? As you saw in the *Let''s try it – how long do
    delays and sleeps really take?* section, delay and sleep APIs aren''t all that
    precise. In fact, a suggested exercise for you to work on later is to test the
    accuracy of the timeout; you can find this in the *Questions/kernel_timer_check* section.
    Also, in a sample solution for this exercise, we will show how using the `time_after()`
    macro is a good idea; it performs a validity check to ensure that the second timestamp
    is actually later than the first. Similar macros can be found in `include/linux/jiffies.h`;
    see the comment preceding this line: `include/linux/jiffies.h:#define time_after(a,b)`).'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，通过调用`add_timer()` API，我们已经启动了我们的内核定时器。它现在是活动的并且在倒计时……大约420毫秒后，它将会过期。（为什么是大约？正如你在*让我们试试吧-延迟和睡眠到底需要多长时间？*部分看到的，延迟和睡眠的API并不是那么精确。事实上，一个建议给你后续工作的练习是测试超时的准确性；你可以在*Questions/kernel_timer_check*部分找到这个。此外，在这个练习的一个示例解决方案中，我们将展示使用`time_after()`宏是一个好主意；它执行一个有效性检查，以确保第二个时间戳实际上比第一个晚。类似的宏可以在`include/linux/jiffies.h`中找到；请参阅这一行之前的注释：`include/linux/jiffies.h:#define
    time_after(a,b)`）。
- en: Our simple kernel timer module – code view 2
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们的简单内核定时器模块-代码视图2
- en: '`add_timer()` started our kernel timer. As you just saw, it will soon expire.
    Internally, as we mentioned earlier, the kernel''s timer softirq will run our
    timer''s callback function. In the preceding section, we initialized the callback
    function to the `ding()` function (ha, *onomatopoeia* – a word that suggests the
    sound it describes – in action!) via the `timer_setup()` API. Hence, this code
    will run when the timer expires:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`add_timer()`启动了我们的内核定时器。正如你刚才看到的，它很快就会过期。内部地，正如我们之前提到的，内核的定时器软中断将运行我们的定时器回调函数。在前面的部分，我们初始化了回调函数为`ding()`函数（哈，*拟声词*
    - 一个描述它所描述的声音的词 - 在行动中！）通过`timer_setup()` API。因此，当定时器过期时，这段代码将会运行：'
- en: '[PRE18]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'There are a few things to keep in mind regarding this function:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个函数有一些事情需要记住：
- en: The timer callback handler code (`ding()` here) runs in atomic (interrupt, softirq)
    context; thus, you aren't allowed to invoke any perform any blocking APIs, memory
    allocation other than with the `GFP_ATOMIC` flag, or any kind of data transfer
    between kernel and user space (we covered this in detail in the previous chapter
    in the *Interrupt context guidelines – what to do and what not to do* section).
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定时器回调处理程序代码（这里是`ding()`）在原子（中断，软中断）上下文中运行；因此，你不被允许调用任何阻塞API，内存分配除了使用`GFP_ATOMIC`标志之外，或者在内核和用户空间之间进行任何数据传输（我们在前一章的*中断上下文指南-要做什么和不要做什么*部分详细介绍了这一点）。
- en: 'The callback function receives, as a parameter, the pointer to the `timer_list`
    structure. Since we have (very deliberately) kept `struct timer_list` within our
    context or private data structure, we can usefully employ the `from_timer()` macro
    to retrieve the pointer to our private structure; that is, `struct st_ctx`). The
    first line of code shown previous does this. How does this work? Let''s look at
    its implementation:'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回调函数接收`timer_list`结构的指针作为参数。由于我们非常有意地将`struct timer_list`保留在我们的上下文或私有数据结构中，我们可以有用地使用`from_timer()`宏来检索指向我们私有结构的指针；也就是`struct
    st_ctx`）。前面显示的代码的第一行就是这样做的。这是如何工作的？让我们看看它的实现：
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: It's really a wrapper over the `container_of()` macro!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它实际上是`container_of()`宏的包装器！
- en: We then print and decrement our `data` value.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，我们打印并减少我们的`data`值。
- en: We then issue our `PRINT_CTX()` macro (recall that it's defined in our `convenient.h` header
    file). It will show that we're running in softirq context.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们发出我们的`PRINT_CTX()`宏（回想一下，它是在我们的`convenient.h`头文件中定义的）。它将显示我们正在softirq上下文中运行。
- en: 'Next, as long as our data member is positive, we force another timeout (of
    the same period) by invoking the `mod_timer()` API:'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，只要我们的数据成员是正数，我们就通过调用`mod_timer()`API来强制另一个超时（相同的时间段）：
- en: '[PRE20]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: As you can see, with `mod_timer()`, when the timer triggers again is completely
    up to you; it's considered an efficient way of updating a timer's expiry date.
    By using `mod_timer()`, you can even arm an inactive timer (the job that `add_timer()`
    does); in this case, the return value is `0`, else it's `1` (implying that we've
    modified an existing active timer).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，使用`mod_timer()`，定时器再次触发完全取决于您；这被认为是更新定时器到期日期的有效方法。通过使用`mod_timer()`，甚至可以启动非活动定时器（`add_timer()`的工作）；在这种情况下，返回值为`0`，否则为`1`（意味着我们修改了现有的活动定时器）。
- en: Our simple kernel timer module – running it
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 我们的简单内核定时器模块 - 运行它
- en: 'Now, let''s test our kernel timer module. On our x86_64 Ubuntu VM, we will
    use our `lkm` convenience script to load up the kernel module. The following screenshot
    shows a partial view of this and the kernel log:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们测试我们的内核定时器模块。在我们的x86_64 Ubuntu VM上，我们将使用我们的`lkm`便利脚本来加载内核模块。以下截图显示了这个过程的部分视图和内核日志：
- en: '![](img/8d3fa66c-52cc-44fa-98b5-e7f92ccd785d.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8d3fa66c-52cc-44fa-98b5-e7f92ccd785d.png)'
- en: Figure 5.2 – A partial screenshot of running our timer_simple.ko kernel module
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 - 运行我们的timer_simple.ko内核模块的部分截图
- en: Study the `dmesg` (kernel log) output shown here. Since we've set the initial
    value of our private structure's `data` member to `3`, the kernel timer expires
    three times (just as our logic demands). Check out the timestamps in the left-most
    column; you can see that the second timer expiry occurred at `4234.289334` (sec.us)
    and the third at `4234.737346`; a quick subtraction reveals that the time difference
    is 448,012 microseconds; that is, about 448 milliseconds. This is reasonable since
    we asked for a 420 ms timeout (its a bit over that; the overheads of the printks
    do matter as well).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 研究这里显示的`dmesg`（内核日志）输出。由于我们将私有结构的`data`成员的初始值设置为`3`，内核定时器会过期三次（正如我们的逻辑要求的那样）。查看最左边的时间戳；您可以看到第二个定时器到期发生在`4234.289334`（秒.微秒），第三个在`4234.737346`；快速减法表明时间差为448,012微秒；即约448毫秒。这是合理的，因为我们要求的超时为420毫秒（略高于此；printks的开销也很重要）。
- en: 'The `PRINT_CTX()` macro''s output is revealing as well; let''s look at the
    second one shown in the preceding screenshot:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`PRINT_CTX()`宏的输出也很有启发性；让我们看看前面截图中显示的第二个：'
- en: '[PRE21]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This shows that (as explained in detail in *Chapter 4*, *Handling Hardware Interrupts*)
    the code ran on CPU 1 (the `001)`) in softirq context (`s` in `..s1`). Furthermore,
    the process context that got interrupted – by the timer interrupt and softirq
    – is the `swapper/1` kernel thread; this is the CPU idle thread running on CPU
    1 when it's idle. This makes sense and is quite typical on an idle or lightly
    loaded system. The system (or at least CPU 1) was idle when the timer interrupt
    was initiated and a subsequent softirq came along and ran our timer callback.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明（如*第4章*中详细解释的那样，*处理硬件中断*），代码在CPU 1（`001`）上以softirq上下文（`s`在`..s1`中）运行。此外，被定时器中断和softirq中断的进程上下文是`swapper/1`内核线程；这是CPU
    1上空闲时运行的CPU空闲线程。这是合理的，在空闲或轻负载系统上很典型。当定时器中断被启动并随后的softirq到来并运行我们的定时器回调时，系统（或至少CPU
    1）是空闲的。
- en: sed1 – implementing timeouts with our demo sed1 driver
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: sed1 - 使用我们的演示sed1驱动程序实现超时
- en: In this section, we'll write a bit of a more interesting driver (the code's
    for this can be found at `ch5/sed1/sed1_driver`). We'll design it so that it encrypts
    and/or decrypts a given message (very trivially, of course). The basic idea is
    that a user mode app (this can be found in `ch5/userapp_sed`) serves as its user
    interface. When run, it opens our `misc` character driver's device file (`/dev/sed1_drv`)
    and issues an `ioctl(2)` system call upon it.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将编写一个更有趣的驱动程序（代码可以在`ch5/sed1/sed1_driver`中找到）。我们将设计它以便加密和/或解密给定的消息（当然非常简单）。基本思想是用户模式应用程序（可以在`ch5/userapp_sed`中找到）作为其用户界面。运行时，它打开我们的`misc`字符驱动程序的设备文件（`/dev/sed1_drv`）并对其进行`ioctl(2)`系统调用。
- en: 'We have provided material online to help you understand how to interface a
    kernel module or device driver to a user space process via several common methods:
    via procfs, sysfs, debugfs, netlink sockets, and the `ioctl()` system call ([https://github.com/PacktPublishing/Learn-Linux-Kernel-Development/blob/master/User_kernel_communication_pathways.pdf](https://github.com/PacktPublishing/Learn-Linux-Kernel-Development/blob/master/User_kernel_communication_pathways.pdf))!'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了在线材料，以帮助您了解如何通过几种常见方法将内核模块或设备驱动程序与用户空间进程进行接口：通过procfs、sysfs、debugfs、netlink套接字和`ioctl()`系统调用（[https://github.com/PacktPublishing/Learn-Linux-Kernel-Development/blob/master/User_kernel_communication_pathways.pdf](https://github.com/PacktPublishing/Learn-Linux-Kernel-Development/blob/master/User_kernel_communication_pathways.pdf)）！
- en: 'The `ioctl()` call passes a data structure that encapsulates the data being
    passed, its length, the operation (or transform) to perform upon it, and a `timed_out` field
    (to figure out if it failed due to it missing its deadline). The valid ops are
    as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`ioctl()`调用传递了一个封装传递的数据、其长度、要对其执行的操作（或转换）以及`timed_out`字段的数据结构（以确定是否由于未能在截止日期前完成而失败）。有效的操作如下：'
- en: Encrypt: `XF_ENCRYPT`
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密：`XF_ENCRYPT`
- en: Decrypt: `XF_DECRYPT`
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解密：`XF_DECRYPT`
- en: Due to lack of space, we don't intend to show the code in great detail here –
    after all, having read so much of this book, you're now in a good position to
    browse and try and understand the code on your own! Nevertheless, certain key
    details relevant to this section will be shown.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 由于空间不足，我们不打算在这里详细显示代码 - 毕竟，阅读了这么多书，现在你已经有能力自己浏览和理解代码了！尽管如此，与本节相关的某些关键细节将被显示。
- en: 'Let''s take a look at its overall design:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下它的整体设计：
- en: Our `sed1` driver (`ch5/sed1/sed1_driver/sed1_drv.c`) is really a pseudo driver,
    in the sense that it doesn't operate on any peripheral hardware controller or
    chip but on memory; nevertheless, it's a full-fledged `misc` class character device
    driver.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的`sed1`驱动程序（`ch5/sed1/sed1_driver/sed1_drv.c`）实际上是一个伪驱动程序，它不是在任何外围硬件控制器或芯片上运行，而是在内存上运行；尽管如此，它是一个完整的`misc`类字符设备驱动程序。
- en: It registers itself as a `misc` device; in the process, a device node is auto-created
    by the kernel (here, we will call it `/dev/sed1_drv`).
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它注册自己作为一个`misc`设备；在这个过程中，内核会自动创建一个设备节点（这里我们称之为`/dev/sed1_drv`）。
- en: We arrange for it to have a driver "context" structure (`struct stMyCtx`) containing
    key members that it uses throughout; one of them is a `struct timer_list` structure
    for a kernel timer, which we initialize in the init code path (with the `timer_setup()` API).
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们安排它有一个驱动程序“上下文”结构（`struct stMyCtx`），其中包含它在整个过程中使用的关键成员；其中一个是用于内核定时器的`struct
    timer_list`结构，在`init`代码路径中进行初始化（使用`timer_setup()`API）。
- en: 'A user space app (`ch5/sed1/userapp_sed/userapp_sed1.c`) opens the device file
    of our `sed1` driver (it''s passed as a parameter to it, along with the message
    to encrypt). It invokes an `ioctl(2)` system call – the command being to encrypt –
    and the `arg` parameter, which is a pointer to a duly populated structure containing
    all the required information (including the message payload to encrypt). Let''s
    take a look at it in brief:'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个用户空间应用程序（`ch5/sed1/userapp_sed/userapp_sed1.c`）打开我们的`sed1`驱动程序的设备文件（它作为参数传递给它，以及要加密的消息）。它调用了一个`ioctl(2)`系统调用
    - 命令是加密 - 以及`arg`参数，它是一个指向包含所有必需信息的结构的指针（包括要加密的消息负载）。让我们简要看一下：
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Our `sed1` driver's `ioctl` method takes over. After performing validity checks,
    it copies the metadata structure (via the usual `copy_from_user()`) and fires
    off our `process_it()` function, which then invokes our `encrypt_decrypt_payload()` routine.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的`sed1`驱动程序的`ioctl`方法接管。在执行有效性检查后，它复制元数据结构（通过通常的`copy_from_user()`）并启动我们的`process_it()`函数，然后调用我们的`encrypt_decrypt_payload()`例程。
- en: '`encrypt_decrypt_payload()` is the key routine here. It does the following:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`encrypt_decrypt_payload()`是关键例程。它做以下事情：'
- en: Starts our kernel timer (with the `mod_timer()` API), setting it to expire in `TIMER_EXPIRE_MS` milliseconds
    from now (here, we've set `TIMER_EXPIRE_MS` to `1`).
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动我们的内核定时器（使用`mod_timer()`API），设置它在`TIMER_EXPIRE_MS`毫秒后过期（这里，我们将`TIMER_EXPIRE_MS`设置为`1`）。
- en: Grabs a timestamp, `t1 = ktime_get_real_ns();`.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取时间戳，`t1 = ktime_get_real_ns();`。
- en: 'Kicks off the actual work – it''s either an encrypt or decrypt operation (we''ve
    kept it very simplistic: a mere `XOR` operation followed by an increment for each
    byte of the payload; the reverse for decryption).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动实际工作 - 它是加密还是解密操作（我们保持它非常简单：对负载的每个字节进行简单的`XOR`操作，然后递增；解密时相反）。
- en: 'As soon as the work''s complete, do two things: grab a second timestamp, `t2
    = ktime_get_real_ns();`, and cancel the kernel timer (with the `del_timer()` API).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作完成后，立即做两件事：获取第二个时间戳，`t2 = ktime_get_real_ns();`，并取消内核定时器（使用`del_timer()`API）。
- en: Show the time taken to complete (via our `SHOW_DELTA()` macro).
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示完成所需的时间（通过我们的`SHOW_DELTA()`宏）。
- en: The user space app then sleeps for 1 second (to gather itself) and runs the `ioctl` decryption,
    resulting in our driver decrypting the message.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后用户空间应用程序休眠1秒钟（以收集自己），并运行`ioctl`解密，导致我们的驱动程序解密消息。
- en: Finally, it terminates.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，终止。
- en: 'The following is the relevant code from the `sed1` driver:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`sed1`驱动程序的相关代码：
- en: '[PRE23]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'That''s pretty much it! To get a feel for how it works, let''s see it in action.
    First, we must insert our kernel driver (LKM):'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！为了了解它是如何工作的，让我们看看它的运行情况。首先，我们必须插入我们的内核驱动程序（LKM）：
- en: '[PRE24]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following screenshot shows a sample run of it encrypting and decrypting
    (here, we deliberately run the **Address Sanitizer** (**ASan**) debug version
    of this app; it might just reveal bugs, so why not!):'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了它加密和解密的示例运行（这里我们故意运行了这个应用的**Address Sanitizer**（**ASan**）调试版本；这可能会暴露bug，所以为什么不呢！）：
- en: '![](img/b69c5a7c-64ac-4b18-83fb-5b944288b6eb.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b69c5a7c-64ac-4b18-83fb-5b944288b6eb.png)'
- en: Figure 5.3 – Our sed1 mini-project encrypting and decrypting a message within
    the prescribed deadline
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 - 我们的`sed1`迷你项目在规定的截止日期内加密和解密消息
- en: Everything went well here.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一切进行得很顺利。
- en: 'Let''s take a look at the code of our kernel timer''s callback function. Here,
    in our simple `sed1` driver, we merely have it do the following:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们内核定时器回调函数的代码。在我们简单的`sed1`驱动程序中，我们只需要让它做以下事情：
- en: Atomically set an integer in our private structure, `timed_out`, to a value of `1`, indicating
    failure. As we copy the data structure back to our user mode app (over `ioctl()`),
    this allows it to easily detect the failure and report/log it (the details on
    using atomic operators and much more will be covered in the last two chapters
    of this book).
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 原子地将我们私有结构中的整数`timed_out`设置为`1`，表示失败。当我们将数据结构通过`ioctl()`复制回用户模式应用程序时，这允许它轻松检测失败并报告/记录它（有关使用原子操作符等更多细节将在本书的最后两章中介绍）。
- en: Emit a `printk` to the kernel log (at the `KERN_NOTICE` level), indicating that
    we timed out.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向内核日志发出`printk`（在`KERN_NOTICE`级别），指示我们超时了。
- en: Invoke our `PRINT_CTX()` macro to show the context details.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用我们的`PRINT_CTX()`宏来显示上下文细节。
- en: 'The code for our kernel timer''s callback function is as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的内核定时器回调函数的代码如下：
- en: '[PRE25]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Can we see this code – the `timesup()` timer expiry function – run? We arrange
    to do just this next.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能看到这段代码 - `timesup()`定时器到期函数 - 运行吗？我们安排下一步就是这样做。
- en: Deliberately missing the bus
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故意错过公交车
- en: 'The part I left out earlier is an interesting wrinkle: just before the second
    timestamp is taken, we insert a bit of code to deliberately miss the sacrosanct
    deadline! How? It''s really very simple:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前遗漏的部分是一个有趣的细节：就在第二个时间戳被取之前，我们插入了一小段代码，故意错过了神圣的截止日期！怎么做？实际上非常简单：
- en: '[PRE26]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`make_it_fail` is a module parameter that is set to `0` by default; thus, only
    if you want to live dangerously (yes, a bit exaggerated!) should you pass it as `1`.
    Let''s try it out and see our kernel timer expire. The user mode app will detect
    this and report the failure as well:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`make_it_fail`是一个模块参数，默认设置为`0`；因此，只有当你想要冒险（是的，有点夸张！）时，你才应该将其传递为`1`。让我们试一试，看看我们的内核定时器何时到期。用户模式应用程序也会检测到这一点，并报告失败：'
- en: '![](img/29cfeb09-64fd-40e7-92e9-8752bcd8fde6.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![](img/29cfeb09-64fd-40e7-92e9-8752bcd8fde6.png)'
- en: Figure 5.4 – Our sed1 mini-project running with the make_it_fail module parameter
    set to 1, causing the deadline to be missed
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 - 我们的sed1迷你项目运行时，make_it_fail模块参数设置为1，导致截止日期被错过
- en: This time, the deadline is exceeded before the timer is canceled, thus causing
    it to expire and fire. Its `timesup()` callback function then runs (highlighted
    in the preceding screenshot). I highly recommend that you take the time to read
    the code of the driver and user mode app in detail and try it out on your own.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这次，截止日期在定时器被取消之前就已经过期，因此导致它到期并触发。它的`timesup()`回调函数随后运行（在前面的截图中突出显示）。我强烈建议您花时间详细阅读驱动程序和用户模式应用程序的代码，并自行尝试。
- en: 'The `schedule_timeout()` function that we briefly used earlier is a great example
    of using kernel timers! Its internal implementation can be seen here: `kernel/time/timer.c:schedule_timeout()`.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前简要使用的`schedule_timeout()`函数是使用内核定时器的一个很好的例子！它的内部实现可以在这里看到：`kernel/time/timer.c:schedule_timeout()`.
- en: Additional information on timers can be found within the `proc` filesystem;
    among the relevant (pseudo) files is `/proc/[pid]/timers` (per-process POSIX timers)
    and the `/proc/timer_list` pseudofile (this contains information about all pending
    high-resolution timers, as well as all clock event sources. Note that the `/proc/timer_stats`
    pseudo-file disappeared after kernel version 4.10). You can find out more information
    about them on the man page about `proc(5)` at [https://man7.org/linux/man-pages/man5/proc.5.html](https://man7.org/linux/man-pages/man5/proc.5.html).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 关于定时器的其他信息可以在`proc`文件系统中找到；其中相关的（伪）文件包括`/proc/[pid]/timers`（每个进程的POSIX定时器）和`/proc/timer_list`伪文件（其中包含有关所有待处理的高分辨率定时器以及所有时钟事件源的信息。请注意，内核版本4.10之后，`/proc/timer_stats`伪文件消失了）。您可以在关于`proc(5)`的man页面上找到更多关于它们的信息，网址为[https://man7.org/linux/man-pages/man5/proc.5.html](https://man7.org/linux/man-pages/man5/proc.5.html)。
- en: In the next section, you will learn how to create and use kernel threads to
    your benefit. Read on!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将学习如何创建和使用内核线程以使其对您有利。继续阅读！
- en: Creating and working with kernel threads
  id: totrans-213
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和使用内核线程
- en: 'A thread is an execution path; it''s purely concerned with executing a given
    function. That function is its life and scope; once it returns from that function,
    it''s dead. In user space, a thread is an execution path within a process; processes
    can be single or multi-threaded. Kernel threads are very similar to user mode
    threads in many respects. In kernel space, a thread is also an execution path,
    except that it runs within the kernel VAS, with kernel privilege. This means that
    kernels are also multi-threaded. A quick look at the output of `ps(1)` (run with
    the **Berkeley Software Distribution** (**BSD**) style `aux` option switches)
    shows us the kernel threads – they''re the ones whose names are enclosed in square
    brackets:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 线程是一个执行路径；它纯粹关注执行给定的函数。那个函数就是它的生命和范围；一旦它从那个函数返回，它就死了。在用户空间，线程是进程内的执行路径；进程可以是单线程或多线程的。在许多方面，内核线程与用户模式线程非常相似。在内核空间，线程也是一个执行路径，只是它在内核VAS中运行，具有内核特权。这意味着内核也是多线程的。快速查看`ps(1)`的输出（使用**伯克利软件发行版**（**BSD**）风格的`aux`选项开关运行）可以显示出内核线程
    - 它们的名称被括在方括号中：
- en: '[PRE27]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The majority of the kernel threads have been created for a definite purpose;
    often, they're created at system startup and run forever (in an infinite loop).
    They put themselves into a sleep state, and, when some work is required to be
    done, wake up, perform it, and go right back to sleep. A good example is that
    of the `ksoftirqd/n` kernel thread(s) (there's typically one per CPU core; that's
    what the `n` signifies – it's the core number); when the softirq load gets too
    heavy, they're woken up by the kernel to help consume the pending softirqs and
    thus help out (we discussed this in [Chapter 4](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling
    Hardware Interrupts*, in the *Employing the ksoftirqd kernel threads* section;
    in the preceding `ps` output, you can see them on a dual-core VM; they have PID
    10 and 18). Similarly, the kernel also employs *"kworker" worker threads*, which
    are dynamic – they come and go as work is required (a quick `ps aux | grep kworker`
    should reveal several of them).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数内核线程都是为了特定目的而创建的；通常它们在系统启动时创建并永远运行（在一个无限循环中）。它们会进入睡眠状态，当需要做一些工作时，就会唤醒，执行它，并立即回到睡眠状态。一个很好的例子是`ksoftirqd/n`内核线程（通常每个CPU核心有一个；`n`表示核心编号）；当软中断负载过重时，它们会被内核唤醒，以帮助消耗待处理的软中断（我们在[第4章](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml)中讨论过这一点，*处理硬件中断*，在*使用ksoftirqd内核线程*部分；在前面的`ps`输出中，您可以在双核VM上看到它们；它们的PID分别为10和18）。同样，内核还使用“kworker”工作线程，它们是动态的
    - 随着工作的需要而来去（快速运行`ps aux | grep kworker`应该会显示出其中几个）。
- en: 'Let''s take a look at a few characteristics of kernel threads:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看内核线程的一些特点：
- en: They always execute in kernel VAS, in kernel mode with kernel privilege.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们总是在内核VAS中执行，在内核模式下具有内核特权。
- en: They always run in process context (refer to the companion guide *Linux Kernel
    Programming -* *Chapter 6*, *Kernel Internals Essentials – Processes and Threads*,
    the *Understanding process and interrupt contexts* section) and they have a task
    structure (and thus a PID and all other typical thread attributes, though their
    *credentials* always are set to `0`, implying root access).
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们总是在进程上下文中运行（参考伴随指南*Linux内核编程 - 第6章，内核内部要点 - 进程和线程*，*理解进程和中断上下文*部分），它们有一个任务结构（因此有一个PID和所有其他典型的线程属性，尽管它们的*凭据*总是设置为`0`，意味着具有根访问权限）。
- en: They compete for the CPU resource with other threads (including user mode threads)
    via the CPU scheduler; kernel threads (often abbreviated as **kthreads**) do get
    a slight bump in priority.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们与其他线程（包括用户模式线程）竞争CPU资源，通过CPU调度程序；内核线程（通常缩写为**kthreads**）确实会获得优先级的轻微提升。
- en: Since they run purely in kernel VAS, they're blind to user VAS; thus, their
    `current->mm` value is always `NULL` (indeed, it's a quick way to identify a kthread).
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于它们纯粹在内核VAS中运行，它们对用户VAS是盲目的；因此，它们的`current->mm`值始终为`NULL`（实际上，这是识别内核线程的一种快速方法）。
- en: All kernel threads descend from the kernel thread named `kthreadd`, which has
    a PID of `2`. This is created by the kernel (technically, the first `swapper/0`
    kthread with a PID of `0`) during early boot; you can verify this by doing `pstree
    -t -p 2` (look up the man page on `pstree(1)` for usage details).
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有内核线程都是从名为`kthreadd`的内核线程派生出来的，它的PID是`2`。这是在早期引导期间由内核（技术上是第一个PID为`0`的`swapper/0`内核线程）创建的；你可以通过执行`pstree
    -t -p 2`来验证这一点（查阅`pstree(1)`的手册页以获取使用详情）。
- en: They have naming conventions. kthreads are named differently, though some conventions
    are followed. Often, the name ends in `/n`; this signifies that it's a per-CPU
    kernel thread. The number specifies the CPU core it's been affined to run upon
    (we covered CPU affinity in the companion guide *Linux Kernel Programming -* *Chapter
    11*,* The CPU Scheduler – Part 2*, in the *Understanding, querying, and setting
    the CPU affinity mask* section). Furthermore, kernel threads are used for specific
    purposes and their name reflects that; for example, `irq/%d-%s` (where `%d` is
    the PID and `%s` is the name) is a threaded interrupt handler (covered in *Chapter
    4*, *Handling Hardware Interrupts*). You can learn how to find out the kthread
    name and about many practical uses of kthreads (and how to tune them to reduce
    jitter) by reading the kernel documentation, *Reducing OS jitter due to per-cpu
    kthreads*, at [https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt](https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt).
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们有命名约定。内核线程的命名方式不同，尽管有一些约定是遵循的。通常，名称以`/n`结尾；这表示它是一个每CPU内核线程。数字指定了它所关联的CPU核心（我们在伴随指南*Linux内核编程
    - 第11章，CPU调度程序 - 第2部分*中介绍了CPU亲和力，在*理解、查询和设置CPU亲和力掩码*部分）。此外，内核线程用于特定目的，它们的名称反映了这一点；例如，`irq/%d-%s`（其中`%d`是PID，`%s`是名称）是一个线程中断处理程序（在*第4章，处理硬件中断*中介绍）。你可以通过阅读内核文档*减少由每CPU内核线程引起的OS抖动*，了解如何找到内核线程的名称以及内核线程的许多实际用途（以及如何调整它们以减少抖动），网址为[https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt](https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt)。
- en: The bit we're interested in is that the kernel modules and device drivers often
    need to run a certain code path in the background, in parallel with other work
    that it and the kernel routinely performs. Let's say you need to block upon an
    asynchronous event that's occurring, or need to, upon some event, execute a user
    mode process from within the kernel, which is time-consuming. The kernel thread
    is just the ticket here; thus, we shall focus on how you, as a module author,
    can create and manage kernel threads.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感兴趣的是，内核模块和设备驱动程序通常需要在后台运行某些代码路径，与它和内核通常执行的其他工作并行进行。假设你需要在发生异步事件时阻塞，或者需要在某些事件发生时在内核中执行一个用户模式进程，这是耗时的。内核线程在这里就派上用场了；因此，我们将重点关注作为模块作者如何创建和管理内核线程。
- en: Yes, you can execute a user mode process or app from within the kernel! The
    kernel provides some**user mode helper** (**umh**) APIs to do so, with a common
    one being `call_usermode_helper()`. You can view its implementation  here: `kernel/umh.c:int call_usermodehelper(const
    char *path, char **argv, char **envp, int wait)`. Be careful, though; you are
    not meant to abuse this API to invoke just any app from the kernel – that's simply
    bad design! There are very few actual use cases of using this API in the kernel;
    use `cscope(1)` to check it out.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，你可以在内核中执行用户模式进程或应用程序！内核提供了一些**用户模式辅助**（**umh**）API来实现这一点，其中一个常见的是`call_usermode_helper()`。你可以在这里查看它的实现：`kernel/umh.c:int
    call_usermodehelper(const char *path, char **argv, char **envp, int wait)`。不过要小心，你不应该滥用这个API从内核中调用任何应用程序
    - 这只是糟糕的设计！在内核中使用这个API的实际用例非常少；使用`cscope(1)`来查看它。
- en: Great; with that, let's learn how to create and work with a kernel thread.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 好的；有了这些，让我们学习如何创建和使用内核线程。
- en: A simple demo – creating a kernel thread
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个简单的演示 - 创建一个内核线程
- en: 'The primary API for creating kernel threads (that''s exposed to us module/driver
    authors) is `kthread_create()`; it''s a macro that invokes the `kthread_create_on_node()`
    API. The fact is, calling `kthread_create()` alone isn''t sufficient to have your
    kernel thread do anything useful; this is because, while this macro does create
    the kernel thread, you need to make it a candidate for the scheduler by setting
    it''s stated to running and waking it up. This can be done with the `wake_up_process()`
    API (once successful, it''s enqueued onto a CPU runqueue, which makes it schedulable
    so that it runs in the near future). The good news is that the `kthread_run()` helper
    macro can be used to invoke both `kthread_create()` and `wake_up_process()` in
    one go. Let''s take a look at its implementation in the kernel:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 创建内核线程的主要API（对于我们模块/驱动程序的作者来说）是`kthread_create()`；它是一个调用`kthread_create_on_node()`API的宏。事实是，仅仅调用`kthread_create()`是不足以使您的内核线程执行任何有用的操作的；这是因为，虽然这个宏确实创建了内核线程，但您需要通过将其状态设置为运行并唤醒它来使其成为调度程序的候选者。这可以通过`wake_up_process()`API来实现（一旦成功，它将被排入CPU运行队列，从而使其可以在不久的将来运行）。好消息是，`kthread_run()`辅助宏可以用来一次性调用`kthread_create()`和`wake_up_process()`。让我们来看看它在内核中的实现：
- en: '[PRE28]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The comments in the preceding code snippet make the parameters and return value
    of `kthread_run()` clear.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 前面代码片段中的注释清楚地说明了`kthread_run()`的参数和返回值。
- en: 'To demonstrate how to create and use a kernel thread, we will write a kernel
    module called `kthread_simple`. The following is the relevant code of its `init`
    method:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示如何创建和使用内核线程，我们将编写一个名为`kthread_simple`的内核模块。以下是其`init`方法的相关代码：
- en: '[PRE29]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: The first parameter to `kthread_run()` is the new kthread's lifeblood – its
    function! Here, we don't intend to pass any data to our newborn kthread, which
    is why the second parameter is `NULL`. The remaining parameters are the printf-style
    format string specifying its name. Once successful, it returns the pointer to
    the new kthread's task structure (we covered the task structures in some detail
    in the companion guide *Linux Kernel Programming -* *Chapter 6*, *Kernel Internals
    Essentials – Processes and Threads*, in the *Understanding and accessing the kernel
    task structure* section). Now, the `get_task_struct()` inline function is important
    – it increments the reference count of the task structure passed to it. This marks
    the task as being in use (later, in the cleanup code, we will issue the `kthread_stop()`
    helper routine; it will perform the converse operation, thus decrementing (and
    ultimately freeing up) the task structure's reference count).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`kthread_run()`的第一个参数是新的内核线程的核心功能！在这里，我们不打算向我们的新生内核线程传递任何数据，这就是为什么第二个参数是`NULL`。其余参数是printf风格的格式字符串，指定了它的名称。一旦成功，它将返回指向新内核线程任务结构的指针（我们在伴随指南*Linux内核编程*-*第6章*-*内核内部要点-进程和线程*-*了解和访问内核任务结构*部分中详细介绍了任务结构）。现在，`get_task_struct()`内联函数很重要-它增加了传递给它的任务结构的引用计数。这标记着任务正在使用中（稍后，在清理代码中，我们将发出`kthread_stop()`辅助例程；它将执行相反的操作，从而减少（最终释放）任务结构的引用计数）。'
- en: 'Now, let''s look at our kernel thread itself (we''ll only show the relevant
    code snippets):'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们的内核线程本身（我们只会显示相关的代码片段）：
- en: '[PRE30]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'The moment `kthread_run()` succeeds in creating the kernel thread, it will
    begin running its code in parallel with the rest of the system: it''s now a schedulable
    thread! Our `PRINT_CTX()` macro reveals that it runs in process context and is
    indeed a kernel thread. (We have mimicked the tradition of enclosing its name
    in square brackets to show just this. The check to verify that the current `mm`
    pointer is `NULL` confirms the same.) You can see the output in *Figure 5.5*.
    All the code in your kernel thread routine is going to be running in the *process
    context*; hence, you can perform blocking operations (unlike with interrupt context).'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`kthread_run()`成功创建内核线程，它将开始与系统的其余部分并行运行其代码：现在它是可调度的线程！我们的`PRINT_CTX()`宏显示它在进程上下文中运行，确实是一个内核线程。（我们模仿了将其名称括在方括号中的传统，以显示这一点。验证当前`mm`指针是否为`NULL`的检查证实了这一点。）您可以在*图5.5*中看到输出。您内核线程例程中的所有代码都将在*进程上下文*中运行；因此，您可以执行阻塞操作（与中断上下文不同）。
- en: 'Next, by default, the kernel thread runs with root ownership and all signals
    are masked. However, as a simple test case, we can turn on a couple of signals
    via the `allow_signal()` helper routine. After that, we simply loop (we''ll get
    to the `kthread_should_stop()` routine shortly); in the loop body, we put ourselves
    to sleep by setting our task''s state to `TASK_INTERRUPTIBLE` (implying that the
    sleep can be interrupted by signals) and invoking `schedule()`:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，默认情况下，内核线程以root所有权运行，并且所有信号都被屏蔽。但是，作为一个简单的测试案例，我们可以通过`allow_signal()`辅助例程打开一些信号。之后，我们简单地循环（我们很快会到`kthread_should_stop()`例程）；在循环体中，我们通过将任务状态设置为`TASK_INTERRUPTIBLE`（意味着睡眠可以被信号中断）并调用`schedule()`来让自己进入睡眠状态：
- en: '[PRE31]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Thus, only when we''re awoken– which will happen when you send the kernel thread
    either the `SIGINT` or `SIGQUIT` signal – will we resume execution. When this
    occurs, we break out of the loop (notice how we first verify that this is indeed
    the case with the `signal_pending()` helper routine!). Now, our kthread resumes
    execution outside the loop, only to (deliberately, and quite dramatically) die:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，只有当我们被唤醒时-当您向内核线程发送`SIGINT`或`SIGQUIT`信号时会发生这种情况-我们才会恢复执行。当这发生时，我们跳出循环（请注意我们首先使用`signal_pending()`辅助例程验证了这一点！）。现在，我们的内核线程在循环外恢复执行，只是（故意而戏剧性地）死亡：
- en: '[PRE32]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The cleanup code of the kernel module is as follows:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 内核模块的清理代码如下：
- en: '[PRE33]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, within the cleanup code path, you're expected to call `kthread_stop()`,
    which performs the necessary cleanup. Internally, it actually waits for the kthread
    to die (via the `wait_for_completion()` routine). So, if you call the `rmmod`
    without having killed the kthread by sending it the `SIGINT` or `SIGQUIT` signal,
    the `rmmod` process will appear to hang here; it's (the `rmmod` process, that
    is) waiting (well, `kthread_stop()` is really the one waiting) for the kthread
    to die! This is why, if the kthread hasn't been signaled yet, this could cause
    a problem.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在清理代码路径中，你应该调用`kthread_stop()`，它执行必要的清理。在内部，它实际上等待内核线程死亡（通过`wait_for_completion()`例程）。因此，如果你在没有通过发送`SIGINT`或`SIGQUIT`信号杀死内核线程的情况下调用`rmmod`，`rmmod`进程将似乎挂起；它（也就是`rmmod`进程）正在等待（嗯，`kthread_stop()`实际上是在等待）内核线程死亡！这就是为什么，如果内核线程还没有被发送信号，这可能会导致问题。
- en: 'There should be a better way to deal with stopping a kernel thread than sending
    it signals from user space. Indeed there is: the correct way is to employ the
    `kthread_should_stop()` routine as the (inverse) condition of the `while` loop
    it runs, so this is exactly what we''ll do! In the preceding code, we have the
    following:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 处理内核线程停止的更好方法应该不是从用户空间发送信号给它。确实有一个更好的方法：正确的方法是使用`kthread_should_stop()`例程作为它运行的`while`循环的（反向）条件，这正是我们要做的！在前面的代码中，我们有以下内容：
- en: '[PRE34]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The `kthread_should_stop()` routine returns a Boolean value that's true if the
    kthread should stop (terminate) now! Calling `kthread_stop()` in the cleanup code
    path will cause `kthread_should_stop()` to return true, thus causing our kthread
    to break out of the `while` loop and terminate via a simple `return 0;`. This
    value (`0`) is passed back to `kthread_stop()`. Due to this, the kernel module
    is successfully unloaded, *even if no signal is ever sent to our kernel thread*.
    We will leave testing this case as a simple exercise for you!
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '`kthread_should_stop()`例程返回一个布尔值，如果内核线程现在应该停止（终止）则为真！在清理代码路径中调用`kthread_stop()`将导致`kthread_should_stop()`返回true，从而导致我们的内核线程跳出`while`循环并通过简单的`return
    0;`终止。这个值（`0`）被传回`kthread_stop()`。由于这个原因，即使没有向我们的内核线程发送信号，内核模块也能成功卸载。我们将把测试这种情况留给你作为一个简单的练习！'
- en: 'Note that the return value of `kthread_stop()` can be useful: it''s an integer
    and the result of the thread function that ran – in effect, it states whether
    your kthread succeeded (`0` returned) in its work or not. It will be the value `-EINTR`
    if your kthread was never woken up.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`kthread_stop()`的返回值可能会有用：它是一个整数，是运行的线程函数的结果 - 实际上，它说明了你的内核线程是否成功（返回`0`）完成了它的工作。如果你的内核线程从未被唤醒，它将是值`-EINTR`。
- en: Running the kthread_simple kernel thread demo
  id: totrans-248
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行kthread_simple内核线程演示
- en: 'Now, let''s try it out (`ch5/kthread_simple`)! We can perform module insertion
    via `insmod(8)`; the module gets inserted into the kernel as planned. The kernel
    log shown in the following screenshot, as well as a quick `ps`, proves that our
    brand new kernel thread has indeed been created. Also, as you can see from the
    code (`ch5/kthread_simple/kthread_simple.c`), our kthread puts itself to sleep
    (by setting its state to `TASK_INTERRUPTIBLE` and then calling `schedule()`):'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们试一下（`ch5/kthread_simple`）！我们可以通过`insmod(8)`进行模块插入；模块按计划插入到内核中。如下截图所示的内核日志，以及快速的`ps`，证明我们全新的内核线程确实已经被创建。另外，正如你从代码（`ch5/kthread_simple/kthread_simple.c`）中看到的，我们的内核线程将自己置于睡眠状态（通过将其状态设置为`TASK_INTERRUPTIBLE`，然后调用`schedule()`）：
- en: '![](img/9c126689-076e-44b5-9a88-b20b3004f4d4.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/9c126689-076e-44b5-9a88-b20b3004f4d4.png)
- en: Figure 5.5 – A partial screenshot showing that our kernel thread is born, alive
    – and, well, asleep
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 - 部分截图显示我们的内核线程诞生、活着 - 还有，嗯，睡着了
- en: 'Quickly running `ps(1) grep` for our kernel thread by name shows that our kthread
    is alive and well (and asleep):'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 通过名称快速运行`ps(1) grep`来查找我们的内核线程，可以看到我们的内核线程是活着的（而且睡着的）。
- en: '[PRE35]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let''s shake things up a bit and send the `SIGQUIT` signal to our kthread.
    This has it wake up (since we''ve set its signal mask to allow the `SIGINT` and
    `SIGQUIT` signals), set its state to `TASK_RUNNING`, and then, well, simply exit.
    We then use `rmmod(8)` to remove the kernel module, as shown in the following
    screenshot:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来点新意，给我们的内核线程发送`SIGQUIT`信号。这将唤醒它（因为我们已经设置了它的信号掩码以允许`SIGINT`和`SIGQUIT`信号），将其状态设置为`TASK_RUNNING`，然后，简单地退出。然后我们使用`rmmod(8)`来移除内核模块，如下截图所示：
- en: '![](img/c3f089f4-57d3-4048-a739-8fe84c1e7292.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: ！[](img/c3f089f4-57d3-4048-a739-8fe84c1e7292.png)
- en: Figure 5.6 – A partial screenshot showing our kernel thread waking up and the
    module successfully unloaded
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 - 部分截图显示我们的内核线程唤醒和模块成功卸载
- en: Now that you have understood how to create and work with kernel threads, let's
    move on and design and implement the second version of our `sed` driver.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了如何创建和使用内核线程，让我们继续设计和实现我们的`sed`驱动程序的第二个版本。
- en: The sed2 driver – design and implementation
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: sed2驱动程序 - 设计与实现
- en: In this section (as mentioned in the *The "sed" drivers – to demo kernel timers, kthreads,
    and workqueues* section), we will write the next evolution of the `sed1`driver,
    called `sed2`.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分（如在*“sed”驱动程序 - 演示内核定时器、内核线程和工作队列*部分中提到的），我们将编写`sed1`驱动程序的下一个演变，称为`sed2`。
- en: sed2 – the design
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: sed2 - 设计
- en: 'Our `sed` v2 (`sed2`*;* code: `ch5/sed2/`) mini-project is very similar to
    our `sed1` project. The key difference is that this time, we''ll carry out the
    "work" via a kernel thread created by the driver for just this purpose. The key
    differences between this version and the previous one are as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`sed` v2（`sed2`*;*代码：`ch5/sed2/`）小项目与我们的`sed1`项目非常相似。关键区别在于，这一次，我们将通过驱动程序专门为此目的创建的内核线程来进行“工作”。这个版本与上一个版本的主要区别如下：
- en: There's just one global shared memory buffer for holding the metadata, along
    with the payload; that is, the message to encrypt/decrypt. This is the `struct
    sed_ds->shmem` member within our driver context structure, `struct stMyCtx`.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个全局共享的内存缓冲区用于保存元数据和有效载荷；也就是说，要加密/解密的消息。这是我们驱动程序上下文结构`struct stMyCtx`中的`struct
    sed_ds->shmem`成员。
- en: The work of encryption/decryption is now performed within a kernel thread (that
    this driver spawns); we keep the kernel thread asleep. Only when work arises does
    the driver wake up the kthread and have it consume (execute) the work.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密/解密的工作现在在内核线程（由此驱动程序生成）中执行；我们让内核线程保持休眠。只有在出现工作时，驱动程序才会唤醒kthread并让其消耗（执行）工作。
- en: We now run the kernel timer within the kthread's context and show if it expires
    prematurely (indicating that the deadline wasn't met).
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在我们在kthread的上下文中运行内核定时器，并显示它是否过早到期（表明未满足截止日期）。
- en: A quick test reveals that eliminating the several `pr_debug()` printks within
    the kernel thread's critical section goes a long way toward reducing the time
    taken to complete the work! (You can always change the Makefile's `EXTRA_CFLAGS`
    variable to undefine the `DEBUG` symbol if you wish to eliminate this overhead (by
    using `EXTRA_CFLAGS += -UDEBUG`)!). Hence, here, the deadline is longer (10 ms).
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速测试表明，在内核线程的关键部分消除了几个`pr_debug()` printks可以大大减少完成工作所需的时间！（如果您希望消除此开销，可以随时更改Makefile的`EXTRA_CFLAGS`变量以取消定义`DEBUG`符号（通过使用`EXTRA_CFLAGS
    += -UDEBUG`）！）。因此，在这里，截止日期更长（10毫秒）。
- en: 'So, in a nutshell, the whole idea here is to primarily demonstrate using a
    custom kernel thread, along with a kernel timer, to timeout an operation. A key
    point to understand that changes the overall design (especially the way that the
    user space app interacts with our `sed2` driver) is that since we''re running
    the work in the context of a kernel thread, it''s not the same context as that
    of the process that `ioctl()` is issued to. Due to this, it''s very important
    to realize the following things:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，简而言之，这里的整个想法主要是演示使用自定义内核线程以及内核定时器来超时操作。一个重要的理解点改变了整体设计（特别是用户空间应用程序与我们的`sed2`驱动程序交互的方式），即由于我们在内核线程的上下文中运行工作，这与发出`ioctl()`的进程的上下文不同。因此，非常重要的是要意识到以下几点：
- en: 'You cannot simply transfer data from the kernel thread''s process context to
    the user space process – they''re completely different (they run in different
    virtual address spaces: the user mode process has its own complete VAS and PID,
    and so on; the kernel thread literally lives within the kernel VAS with its own
    PID and kernel mode stack). Due to this, using the `copy_{from|to}_user()` (and
    similar) routine is out of question for communicating from the kthread to the
    user mode app.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不能简单地将数据从内核线程的进程上下文传输到用户空间进程 - 它们完全不同（它们在不同的虚拟地址空间中运行：用户模式进程有自己完整的VAS和PID等；内核线程实际上生活在内核VAS中，有自己的PID和内核模式堆栈）。因此，使用`copy_{from|to}_user()`（以及类似的）例程来从kthread通信到用户模式应用程序是不可能的。
- en: The potential for dangerous *races *is significant; the kernel thread runs asynchronously
    with respect to the user process context; thus, we can end up creating concurrency-related
    bugs if we're not careful. This is the entire reason for the last two chapters
    of this book, where we'll cover kernel synchronization, locking (and related)
    concepts, and technologies. For now, bear with us – we keep things as simple as
    possible by using some simple polling tricks in place of proper synchronization.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 危险的*竞争*可能性很大；内核线程与用户进程上下文异步运行；因此，如果我们不小心，就可能产生与并发相关的错误。这就是本书最后两章的整个原因，我们将在其中涵盖内核同步、锁定（以及相关）概念和技术。目前，请耐心等待
    - 我们通过使用一些简单的轮询技巧来代替适当的同步，尽量保持简单。
- en: 'We have four operations inside our `sed2` project:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`sed2`项目内有四个操作：
- en: '**Encrypt** the message (this also gets the message from user space into the
    driver; thus, this has to be done first).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**加密**消息（这也将消息从用户空间传输到驱动程序；因此，这必须首先完成）。'
- en: '**Decrypt**the message.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解密**消息。'
- en: '**Retrieve **the message (sent from the driver to the user space app).'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**检索**消息（从驱动程序发送到用户空间应用程序）。'
- en: '**Destroy**the message (in effect, it''s reset – the memory and metadata are
    wiped clean within the driver).'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**销毁**消息（实际上，它被重置 - 驱动程序内的内存和元数据被清除）。'
- en: 'It''s important to realize that due to the potential for races, we *cannot
    simply *transfer data directly from the kthread to the user space app. Due to
    this, we must do the following:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要意识到，由于存在竞争的可能性，我们*不能简单地*直接从kthread传输数据到用户空间应用程序。因此，我们必须执行以下操作：
- en: We must carry out the retrieve and destroy operations in the process context
    of the user space process by issuing the `ioctl()` system calls.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们必须通过发出`ioctl()`系统调用在用户空间进程的进程上下文中执行检索和销毁操作。
- en: We must carry out the encrypt and decrypt operations in the process context
    of our kernel thread, asynchronously with respect to the user space app (we run
    it within a kernel thread, not because we *have to *but because we want to; this
    is, after all, the point of this topic!).
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们必须在我们的内核线程的进程上下文中异步执行加密和解密操作（我们在内核线程中运行它，不是因为我们*必须*，而是因为我们想要；毕竟，这是这个主题的重点！）。
- en: 'This design can be summarized by a simple ASCII-art diagram:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 这个设计可以用一个简单的ASCII艺术图来总结：
- en: '![](img/f2d0e4db-7478-467d-b76a-16fcd637e48b.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2d0e4db-7478-467d-b76a-16fcd637e48b.png)'
- en: Figure 5.7 – The high-level design of our sed2 mini-project
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 - 我们的sed2迷你项目的高级设计
- en: Right, let's now check out the relevant code implementation for `sed2`.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，现在让我们来查看`sed2`的相关代码实现。
- en: sed2 driver – code implementation
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: sed2驱动程序 - 代码实现
- en: 'In terms of code, the `ioctl()` method''s code within the `sed2`driver for
    the encrypt operation is as follows (for clarity, we won''t show all the error
    checking code here; we will show only the most relevant parts). You can find the
    full code at `ch5/sed2/`:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码方面，`sed2`驱动程序中用于加密操作的`ioctl()`方法的代码如下（为了清晰起见，我们不会在这里显示所有的错误检查代码；我们只会显示最相关的部分）。您可以在`ch5/sed2/`找到完整的代码：
- en: '[PRE36]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The driver, after performing several validity checks in its `ioctl()` method,
    gets down to work: for the encryption operation, we check if the current payload
    is already encrypted (obviously, we have a state member within our context structure
    that is updated to hold this information; that is, `priv->msg_state`). If everything
    is fine, it copies in the message (along with the required metadata in `struct
    sed_ds`) from the user space app. Then, it *wakes up our kernel thread*(via the
    `wake_up_process()` API; the parameter is the pointer to its task structure, which
    is the return value from the `kthread_create()` API). This causes the kernel thread
    to resume execution!'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动程序在其`ioctl()`方法中执行了几个有效性检查后，开始工作：对于加密操作，我们检查当前有效载荷是否已经加密（显然，我们在上下文结构中有一个状态成员，用于更新并保存这些信息；即`priv->msg_state`）。如果一切正常，它会从用户空间应用程序中复制消息（以及`struct
    sed_ds`中所需的元数据）。然后，它*唤醒我们的内核线程*（通过`wake_up_process()` API；参数是从`kthread_create()`
    API返回的任务结构指针）。这会导致内核线程恢复执行！
- en: In the `init` code, we created the kthread with the `kthread_create()` API (and
    not the `kthread_run()` macro) as we do *not* want the kthread to run immediately!
    Instead, we prefer to keep it asleep, only awakening it when work is required
    of it. This is the typical approach we should follow when employing a worker thread
    (the so-called manager-worker model).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在`init`代码中，我们使用`kthread_create()` API（而不是`kthread_run()`宏）创建了kthread，因为我们*不*希望kthread立即运行！相反，我们更喜欢让它保持睡眠状态，只有在需要工作时才唤醒它。这是我们在使用工作线程时应该遵循的典型方法（所谓的管理者-工作者模型）。
- en: 'The following code within our `init` method creates the kernel thread:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`init`方法中创建内核线程的代码如下：
- en: '[PRE37]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'After this, the timer is initialized (via the `timer_setup()` API). The (truncated)
    code of our worker thread looks as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，通过`timer_setup()` API初始化了定时器。我们的工作线程的（截断的）代码如下所示：
- en: '[PRE38]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Here, you can see the timer being started (`mod_timer()`), the actual encrypt/decrypt
    functions being invoked as required, the timestamps being captured, and then the
    kernel timer being canceled. This is what happened in `sed1`except that, this
    time (`sed2`), the work happens in the context of our kernel thread! The kernel
    thread function then makes itself go to sleep while yielding the processor by
    (as was covered in the companion guide *Linux Kernel Programming -* *Chapter 10*,
    *The CPU Scheduler – Part 1*, and *Chapter 11*, *The CPU Scheduler – Part 2*)
    setting the task state to a sleep state (`TASK_INTERRUPTIBLE`) and invoking `schedule()`.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到定时器被启动（`mod_timer()`），根据需要调用实际的加密/解密功能，捕获时间戳，然后取消内核定时器。这就是`sed1`中发生的事情，只是这次（`sed2`）工作发生在我们的内核线程的上下文中！内核线程函数然后使自己进入睡眠状态，通过（正如在配套指南*Linux内核编程
    - 第10章，CPU调度器 - 第1部分和第11章，CPU调度器 - 第2部分中所介绍的）将任务状态设置为睡眠状态（`TASK_INTERRUPTIBLE`）并调用`schedule()`来让出处理器。
- en: 'Hang on a minute – within the `ioctl()` method, did you notice the call to
    the `POLL_ON_WORK_DONE(1);` macro just before the kernel thread was woken up?
    Take a look at the following code:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 等一下 - 在`ioctl()`方法中，您是否注意到在唤醒内核线程之前调用了`POLL_ON_WORK_DONE(1);`宏？看一下以下代码：
- en: '[PRE39]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The poll is used to circumvent a possible race: what if one (user mode) thread
    invokes `ioctl()` to, say, encrypt a given message, and simultaneously on another
    CPU core, another user mode thread invokes `ioctl()` to, say, decrypt a given
    message? This will cause concurrency issues! Again, the last two chapters of this
    book are devoted to understanding and handling these; but here and now, what can
    we do? Let''s implement a poor man''s synchronization solution: *polling*.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 使用轮询来规避可能的竞争：如果一个（用户模式）线程调用`ioctl()`来加密给定的消息，同时在另一个CPU核心上，另一个用户模式线程调用`ioctl()`来解密给定的消息会发生什么？这将导致并发问题！再次强调，本书的最后两章致力于理解和处理这些问题；但在这里和现在，我们能做什么？让我们实现一个简陋的同步解决方案：*轮询*。
- en: 'This is not ideal but will have to do. We''ll make use of the fact that the
    driver sets an atomic variable in the driver''s context structure, named `work_done`,
    to `1` when the work is done; its value is `0` otherwise. We poll for this within
    this macro:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不理想，但只能这样做。我们将利用驱动程序在驱动程序上下文结构中设置的一个名为`work_done`的原子变量，当工作完成时，其值为`1`；否则为`0`。我们在这个宏中进行轮询：
- en: '[PRE40]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: To keep this code somewhat palatable, we aren't hogging the processor; if the
    work isn't done (yet), we sleep for a millisecond (via the `msleep_interruptible()`
    API) and try again.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这段代码看起来更加可接受，我们不会独占处理器；如果工作还没有完成，我们会通过`msleep_interruptible()` API睡眠一毫秒，并再次尝试。
- en: 'So far, we''ve covered the relevant code for the encrypt and decrypt functionality
    of `sed2` (both of which run in our worker kthread''s context). Now, let''s look
    at the remaining two pieces of functionality – retrieving and destroying messages.
    These are carried out in the original user space process context – the process
    (or thread) that issues the `ioctl()` system calls. Here''s the relevant code
    for them:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经涵盖了`sed2`的`encrypt`和`decrypt`功能的相关代码（这两个功能都在我们的工作线程的上下文中运行）。现在，让我们看看剩下的两个功能
    - 检索和销毁消息。这些功能是在原始用户空间进程上下文中执行的 - 发出`ioctl()`系统调用的进程（或线程）。以下是它们的相关代码：
- en: '[PRE41]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Now that you've seen the (relevant) `sed2` code, let's try it out!
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经看到了（相关的）`sed2`代码，让我们来尝试一下吧！
- en: sed2 – trying it out
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: sed2 - 尝试它
- en: 'Let''s take a look at a sample run of our `sed2` mini project over a couple
    of screenshots; ensure that you look at them carefully:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们的`sed2`迷你项目的一个示例运行，确保您仔细查看它们：
- en: '![](img/a00d3a39-6d42-400c-aa33-930747f6a037.png)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a00d3a39-6d42-400c-aa33-930747f6a037.png)'
- en: Figure 5.8 – Our sed2 mini-project showing off an interactive menu system. Here,
    a message has been successfully encrypted
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 - 我们的sed2迷你项目展示了一个交互式菜单系统。在这里，一条消息已成功加密
- en: 'So, we have encrypted a message, but how do we view it? Simple: we use the
    menu! Select option `2` to retrieve the (encrypted) message (it will be displayed
    for your leisurely perusal), option `3` to decrypt it, option `2` once more to
    view it, and option `5` to see the kernel log – quite useful! Some of these options
    are shown in the following screenshot:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们已经加密了一条消息，但我们如何查看它呢？简单：我们使用菜单！选择选项`2`来检索（加密的）消息（它将显示供您悠闲阅读），选项`3`来解密它，再次选择选项`2`来查看它，选项`5`来查看内核日志-非常有用！以下截图显示了其中一些选项：
- en: '![](img/35866e17-68c1-4168-abb3-8c5e3c2d856c.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![](img/35866e17-68c1-4168-abb3-8c5e3c2d856c.png)'
- en: Figure 5.9 – Our sed2 mini-project showing off an interactive menu system. Here,
    a message has been successfully encrypted
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9-我们的sed2迷你项目展示了一个交互式菜单系统。在这里，一条消息已经成功加密
- en: 'As shown in the kernel log, our user mode app (`userapp_sed2_dbg_asan`) has
    opened the device and issued the retrieve operation, followed by the encrypt operation
    a few seconds later (the timestamps in the bottom-left corner of the preceding
    screenshot help you figure this out). Then, the driver wakes up the kernel thread;
    you can see its printk output, as well as the output of `PRINT_CTX()`, here:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 正如内核日志中所示，我们的用户模式应用程序（`userapp_sed2_dbg_asan`）已经打开了设备并发出了检索操作，然后几秒钟后进行了加密操作（前面截图左下角的时间戳可以帮助你弄清楚这一点）。然后，驱动程序唤醒了内核线程；你可以看到它的printk输出，以及`PRINT_CTX()`的输出，如下所示：
- en: '[PRE42]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The encrypt operation then completes (successfully and within the deadline;
    the timer is canceled):'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，加密操作完成（成功并在截止日期内；定时器被取消）：
- en: '[PRE43]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Similarly, other operations are carried out. We shall refrain from showing the
    user space app's code here since it's a simple user mode "C" program. This time
    (unusually), it's an interactive app with a simple menu (as shown in the screenshots);
    do check it out. I'll leave it to you to read and understand the `sed2`code in
    detail and try it out for yourself.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，其他操作也在进行中。我们将在这里避免显示用户空间应用程序的代码，因为它是一个简单的用户模式“C”程序。这次（不寻常的是），它是一个带有简单菜单的交互式应用程序（如屏幕截图所示）；请查看一下。我将让你自己详细阅读和理解`sed2`代码，并尝试自己使用它。
- en: Querying and setting the scheduling policy/priority of a kernel thread
  id: totrans-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查询和设置内核线程的调度策略/优先级
- en: In closing, how can you query and/or change the scheduling policy and (real-time)
    priority of a kernel thread? The kernel provides APIs for this (the `sched_setscheduler_nocheck()`
    API is often used within the kernel). As a practical example, the kernel will
    require kernel threads for the purpose of servicing interrupts – the *threaded
    interrupt *model, which we covered in [Chapter 4](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml),
    *Handling Hardware Interrupts, *in the *Internally implementing the threaded interrupt*
    section).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你如何查询和/或更改内核线程的调度策略和（实时）优先级呢？内核为此提供了API（`sched_setscheduler_nocheck()`API经常在内核中使用）。作为一个实际的例子，内核将需要内核线程来处理中断-我们在[第4章](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml)中介绍的*线程化中断*模型，在*内部实现线程化中断*部分中已经涵盖了。
- en: 'It creates these threads (via `kthread_create()`) and changes their scheduling
    policy and real-time priority via the `sched_setscheduler_nocheck()` API. We won''t
    explicitly cover their usage here as we covered this in the companion guide *Linux
    Kernel Programming -* *Chapter 11*, *The CPU Scheduler – Part 2*. It''s interesting:
    the `sched_setscheduler_nocheck()` API is just a simple wrapper over the underlying `_sched_setscheduler()`
    routine. Why? The `_sched_setscheduler()` API isn''t exported at all and is thus
    unavailable to module authors; the `sched_setscheduler_nocheck()` wrapper is exported
    via the `EXPORT_SYMBOL_GPL()` macro (implying that only GPL licensed code can
    actually make use of it!).'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 它通过`kthread_create()`创建这些线程，并通过`sched_setscheduler_nocheck()`API更改它们的调度策略和实时优先级。我们不会在这里明确介绍它们的用法，因为我们在配套指南*Linux内核编程*的*第11章*“CPU调度器-第2部分”中已经介绍过了。有趣的是：`sched_setscheduler_nocheck()`API只是对底层`_sched_setscheduler()`例程的简单包装。为什么呢？`_sched_setscheduler()`API根本没有被导出，因此模块作者无法使用它；`sched_setscheduler_nocheck()`包装器是通过`EXPORT_SYMBOL_GPL()`宏导出的（这意味着只有GPL许可的代码才能使用它！）。
- en: What about querying and/or changing the scheduling policy and (real-time) priority
    of **user space threads**? The Pthreads library provides wrapper APIs to do just
    this; the `pthread_[get|set]schedparam(3)` pair can be used here since they're
    wrappers around system calls such as `sched_[get|set]scheduler(2)` and `sched_[get|set]attr(2)`.
    They require root access and, for security purposes, have the `CAP_SYS_NICE` capability
    bit set in the binary executable file.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，如何查询和/或更改**用户空间线程**的调度策略和（实时）优先级呢？Pthreads库提供了包装API来做到这一点；`pthread_[get|set]schedparam(3)`对可以在这里使用，因为它们是对`sched_[get|set]scheduler(2)`和`sched_[get|set]attr(2)`等系统调用的包装。它们需要root访问权限，并且出于安全目的，在二进制可执行文件中设置了`CAP_SYS_NICE`能力位。
- en: 'Though this book only covers kernel programming, I''ve mentioned this here
    as it''s a really powerful thing: in effect, the user space app designer/developer
    has the ability to create and deploy application threads perfectly suited to their
    purpose: real-time threads at differing scheduling policies, real-time priorities
    between 1 and 99, non-RT threads (with the base nice value of `0`), and so on. Indiscriminately
    creating kernel threads is frowned upon, and the reason is clear – every additional
    kernel thread adds overhead, both in terms of memory and CPU cycles. When you''re
    in the design phase, pause and think: do you really require one or more kernel
    threads? Or is there a better way of doing things? Workqueues are often exactly
    that – a better way!'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书只涵盖内核编程，但我在这里提到它，因为这是一个非常强大的东西：实际上，用户空间应用程序的设计者/开发者有能力创建和部署完全适合其目的的应用程序线程：具有不同调度策略的实时线程，实时优先级在1到99之间，非实时线程（基本nice值为`0`），等等。不加区别地创建内核线程是不被赞成的，原因很明显-每个额外的内核线程都会增加开销，无论是内存还是CPU周期。当你处于设计阶段时，请暂停一下并思考：你真的需要一个或多个内核线程吗？还是有更好的方法来做这些事情？工作队列通常就是这样-更好的方法！
- en: Now, let's look at workqueues!
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看看工作队列！
- en: Using kernel workqueues
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内核工作队列
- en: 'A **workqueue** is an abstraction layer over the creation and management of
    kernel worker threads. They help solve a crucial problem: directly working with
    kernel threads, especially when several are involved, is not only difficult but
    can quite easily result in dangerous bugs such as races (and thus the potential
    for deadlock), as well as poor thread management, resulting in efficiency losses.
    Workqueues are *bottom-half *mechanisms that are employed within the Linux kernel
    (along with tasklets and softirqs).'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '**工作队列**是在创建和管理内核工作线程方面的一个抽象层。它们有助于解决一个关键问题：直接与内核线程一起工作，特别是当涉及到多个线程时，不仅困难，而且很容易导致危险的错误，如竞争（从而可能导致死锁），以及线程管理不善，导致效率损失。工作队列是在Linux内核中使用的*底半部*机制（连同tasklets和softirqs）。'
- en: The modern workqueue implementation in the Linux kernel – called the **concurrency
    managed work queue** (**cmwq**) – is really a pretty elaborate framework, with
    various strategies for dynamically and efficiently provisioning kernel threads
    based on specific requirements.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核中的现代工作队列实现 - 称为**并发管理工作队列**（**cmwq**）- 实际上是一个非常复杂的框架，具有根据特定要求动态和高效地提供内核线程的各种策略。
- en: In this book, we prefer to focus on the *usage *of the kernel-global workqueue
    rather than its internal design and implementation. If you'd like to learn more
    about the internals, I recommend that you read the "official" kernel documentation
    here: [https://www.kernel.org/doc/Documentation/core-api/workqueue.rst](https://www.kernel.org/doc/Documentation/core-api/workqueue.rst).
    The *Further reading *section also contains some useful resources.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们更喜欢专注于内核全局工作队列的使用，而不是其内部设计和实现。如果您想了解更多关于内部工作的信息，我建议您阅读这里的“官方”内核文档：[https://www.kernel.org/doc/Documentation/core-api/workqueue.rst](https://www.kernel.org/doc/Documentation/core-api/workqueue.rst)。*进一步阅读*部分还包含一些有用的资源。
- en: 'The key characteristics of the workqueue are as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 工作队列的关键特征如下：
- en: The workqueue task(s) (callbacks) always execute in a preemptible process context.
    This is obvious once you realize that they are executed by kernel (worker) threads,
    which run in a preemptible process context.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作队列任务（回调）始终在可抢占的进程上下文中执行。一旦你意识到它们是由内核（工作）线程执行的，这一点就很明显，这些线程在可抢占的进程上下文中运行。
- en: By default, all interrupts are enabled and no locks are taken.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，所有中断都是启用的，不会采取任何锁。
- en: The aforementioned points imply that you can do lengthy, blocking, I/O-bound
    work within your workqueue function(s) (this is diametrically opposite to an atomic
    context such as a hardirq, tasklet, or softirq!).
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上述观点意味着你可以在你的工作队列函数中进行漫长的、阻塞的、I/O密集型的工作（这与原子上下文（如硬中断、tasklet或softirq）完全相反！）。
- en: Just as you learned about kernel threads, transferring data to and from user
    space (via the typical `copy_[to|from]_user()` and similar routines) is *not *possible;
    this is because your workqueue handler (function) executes within its own process
    context – that of a kernel thread. As we know, kernel threads have no user mapping.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就像你了解内核线程一样，通过典型的`copy_[to|from]_user()`和类似的例程传输数据到用户空间（*不*可能）；这是因为你的工作队列处理程序（函数）在其自己的进程上下文中执行
    - 即内核线程的上下文。正如我们所知，内核线程没有用户映射。
- en: 'The kernel workqueue framework maintains worker pools. These are literally
    several kernel worker threads organized in differing ways according to their needs.
    The kernel handles all the complexity of managing them, as well as concurrency
    concerns. The following screenshot shows several workqueue kernel worker threads
    (this was taken on my x86_64 Ubuntu 20.04 guest VM):'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核工作队列框架维护工作池。这些工作池实际上是以不同方式组织的几个内核工作线程。内核处理所有管理它们以及并发性问题的复杂性。以下截图显示了几个工作队列内核工作线程（这是在我的x86_64
    Ubuntu 20.04虚拟机上拍摄的）：
- en: '![](img/3c46ac29-5b59-49ec-bb67-8209b7f52082.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3c46ac29-5b59-49ec-bb67-8209b7f52082.png)'
- en: Figure 5.10 – Several kernel threads serving the kernel workqueue's bottom-half
    mechanism
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.10 - 为内核工作队列的底半部机制提供服务的几个内核线程
- en: As we mentioned in the *Creating and working with kernel threads* section, one
    way to figure out the kthread's name and learn about the many practical uses of
    kthreads (and how to tune them to reduce jitter) is by reading the relevant kernel
    documentation; that is, *Reducing OS jitter due to per-cpu kthreads* ([https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt](https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt)).
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*创建和使用内核线程*部分中提到的，了解kthread的名称并了解kthreads的许多实际用途（以及如何调整它们以减少抖动）的一种方法是阅读相关的内核文档；也就是说，*减少由于每个CPU
    kthreads而导致的OS抖动*（[https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt](https://www.kernel.org/doc/Documentation/kernel-per-CPU-kthreads.txt)）。
- en: In terms of how to use workqueues (and the other bottom-half mechanisms), refer
    back to [*Chapter 4*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml), *Handling Hardware
    Interrupts*, the *Hardirqs, tasklets, and threaded handlers – what to use when*
    section,especially the table there.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 关于如何使用工作队列（以及其他底半部机制），请参阅[*第4章*](cfd1ca5d-cd0b-451d-8a35-31e65a09d2e4.xhtml)，*处理硬件中断*，*硬中断、tasklet和线程处理程序
    - 何时使用*部分，特别是那里的表格。
- en: It's important to understand that the kernel has an always-ready default workqueue
    available for use; it's known as the ***kernel-global workqueue*** or ***system
    workqueue***. To avoid stressing the system, it's highly recommended that you
    use it. We shall use the kernel-global workqueue, enque our work task(s) on it,
    and have it consume our work.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解内核始终有一个可用的默认工作队列；它被称为***内核全局工作队列***或***系统工作队列***。为了避免过度使用系统，强烈建议您使用它。我们将使用内核全局工作队列，将我们的工作任务排队，并让它消耗我们的工作。
- en: You can even use and create other kinds of workqueues! The kernel provides the
    elaborate *cmwq* framework, along with a set of APIs, to help you create specific
    types of workqueues. We'll look at this in more detail in the next section.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以使用和创建其他类型的工作队列！内核提供了复杂的*cmwq*框架，以及一组API，帮助您创建特定类型的工作队列。我们将在下一节中更详细地讨论这个问题。
- en: The bare minimum workqueue internals
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最低限度的工作队列内部
- en: We don't go into too much depth about the internals of the workqueue here; in
    fact, we will merely scratch the surface (as we mentioned previously, our purpose
    here is to only focus on using the kernel-global workqueue).
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里不会深入讨论工作队列的内部；实际上，我们只会浅尝辄止（正如我们之前提到的，我们在这里的目的只是专注于使用内核全局工作队列）。
- en: 'It''s always recommended that you use the default kernel-global (system) workqueue
    to consume your asynchronous background work. If this is deemed to be insufficient,
    don''t worry – certain interfaces are exposed that let you create your workqueues.
    (Keep in mind that doing so will increase stress on the system!) To allocate a
    new workqueue instance, you can use the `alloc_workqueue()` API; this is the primary
    API that''s used for creating (allocating) workqueues (via the modern *cmwq* framework):'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 始终建议您使用默认的内核全局（系统）工作队列来处理异步后台工作。如果认为这不够用，不用担心 - 有一些接口可以让您创建自己的工作队列。（请记住，这样做会增加系统的压力！）要分配一个新的工作队列实例，您可以使用`alloc_workqueue()`
    API；这是用于创建（分配）工作队列的主要API（通过现代*cmwq*框架）：
- en: '[PRE44]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Note that it''s exported via `EXPORT_SYMBOL_GPL()`, which means it''s only
    available to modules and drivers that use the GPL license. `fmt` (and the parameters
    following `max_active`) specifies how to name the workqueue threads in the pool.
    The `flags` parameter specifies a bitmask of special behavioral values or other
    characteristics, such as the following:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，它是通过`EXPORT_SYMBOL_GPL()`导出的，这意味着它只对使用GPL许可证的模块和驱动程序可用。`fmt`（以及`max_active`后面的参数）指定了如何命名池中的工作队列线程。`flags`参数指定了特殊行为值或其他特性的位掩码，例如以下内容：
- en: Use the `WQ_MEM_RECLAIM` flag when the workqueue needs forward progress guarantees
    under memory pressure.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当工作队列在内存压力下需要前进保证时，请使用`WQ_MEM_RECLAIM`标志。
- en: Use the `WQ_HIGHPRI` flag when work items are to be serviced by a worker pool
    of kthreads at an elevated priority level.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当工作项需要由一个优先级较高的kthreads工作池来服务时，请使用`WQ_HIGHPRI`标志。
- en: Use the `WQ_SYSFS` flag to make some of the workqueue details visible to user
    space via sysfs (practically, look under `/sys/devices/virtual/workqueue/`).
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`WQ_SYSFS`标志，使一些工作队列的细节通过sysfs对用户空间可见（实际上，在`/sys/devices/virtual/workqueue/`下查看）。
- en: Similarly, there are several other flags. Take a look at the official kernel
    documentation for more details ([https://www.kernel.org/doc/Documentation/core-api/workqueue.rst](https://www.kernel.org/doc/Documentation/core-api/workqueue.rst);
    it provides some interesting coverage on reducing "jitter" due to workqueue execution
    within the kernel).
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样，还有其他几个标志。查看官方内核文档以获取更多详细信息（[https://www.kernel.org/doc/Documentation/core-api/workqueue.rst](https://www.kernel.org/doc/Documentation/core-api/workqueue.rst)；它提供了一些有趣的内容，关于减少内核中工作队列执行的“抖动”）。
- en: The `max_active` parameter is used to specify the maximum number of kernel threads
    per CPU that can be assigned to a work item.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '`max_active`参数用于指定每个CPU可以分配给工作项的最大内核线程数。'
- en: 'Broadly speaking, there are two types of workqueues:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 大体上，有两种类型的工作队列：
- en: '**Single-threaded** (**ST**) **workqueues or ordered workqueues**: Here, only
    one thread can be active at any given point in time across the system. They can
    be created with `alloc_ordered_workqueue()` (it''s really just a wrapper over `alloc_workqueue()`
    specifying the ordered flags with `max_active` set to exactly `1`).'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单线程**（**ST**）**工作队列或有序工作队列**：在这里，系统中任何给定时间只能有一个线程处于活动状态。它们可以使用`alloc_ordered_workqueue()`来创建（实际上只是一个在`alloc_workqueue()`上指定有序标志和`max_active`设置为`1`的包装器）。'
- en: '**Multi-threaded** (**MT**) **workqueues**: This is the default option. The
    exact `flags` specify the behavior; `max_active` specifies the maximum number
    of worker kernel threads the work item can possibly have per CPU.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多线程**（**MT**）**工作队列**：这是默认选项。确切的`flags`指定了行为；`max_active`指定了每个CPU可能拥有的工作项的最大工作线程数。'
- en: 'All workqueues can be created via the `alloc_workqueue()` API. The code for
    creating them is as follows:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 所有的工作队列都可以通过`alloc_workqueue()` API来创建。创建它们的代码如下：
- en: '[PRE45]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: This happens early in the boot process (literally in the early init kernel code
    path). The first is highlighted in bold; this is the kernel-global workqueue or
    the system workqueue being created. Its worker pool is named `events`. (The name
    of the kernel threads that belong to this pool follow this naming convention and
    have the word `events` in their name; see *Figure 5.10* again. The same happens
    with kthreads belonging to other worker pools.)
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 这发生在引导过程的早期（确切地说是在早期的init内核代码路径中）。第一个被加粗了；这是正在创建的内核全局工作队列或系统工作队列。它的工作池被命名为`events`。（属于这个池的内核线程的名称遵循这个命名约定，并且在它们的名称中有`events`这个词；再次参见*图5.10*。其他工作池的kthreads也是如此。）
- en: 'The underlying framework has evolved a great deal; an earlier *legacy* workqueue
    framework (prior to 2010) used to use the `create_workqueue()` and friends APIs;
    however, these are now considered deprecated. The modern **concurrency managed
    workqueue** (**cmwq**) framework (around 2010 onward) is, interestingly, backward
    compatible with the old one. The following table summarizes the mapping of the
    older workqueue APIs to the modern cmwq ones:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 底层框架已经发展了很多；早期的*传统*工作队列框架（2010年之前）曾经使用`create_workqueue()`和相关API；然而，现在这些被认为是不推荐的。现代**并发管理工作队列**（**cmwq**）框架（2010年以后）有趣的是，它向后兼容旧的框架。以下表总结了旧的工作队列API与现代cmwq的映射：
- en: '| **Legacy (old and deprecated) workqueue API** | **Modern (cmwq) workqueue
    API** |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| **传统（旧的和不推荐的）工作队列API** | **现代（cmwq）工作队列API** |'
- en: '| `create_workqueue(name)` | `alloc_workqueue(name,WQ_MEM_RECLAIM, 1)` |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| `create_workqueue(name)` | `alloc_workqueue(name,WQ_MEM_RECLAIM, 1)` |'
- en: '| `create_singlethread_workqueue(name)` | `alloc_ordered_workqueue(name, WQ_MEM_RECLAIM)`
    |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| `create_singlethread_workqueue(name)` | `alloc_ordered_workqueue(name, WQ_MEM_RECLAIM)`
    |'
- en: '| `create_freezable_workqueue(name)` | `alloc_workqueue(name, WQ_FREEZABLE
    &#124; WQ_UNBOUND &#124; WQ_MEM_RECLAIM, 1)` |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| `create_freezable_workqueue(name)` | `alloc_workqueue(name, WQ_FREEZABLE
    &#124; WQ_UNBOUND &#124; WQ_MEM_RECLAIM, 1)` |'
- en: Table 5.3 – Mapping of the older workqueue APIs to the modern cmwq ones
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.3 - 旧的工作队列API与现代cmwq的映射
- en: 'The following diagram summarizes (in a simple, conceptual manner) the kernel 
    workqueue subsystem:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表以简单的概念方式总结了内核工作队列子系统：
- en: '![](img/6a2e40f7-3546-45d4-843f-520afe0c298b.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6a2e40f7-3546-45d4-843f-520afe0c298b.png)'
- en: Figure 5.11 – A simple conceptual view of the workqueue subsystem within the
    kernel
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.11 - 内核工作队列子系统的简单概念视图
- en: The kernel's workqueue framework dynamically maintains these worker pools (of
    kernel threads); some, such as the `events` workqueue (corresponding to the kernel-global
    workqueue) are general-purpose, while others are created and maintained for a
    specific purpose (in terms of the names given to their kernel threads, such as
    block I/O, `kworker*blockd`, memory control, `kworker*mm_percpu_wq`, device-specific
    ones such as tpm, `tpm_dev_wq`, CPU frequency governor drivers, `devfreq_wq`,
    and so on).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 内核的工作队列框架动态维护这些工作线程池；一些，如`events`工作队列（对应于全局内核工作队列）是通用的，而其他一些是为特定目的创建和维护的（就其内核线程的名称而言，如块I/O，`kworker*blockd`，内存控制，`kworker*mm_percpu_wq`，特定设备的，如tpm，`tpm_dev_wq`，CPU频率管理驱动程序，`devfreq_wq`等）。
- en: Note that the kernel workqueue subsystem maintains all these workqueues (and
    their associated worker pools of kernel threads) automatically, elegantly, and
    efficiently.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，内核工作队列子系统自动、优雅、高效地维护所有这些工作队列（及其相关的内核线程的工作线程池）。
- en: So, how do you actually make use of the workqueue? The next section will show
    you how to use the kernel-global workqueue. This will be followed by a demo kernel
    module that clearly demonstrates its usage.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，您如何实际使用工作队列？下一节将向您展示如何使用全局内核工作队列。接下来将是一个演示内核模块，清楚地展示了其用法。
- en: Using the kernel-global workqueue
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用全局内核工作队列
- en: In this section, we shall learn how exactly to use the kernel-global (also known
    as the system or events workqueue, which is the default) workqueue. This typically
    involves initializing the workqueue with your work task, having it consume your
    work, and finally, performing cleanup.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何使用全局内核（也称为系统或事件工作队列，这是默认的）工作队列。这通常涉及使用您的工作任务初始化工作队列，让它消耗您的工作，并最终进行清理。
- en: Initializing the kernel-global workqueue for your task – INIT_WORK()
  id: totrans-364
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为您的任务初始化全局内核工作队列 - INIT_WORK()
- en: 'Enqueuing work onto this workqueue is actually very easy: use the `INIT_WORK()` macro!
    This macro takes two parameters:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 将工作排队到这个工作队列上实际上非常容易：使用`INIT_WORK()`宏！这个宏接受两个参数：
- en: '[PRE46]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The `work_struct` structure is the workhorse structure for work queues (from
    the module/driver author's point of view, at least); you are to allocate memory
    to it and pass the pointer as the first parameter. The second parameter to `INIT_WORK()`
    is a pointer to the workqueue callback function – the function that will be consumed
    by the worker thread(s) of the workqueue! `work_func_t` is a `typedef` that specifies
    the signature for this function, which is `void (*work_func_t)(struct work_struct
    *work)`.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '`work_struct`结构是工作队列的工作结构（至少从模块/驱动程序作者的角度来看）；您需要为其分配内存并将指针作为第一个参数传递。`INIT_WORK()`的第二个参数是指向工作队列回调函数的指针
    - 这个函数将被工作队列的工作线程消耗！`work_func_t`是一个`typedef`，指定了这个函数的签名，即`void (*work_func_t)(struct
    work_struct *work)`。'
- en: Having your work task execute – schedule_work()
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 让您的工作任务执行 - schedule_work()
- en: 'Calling `INIT_WORK()` registers the specified work structure and function with
    the in-house default kernel-global workqueue. But it doesn''t execute it – yet!
    You have to tell it when to execute your "work" by calling the `schedule_work()` API
    at the appropriate moment:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`INIT_WORK()`会将指定的工作结构和函数注册到内部默认的全局内核工作队列中。但它不会执行它 - 还没有！您需要在适当的时刻调用`schedule_work()`API来告诉它何时执行您的“工作”：
- en: '[PRE47]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Clearly, the parameter to `schedule_work()` is the pointer to the `work_struct`
    structure (which you initialized earlier via the `INIT_WORK()` macro). It returns
    a Boolean (quoting directly from the source): `%false if @work was already on
    the kernel-global workqueue and %true otherwise True`. In effect, `schedule_work()` checks
    if the function that was specified (via the work structure) is already on the
    kernel-global workqueue; if not, it enqueues it there; if it already was there,
    it leaves it alone in the same position (it doesn't add one more instance). It
    then marks the work item for execution. This typically happens as soon as the
    underlying kernel thread(s) corresponding to the workqueue get scheduled, thus
    giving you a chance to run your work.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，`schedule_work()`的参数是指向`work_struct`结构的指针（您之前通过`INIT_WORK()`宏初始化）。它返回一个布尔值（直接引用源代码）：如果@work已经在全局内核工作队列上，则返回`%false`，否则返回`%true`。实际上，`schedule_work()`检查通过工作结构指定的函数是否已经在全局内核工作队列上；如果没有，它会将其排队在那里；如果它已经在那里，它会保持在同一位置（不会添加更多的实例）。然后标记工作项以执行。这通常会在相应的内核线程被调度时立即发生，从而给您一个运行您的工作的机会。
- en: 'To have two work items (functions) within your module or driver execute via
    the (default) kernel-global workqueue, simply call the `INIT_WORK()` macro twice,
    each time passing different work structures and functions. Similarly, for more
    work items, call `INIT_WORK()` for each of them... (For example, take this kernel
    block driver (`drivers/block/mtip32xx/mtip32xx.c`): apparently, for Micron PCIe
    SSDs, it calls `INIT_WORK()` eight times in a row (!) with its probe method, using
    arrays to hold all the items).'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 要使您的模块或驱动程序中的两个工作项（函数）通过（默认）全局内核工作队列执行，只需两次调用`INIT_WORK()`宏，每次传递不同的工作结构和函数。类似地，对于更多的工作项，为每个工作项调用`INIT_WORK()`...（例如，考虑这个内核块驱动程序（`drivers/block/mtip32xx/mtip32xx.c`）：显然，对于Micron
    PCIe SSD，它在其探测方法中连续调用`INIT_WORK()`八次（！），使用数组来保存所有的项目）。
- en: Note that you can call `schedule_work()` in an atomic context! The call is non-blocking;
    it merely schedules the work item to be consumed at a later, deferred (and safe)
    point in time, when it will run in process context.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，您可以在原子上下文中调用`schedule_work()`！这个调用是非阻塞的；它只是安排工作项在稍后的延迟（和安全）时间点被消耗时运行在进程上下文中。
- en: Variations of scheduling your work task
  id: totrans-374
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 调度工作任务的变化
- en: 'There are a few variations of the `schedule_work()` API we just described,
    all of which are available via the `schedule[_delayed]_work[_on]()` APIs. Let''s
    briefly enumerate them. First, let''s look at the `schedule_delayed_work()` inline
    function, whose signature is as follows:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚描述的`schedule_work()` API有一些变体，所有这些变体都可以通过`schedule[_delayed]_work[_on]()`API获得。让我们简要列举一下。首先，让我们看一下`schedule_delayed_work()`内联函数，其签名如下：
- en: '[PRE48]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Use this routine when you want to delay the execution of the workqueue handler
    function by a specified amount of time; the second parameter, `delay`, is the
    number of `jiffies` you want to wait for. Now, we know that the `jiffies` variable
    increments by `HZ` jiffies per second; thus, to have your work task delayed by
    `n` seconds, specify `n * jiffies`. Similarly, you could always pass the `msecs_to_jiffies(n)` value
    as the second parameter to have it execute `n` milliseconds from now.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 当您希望延迟执行工作队列处理程序函数一定时间时，请使用此例程；第二个参数`delay`是您希望等待的`jiffies`数。现在，我们知道`jiffies`变量每秒增加`HZ`个`jiffies`；因此，要延迟`n`秒执行您的工作任务，请指定`n
    * jiffies`。同样，您也可以将`msecs_to_jiffies(n)`值作为第二个参数传递，以便`n`毫秒后执行。
- en: Next, notice that the first parameter to `schedule_delayed_work()` is different;
    it's a `delayed_work` structure, which itself contains the now-familiar `work_struct`
    structure as a member, along with other housekeeping members (a kernel timer,
    a pointer to the workqueue structure, and a CPU number). To initialize it, just allocate
    memory to it and then make use of the  `INIT_DELAYED_WORK()` macro (the syntax
    remains identical to `INIT_WORK()`); it will take care of all initialization.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，请注意`schedule_delayed_work()`的第一个参数不同；它是一个`delayed_work`结构，其中包含了现在熟悉的`work_struct`结构作为成员，以及其他一些管理成员（内核定时器、指向工作队列结构的指针和CPU编号）。要初始化它，只需为其分配内存，然后利用`INIT_DELAYED_WORK()`宏（语法与`INIT_WORK()`保持相同）；它将负责所有初始化工作。
- en: 'Another slight variation on the theme is the `schedule[_delayed]_work_on()`
    routine; `on` in the name allows you to specify which CPU core your work task
    will be scheduled upon when it executes. Here''s the signature of the `schedule_delayed_work_on()`
    inline function:'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 主题的另一个轻微变体是`schedule[_delayed]_work_on()`例程；名称中的`on`允许您指定执行工作任务时将在哪个CPU核心上安排。以下是`schedule_delayed_work_on()`内联函数的签名：
- en: '[PRE49]'
  id: totrans-380
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The first parameter specifies the CPU core to execute the work task upon, while
    the remaining two parameters are identical to the `schedule_delayed_work()` routine's
    parameters. (You can employ the `schedule_delayed_work()` routine to schedule
    your task – immediately – on a given CPU core).
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数指定要在其上执行工作任务的CPU核心，而其余两个参数与`schedule_delayed_work()`例程的参数相同。（您可以使用`schedule_delayed_work()`例程在给定的CPU核心上立即安排您的任务）。
- en: Cleaning up – canceling or flushing your work task
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清理 - 取消或刷新您的工作任务
- en: 'At some point, you will want to ensure that your work task(s) have actually
    completed execution. You may wish to do this before destroying your workqueue
    (assuming it''s a custom created one and not the kernel-global one) or, more likely,
    when using the kernel-global workqueue in the cleanup method of your LKM or driver.
    The typical API to use here is `cancel_[delayed_]work[_sync]()`. Its variations
    and signatures are as follows:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时候，您会希望确保您的工作任务已经完成执行。您可能希望在销毁工作队列之前（假设这是一个自定义创建的工作队列，而不是内核全局的工作队列），或者更可能是在使用内核全局工作队列时，在LKM或驱动程序的清理方法中执行此操作。在这里使用的典型API是`cancel_[delayed_]work[_sync]()`。它的变体和签名如下：
- en: '[PRE50]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'It''s quite simple, really: use `cancel_work_sync()` once you have used the
    `INIT_WORK()` and `schedule_work()` routines; use the latter two when you''ve
    delayed your work task. Notice that two of the routines are suffixed with `_sync`;
    this implies that the cancellation is *synchronous* – the kernel will wait until
    your work tasks have completed execution before these functions return! This is
    usually what we want. These routines return a boolean: `True` if there was work
    pending and `False` otherwise.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 这很简单：一旦使用了`INIT_WORK()`和`schedule_work()`例程，请使用`cancel_work_sync()`；当您延迟了工作任务时，请使用后两者。请注意，其中两个例程的后缀是`_sync`；这意味着取消是*同步的*
    - 内核将等待您的工作任务完成执行，然后这些函数才会返回！这通常是我们想要的。这些例程返回一个布尔值：如果有待处理的工作，则返回`True`，否则返回`False`。
- en: Within a kernel module, not canceling (or flushing) your work task(s) in your
    cleanup (`rmmod`) code path is a sure-fire way to cause serious issues; ensure
    you do so!
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 在内核模块中，不取消（或刷新）您的工作任务在清理（`rmmod`）代码路径中是导致严重问题的一种确定方法；请确保您这样做！
- en: The kernel workqueue subsystem also provides a few `flush_*()` routines (including `flush_scheduled_work()`, `flush_workqueue()`,
    and `flush_[delayed_]work()`). The kernel documentation ([https://www.kernel.org/doc/html/latest/core-api/workqueue.html](https://www.kernel.org/doc/html/latest/core-api/workqueue.html))
    clearly warns us that these routines are not the easiest to use as you can easily
    cause deadlock issues with them. It's recommended that you use the aforementioned `cancel_[delayed_]work[_sync]()` APIs
    instead.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 内核工作队列子系统还提供了一些`flush_*()`例程（包括`flush_scheduled_work()`、`flush_workqueue()`和`flush_[delayed_]work()`）。内核文档（[https://www.kernel.org/doc/html/latest/core-api/workqueue.html](https://www.kernel.org/doc/html/latest/core-api/workqueue.html)）明确警告我们，这些例程不容易使用，因为您很容易因为它们而导致死锁问题。建议您改用前面提到的`cancel_[delayed_]work[_sync]()`API。
- en: A quick summary of the workflow
  id: totrans-388
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作流程的快速总结
- en: 'When using the kernel-global workqueue, a simple pattern (workflow) emerges:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用内核全局工作队列时，出现了一个简单的模式（工作流程）：
- en: '*Initialize* the work task.'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*初始化*工作任务。'
- en: At the appropriate point in time, *schedule* it to execute (perhaps with a delay
    and/or on a particular CPU core).
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在适当的时间点，*安排*它执行（也许延迟和/或在特定的CPU核心上）。
- en: Clean up. Typically, in the kernel module (or driver's) cleanup code path, *cancel*
    it. (Preferably, do this with synchronization so that any pending work tasks are
    completed first. Here, we will stick to employing the recommended `cancel*work*()`
    routines, avoiding the `flush_*()` ones).
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理。通常，在内核模块（或驱动程序）的清理代码路径中，*取消*它。（最好是同步进行，以便首先完成任何待处理的工作任务。在这里，我们将坚持使用推荐的`cancel*work*()`例程，避免使用`flush_*()`例程）。
- en: 'Let''s summarize this using a table:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们用表格总结一下：
- en: '| **Using the kernel-global workqueue** | **Regular work task** | ** Delayed
    work task** | ** Execute work task on given CPU** |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| **使用内核全局工作队列** | **常规工作任务** | **延迟工作任务** | **在给定CPU上执行工作任务** |'
- en: '| 1\. Initialization  | `INIT_WORK()` | `INIT_DELAYED_WORK()` | *< either immediate or
    delayed''s fine >* |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 1. 初始化 | `INIT_WORK()` | `INIT_DELAYED_WORK()` | *<立即或延迟都可以>* |'
- en: '| 2\. Schedule work task to execute | `schedule_work()` | `schedule_delayed_work()`
    | `schedule_delayed_work_on()` |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 2. 安排工作任务执行 | `schedule_work()` | `schedule_delayed_work()` | `schedule_delayed_work_on()`
    |'
- en: '| 3\. Cancel (or flush) it; *foo_sync()* to ensure it''s complete | `cancel_work_sync()`
    | `cancel_delayed_work_sync()` | *< either immediate or delayed''s fine >* |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 3. 取消（或刷新）它；*foo_sync()*以确保它完成 | `cancel_work_sync()` | `cancel_delayed_work_sync()`
    | *<立即或延迟都可以>* |'
- en: Table 5.4 – Using the kernel-global workqueue – summary of the workflow
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.4 - 使用内核全局工作队列 - 工作流程摘要
- en: In the next few sections, we'll write a simple kernel module using the kernel-default
    workqueue in order to execute a work task.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将编写一个简单的内核模块，使用内核默认工作队列来执行工作任务。
- en: Our simple work queue kernel module – code view
  id: totrans-400
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的简单工作队列内核模块 - 代码视图
- en: 'Let''s get hands-on with a work queue! In the following sections, we will write
    a simple demo kernel module (`ch5/workq_simple`) that demonstrates using the kernel-default
    workqueue to execute a work task. It''s actually built upon our earlier LKM, which
    we used to demonstrate kernel timers (`ch5/timer_simple`). Let''s check it out
    code-wise (as usual, we won''t show the full code here, only the most relevant
    portions). We''ll begin by looking at its private context data structure and *init*
    method:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们动手使用工作队列！在接下来的几节中，我们将编写一个简单的演示内核模块（`ch5/workq_simple`），演示使用内核默认工作队列来执行工作任务。实际上，它是建立在我们之前用来演示内核定时器的LKM（`ch5/timer_simple`）之上的。让我们来看看代码（像往常一样，我们不会在这里展示完整的代码，只展示最相关的部分）。我们将从它的私有上下文数据结构和*init*方法开始：
- en: '[PRE51]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'A key point to ponder: how will we manage to pass along some useful data items
    to our work function? The `work_struct` structure only has an atomic long integer
    that''s used for internal purposes. A good (and very typical!) trick is to have
    your `work_struct` structure embedded within your driver''s context structure;
    then, within the work task callback function, use the `container_of()` macro to
    gain access to the parent context data structure! This is a strategy that''s often
    employed. (The `container_of()` is a powerful macro, but not really easy to decipher!
    We''ve provided a couple of useful links for this in the *Further reading *section.)
    So, in the preceding code, we have our driver''s context structure embed a `struct
    work_struct` within it. You can see the initialization of our work task within
    the `INIT_WORK()` macro.'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 一个需要考虑的关键问题是：我们将如何将一些有用的数据项传递给我们的工作函数？`work_struct`结构只有一个用于内部目的的原子长整型。一个好的（非常典型的！）技巧是将你的`work_struct`结构嵌入到驱动程序的上下文结构中；然后，在工作任务回调函数中，使用`container_of()`宏来访问父上下文数据结构！这是一种经常使用的策略。（`container_of()`是一个强大的宏，但并不容易解释！我们在*进一步阅读*部分提供了一些有用的链接。）因此，在前面的代码中，我们的驱动程序上下文结构嵌入了一个`struct
    work_struct`。你可以在`INIT_WORK()`宏中看到我们的工作任务的初始化。
- en: 'Once the timer''s been armed (`add_timer()` does the trick here), it will expire
    in approximately 420 milliseconds and the timer callback function will run in
    the timer softirq context (this is very much an atomic context):'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定时器被装备好（`add_timer()`在这里起作用），它将在大约420毫秒后到期，并且定时器回调函数将在定时器softirq上下文中运行（这实际上是一个原子上下文）：
- en: '[PRE52]'
  id: totrans-405
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: After decrementing the `data` variable, it sets up the timer to fire again (in
    420 ms, via `mod_timer()`), after which, via the `schedule_work()` API, it schedules
    our work queue callback to run! The kernel will recognize that the work queue
    function must now be executed (consumed) as soon as is viable. But hang on – the
    work queue callback must and will run *only in the process context, via a global
    kernel worker thread* – the so-called events thread(s). Thus, only once we're
    out of this softirq context and (one of) the "events" kernel worker threads is
    on a CPU runqueue and actually runs will our work queue callback function be invoked.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在减少`data`变量之后，它设置定时器再次触发（通过`mod_timer()`，在420毫秒后），然后通过`schedule_work()` API，安排我们的工作队列回调运行！内核将意识到现在必须执行（消耗）工作队列函数，只要是可行的。但是等一下
    - 工作队列回调必须且将仅在进程上下文中通过全局内核工作线程运行 - 所谓的事件线程。因此，只有在我们退出这个softirq上下文并且（其中之一）"事件"内核工作线程在CPU运行队列上，并且实际运行时，我们的工作队列回调函数才会被调用。
- en: Relax – it will happen soon enough... the whole point of using workqueues is
    that not only is the thread management completely taken care of by the kernel,
    but the function runs in the process context, where it's then possible to perform
    lengthy blocking or I/O operations.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 放松 - 它很快就会发生...使用工作队列的整个目的不仅是线程管理完全由内核负责，而且函数在进程上下文中运行，因此可以执行漫长的阻塞或I/O操作。
- en: 'Again, how soon is soon? Let''s attempt to measure this: we take a timestamp
    (via the usual `ktime_get_real_ns()` inline function) immediately after `schedule_work()` as
    the first line of code in the work queue function. Our trusty `SHOW_DELTA()` macro
    shows the difference in time. As expected, it''s small, typically within a few
    hundredths of a microsecond''s range (of course, this depends on several factors,
    including the hardware platform, kernel version, and so on). A highly loaded system
    would result in it taking longer to context switch to the events kernel thread(s),
    which could cause a delay in your work queue''s functionality executing. You will
    see it in a sample run within a screenshot capture (*Figure 5.12*) in the following
    section.'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，多快是“很快”？让我们尝试测量一下：我们在`schedule_work()`之后立即（通过通常的`ktime_get_real_ns()`内联函数）获取一个时间戳作为工作队列函数中的第一行代码。我们信任的`SHOW_DELTA()`宏显示了时间差。正如预期的那样，它很小，通常在几百分之几微秒的范围内（当然，这取决于几个因素，包括硬件平台、内核版本等）。高负载系统会导致切换到事件内核线程花费更长的时间，这可能会导致工作队列的功能执行出现延迟。您将在以下部分的截图捕获（*图5.12*）中看到一个样本运行。
- en: 'The following code is of our work task function. This is where we employ the
    `container_of()` macro to gain access to our module''s context structure:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是我们的工作任务函数。这是我们使用`container_of()`宏访问我们模块上下文结构的地方：
- en: '[PRE53]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Furthermore, our `PRINT_CTX()` macro's output conclusively shows that this function
    runs in the process context.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们的`PRINT_CTX()`宏的输出明确显示了这个函数是在进程上下文中运行的。
- en: Be careful when you're using `container_of()` within a *delayed* work task callback
    function – you'll have to specify the third parameter as a `work` member of `struct
    delayed_work` (one of our exercise questions has you try out this very thing!
    There's a solution provided as well...). I suggest that you master the basics
    first before trying this out for yourself.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 在*延迟*工作任务回调函数中使用`container_of()`时要小心 - 您必须将第三个参数指定为`struct delayed_work`的`work`成员（我们的一个练习问题让您尝试这个东西！也提供了解决方案...）。我建议您先掌握基础知识，然后再尝试自己做这个。
- en: In the next section, we will run our kernel module.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将运行我们的内核模块。
- en: Our simple work queue kernel module – running it
  id: totrans-414
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的简单工作队列内核模块 - 运行它
- en: 'Let''s take it for a spin! Take a look at the following screenshot:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试一试！看一下以下的截图：
- en: '![](img/a9d89aad-617f-47e8-88d5-37443a49ce5b.png)'
  id: totrans-416
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a9d89aad-617f-47e8-88d5-37443a49ce5b.png)'
- en: Figure 5.12 – Our workq_simple.ko LKM with the work queue function execution
    highlighted
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.12 - 我们的workq_simple.ko LKM，突出显示了工作队列函数的执行
- en: 'Let''s take a look at this code in more detail:'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地看一下这段代码：
- en: Via our `lkm` helper script, we build and then `insmod(8)` the kernel module;
    that is, `workq_simple.ko`.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过我们的`lkm`辅助脚本，我们构建然后`insmod(8)`内核模块；也就是`workq_simple.ko`。
- en: 'The kernel log is displayed via `dmesg(1)`:'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核日志通过`dmesg(1)`显示：
- en: Here, the workqueue and kernel timer are initialized and armed within the init
    method.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在init方法中初始化和启用了工作队列和内核定时器。
- en: The timer expires (in approximately 420 ms); you can see its printks (showing `timed
    out...` and the value of our `data` variable).
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定时器到期（大约420毫秒）；您可以看到它的printks（显示`timed out...`和我们的`data`变量的值）。
- en: It invokes the `schedule_work()` API, causing our workqueue function to run.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它调用`schedule_work()`API，导致我们的工作队列函数运行。
- en: As highlighted in the preceding screenshot, our work queue function, `work_func()`,
    indeed runs; it displays the data variable's current value, proving that it correctly
    gained access to our "context" or private data structure.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如前面的截图所示，我们的工作队列函数`work_func()`确实运行了；它显示了数据变量的当前值，证明它正确地访问了我们的“上下文”或私有数据结构。
- en: 'Note that we used our `PRINT_CTX()` macro in this LKM (it''s within our `convenient.h`
    header) to reveal something interesting:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们在这个LKM中使用了我们的`PRINT_CTX()`宏（它在我们的`convenient.h`头文件中）来揭示一些有趣的东西：
- en: When it runs in the context of the timer callback function, its status bits
    contain the `s` character (the third character within the four-character field
    – `.Ns1` or similar), showing that it's running in *softirq* (an interrupt, atomic)
    context.
  id: totrans-426
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当它在定时器回调函数的上下文中运行时，它的状态位包含`s`字符（在四字符字段中的第三个字符 - `.Ns1`或类似的），表明它在*softirq*（中断、原子）上下文中运行。
- en: When it runs in the context of the work queue callback function, its status
    bit's third character will *never* contain the `s` character; it will always be
    a `.`, *proving that the workqueue always executes in the process context!*
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当它在工作队列回调函数的上下文中运行时，它的状态位的第三个字符将*永远*不包含`s`字符；它将始终是一个`.`，*证明工作队列总是在进程上下文中执行！*
- en: Next, the `SHOW_DELTA()` macro calculates and spits out the time difference
    between the workqueue being scheduled and actually executing. As you can see (here,
    at least, on our lightly loaded x86_64 guest VM), it's in the range of a few hundred
    microseconds.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，`SHOW_DELTA()`宏计算并输出了工作队列被调度和实际执行之间的时间差。正如您所看到的（至少在我们轻载的x86_64虚拟机上），它在几百微秒的范围内。
- en: 'Why not look up the actual kernel worker thread that was used to consume our
    work queue? A simple `ps(1)` on the PID is all that''s required here. In this
    particular case, it happens to be one of the kernel''s per CPU core generic workqueue
    consumer threads – a kernel worker (`kworker/...`) thread:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不查找实际使用来消耗我们的工作队列的内核工作线程呢？在这里只需要对PID进行简单的`ps(1)`。在这种特殊情况下，它恰好是内核的每个CPU核心的通用工作队列消费者线程之一
    - 一个内核工作线程（`kworker/...`线程）：
- en: '[PRE54]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Of course, the kernel code base is littered with workqueue usage (especially
    many device drivers). Please use `cscope(1)` to find and browse through instances
    of such code.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，内核代码库中到处都是工作队列的使用（特别是许多设备驱动程序）。请使用`cscope(1)`来查找和浏览这类代码的实例。
- en: The sed3 mini project – a very brief look
  id: totrans-432
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: sed3迷你项目 - 简要介绍
- en: Let's conclude this chapter by taking a very brief look at the evolution of
    our `sed2` project to `sed3`. This mini-project is identical to `sed2` except
    that it's simpler! The (en/de)crypt work **is now carried out by our work task
    (function) via the kernel's workqueue functionality** or bottom-half mechanism.
    We use a workqueue – the default kernel-global workqueue – to get the work done
    instead of manually creating and managing kthreads (as we did in `sed2`)!
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过简要地看一下我们的`sed2`项目演变为`sed3`来结束本章。这个小项目与`sed2`相同，只是更简单！（加/解密）工作现在是通过我们的工作任务（函数）通过内核的工作队列功能或底半机制来执行的。我们使用一个工作队列
    - 默认的内核全局工作队列 - 来完成工作，而不是手动创建和管理k线程（就像我们在`sed2`中所做的那样）！
- en: 'The following screenshot shows us accessing the kernel log of a sample run;
    in the run, we had the user mode app encrypt, then decrypt, and then retrieve
    the message for viewing. We''ve highlighted the interesting bit here – the execution
    of our work task via the kernel-global workqueue''s worker threads – in the two
    red rectangles:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示我们访问样本运行的内核日志；在运行中，我们让用户模式应用程序进行加密，然后解密，最后检索消息进行查看。我们在这里突出显示了有趣的部分 - 通过内核全局工作队列的工作线程执行我们的工作任务
    - 在两个红色矩形中：
- en: '![](img/670779a5-067a-4d15-be9b-d4dcd7b862b5.png)'
  id: totrans-435
  prefs: []
  type: TYPE_IMG
  zh: '![](img/670779a5-067a-4d15-be9b-d4dcd7b862b5.png)'
- en: Figure 5.13 – Kernel log when running our sed3 driver; the work task running
    via the default kernel-global workqueue is highlighted
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.13 - 运行我们的sed3驱动程序时的内核日志；通过默认的内核全局工作队列运行的工作任务被突出显示
- en: By the way, the user mode app is identical to the one we used in `sed2`. The
    preceding screenshot shows (via our trusty `PRINT_CTX()` macro) the actual kernel
    worker threads that the kernel-global workqueue employed to run our encrypt and
    decrypt work; in this particular case, it's `[kworker/1:0]` PID 9812 for the encrypt
    work and `[kworker/0:2]` PID 9791 for the decrypt work. Note how they both run
    in the process context. We shall leave it to you to browse through the code of
    `sed3` (`ch5/sed3`).
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，用户模式应用程序与我们在`sed2`中使用的应用程序相同。前面的截图显示了（通过我们可靠的`PRINT_CTX()`宏）内核工作线程，内核全局工作队列用于运行我们的加密和解密工作；在这种情况下，加密工作是`[kworker/1:0]`
    PID 9812，解密工作是`[kworker/0:2]` PID 9791。请注意它们都在进程上下文中运行。我们将让您浏览`sed3`（`ch5/sed3`）的代码。
- en: This brings this section to a close. Here, you learned how the kernel workqueue
    infrastructure is indeed a blessing for module/driver authors as it helps you
    add a powerful abstraction layer over the underlying details regarding kernel
    threads, their creation, and intricate management and manipulation. It makes it
    very easy for you to perform work in the kernel – especially by employing the
    pre-existing kernel-global (default) workqueue – without having to worry about
    the gory details.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了本节。在这里，您了解了内核工作队列基础设施确实是模块/驱动程序作者的福音，因为它帮助您在关于内核线程的底层细节、它们的创建以及复杂的管理和操作方面添加了一个强大的抽象层。这使得您可以非常轻松地在内核中执行工作
    - 尤其是通过使用预先存在的内核全局（默认）工作队列 - 而不必担心这些令人讨厌的细节。
- en: Summary
  id: totrans-439
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Well done! We covered a lot of ground in this chapter. First, you learned how
    to create delays in kernel space, both the atomic and the blocking types (via
    the `*delay()` and `*sleep()` routines, respectively). Next, you learned how to
    set up and use kernel timers within your LKM (or driver) – a very common and required
    task. Directly creating and working with kernel threads can be a heady (and even
    difficult) experience, which is why you learned the basics of doing so. After
    that, you looked at the kernel workqueue subsystem, which solves complexity (and
    concurrency) issues. You learned what it is and how to practically make use of
    the kernel-global (default) workqueue to make your work task(s) execute when required.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 干得好！在本章中，我们涵盖了很多内容。首先，您学会了如何在内核空间中创建延迟，包括原子和阻塞类型（通过`*delay()`和`*sleep()`例程）。接下来，您学会了如何在LKM（或驱动程序）中设置和使用内核定时器
    - 这是一个非常常见和必需的任务。直接创建和使用内核线程可能是一种令人兴奋（甚至困难）的体验，这就是为什么您学会了如何做到这一点的基础知识。之后，您看了内核工作队列子系统，它解决了复杂性（和并发性）问题。您了解了它是什么，以及如何实际利用内核全局（默认）工作队列在需要时执行您的工作任务。
- en: 'The series of three `sed` (simple encrypt decrypt) demo drivers we designed
    and implemented showed you a bit of a more sophisticated use case for these interesting
    technologies: `sed1` with the timeout implementation, `sed2` adding to the kernel
    thread to perform work, and `sed3` using the kernel-global workqueue to have work
    consumed when required.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计和实现的三个`sed`（简单加密解密）演示驱动程序向您展示了这些有趣技术的一个更复杂的用例：`sed1`实现了超时，`sed2`增加了内核线程来执行工作，`sed3`使用内核全局工作队列在需要时消耗工作。
- en: 'Please take some time to work on the following *Questions*/exercises for this
    chapter and browse through the *Further reading *resources. When you''re done,
    I suggest that you take a well-deserved break and jump back in. We''re almost
    there: the final two chapters cover a really key topic – kernel synchronization!'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 请花一些时间来解决本章的以下*问题*/练习，并浏览*进一步阅读*资源。完成后，我建议您休息一下，然后重新开始。我们快要完成了：最后两章涵盖了一个非常关键的主题
    - 内核同步！
- en: Questions
  id: totrans-443
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Spot the bug(s) in the following pseudocode:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找出以下伪代码中的错误。
- en: '[PRE55]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '`timer_simple_check`: Enhance the `timer_simple` kernel module so that it checks
    the amount of time that elapsed between setting up a timeout and it actually being
    serviced.'
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`timer_simple_check`: 增强`timer_simple`内核模块，以便检查设置超时和实际服务之间经过的时间量。'
- en: '`kclock`: Write a kernel module that sets up a kernel timer so that it times
    out every second. Then, use this to print the timestamp to the kernel log to get,
    in effect, a simple "clock app" in the kernel.'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kclock`: 编写一个内核模块，设置一个内核定时器，以便每秒超时一次。然后，使用这个来将时间戳打印到内核日志中，实际上得到一个简单的“时钟应用程序”在内核中。'
- en: '`mutlitime`*:* Develop a kernel module that takes the number of seconds to
    issue a timer callback in as a parameter. Have it default to zero (implying no
    timer and thus a validity error). Here''s how it should work: if the number that''s
    passed is 3, it should create three kernel timers; the first one will expire in
    3 seconds, the second in 2 seconds, and the last in 1 second. In other words, if
    the number passed is "n", it should create "n" kernel timers; the first one will
    expire in "n" seconds, the second in "n-1" seconds, the third in "n-2" seconds,
    and so on until the count hits zero.'
  id: totrans-448
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`mutlitime`*：开发一个内核模块，以秒数作为参数发出定时器回调。默认为零（表示没有定时器，因此是一个有效性错误）。它应该这样工作：如果传递的数字是3，它应该创建三个内核定时器；第一个将在3秒后到期，第二个在2秒后到期，最后一个在1秒后到期。换句话说，如果传递的数字是“n”，它应该创建“n”个内核定时器；第一个将在“n”秒后到期，第二个在“n-1”秒后到期，第三个在“n-2”秒后到期，依此类推，直到计数达到零。'
- en: Build and run the `sed[123]` mini-projects provided in this chapter and verify
    (by looking at the kernel logs) that they work the way they should.
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本章中提供的`sed[123]`迷你项目中构建并运行，并通过查看内核日志验证它们是否按预期工作。
- en: '`workq_simple2`: The `ch5/workq_simple` LKM we provided sets up and "consumes"
    one work item (function) via the kernel-global workqueue; enhance it so that it
    sets up and executes two "work" tasks. Verify that it works correctly.'
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`workq_simple2`：我们提供的`ch5/workq_simple` LKM设置并通过内核全局工作队列“消耗”一个工作项（函数）；增强它，以便设置并执行两个“工作”任务。验证它是否正常工作。'
- en: '`workq_delayed`: Build upon the previous assignment (`workq_simple2`) to execute
    two work tasks, plus one more task (from the init code path). This one (the third
    one) should be delayed; the amount of time to delay by should be passed as a module parameter
    named `work_delay_ms` (in milliseconds; the default should be 500 ms).'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`workq_delayed`：在之前的任务（`workq_simple2`）的基础上构建，以执行两个工作任务，再加上一个任务（来自init代码路径）。第三个任务应该延迟执行；延迟的时间量应该作为名为`work_delay_ms`的模块参数传递（以毫秒为单位；默认值应为500毫秒）。'
- en: '[*Tip:* Be careful when using `container_of()` within the delayed work task
    callback function; you''ll have to specify the third parameter as a `work` member
    of `struct delayed_work`; check out a solution we''ve provided].'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: '[*提示：*在延迟工作任务回调函数中使用`container_of()`时要小心；您必须将第三个参数指定为`struct delayed_work`的`work`成员；查看我们提供的解决方案]。'
- en: 'You will find some of the questions answered in the book''s GitHub repo: [https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn).'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在书的GitHub存储库中找到一些问题的答案：[https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn)。
- en: Further reading
  id: totrans-454
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Kernel documentation: *Delays, sleep mechanisms*: [https://www.kernel.org/doc/Documentation/timers/timers-howto.tx](https://www.kernel.org/doc/Documentation/timers/timers-howto.txt)'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核文档：*延迟，睡眠机制*：[https://www.kernel.org/doc/Documentation/timers/timers-howto.tx](https://www.kernel.org/doc/Documentation/timers/timers-howto.txt)
- en: Kernel Timer Systems: [https://elinux.org/Kernel_Timer_Systems#Timer_information](https://elinux.org/Kernel_Timer_Systems#Timer_information)
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核定时器系统：[https://elinux.org/Kernel_Timer_Systems#Timer_information](https://elinux.org/Kernel_Timer_Systems#Timer_information)
- en: 'Workqueues:'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作队列：
- en: 'This is a very good presentation: *Async execution with workqueues*, Bhaktipriya
    Shridhar: [https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf](https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf)'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个非常好的演示：*使用工作队列进行异步执行*，Bhaktipriya Shridhar：[https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf](https://events.static.linuxfound.org/sites/events/files/slides/Async%20execution%20with%20wqs.pdf)
- en: 'Kernel documentation: *Concurrency Managed Workqueue (cmwq)*: [https://www.kernel.org/doc/html/latest/core-api/workqueue.html#concurrency-managed-workqueue-cmwq](https://www.kernel.org/doc/html/latest/core-api/workqueue.html#concurrency-managed-workqueue-cmwq)'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核文档：*并发管理工作队列（cmwq）*：[https://www.kernel.org/doc/html/latest/core-api/workqueue.html#concurrency-managed-workqueue-cmwq](https://www.kernel.org/doc/html/latest/core-api/workqueue.html#concurrency-managed-workqueue-cmwq)
- en: 'The `container_of()` macro explained:'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解释了`container_of()`宏：
- en: '*The Magical container_of() Macro*, November 2012: [https://radek.io/2012/11/10/magical-container_of-macro/](https://radek.io/2012/11/10/magical-container_of-macro/)'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*神奇的container_of()宏*，2012年11月：[https://radek.io/2012/11/10/magical-container_of-macro/](https://radek.io/2012/11/10/magical-container_of-macro/)'
- en: '*Understanding of container_of macro in Linux kernel*: [https://embetronicx.com/tutorials/linux/c-programming/understanding-of-container_of-macro-in-linux-kernel/](https://embetronicx.com/tutorials/linux/c-programming/understanding-of-container_of-macro-in-linux-kernel/)'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*在Linux内核中理解container_of宏*：[https://embetronicx.com/tutorials/linux/c-programming/understanding-of-container_of-macro-in-linux-kernel/](https://embetronicx.com/tutorials/linux/c-programming/understanding-of-container_of-macro-in-linux-kernel/)'
