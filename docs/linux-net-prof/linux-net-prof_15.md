# 第十二章：使用 Linux 进行网络监控

在本章中，我们将讨论各种网络监控和管理协议、工具和方法。我们将介绍使用 syslog 进行日志记录，它可以用于记录各种主机上感兴趣的事件。这将扩展到基于云的 syslog 事件收集，允许你总结防火墙流量并将你的流量模式与互联网上的流量进行比较。

我们将讨论使用 SNMP 来收集各种网络设备和主机的性能统计数据，这在故障排除和容量规划中都很有用。

最后，我们将使用 NetFlow 和其他流量收集协议来寻找流量异常——我们将使用 NetFlow 来进行典型的事件调查，揭示一个大规模的数据外泄事件。

具体来说，我们将涵盖以下主题：

+   使用 Syslog 进行日志记录

+   Dshield 项目

+   在 Linux 上收集 NetFlow 数据

# 技术要求

在这一章中，我们将讨论网络管理的几个方面。虽然你可以在本章中重新创建示例构建，但请注意你的数据将会不同。因此，虽然使用各种数据类型进行监控或故障排除的方法将保持不变，但要在你的环境中使用你的数据（以及任何需要解决的问题），你将需要不同的搜索词。

也就是说，你现有的 Linux 主机或 VM 可以用来构建本章中描述的任何一个或所有示例系统。然而，在生产中，你会将这些功能分开部署在一个、两个甚至更多的专用服务器上。如果你在实验室中使用 VM，我最好的建议是从一个新的、干净的映像开始，并从那里开始构建——这样，如果你发现我们使用的各种**网络管理系统**（**NMSes**）有用，你可以直接将它们移植到生产中。

NMS 部分侧重于 LibreNMS 应用程序。对于那组示例，建议下载并安装该应用程序的预构建 Linux VM 映像（OVA 格式）。

# 使用 Syslog 进行日志记录

**日志记录**是管理任何系统的关键方面，几乎普遍建议进行中央日志记录。中央日志记录允许你将来自多台服务器或服务（例如防火墙、负载均衡器和 Web 服务器）的日志合并到一个按时间顺序排列的文件中。这通常可以加快任何故障排除或诊断，因为你可以看到事件从一个平台移动到下一个。从安全的角度来看，这在**事件响应**（**IR**）中尤为重要。在响应事件时，你可能会看到恶意软件通过电子邮件到达，然后作为一个进程执行，然后横向移动（通常称为“东/西”）到其他工作站主机，或向“北”向你的服务器移动。再加上定期（通常每小时）更新后，你的工具的当前版本很可能能够从日志中找出可能在昨天被忽略的恶意软件。

此外，从安全的角度来看，将日志记录到中央位置可以将这些日志条目的副本从源主机中移出。如果源主机受到攻击，这可以给你一个“更可信”的真相版本。在初始受损后，攻击者必须付出更多的努力来找到并攻击中央日志服务器。在很多情况下，这种延迟可以被用于你的优势，以识别并警告攻击已经发生。通常，防御都是关于延迟攻击者，并在此延迟期间向防御者提供尽可能多的细节。中央日志记录，以及对日志条目进行接近实时的分析或触发器，是这一点的一个很好的例子。

那么，在部署和使用中央日志记录时，我们应该考虑哪些设计和可用性考虑？

## 日志大小、轮换和数据库

你会注意到关于日志的第一件事是它们增长得非常快。如果你在防火墙上进行全面日志记录，即使在一个小组织中，这些日志也会很快增长到每天几 GB。再加上路由器、交换机、服务器以及这些服务器上的服务的日志，日志可能会变得非常复杂和难以搜索。

人们经常做的第一件事是分离日志。保留“全部日志”总是明智的，但将每个设备或服务日志的副本分开并分成单独的较小日志可能会很方便。虽然防火墙日志可能有几 GB 大小，但同一时期的路由器日志很可能只有几 KB 大小，通常是个位数。日志大小通常可以成为问题的指标 - 例如，如果你有一个典型每天 3-5KB 的日志，突然增长到每天 2-3MB，这通常表明出现了问题。或者，如果你有 15 个分支办公室应该是相同的，但其中一个路由器或防火墙日志的大小是其他的 3 倍或 10 倍，那也是一个很大的箭头指向“这里看看！”

通常，人们会采取混合方法 - 保留包含所有内容的单一日志，为所有内容保留单独的日志，然后合并那些不那么“啰嗦”的东西 - 例如，只删除防火墙日志以及 Linux 和 Hypervisor 主要 syslog 日志可以大大减少日志大小，但仍保留一个合理的合并日志文件。

所有这些都占用了磁盘空间，每次你以不同的方式切割数据，都很可能会大幅增加空间需求。要注意数据的整体大小和存储它的容量 - 你绝不希望处于攻击者可以填满日志容量的位置。这种情况可能会完全停止日志记录过程，因此你不知道攻击者去了哪里。它还可以覆盖事件的初始集，因此你不知道攻击者是如何首次立足的。在最坏的情况下，它可能两者兼而有之。

解决这个空间问题的一种方法是归档日志 - 保留 1-5-7-10 天的日志以便轻松搜索，但在那之后，可能会归档和压缩主要日志并删除其余部分。这可以保留传统的文本文件，以及传统的`grep`/`cut`/`sort`/`uniq 搜索`方法，但保持大小可管理。

更现代的方法可能是保留那个单一的“全部”日志文件，并进行定期的离线存储，这样可以轻松地保留几个月甚至几年的日志 - 根据你的政策、程序或合规要求。然后，你可以根据需要从这个中央位置重新转发流量到你的 SIEM。所有这些日志都可以使用命令行工具进行搜索。

对于日常故障排除，解析日志数据并将其存储在数据库中。这样可以实现更快的搜索，尤其是在应用了战略索引之后，还可以更轻松地管理数据的整体大小。这种方法的关键不是管理磁盘空间，而是（尽可能地）通过目标时间间隔来管理日志容量，以便实现可预测、可重复的故障排除和报告窗口。

让我们深入探讨如何在故障排除时逐步添加搜索项以找到最终答案。

## 日志分析 - 寻找“关键”

人们一旦将日志存储在磁盘上，面临的主要挑战是如何使用它们。特别是在故障排除或处理安全事件时，你知道日志中有很好的信息，但要知道在哪里搜索、如何搜索以及使用什么工具是一个艰巨的任务，如果你刚开始进行日志分析的话。

### 要查找的地方

通常，确定你正在寻找问题的 OSI 堆栈的哪个位置是有意义的。诸如重复的 IP 地址之类的问题是第 3 层的问题 - 你会在路由器或交换机日志中寻找它们。然而，同样的问题可能会从最终用户报告开始，他们声称“Web 服务器不稳定”，所以你可能会从 Web 服务器的应用程序日志开始 - 你可能需要一些时间来通过各种服务器和设备日志逐步解决这个问题，找到根本问题。最近的一个例子中，我与帮助台合作部署了一台新打印机，我不小心错误地在打印机配置中使用了 Web 服务器集群地址之一。

虽然在更大的日志中查找这些问题可能会更快，但在一个多 GB 的文本日志中搜索可能需要 5-10-15 分钟每次“尝试”，因为你需要交互式地得到最终的搜索词组。同样，在文本日志的情况下，你通常会从“最有可能的”日志开始搜索，而不是“在这里搜索，它包含所有内容”的日志。

既然我们正在寻找正确的地方，我们如何缩小所有这些日志条目以找到“答案”呢？

### 如何搜索

在大多数情况下，搜索日志将包括一系列“找到这个”和“排除那个”的子句。如果你在搜索文本日志，这通常是`grep -i "包含文本"`或`grep -i -v "排除文本"`。请注意，使用`-i`会使你的搜索不区分大小写。如果你按正确的顺序串联足够多的这些内容，通常就足够了。

然而，如果你想“计算”特定事件，`uniq -c`可能会有所帮助，它将计算唯一事件。然后，你可以使用`sort -r`将它们按降序排序。

例如，要查找到外部 DNS 服务器的 DNS 查询，你需要搜索防火墙日志。如果防火墙是 Cisco ASA，查询可能类似于这个序列：

![](img/B16336_12_Table_01.jpg)

我们的最终命令？让我们来看一下：

```
cat logfile.txt | grep –v  "a.a.a.a" | grep –v "b.b.b.b" | grep "/53 " | sed s/\t/" "/g | tr –s " " | cut -d " " -f 13 | sed s/:/" "/g | sed s/\//" "/g | cut -d " " -f 2 | sort | uniq –c | sort –r
```

这看起来很复杂，但请记住，这是迭代完成的 - 我们分别解决每个请求中的“子句”，然后按顺序将它们串联在一起。此外，在许多情况下，我们可能会花费几分钟甚至几个小时来完善一个查询，但然后在以后的几年中以自动化的方式使用该查询，所以这是值得花费的时间！

此外，虽然我们展示了使用 Linux 命令行文本处理命令进行查询，但相同的方法可以用于数据库日志存储库，甚至用于针对不同防火墙的查询。无论目标设备、日志存储库类型或我们要解决的问题是什么，方法通常是这样的：

+   使用一些广泛的查询或选择（包括或排除）来将数据减少到更可管理的量。

+   做任何必要的工作来处理数据，以便可以更具体地查询。

+   使用一些更具体的查询来进一步缩小范围。

+   如果我们正在寻找计数或最常见的事件，就要总结数据以匹配所需的内容。

+   测试最终的查询/选择标准。

+   将最终的搜索词组插入到所需的自动化中，以便以所需的频率对此信息进行总结或报告。

这涵盖了如何通过日志搜索过去的事件来诊断过去的问题，但我们不能使用日志立即告诉我们已知的问题何时发生吗？简短的答案是“是的，绝对可以”。让我们探讨一下这是如何做到的。

## 特定事件的警报

这是“寻找事物”对话的延伸 - 也许是“何时寻找”的话题。当然，找到问题的最佳时间是它发生的瞬间 - 或者甚至是在它发生之前，这样你就可以尽快修复它。

为此，通常会定义简单的文本字符串，这些字符串可能会指示问题并在发生时警报相关人员。您可能会在发生此类警报时发送电子邮件警报或短信，或者可能会收集一天的警报并发送每日摘要-您的方法可能取决于您的环境以及所见到的警报的严重程度。

搜索常见术语包括以下内容（几乎总是建议不区分大小写搜索）：

![](img/B16336_12_Table_02a.jpg)![](img/B16336_12_Table_02b.jpg)

在所有这些情况下，您可能希望添加一个`not`子句来过滤可能正在浏览或搜索这些术语的用户-例如，“batter”将找到所有电池事件，但它也会找到搜索蛋糕食谱和棒球新闻故事的用户。如果从搜索术语中排除“http”，那通常会得到您所需的内容。

有了这些触发器，您可以在问题变成问题之前解决一堆问题-这总是一件好事。

现在我们已经讨论了搜索和触发器，让我们建立一个日志服务器并尝试这些方法！

## Syslog 服务器示例-Syslog

要在 Linux 主机上运行基本的 syslog 服务，我们将配置`rsyslog`服务。默认情况下，此服务侦听端口`514/udp`，尽管端口和协议都是可配置的。

日志事件以各种优先级或严重级别出现，通常由发送设备设置：

+   `emerg, panic`（紧急）-级别`0`：这是最低的日志级别。系统无法使用。通常这些是在系统崩溃之前您将看到的最后消息。

+   `alert`（警报）：级别`1`：必须立即采取行动。这些通常会影响整个系统的操作。

+   `crit`（临界）：级别`2`：与警报一样，必须立即采取行动。系统的主要功能可能无法正常运行。

+   `err`（错误）：级别`3`：重要错误，但系统仍在运行。系统的主要功能可能受到影响。

+   `warn`（警告）：级别`4`：警告条件。

+   `notice`（通知）：级别`5`：正常但重要的条件。

+   `info`（信息）：级别`6`：信息消息。

+   `debug`（调试）：级别`7`：这是最高级别-调试级别消息。

通常，当您配置一个日志记录级别时，所有较低的日志记录级别都会包括在内。因此，如果您在主机上配置了级别 4 的 syslog，则也会包括 0、1、2 和 3。这就解释了为什么在大多数情况下，您只为任何给定的主机配置一个日志记录级别。

很可能`rsyslog`已经安装并在您的 Linux 主机上运行。让我们来检查一下：

```
~$ sudo systemctl status rsyslog
• rsyslog.service - System Logging Service
     Loaded: loaded (/lib/systemd/system/rsyslog.service; enabled; vendor prese>
     Active: active (running) since Tue 2021-06-15 13:39:04 EDT; 11min ago
TriggeredBy: • syslog.socket
       Docs: man:rsyslogd(8)
             https://www.rsyslog.com/doc/
   Main PID: 783 (rsyslogd)
      Tasks: 4 (limit: 9334)
     Memory: 4.1M
     CGroup: /system.slice/rsyslog.service
             └─783 /usr/sbin/rsyslogd -n -iNONE
Jun 15 13:39:04 ubuntu systemd[1]: Starting System Logging Service...
Jun 15 13:39:04 ubuntu rsyslogd[783]: imuxsock: Acquired UNIX socket '/run/syst>
Jun 15 13:39:04 ubuntu rsyslogd[783]: rsyslogd's groupid changed to 110
Jun 15 13:39:04 ubuntu rsyslogd[783]: rsyslogd's userid changed to 104
Jun 15 13:39:04 ubuntu rsyslogd[783]: [origin software="rsyslogd" swVersion="8.>
Jun 15 13:39:04 ubuntu systemd[1]: Started System Logging Service.
Jun 15 13:39:05 ubuntu rsyslogd[783]: origin software="rsyslogd" swVersion="8.
```

如果您尚未安装此服务，只需运行以下命令即可：

```
$ sudo apt-get install rsyslog 
```

安装并运行服务后，让我们继续配置。编辑`/etc/rsyslog.conf`文件，确保您具有`sudo`权限进行此操作。

您会发现控制监听端口的行如下。取消注释 UDP 的行，如下所示（其中包含`imudp`的两行）。如果您还想在`514/tcp`上接受 syslog，请随时取消注释（这两个在此处都取消了注释）：

```
# provides UDP syslog reception
module(load="imudp")
input(type="imudp" port="514")
# provides TCP syslog reception
module(load="imtcp")
input(type="imtcp" port="514")
```

如果您想将 syslog 客户端限制为特定的子网或 DNS 域集，可以通过在此文件中添加`AllowedSender`行来实现，如下所示，在我们刚刚取消注释的“input”行之后（请务必根据您要添加此行的部分使用正确的协议）：

```
$AllowedSender UDP, 127.0.0.1, 192.168.0.0/16, *.coherentsecurity.com
```

接下来，我们将向下滚动到同一文件的“全局指令”部分。就在那一行之前，我们将添加一行作为“模板”，以命名传入的文件并标识它们的位置。我们可以使用几个以“％”分隔的变量，其中最常见的如下：

![](img/B16336_12_Table_03.jpg)
    
在我们的配置中，我们将使用主机 IP 作为文件名，然后按日期拆分日志：

```
$template remote-incoming-logs, "/var/log/%$year%-%$month%-%$day%/%FROMHOST-IP%.log"*.* ?remote-incoming-logs
```
使用以下命令检查文件语法：

```
$ rsyslogd -N 1
rsyslogd: version 8.2001.0, config validation run (level 1), master config /etc/rsyslog.confrsyslogd: End of config validation run. Bye.
```

可以用于模板化 syslog 文件的其他变量名称包括以下内容：![](img/B16336_12_Table_04.jpg)

现在，保存文件并重新启动`rsyslog`服务：

```
$ sudo systemctl restart rsyslog
```

现在，我们只需要配置我们的各种服务器和设备，将日志转发到这台服务器，对吧？

有点像 - 这给我们带来的是一个非常昂贵（以磁盘空间计算）的日志堆。我们实际想要的是一种方法，从这些日志中实时获取一些警报。我们将使用一个名为`tail`命令的过程来实现这一点，该命令将使用以下命令将行回显到文本文件中：

```
tail –f < filename.txt
```

这会回显文本，但不会给我们任何警报。为此，我们必须安装一个名为`swatch`（用于“syslog watch”）的软件包：

```
Apt-get install swatch
```

安装完成后，我们将创建一个配置文件来告诉工具要查找什么。回顾我们的常见警报列表，像这样的`swatch.conf`文件可能是一个很好的开始：

```
watchfor /batter/i
echo red
mail=facilities@coherentsecurity.com, subject="ALERT: Battery Issue"
watchfor /temperature|fan|water/i
echo environmental
mail=rob@coherentsecurity.com, subject="ALERT: Environmental Alert"
watchfor /BGP/
echo routing_issue
mail=rob@coherentsecurity.com, subject="ALERT: Routing Issue"
watchfor /SEC_LOGIN_FAILED/
echo security_event
mail=rob@coherentsecurity.com, subject="ALERT: Administrative Login Failed"
continue
watchfor /SEC_LOGIN_FAILED/
threshold type=threshold,count=5,seconds=600
echo security_event
mail=rob@coherentsecurity.com, subject="ALERT: Possible Password Stuffing Attack in Progress"
```

这里有几点需要注意 - 我们要查找的文本在`watchfor`子句中。请注意，在每种情况下，被监视的文本都是“正则表达式”或`regex`。`regex`语法非常灵活，既可以非常简单（如前面所示），也可以非常复杂，难以理解。我在本章末尾包含了一些正则表达式参考资料。

在我们的示例中，第一个正则表达式以`/I`结尾，这告诉`watchfor`命令这是一个不区分大小写的搜索。请注意，这会消耗相当多的 CPU 资源，因此如果您知道匹配文本的大小写，最好将其正确地放入正则表达式中。

在第二个子句中，请注意我们有三个不同的搜索项，用`|`字符分隔，这是一个逻辑或 - 换句话说，“温度”或“风扇”或“水”。

最后两个示例是相关的。第一个示例查找失败的登录并为每个登录提供警报。但然后它有一个`continue`命令，告诉 swatch 继续。下一个子句匹配相同的文本，但有一个阈值 - 如果 swatch 在 5 分钟内看到五次失败的登录尝试，它将识别可能的密码填充攻击。

您还可以使用`exec`命令而不是`mail`来触发匹配的日志语句执行脚本。

最后，我们将要开始样本过程：

```
$swatchdog –c /path/swatch.conf –t /path/logfile.log
```

这个命令提出了两个观点：

+   我们已经提到日志大小是一个问题，因此我们存储日志的当前路径不应该与`/var/log`在同一个分区中，后者仅用于本地日志。它绝对不应该与引导或任何其他系统分区在同一个分区中。填满 syslog 分区将导致日志丢失，还可能导致服务器崩溃或无法引导！我们希望我们的日志在一个单独的、专用的分区中，大小合适以存储我们需要的内容。归档日志可以在同一个分区中，也可以在第二个分区中，专门用于存档（很可能是 ZIP 压缩）日志。

+   我们为`rsyslog`配置的当前配置需要 sudo 权限来查看日志。因此，我们要么需要修改文件和目录权限，要么需要使用 sudo 运行我们的`swatchdog`。这两种方法都带有一定程度的风险，但为了便于使用日志进行故障排除，让我们更改文件权限。这可以在`/etc/rsyslog.conf`文件中通过修改这些行来完成：

```
$FileOwner syslog
$FileGroup adm
$FileCreateMode 0640
*.*
$DirCreateMode 0755
*.*
$Umask 0022
$PrivDropToUser syslog
$PrivDropToGroup syslog
```

在大多数情况下，您可以将`FileGroup`命令更改为不同的组，并将各种管理员放入该组，以及您从中运行“swatch”设置的任何帐户。

或者，您可以更改文件和目录`CreateMode`行，甚至包括"everyone"，使用`0777`。由于日志条目始终包含敏感信息，我不建议这样做 - 作为一名渗透测试人员，发现密码在日志文件中是相当常见的 - 令人惊讶的是，人们经常在`userid`字段中输入密码，然后再次尝试正确的信息！

您仍然可以在目录名称中使用日期，但通常，保持一致的文件和目录名称对于实时文件更容易。这使得日志监控工具和解决问题的人更容易找到“今天”。在您的归档脚本中使用日期值意味着历史日志文件将位于“日期”目录中或具有“日期”ZIP 文件名。

话虽如此，我们修改后的 swatch 命令将类似于以下内容：

```
$swatchdog –c /path/swatch.conf –t /path/logfile.log --daemon
```

请注意，我们在命令中添加了`-d` - 一旦一切都调试和正常工作，您将希望在后台运行该命令（作为守护进程）。

您可能需要做更多的工作才能使 swatch 在生产中运行 - 例如，为您的环境获得那些权限，检查您的网络清单，并确保您的所有设备都有中央日志记录，调整日志分区大小，并使日志轮换工作。我们已经涵盖的内容应该足以让您上路，尽管这些其他工作大部分将是针对您的环境的。

在我们组织的日志得到覆盖后，现在出现了其他问题：我们的事件如何与其他组织相比？我们是否看到与其他人相同的攻击，或者我们可能是特定事物的目标？我们如何获得这些信息？我们将在下一节中讨论这个问题。

# Dshield 项目

Dshield 项目由互联网风暴中心（[`isc.sans.edu`](https://isc.sans.edu)）的人员维护，允许参与者将他们的（匿名化的）日志转发到一个中央存储库，这些日志被聚合起来，以提供一个关于“互联网上发生了什么”的良好图景。

具体来说，转发的信息是由您的防火墙阻止的连接尝试。如果您不想使用实际的防火墙日志，还可以使用专用的 Dshield 传感器。参与说明可以在这里找到：[`isc.sans.edu/howto.html`](https://isc.sans.edu/howto.html)。

这些聚合数据让我们了解恶意行为者正在寻找哪些端口，以便利用它们。参与者的地址是匿名化的信息。各种高级报告可以在这里查看：[`isc.sans.edu/reports.html`](https://isc.sans.edu/reports.html)。

特别是，您可以深入研究该页面上的任何“前 10 个端口”，以查看最受欢迎的端口上随时间的活动。例如，您可以转到[`isc.sans.edu/port.html?port=2222`](https://isc.sans.edu/port.html?port=2222)，如下图所示：

![图 12.1 - 一个端口的 Dshield 数据](img/B16336_12_001.jpg)

图 12.1 - 一个端口的 Dshield 数据

通过这种模式，您可以看到如何查询任何端口，如果您有特定的流量需要进行取证。

此外，如果您更愿意使用脚本或应用程序来消耗这些聚合信息，这些信息也可以通过 API 查询。 Dshield API 的文档在这里：[`isc.sans.edu/api/`](https://isc.sans.edu/api/)。

例如，要收集端口`2222`的摘要信息，我们可以使用`curl`（只是一个例子）：

```
$ curl –s –insecure https://isc.sans.edu/api/port/2222 | grep –v encoding\= | xmllint –format –
<?xml version="1.0"?>
<port>
  <number>2222</number>
  <data>
    <date>2021-06-24</date>
    <records>122822</records>
    <targets>715</targets>
    <sources>3004</sources>
    <tcp>100</tcp>
    <udp>0</udp>
    <datein>2021-06-24</datein>
    <portin>2222</portin>
  </data>
  <services>
    <udp>
      <service>rockwell-csp2</service>
      <name>Rockwell CSP2</name>
    </udp>
    <tcp>
      <service>AMD</service>
      <name><![CDATA[[trojan] Rootshell left by AMD exploit]]></name>
    </tcp>
  </services>
</port>
```

因为在此示例中返回的数据是 XML 格式，所以您可以使用标准库或语言组件来消耗它。您还可以将返回的格式更改为 JSON、文本或 PHP。在某些情况下，数据适合逗号或制表符分隔的格式（CSV、制表符）。

要更改格式，只需将`?format_type`添加到查询中，其中`format_type`可以是 JSON、文本、PHP，或者在某些情况下可以是 CSV 或制表符。

每个用户都有自己的网络门户，显示他们自己设备的相同统计数据 - 这些数据在故障排除时可能很有价值，或者与聚合数据进行对比，以查看您的组织是否可能受到攻击。但这种方法的强大之处在于聚合数据，它可以很好地反映特定日期的互联网“天气”情况，以及整体“气候”趋势。

现在我们已经配置了本地日志记录，并将我们的防火墙日志聚合以进行更好的互联网流量分析，让我们考虑其他网络管理协议和方法，首先是**简单网络管理协议**（**SNMP**）管理/性能和正常运行时间。

## 使用 SNMP 进行网络设备管理

在本质上，SNMP 是从目标网络设备收集信息的一种方式。通常，这是通过基于服务器的应用程序完成的，但您当然也可以从命令行查询 SNMP。目前有几个版本的 SNMP，其中有两个是常用的。

SNMPv2c（第 2c 版）是对初始 v1 协议的轻微改进，但仍然是一种“老派”数据收集方法 - SNMP 查询和响应都是通过 UDP 以明文传输的。它使用密码短语（称为*社区字符串*）进行安全保护，但这也是以明文发送的，因此工具如 Ettercap 可以轻松收集这些信息 - 即使通常建议使用“长且复杂”的字符串，也无法保护您，如果攻击者可以轻松地复制并重用它们。此外，默认的社区字符串（只读访问为 public，读写访问为 private）通常保持不变，因此只需使用这些字符串进行查询，通常就可以为攻击者带来良好的结果。通常建议在目标设备上使用 ACL 来保护对 SNMP 的访问。但是，考虑到进行 ARP 欺骗攻击的简单性，位置良好的攻击者也可以轻松绕过这些 ACL。

SNMPv3 是该协议的最新版本，增加了一个非常受欢迎的加密功能。与 SNMPv2c 提供的“只读或读/写”访问控制相比，它还具有更加细致的访问控制方法。

正如我们之前提到的，SNMP（任一版本）可用于向目标设备“轮询”信息。此外，该设备可以向 SNMP 服务器或日志收集器发送未经请求的 SNMP“陷阱”。SNMP 轮询使用`161/udp`，而 SNMP 陷阱发送到`162/udp`（尽管可以配置为使用 TCP）。

在涵盖了一些背景知识之后，让我们来做一些示例查询。

### 基本的 SNMP 查询

在 Linux 中进行命令行查询之前，您可能需要安装`snmp`软件包：

```
$ sudo apt-get install snmp
```

现在，我们可以进行一个示例查询。在我们的第一个示例中，我正在收集实验室交换机的 IOS 版本：

```
$ snmpget –v2c –c <snmpstring> 192.168.122.7 1.3.6.1.2.1.1.1.0
iso.3.6.1.2.1.1.1.0 = STRING: "SG550XG-8F8T 16-Port 10G Stackable Managed Switch"
```

要收集系统正常运行时间，以秒和人类可读的时间戳，使用以下命令：

```
$ snmpget -v2c -c <snmpstring> 192.168.122.7 1.3.6.1.2.1.1.3.0
iso.3.6.1.2.1.1.3.0 = Timeticks: (1846451800) 213 days, 17:01:58.00
```

接口的统计数据呢？让我们从名称开始：

```
snmpget -v2c -c <snmpstring> 192.168.122.7 .1.3.6.1.2.1.2.2.1.2.2
iso.3.6.1.2.1.2.2.1.2.2 = STRING: "TenGigabitEthernet1/0/2"
```

然后，我们可以获取进出的数据包（单播）：

```
$ snmpget -v2c -c <snmpstring> 192.168.122.7 .1.3.6.1.2.1.2.2.1.11.2
iso.3.6.1.2.1.2.2.1.11.2 = Counter32: 4336153
$ snmpget -v2c -c public 192.168.122.7 .1.3.6.1.2.1.2.2.1.17.2
iso.3.6.1.2.1.2.2.1.17.2 = Counter32: 5940727
```

您明白了吧 - 几乎每个常见参数都有一个 OID。但我们如何保持这些参数的清晰？

首先，这是在 RFC 1213 中标准化的，MIB-2 是大多数供应商支持的最新一组定义，作为“最低公共分母”实现。其次，该定义是分层的。这显示了基本树的“顶部”，其中突出显示了**mib-2**的 OID：

![图 12.2 - SNMP OID 树，显示 mib-2](img/B16336_12_002.jpg)

图 12.2 - SNMP OID 树，显示 mib-2

当有一组接口时，将会有一个计数，然后是每个接口统计的表（按接口索引）。如果使用`snmpwalk`而不是`snmpget`，您可以收集整个列表，以及每个条目的所有子参数。这显示了 mib-2 的`ifTable`（接口表）部分的开头：

![图 12.3 - SNMP OID 树，显示接口信息（ifTable）](img/B16336_12_003.jpg)

图 12.3 - SNMP OID 树，显示接口信息（ifTable）

此外，他们维护了每个供应商的 OID 起始点列表，每个供应商都有其自定义的项目树。 OID 树的**private**分支的顶部显示在此处。请注意，在树的顶部，您往往会发现一些可能已被收购或由于某种原因在企业环境中不再常见的组织：

![图 12.4 - SNMP OID 树，显示供应商 OID 部分](img/B16336_12_004.jpg)

图 12.4 - SNMP OID 树，显示供应商 OID 部分

这个模型或多或少地很好地结合在一起，各种设备维护着它们的各种计数器，等待一个有效的服务器来查询这些值。

如果您有一个起点，您可以使用`snmpwalk`命令遍历从该点向下的 OID 树（请参阅*SNMPv3*部分以获取示例）。不用说，这可能会变成一个混乱的业务，“找到我真正想要的数字”，分散在数百行文本中。

此外，正如您所看到的，SNMP 树中的每个“节点”都有名称。如果您有适当的定义，您可以按名称而不是 OID 进行查询。您可能已经在 Linux 主机上安装了 MIB-2 定义，因此您也可以导入和管理供应商的 MIB 定义。安装或管理各种 MIB 定义的简单方法是使用`snmp-mibs-downloader`软件包（使用我们熟悉的`apt-get install`方法安装此软件包）。

要安装供应商的 MIB，我们可以使用 Cisco（作为示例）。安装`snmp-mibs-downloader`后，编辑`/etc/snmp-mibs-downloader/snmp-mibs-downloader.conf`文件，并将`cisco`指示符添加到`AUTOLOAD`行。现在这行应该是这样的：

```
AUTOLOAD="rfc ianarfc iana cisco"
```

cisco MIB 的收集位置和方式的定义在`/etc/snmp-mibs-downloader/cisco.conf`中：

```
# Configuarions for Cisco v2 MIBs download from cisco.com
#
HOST=ftp://ftp.cisco.com
ARCHIVE=v2.tar.gz
ARCHTYPE=tgz
ARCHDIR=auto/mibs/v2
DIR=pub/mibs/v2/
CONF=ciscolist
DEST=cisco
```

各个 MIB 定义在`/etc/snmp-mibs-downloader/ciscolist`中 - 正如您所看到的，这个文件太长了，无法在这里列出：

```
# cat :/etc/snmp-mibs-downloaderciscolist | wc -l
1431
```

更新了`snmp-mibs-downloader.conf`文件后，只需运行以下命令：

```
# sudo download-mibs
```

您将看到每个 MIB 文件都被下载（共 1,431 个文件）。

现在加载了 MIB 文本描述（默认在安装`snmp-mibs-downloader`后加载），您现在可以使用文本描述查询 SNMP - 在这种情况下，我们将查询实验交换机的`sysDescr`（系统描述）字段：

```
snmpget -Os -c <snmpstring> -v2c   192.168.122.5 SNMPv2-MIB::sysDescr.0
sysDescr.0 = STRING: SG300-28 28-Port Gigabit Managed Switch
```

即使使用描述性字段名称，这个过程也会非常快速地变得非常复杂 - 这就是**网络管理系统**（**NMS**）的用武之地。大多数 NMS 系统都有一个点对点的 Web 界面，您可以从 IP 开始，然后通过接口或其他统计数据深入查询所需的信息。然后以图形方式呈现这些信息，通常随着时间的推移。大多数更好的 NMS 系统将弄清楚设备是什么，并创建您通常想要的所有图表，而无需进一步提示。

**这是哪里出了问题？**

SNMPv2 的明文性质是一个持续的问题 - 许多组织简单地没有转向更安全的传输 SNMPv3。

更糟糕的是，许多组织仍然继续使用默认的 SNMP 社区字符串；也就是说，“public”和“private”。在几乎所有情况下，没有必要对 SNMP 进行读写访问，但人们还是进行了配置。这种情况变得更糟糕的是，不仅可以通过读/写访问关闭接口或重新启动设备，而且还可以通过该访问通常检索完整的设备配置 - 甚至有一个 nmap 脚本来检索 Cisco IOS 运行配置。

在操作上，如果您查询设备上的每个接口和统计信息，通常会影响该设备的 CPU。从历史上看，特别是在交换机上，如果您查询每个接口，您将（在操作系统的某个版本上）发现内存泄漏错误。这些错误可能非常严重，以至于您可以绘制内存利用率并看到这些查询不返回几个字节的情况下直线增加，最终导致设备没有足够的内存运行。

因此，这些是明显的建议。使用 SNMPv3，限制对已知服务器的 SNMP 访问，并仅查询您需要的接口。在防火墙和路由器上，这可能包括所有接口，但在交换机上，您通常只查询上行链路和关键服务器的接口 - 特别是虚拟化程序。

有了一些理论知识，让我们来构建一个流行的基于 Linux 的 NMS - LibreNMS。

## SNMP NMS 部署示例 - LibreNMS

LibreNMS 是一个从 Nagios NMS 分叉出来的 NMS（现在主要是商业产品），对于一个免费的 NMS 应用来说，它相当全面。更重要的是，将您的设备注册的学习曲线非常简单，安装也可以大大简化。

首先，LibreNMS 的安装文档非常完整，涵盖了各种数据库、网站和其他依赖组件。我们不会在这里涵盖这些说明，因为它们会随着版本的更改而改变；最好的来源是供应商下载页面。

但与其从头开始安装，通常更简单的方法是使用任何一个预安装的映像并从那里开始。VMware 和 Hyper-V 都是非常普遍的虚拟化程序，并且是许多企业的主要计算平台。对于这些，LibreNMS 在预打包的**Open Virtualization Format**（**OVA**）文件中有一个完整的 Ubuntu 安装。实际上，正如其名称所示，该文件类型几乎普遍支持部署预构建的 VM 映像。

在本章的示例中，您可以下载并导入 LibreNMS 的 OVA 文件。您要查询的设备可能与示例中的不同，这取决于您的环境中有什么，但核心概念将保持不变。部署 NMS 的一个很大的副作用是，就像日志和日志警报一样，您可能会发现您不知道的问题 - 从过热的 CPU 到接口以最大或“接近最大”容量运行的一切问题。

### 虚拟化程序的具体信息

确保您部署 LibreNMS VM 的网络可以访问您将要监视的设备。

在 VMware 中，该 VM 的默认磁盘格式为“thin provisioned”。这意味着虚拟磁盘将从足够容纳其上的文件的大小开始，并且随着文件存储的需求增加而增长。这对于实验/测试 VM 来说是可以的，但在生产中，您几乎总是希望有一个“thick provisioned”磁盘 - 您不希望服务器意外“增长”并耗尽存储空间。这永远不会有好结果，特别是如果您在同一数据存储中有多个 thin-provisioned 服务器！

部署后，您需要使用`librenms`帐户登录 - 该密码会随着版本的更改而更改，因此请务必参考您下载的文档。登录后，请注意该帐户具有 root 权限，因此请使用`passwd`命令更改`librenms`的密码。

使用`ip address`命令获取当前 IP 地址（参见*第二章*，*基本 Linux 网络配置和操作 - 使用本地接口*）。考虑到这台主机将使用 SNMP 监视关键设备，并且您可能希望为这些设备中的每一个添加 ACL 以限制对 SNMP 的访问 - 鉴于您可能希望手动设置 IP 地址、子网掩码、网关和 DNS 服务器为静态值。您可以使用静态 DHCP 预留或者在服务器上静态分配它 - 选择您组织的标准方法。

完成后，使用 HTTP 而不是 HTTPS 浏览到该地址。考虑到该服务器上的信息的敏感性，我建议安装证书并强制使用 HTTPS，但我们不会在本章中涵盖这一点（尽管 LibreNMS 文档在这方面做得很好）。Web 登录也是`librenms`，但是默认密码将不同；同样，请查阅您下载的文档。

现在您应该看到一个**编辑仪表板**的启动屏幕：

![图 12.5 - LibreNMS 编辑仪表板启动屏幕](img/B16336_12_005.jpg)

图 12.5 - LibreNMS 编辑仪表板启动屏幕

在继续之前，请点击屏幕右上角的`librenms`账户图标：

![图 12.6 - LibreNMS“账户”和“系统”图标](img/B16336_12_006.jpg)

图 12.6 - LibreNMS“账户”和“系统”图标

然后，也更新 Web 账户的密码：

![图 12.7 - 在 LibreNMS 中更改默认密码](img/B16336_12_007.jpg)

图 12.7 - 在 LibreNMS 中更改默认密码

服务器已经运行起来了，让我们来看看如何添加一些设备进行管理。

### 设置基本的 SNMPv2 设备

要添加最基本的设备，您需要转到该设备。您需要启用 SNMP（在本例中是第 2 版），然后添加一个社区字符串，希望还添加一个 ACL 来限制访问。例如，在典型的思科交换机上，会是这样的：

```
ip access-list standard ACL-SNMP
 permit 192.168.122.174
 deny   any log
snmp-server community ROSNMP RO ACL-SNMP
```

就是这样！请注意，我们在 SNMP 社区字符串中使用了`ROSNMP` - 这对于生产环境来说太简单了。另外，请注意`RO`参数确保该字符串只允许只读权限。

现在，在 LibreNMS 中，从主仪表板中选择**设备** > **添加设备**：

![图 12.8 - 在 LibreNMS 中添加设备](img/B16336_12_008.jpg)

图 12.8 - 在 LibreNMS 中添加设备

填写您设备的 IP 地址，以及社区字符串。您的屏幕应该看起来像这样（当然要用您自己设备的 IP 地址）：

![图 12.9 - 在 LibreNMS 中添加设备详细信息](img/B16336_12_009.jpg)

图 12.9 - 在 LibreNMS 中添加设备详细信息

现在，您可以通过选择**设备** > **所有设备**，然后点击您的设备来浏览刚刚添加的设备。

请注意，LibreNMS 已经开始绘制 CPU 和内存利用率，以及每个已启用接口的流量。这里显示了网络设备（在本例中是防火墙）的默认页面：

![图 12.10 - 在 LibreNMS 中收集的设备统计信息](img/B16336_12_010.jpg)

图 12.10 - 在 LibreNMS 中收集的设备统计信息

当您深入了解任何特定的可点击链接或图表时，将显示有关收集统计信息的更多详细信息。通常，甚至将鼠标悬停在链接上也会显示详细信息 - 在这种情况下，将鼠标悬停在`vmx0`链接上，将显示有关该特定接口的详细信息：

![图 12.11 - 在 LibreNMS 中悬停在接口上以获取接口详细信息](img/B16336_12_011.jpg)

图 12.11 - 在 LibreNMS 中悬停在接口上以获取接口详细信息

我们已经讨论过部署 SNMPv2 是有风险的，因为它是明文传输和简单认证。让我们通过改用 SNMPv3 来解决这个问题。

## SNMPv3

配置 SNMP 版本 3 并不复杂。在大多数情况下，我们采用默认的“只读”SNMP 视图，只需添加用于身份验证的密码和加密密钥。在设备端，这是 Cisco IOS 配置的一个示例：

```
ip access-list standard ACL-SNMP
    permit 192.168.122.174
    deny   any log
snmp-server view ViewDefault iso included 
snmp-server group GrpMonitoring v3 priv read ViewDefault access ACL-SNMP
snmp-server user snmpadmin GrpMonitoring v3 auth sha AuthPass1 priv aes 128 somepassword
```

关键参数如下：

![](img/B16336_12_Table_05.jpg)

我们可以使用`snmpwalk`或`snmpget`命令进行测试。例如，`snmpwalk`命令提取系统描述值（请注意，我们将需要 ACL-SNMP 访问列表中的调用站点的 IP）：

```
$ snmpwalk -v3 -l authPriv -u snmpadmin -a SHA -A AuthPass1 -x AES -X somepassword 192.168.122.200:161 1.3.6.1.2.1.1.1.0
iso.3.6.1.2.1.1.1.0 = STRING: "Cisco IOS Software, CSR1000V Software (X86_64_LINUX_IOSD-UNIVERSALK9-M), Version 15.5(2)S, RELEASE SOFTWARE (fc3)
Technical Support: http://www.cisco.com/techsupport
Copyright (c) 1986-2015 by Cisco Systems, Inc.
Compiled Sun 22-Mar-15 01:36 by mcpre"
```

在 NMS 端，只需匹配我们在设备上使用的各种配置密码和参数即可：

![图 12.12 - 使用 SNMPv3 将设备添加到 LibreNMS 库存中](img/B16336_12_012.jpg)

图 12.12 - 使用 SNMPv3 将设备添加到 LibreNMS 库存中

注册后，我们可以通过编辑设备来修复设备名称，然后将设备名称更改为更容易记住的内容，并添加 IP 覆盖（NMS 将使用该 IP 进行访问）。当然，如果设备有 DNS 名称，那么使用其 FQDN 进行注册也可以。但是，如果您需要 NMS 进行故障排除时 DNS 可能不可用，依赖 DNS 可能会成为一个问题 - 实际上，您可能正在解决 DNS 问题！

![图 12.13 - 在 LibreNMS 中更改设备名称并添加"覆盖 IP"](img/B16336_12_013.jpg)

图 12.13 - 在 LibreNMS 中更改设备名称并添加"覆盖 IP"

请注意，即使我们已经添加了真正的身份验证（在传输中使用哈希密码）和授权（通过添加授权到访问级别），以及对实际数据的加密，我们仍然添加了一个普通的访问列表来保护路由器上的 SNMP 服务。 "深度防御"的口头禅让我们认为，最好总是假设一个或多个保护层可能在某个时候被破坏，因此向任何目标服务添加更多的防御层将更好地保护它。

我们可以通过使用 SNMPv3 将其用于发送加密的 SNMP 陷阱消息来扩展 SNMPv3 的使用，以替换明文 syslog 日志记录。这在某种程度上使我们的日志服务变得复杂，但是非常值得！

SNMPv3 还提供了其他安全配置；您的平台的 CIS 基准通常是一个很好的参考。如果您只想深入了解，或者如果您的路由器或交换机没有基准或来自供应商的良好安全指导，那么 Cisco IOS 的 CIS 基准是一个很好的起点。

除了提供额外的保护之外，SNMP 版本 2 和 3 之间的基本 SNMP 功能几乎保持不变。一旦在 NMS 中注册，使用 SNMPv2 和 SNMPv3 的设备在系统中的操作或外观方式没有任何显着的不同。

现在我们正在使用 SNMP 监视所有各种网络连接的设备和服务器，我们可以使用 NMS 的轮询引擎添加警报以监视关闭的设备或服务吗？

### 警报

您将想要做的主要事情之一是添加一些警报以配合您的统计数据。例如，如果您转到**警报** > **警报规则**并单击**从收集创建规则**，您将看到此屏幕：

![图 12.14 - LibreNMS 中的默认警报收集](img/B16336_12_014.jpg)

图 12.14 - LibreNMS 中的默认警报收集

让我们添加一个警报，当任何接口利用率超过 80%时触发。要查看默认收集中是否有类似的内容，请在*搜索*字段中键入`utili` - 随着您的输入，搜索结果将被缩小：

![图 12.15 - 在 LibreNMS 中添加警报](img/B16336_12_015.jpg)

图 12.15 - 在 LibreNMS 中添加警报

选择规则；我们将得到一些选项：

![图 12.16 - LibreNMS 中的警报规则选项](img/B16336_12_016.jpg)

图 12.16 - LibreNMS 中的警报规则选项

从顶部开始，您应该重命名规则。如果您决定导入默认规则集，您不希望因为尝试使用重复的规则名称而导致失败。通常，我会将自定义规则命名为以下划线字符开头；这可以确保它们在排序时始终位于规则列表的顶部。由于我们正在复制收集中的内容，我们也可以轻松地更改触发警报的百分比。

关于**匹配设备、组和位置列表**，情况变得棘手。目前，匹配列表中没有任何内容，**除列表中的所有设备**设置为**关闭**，因此此规则不会匹配任何内容。让我们选择我们的设备：

![图 12.17-在 LibreNMS 中匹配设备和组的警报规则](img/B16336_12_017.jpg)

图 12.17-在 LibreNMS 中匹配设备和组的警报规则

现在，保存规则。是的，就是这么简单！

你是否注意到前面菜单中的**组**选择了吗？使用设备组是将一个规则分配给所有相似设备的好方法 - 例如，您可能对路由器或交换机端口设置不同的端口阈值。这是因为增加路由器的 WAN 链路速度可能需要几周的时间，而改变交换机端口可能只涉及将电缆从 1G 端口移动到 10G 端口（例如）。因此，在这种情况下，对所有路由器设置一个规则（可能为 60%），对所有交换机设置一个不同的规则（设置为更高的数字）是很有道理的。

探索规则 - 您会看到许多您可能想要启用的规则 - 用于设备或服务宕机的警报，CPU、内存或接口利用率，以及温度或风扇警报。其中一些警报依赖于 syslog - 是的，LibreNMS 确实内置了一个 syslog 服务器。您可以在**概述** > **Syslog**中探索这一点：

![图 12.18-在 LibreNMS 中的 Syslog 显示](img/B16336_12_018.jpg)

图 12.18-在 LibreNMS 中的 Syslog 显示

请注意，您可以进行一些简单的搜索，但这相当简单。这个 syslog 服务器是一个很好的东西，可以用来监视警报 - 这将比我们在本章早些时候设置的警报简单得多。但是，您仍然希望保留我们设置的文本日志，既可以进行更好的搜索，也可以进行长期存储。

当我们向我们的 NMS 添加设备，或者说当我们部署设备并对其进行命名时，有一些事情我们应该牢记。

### 在添加设备时要牢记的一些事情

在添加设备和组时，请务必对其进行命名，特别是设备，以便它们可以逻辑排序。命名约定通常会使用设备类型（例如 FW、SW 或 RT）、位置名称的标准（例如分公司编号）或城市名称的简称（例如 CHI、TOR 和 NYC 代表芝加哥、多伦多和纽约市）。重要的是要保持一致性，规划如何对事物进行排序，并保持名称中各种术语的简短 - 记住，您将要输入这些内容，它们最终也会出现在电子表格列中。

到目前为止，我们已经专注于使用 SNMP 来监视统计信息。现在，让我们监视设备上运行的服务。

### 监视服务

请记住，主机上的服务是需要监视的关键事项。通常会使用 NMS 中类似 nmap 的功能来监视数据库访问、API 和 Web 和 VPN 服务的端口。更高级的监视器将轮询服务并确保从轮询返回的数据是正确的。

在我们监视服务之前，我们需要启用服务检查。SSH 到您的 LibreNMS 主机并编辑`/opt/librenms/config.php`文件。添加以下行：

```
$config['show _services']             =1;
```

您可能还希望取消注释这些`$config`行中的一些或全部内容（以便您可以扫描子网，而不是一次添加一个设备）：

```
### List of RFC1918 networks to allow scanning-based discovery
#$config['nets'][] = "10.0.0.0/8";
#$config['nets'][] = "172.16.0.0/12";
$config['nets'][] = "192.168.0.0/16";
```

现在，我们将通过向`/etc/cron.d/librenms`文件添加以下行来更新应用程序的 cron 调度程序：

```
*/5  *    * * *   librenms    /opt/librenms/services-wrapper.py 1
```

默认情况下，并非所有插件都已安装——事实上，在我的安装中，没有一个插件被安装。像这样安装它们：

```
apt-get install nagios-plugins nagios-plugins-extra
```

现在，我们应该能够添加一个服务。选择`22`）：

![图 12.19–LibreNMS 中监控基本服务](img/B16336_12_019.jpg)

图 12.19–LibreNMS 中监控基本服务

你可以扩展这一点——你是否注意到当你添加第一个服务时，列表中有多少服务检查？让我们为 HTTP 服务添加一个监视器。在这种情况下，我们将在我们的防火墙上观察它。这对于监视 SSL VPN 服务也很方便：

![图 12.20–使用参数在 LibreNMS 中监控 HTTPS 服务](img/B16336_12_020.jpg)

图 12.20–使用参数在 LibreNMS 中监控 HTTPS 服务

请注意，这里的参数很重要。`-S`表示检查应该使用 SSL（或更具体地说是 TLS）。`–p 443`表示轮询的端口。

现在，当我们导航到**服务**页面时，我们将看到我们刚刚添加的两个服务。你可能需要给 LibreNMS 一些时间来轮询它们：

![图 12.21–LibreNMS 中的服务显示](img/B16336_12_021.jpg)

图 12.21–LibreNMS 中的服务显示

可以直接从**服务配置**页面的下拉菜单中查看所有可用插件的完整列表：

![图 12.22–LibreNMS 中可用的服务检查](img/B16336_12_022.jpg)

图 12.22–LibreNMS 中可用的服务检查

一些常用的检查包括以下内容：

![](img/B16336_12_Table_06.jpg)

所有这些检查的参数文档位于[`www.monitoring-plugins.org/doc/man/index.html`](https://www.monitoring-plugins.org/doc/man/index.html)。

这大致涵盖了 LibreNMS 系统的基本操作。现在，让我们继续收集和分析流量。我们不会使用数据包捕获，而是使用 NetFlow 协议系列将高级流量信息聚合成“流”。

# 在 Linux 上收集 NetFlow 数据

当查看接口吞吐量不够时，你该怎么办？很多时候，那些 SNMP 吞吐量图表会告诉你有问题，但不会带你迈出下一步——是哪种协议或哪些人在消耗所有的带宽？这是我可以通过配置解决的问题，还是我需要制定政策来帮助控制组织中人们的视频习惯，还是我真的需要更多的带宽？

我们如何获得这些信息？这并不像 SNMP 那样容易，但 NetFlow 收集了你可能需要的所有信息，以帮助成为“带宽侦探”。让我们讨论一下它是如何工作的，以及涉及哪些协议。

## 什么是 NetFlow 及其“表兄弟”SFLOW、J-Flow 和 IPFIX？

如果你回忆一下*第三章*，*使用 Linux 和 Linux 工具进行网络诊断*，以及*第十一章*，*Linux 中的数据包捕获和分析*，我们在那里讨论了数据包“元组”，这就是我们将那个概念用于几乎所有事情的地方。NetFlow 是一项服务，它从已识别的接口（通常是路由器、交换机或防火墙）收集流量并对其进行汇总。它几乎总是包括我们在本书前面讨论过的核心元组值的信息：

+   源 IP

+   目标 IP

+   协议（TCP、UDP、ICMP 或其他协议）

+   源端口

+   目标端口

然而，正如我们将在后面看到的，现代 NetFlow 配置可以通过添加以下内容来扩展标准元组值：

+   QOS 信息（TOS 或 DSCP 位）

+   BGP **自治系统**（**AS**）号码

+   TCP 标志（SYN，ACK 等）

TCP 标志是至关重要的，因为第一个数据包（只设置了 SYN 标志）定义了在任何对话中哪个主机是客户端，哪个是服务器。

NetFlow 最初由思科开发，但在 RFC 过程下进行了开发，以允许行业更广泛地采用，除了思科之外，许多供应商也支持 NetFlow。NetFlow 有两个常见的版本-5 和 9-主要区别在于支持的字段数量。经常见到一些“表兄弟”协议：

+   sFlow 由 InMon 开发为开放标准，并有支持 RFC。通常会看到支持 NetFlow 和 sFlow 的网络设备。

+   IPFIX（IP 流信息导出）是另一个开放标准，它建立在 NetFlow v9 的基础上，几乎是 NetFlow v9 的超集。

+   J-Flow 是 Juniper 设备的 NetFlow 等效物，尽管在其最新版本（J-Flow v9）中，它似乎与 IPFIX 相同，并且在 Juniper 的设备特定文档中是这样记录的。

无论您使用哪种协议来导出流信息，接收此信息的系统通常会接收任何或所有这些信息。导出通常在 UDP 端口上进行。虽然在某些情况下，端口将在规范中定义，但它总是可以更改，并且通常会因供应商而异。例如，NetFlow 通常出现在端口`2055`、`2056`、`4432`、`9995`或`9996`上。sFlow 正式定义为端口`6343`，但通常部署在其他端口上。IPFIX 目前并不常见（除了作为 J-Flow v9），但被指定为`4739`端口。

虽然有一些细微差别（特别是 sFlow 在数据收集和汇总方面有一些差异），但结果是相同的。在被汇总后，数据被发送到后端服务器，可以进行查询。在这些数据存储库中，网络管理员寻找与警察侦探相同的事物：

+   谁发送了数据，发送到哪里？（源和目的地 IP）

+   数据是什么（源和特别是目的地端口）

+   它是何时发送的？

+   通常通过定义用于发送数据的应用程序来推断原因-思科的基于网络的应用程序识别（NBAR）附加组件在这方面可能有所帮助，或者您通常可以从目的地端口（在流的服务器端）推断应用程序。

+   每个时间间隔发送了多少数据。

让我们深入了解一下收集、汇总和发送流量数据的工作方式，以及这可能如何影响您在组织网络中的设计和实施。

## 流量收集实施概念

所有这些流量收集协议中的一个关键概念是抽样。所有这些协议在其配置中都具有“每 y 个数据包抽样 x 个数据包”的属性，各种供应商和平台具有不同的默认值。例如，较新的路由器通常会将默认采样率设置为 100％，因为它们通常是较低带宽平台（通常低于 100 Mbps），并且具有 CPU 来支持该收集速率。在 1G、10G 或更快的交换机上，这种速率通常不实用-在这些情况下，以合理的速率进行抽样变得至关重要。

在实施方面，选择接口也很关键。与 SNMP 一样，在大型交换机的所有端口上收集流量信息可能会严重影响交换机的 CPU（以及其整体吞吐量）。不过，您的情况可能有所不同，因为高端交换机通常会将遥测功能卸载到专用硅上，以减少主机机箱 CPU 的使用。

选择收集拓扑结构也很重要。例如，在数据中心/总部/分公司的情况下，如果大部分流量是“中心和辐射”（即，分公司之间的通信很少），您可能只会在中心位置收集流量数据，并将流量收集器放在同一中心位置。在这种情况下，分公司流量简单地是总部流量的倒数，因此第二次发送该流量，通过您为带宽付费的 WAN，通常是不明智的。

唯一的例外是 VoIP。如果您回忆一下第十一章《Linux 中的数据包捕获和分析》，呼叫设置使用 SIP 协议，位于电话机和 PBX 之间。但呼叫本身使用 RTP，直接从一个电话机到另一个电话机。如果分支之间的 VoIP 通信量很大，您可能还会选择监视分支路由器的 WAN 接口。

最后，请记住，虽然这些数据是抽样和聚合的，但最终它们会到达服务器并且必须存储在磁盘上，这往往会很快积累起来。您可能会发现，随着您在保留多少信息以创建有意义的报告方面的“摸索”，您可能需要经常增加您的分区或数据库大小（不幸的是，总是增加）。

同样地，随着数据量的增长，对内存和 CPU 的需求也会增加。您可能会发现，在数据库中偶尔添加索引可以加快报告或 Web 界面本身的速度。不幸的是，添加索引通常会增加额外的磁盘和内存需求，所以也要记住这一点。随着您深入研究这一需求的过程，您会发现您的数据库管理技能会随着时间的推移而增长，并且最终可能会帮助您优化其他以数据库为中心的应用程序。

总是会有一种诱惑，即将 syslog、SNMP 和流量收集合并到一个单一的网络管理服务器上。虽然合并 syslog 和 SNMP 是一件常见的事情，但如果 NMS 使用数据库来记录信息，您可能会希望有一个单独的基于文本的日志存储库，这样可以使您的长期日志存储过程变得简单。关于流量收集，您几乎总是会将其放在一个单独的服务器上。在较小的环境中，您可能会采用“一体化”方法，但即使在许多小型环境中，您会发现流量收集的资源远远超过其他两个功能。此外，对后端数据库的依赖和入站数据的高速率意味着这可能会使您的流量收集服务器异常“脆弱” - 您可能会发现您需要每年一两次重建此服务器以解决“无法解释”的问题。此外，由于这个原因，您会发现组织普遍会在发生这种情况时切换到不同的应用程序或数据库平台（除非涉及商业许可），只是因为到那时，他们会知道他们不喜欢以前的构建，而且由于有了重建，测试下一个解决方案的门槛很低。

在涵盖了所有这些基本流信息之后，让我们为真实情况构建一个 NetFlow 解决方案，从一个典型的路由器开始。

## 配置路由器或交换机进行流量收集

首先，我们将定义我们要收集的内容。首先，我们想要我们的标准元组信息 - 源和目的 IP、协议和端口信息。我们还将添加 QoS 信息（`ipv4 tos`行），以及方向和路由信息（如果可能的话，`as`信息是 BGP 自治系统信息）。在这个定义中，我们还有`应用程序名称`。这主要是用于如果您还在运行 Cisco 的 NBAR 附加组件。NBAR 设置在接口上（您将在下一页看到），并帮助通过其组成的网络流量识别应用程序的名称。

```
flow record FLOW-RECORD-01
  match ipv4 tos
  match ipv4 protocol
  match ipv4 source address
  match ipv4 destination address
  match transport source-port
  match transport destination-port
  match application name
  match flow direction
  match interface input
  match interface output
  collect routing source as
  collect routing destination as
  collect transport tcp flags
  collect counter bytes
  collect counter packets
```

接下来，我们将定义流出口。这告诉系统从哪里发送流信息以及从哪个接口发送。流源很重要，因为如果发生变化，它将看起来像 NetFlow 服务器上的另一个设备。还要注意，我们在此部分中定义了一个接口表，它将发送足够的接口信息以帮助定义服务器上的主机和接口特性。请注意，流目的地端口几乎总是 UDP，但端口号没有标准化。供应商通常有自己的默认值，并且在我看到的所有实现中，该端口号是可配置的：

```
flow exporter FLOW-EXPORT-01
  destination 10.17.33.187
  source GigabitEthernet0/0/0
  transport udp 9996
  template data timeout 120
  option interface-table
  option exporter-stats timeout 120
  option application-table timeout 120
```

如您在定义中所见，流量监视器将出口和流记录绑定在一起，以便可以将其作为一个“整体”应用于接口：

```
flow monitor FLOW-MONITOR-01
  exporter FLOW-EXPORT-01
  cache timeout active 60
  record FLOW-RECORD-01
```

在接口上，您将看到我们定义了一个既入站又出站的流量监视器。请注意，您可以定义多个记录器和监视器。通常，只有一个流出口（因为通常对于任何给定的设备，只有一个流目的地）：

`带宽`语句通常用于帮助定义 OSPF 或 EIGRP 路由协议中的路由器指标。在流量收集的情况下，定义带宽通常会自动配置各种流图的每个接口的总带宽。定义每个物理接口的总带宽是关键的，这样每个图表都有准确的上限，并且随后将显示聚合和特定元组统计的准确百分比：

```
Interface Gigabit 0/0/1
  bandwidth 100000
  ip nbar protocol-discovery
  ip flow monitor FLOW-MONITOR-01 input
  ip flow monitor FLOW-MONITOR-01 output
```

第 2 层流量收集-例如，在单个交换机端口上-通常要简单得多。例如，在 HP 交换机上，在一个交换机端口上收集 sFlow 数据可能看起来像以下示例。

请注意端口号为`6343`。与 NetFlow 相比，sFlow 将`6343/udp`分配为其默认端口。当然，客户端和服务器端都可以配置为其他值：

```
sflow 1 destination 10.100.64.135 6343
interface <x>
 sflow 1 sampling 23 50
 sflow 1 polling 23 20
interface <y>
 sflow 1 sampling 23 50
 sflow 1 polling 23 20
```

请注意定义的采样率和轮询间隔。还要注意，由于在这种情况下在第 2 层收集流量数据，因此您的元组可能会受到限制，这取决于交换机型号。这也有助于解释为什么配置要简单得多-除非交换机解构采样帧以获取每个数据包的 L3/L4 信息，否则要收集的信息就会更少。

构建了路由器配置后，让我们继续构建和配置此方程式的服务器端。

## 使用 NFDump 和 NFSen 的示例 NetFlow 服务器

NFDump 和**NetFlow Sensor**（**NFSen**）是流量收集世界的良好入门级工具。特别有趣的是，NFDump 使用自己的文件格式，并且命令行工具在操作上与 tcpdump 非常相似（我们在*第十一章*中介绍了 Linux 中的*数据包捕获和分析*）。因此，如果您喜欢我们在该章节中的过滤讨论和示例，那么使用 NFDump 工具进行“top n”类型的统计和报告将非常合适！

NFCapd 是一个流量收集器应用程序。我们将在前台和后台运行它。

NFSen 是 NFDump 的简单 Web 前端。

我们将在独立的 Linux 主机上运行此操作；您可以使用我们在整本书中一直在使用的 Ubuntu VM 或物理主机。让我们首先安装`nfdump`软件包（这将为我们提供几个与 NetFlow 相关的命令）：

```
$ sudo apt-get install nfdump
```

现在，编辑`/etc/nfdump/.default.conf`文件并更改顶部的`options`行：

```
options='-l /var/cache/nfdump/live/source1 -S 1 -p 2055'
```

这将把数据放在我们的 NFSen 服务器稍后期望的位置。`-S`参数告诉 NFCapd 进程（我们将作为守护进程运行）将日期戳附加到路径上。因此，对于 2021 年 6 月 23 日，我们捕获的所有 NetFlow 数据将在目录中：

```
/var/cache/nfdump/live/source1/2021/06/23
```

正如您所期望的那样，这些数据往往会迅速积累，这可能会有风险，因为`/var`也是存储日志和其他重要系统数据的地方。在生产中，我建议您为此单独设置一个分区，并将路径的根目录设置为不同的内容，也许是`/netflow`。这样，如果您的 NetFlow 容量填满，其他系统服务不会直接受到影响。

`-p`参数定义了我们的`nfcapd`进程将监听的端口-默认的`2055`在大多数情况下应该很好用，但根据需要进行更改。

现在，我们可以开始将 NetFlow 流量定向到此收集器 IP，使用端口`2055/udp`。几分钟后，我们可以使用`nfdump`查看 NetFlow 数据。数据文件存储在`/var/cache/nfdump/live/source1/`中（从那里跟踪到今天的日期）。

让我们查看一个文件的前几行：

```
nfdump -r nfcapd.202106212124 | | head
Date first seen          Event  XEvent Proto      Src IP Addr:Port          Dst IP Addr:Port     X-Src IP Addr:Port        X-Dst IP Addr:Port   In Byte Out Byte
1970-01-01 00:00:00.000 INVALID  Ignore TCP     192.168.122.181:51702 ->     52.0                                      .134.204:443            0.0.0.0:0     ->          0.0.0.0:0           460                                              0
1970-01-01 00:00:00.000 INVALID  Ignore TCP      17.57.144.133:5223  ->  192.168                                      .122.140:63599          0.0.0.0:0     ->          0.0.0.0:0          5080                                              0
```

请注意，每行都换行了。让我们只看元组信息和每个样本间隔移动的数据量。我们将去掉列标题：

```
$ nfdump -r nfcapd.202106212124 | head | tr -s " " | cut -d " " -f 5,6,7,8,10,12,13 | grep –v Port
TCP 192.168.122.181:51702 -> 52.0.134.204:443 -> 460 0
TCP 17.57.144.133:5223 -> 192.168.122.140:63599 -> 5080 0
TCP 192.168.122.140:63599 -> 17.57.144.133:5223 -> 980 0
TCP 192.168.122.181:55679 -> 204.154.111.118:443 -> 6400 0
TCP 192.168.122.181:55080 -> 204.154.111.105:443 -> 920 0
TCP 192.168.122.151:51201 -> 151.101.126.73:443 -> 460 0
TCP 31.13.80.8:443 -> 192.168.122.151:59977 -> 14500 0
TCP 192.168.122.151:59977 -> 31.13.80.8:443 -> 980 0
TCP 104.124.10.25:443 -> 192.168.122.151:59976 -> 17450 0
```

现在，我们开始看起来像是信息了！让我们通过添加`-b`来聚合双向流量。我们还将从目录中可用的所有文件中读取。现在的列是`Protocol`，`Src IP:Port`，`Dst IP:Port`，`Out Pkt`，`In Pkt`，`Out Byte`，`In Byte`和`Flows`。请注意，在某些情况下，我们在该时间段有一个活动流，但没有数据进出：

```
$  nfdump -b -R /var/cache/nfdump | head | tr -s " " | cut -d " " -f 4,5,6,7,8,10,12,13 | grep -v Port
UDP 192.168.122.174:46053 <-> 192.168.122.5:161 0 0 1
TCP 52.21.117.50:443 <-> 99.254.226.217:44385 20 1120 2
TCP 172.217.1.3:443 <-> 99.254.226.217:18243 0 0 1
TCP 192.168.122.181:57664 <-> 204.154.111.113:443 0 0 1
TCP 192.168.122.201:27517 <-> 52.96.163.242:443 60 4980 4
UDP 8.8.8.8:53 <-> 192.168.122.151:64695 0 0 1
TCP 23.213.188.93:443 <-> 99.254.226.217:39845 0 0 1
TCP 18.214.243.14:443 <-> 192.168.122.151:60020 20 1040 2
TCP 40.100.163.178:443 <-> 99.254.226.217:58221 10 2280 2
```

让我们查看来自一个 IP 地址的流量：

```
$  nfdump -b -s ip:192.168.122.181 -R /var/cache/nfdump | grep -v 1970
Command line switch -s overwrites -a
Top 10 IP Addr ordered by -:
Date first seen          Duration Proto           IP Addr    Flows(%)     Packets(%)       Bytes(%)         pps       bps   bpp
2021-06-21 21:42:19.468   256.124 UDP      34.239.237.116        2( 0.0)       20( 0.0)     1520( 0.0)        0       47    76
2021-06-21 21:29:40.058    90.112 TCP      204.79.197.219        4( 0.1)       80( 0.0)    12000( 0.0)        0     1065   150
2021-06-21 21:31:15.651   111.879 TCP      204.79.197.204        6( 0.1)      110( 0.0)    44040( 0.0)        0     3149   400
2021-06-21 21:39:42.414    58.455 TCP      204.79.197.203        7( 0.1)      150( 0.0)    92530( 0.0)        2    12663   616
2021-06-21 21:28:21.682  1046.074 TCP      204.79.197.200       18( 0.2)      570( 0.1)   288990( 0.1)        0     2210   507
2021-06-21 21:31:24.158    53.392 TCP     209.191.163.209       13( 0.2)      180( 0.0)    86080( 0.0)        3    12897   478
```

数据已经包装，但您可以看到这变得越来越有用。这不是完整的数据包捕获，但在许多天里，这是您可能需要的所有数据包捕获信息！

`-s`（统计）参数非常有用，因为您可以查询扩展元组中收集的任何可能的 NetFlow 信息。`-A`允许您在相同的扩展信息上进行聚合，而`-a`仅在基本的 5 元组上进行聚合。请注意，当您设置了`-b`时，您无法对源 IP 或目标 IP 进行聚合（因为`-b`已经对这两个进行了聚合）。

通常，您需要收集特定时间窗口的信息；也就是说，在出现问题或症状时。在这些情况下，`-t`（timewin）是您的朋友-让我们在 21:31 和 21:32 之间查看，仍然只针对该 IP 地址。再次注意，您需要根据您的日期和流量模式进行修改：

```
$  nfdump -b -s ip:192.168.122.181 -t 2021/06/21.21:31:00-2021/06/21.21:32:59 -R /var/cache/nfdump
Command line switch -s overwrites -a
Top 10 IP Addr ordered by -:
Date first seen          Duration Proto           IP Addr    Flows(%)     Packets(%)       Bytes(%)         pps       bps   bpp
2021-06-21 21:32:43.075     0.251 IGMP         224.0.0.22        1( 0.1)       20( 0.0)      920( 0.0)       79    29322    46
2021-06-21 21:32:09.931     0.000 UDP     239.255.255.251        1( 0.1)       10( 0.0)      640( 0.0)        0        0    64
2021-06-21 21:31:07.030    47.295 UDP     239.255.255.250        4( 0.3)       60( 0.1)    18790( 0.0)        1     3178   313
2021-06-21 21:31:15.651     0.080 TCP      204.79.197.204        3( 0.2)       60( 0.1)    21220( 0.0)      750    2.1 M   353
2021-06-21 21:31:24.158    53.392 TCP     209.191.163.209       13( 0.9)      180( 0.2)    86080( 0.1)        3    12897   478
2021-06-21 21:31:09.920     0.252 TCP      52.207.151.151        4( 0.3)      170( 0.2)   142280( 0.2)      674    4.5 M   836
2021-06-21 21:32:12.799    11.421 TCP       52.95.145.171        7( 0.5)      110( 0.1)    22390( 0.0)        9    15683   203
2021-06-21 21:31:53.512     0.054 TCP     162.159.136.232        4( 0.3)       50( 0.1)     5250( 0.0)      925   777777   105
2021-06-21 21:31:11.890    51.148 TCP        209.15.45.65        5( 0.4)       60( 0.1)    32020( 0.1)        1     5008   533
2021-06-21 21:31:07.531    69.964 TCP        69.175.41.15       22( 1.6)      460( 0.5)   222720( 0.4)        6    25466   484
Summary: total flows: 1401, total bytes: 58.9 M, total packets: 85200, avg bps: 4.0 M, avg pps: 716, avg bpp: 691
Time window: 2021-06-21 21:26:17 - 2021-06-21 21:58:40
Total flows processed: 8052, Blocks skipped: 0, Bytes read: 516768
Sys: 0.003s flows/second: 2153517.0  Wall: 0.002s flows/second: 3454311.5 
```

在一条命令行中，我们总结了一个主机在 2 分钟内进出的所有流量！

在我们的基本功能正常工作后，让我们安装收集器的 Web 界面。这是 NetFlow 数据最常见的消耗方式-通过眼睛很容易看到协议模式中的异常。

以下说明来自[`github.com/mbolli/nfsen-ng`](https://github.com/mbolli/nfsen-ng)（正在安装的应用程序是`nfsen-ng`）：

首先，让我们提升我们的权限到 root-几乎这里的所有内容都需要这些权限：

```
sudo su -
```

安装我们需要的所有软件包：

```
apt install apache2 git nfdump pkg-config php7.4 php7.4-dev libapache2-mod-php7.4 rrdtool librrd-dev
```

启用 Apache 模块：

```
a2enmod rewrite deflate headers expires
```

为 PHP 安装`rrd`库：

```
pecl install rrd 
```

配置 RRD 库和 PHP：

```
echo "extension=rrd.so" > /etc/php/7.4/mods-available/rrd.ini
phpenmod rrd
```

配置虚拟主机以便它可以读取`.htaccess`文件。编辑`/etc/apache2/apache2.conf`文件，并编辑`/var/www`部分中的`Allow Override`行：

```
<Directory /var/www/>
        Options Indexes FollowSymLinks
        AllowOverride All
        Require all granted
</Directory>
```

最后，重新启动 Apache 服务器：

```
systemctl restart apache2
```

现在，我们准备安装`nfsen-ng`并设置文件/目录标志：

```
cd /var/www/html
git clone https://github.com/mbolli/nfsen-ng
chown -R www-data:www-data .
chmod +x nfsen-ng/backend/cli.php
```

仍然使用 root 权限，将默认设置复制到设置文件：

```
cd /var/www/html/nfsen-ng/backend/settings
cp settings.php.dist settings.php
```

编辑生成的`settings.php`文件。

在`nfdump`部分，更新以下行以匹配：

```
    'nfdump' => array(
        'profiles-data' => '/var/cache/nfdump/',
        'profile' => '',
```

请注意，您可以更改这一点，特别是如果您计划按`nfdump`文件的日期进行日志轮换，但这不是我们目前的范围。

现在，让我们测试我们的配置（仍然作为 root 用户）：

```
cd /var/www/html/nfsen-ng/backend
./cli.php -f import
2021-06-22 09:03:35 CLI: Starting import
Resetting existing data...
Processing 2 sources...                                         0.0% 0/2194 ETC: ???. Elapsed: < 1 sec [>                              ]
Processing source source1 (1/2)...
Processing 2 sources...                                 50.0% 1097/2194 ETC: < 1 sec. Elapsed: < 1 sec [===============>               ]
Processing source source2 (2/2)...
Processing 2 sources...                                100.0% 2194/2194 ETC: < 1 sec. Elapsed: < 1 sec [===============================]
```

如果这个过程没有错误，您的配置将看起来很好！

现在，将各种网络设备指向将它们的 NetFlow 结果发送到此主机的 IP 地址，端口为`2055/udp`（请注意，您可以通过编辑`/etc/nfdump/default.conf`来更改此监听端口）。

让我们收集一些数据。您可以通过观察目标目录中的文件大小来验证它是否正常工作。一个“空”文件大小为 276 字节，但一旦开始接收数据，您应该会看到更大的文件。

现在，浏览到您的服务器。由于我们在 apache 中没有做任何花哨的东西，您的 URL 将如下：

```
http://<your server's IP address>/nfsen-ng/frontend/ 
```

现在，让我们看看图形方面的东西。浏览到您的服务器 IP 地址 - URL 应该看起来像[`192.168.122.113/nfsen-ng/frontend/`](http://192.168.122.113/nfsen-ng/frontend/)。当然，您可以通过配置 Apache 重新指向主页来简化此 URL。

您的显示现在应该看起来像这样（您的数据值将有所不同）：

![图 12.23 - 图形显示中的基本流数据，带有 NFSen 中的显示/过滤控件](img/B16336_12_023.jpg)

图 12.23 - 图形显示中的基本流数据，带有 NFSen 中的显示/过滤控件

一个好的方法是选择一个合理的时间尺度，然后使用滑块来扩大或缩小窗口。在这种情况下，我们从一个 24 小时的图表开始，最终显示了大约 6 小时。

这个显示通常会突出显示可能引起关注的时间 - 您可以在这些时间上“放大”这个图表以获得更多细节。

下一站将是**流量**按钮（在显示的右上角）。在这里，一个合理的起始窗口将是一个很好的选择。接下来，选择各种聚合。

通常，您会希望使用目标端口聚合进行协议聚合。接下来，您通常会希望将 IP 地址按源 IP 和目标 IP 进行聚合。添加 NFDUMP 过滤器以获取确切的时间窗口通常也很有帮助。如果可能的话，您可以将显示限制在尽可能短的时间内 - 如果可能的话，几分钟内，您将从这些显示中获得最大的价值：

![图 12.24 - NFSen 中聚合和过滤的流显示控件](img/B16336_12_024.jpg)

图 12.24 - NFSen 中聚合和过滤的流显示控件

最终的选择将取决于您要解决的问题，可能需要尝试几次才能获得您需要的显示以进行最终诊断。

当您的选择完成后，选择**处理数据**以在屏幕的下半部分获得结果：

![图 12.25 - NFSen 中的过滤结果](img/B16336_12_025.jpg)

图 12.25 - NFSen 中的过滤结果

您可能希望将其导出为 CSV，以便在电子表格中进一步操作您的数据。

在真实的事件中，这是什么样子？让我们打开默认窗口，在那里我们会注意到流量可能可疑的“峰值”。我们还可以从帮助台或桌面团队那里获得这个时间段，他们可能有取证信息，IPS 事件（见[*第十三章*]（B16336_13_Final_NM_ePub.xhtml#_idTextAnchor236），*Linux 上的入侵防范系统*），或来自桌面保护应用程序或反恶意软件应用程序的事件。在这个每日视图中，我们可以看到在下午 2:30 之前出现了一个可疑的峰值。请注意，我们使用滑块来放大感兴趣的时间窗口。还要注意，我们正在查看“流量”或“字节”视图 - 数据外泄通常只会发生在一两个流中，因此这些攻击通常会在默认显示中显眼：

![图 12.26 - 发现异常流量“峰值”](img/B16336_12_026.jpg)

图 12.26 - 发现异常流量“峰值”

让我们切换到协议显示并稍微浏览一下。在这个显示中，我们已经将事情简化，只显示 UDP，我们可以看到一些可疑的东西 - 这种 UDP 流量的数量对于这个组织来说并不正常：

![图 12.27 - 协议显示中的显示调整，仅显示 UDP](img/B16336_12_027.jpg)

图 12.27 - 协议显示中的显示调整，仅显示 UDP

有了那个在 14:20 出现的可疑流量峰值，让我们深入一点。让我们添加一个 nfdump 过滤器来查看 UDP，但提取我们在内部 DNS 服务器上配置的所有 DNS 转发器的请求：

![图 12.28 – UDP 搜索结果 – 删除合法的 DNS 流量](img/B16336_12_028.jpg)

图 12.28 – UDP 搜索结果 – 删除合法的 DNS 流量

现在，让我们深入挖掘一下，只看那个可疑的 IP 地址：

![图 12.29 – 过滤可疑 IP 地址](img/B16336_12_029.jpg)

图 12.29 – 过滤可疑 IP 地址

这给我们以下结果，显示了防火墙上 NAT 之前和之后的相同传输，除了这一大数据传输之外没有其他流量：

![图 12.30 – 防火墙上 NAT 之前和之后的可疑流量](img/B16336_12_030.jpg)

图 12.30 – 防火墙上 NAT 之前和之后的可疑流量

观察`53/udp`中的总数，我们知道这通常用于 DNS。

使用 DNS，甚至可以使用有效的查询来外泄数据 – 首先，使用 base64 对数据进行编码，然后以已知的“块”大小进行顺序的“A”记录查询。接收服务器然后重新组装数据并将其解码为原始的二进制格式。如果担心数据包的顺序问题，甚至可以将序列号编码到传输中。

既然我们发现了这次攻击，我们如何在网络层面进行防御呢？

一个很好的起点是为出站流量创建一个合理的访问列表，通常称为出口过滤器。它可能是这样工作的：

+   允许从我们的 DNS 服务器到它们已知的转发器 IP 的`53/udp`和`tcp`。

+   拒绝所有其他的`53/udp`和`tcp`，并将该流量记录为警报。

+   允许`ssh`，`scp`，`ftp`和其他已知的流量通过协议和端口到已知的目标主机。

+   拒绝所有其他主机的这些协议，并将其记录为警报。

+   允许 HTTP 和 HTTPS 到任何 IP（但另外增加一层保护，也许是声誉过滤或内容控制）。

+   拒绝所有其他流量，并将该流量记录为警报。

关键是总会有“下一次攻击” – 但是记录和警报你知道的攻击通常至少会在攻击开始时给你一些警告，通常足够让你采取行动，防止攻击者达到最终目标。

到目前为止，您对使用 NFDUMP 和 NFSEN 组合有一些了解。但是还有哪些开源 NetFlow 收集器应用程序可供您选择？

### 其他开源 NetFlow 替代方案

nProbe 是由 ntop 团队编写的，托管在[`www.ntop.org/products/netflow/nprobe/#`](https://www.ntop.org/products/netflow/nprobe/#)。这允许您在任何主机上安装 NetFlow 收集器。ntop 工具（[`www.ntop.org/products/traffic-analysis/ntop/`](https://www.ntop.org/products/traffic-analysis/ntop/)）是他们的收集器，在 NetFlow 流行之前就为我们提供了许多 NetFlow 的好处，但使用了数据包捕获和分析方法。它已经扩展到支持所有版本的 NetFlow 和 IPFIX。选择 ntop 最吸引人的因素是它是一个单一的安装，所有东西都打包在一起 – 大部分繁琐的配置都已经处理好了。它还以更详细的方式分解数据，甚至在初始的图形界面上也是如此。不足之处是没有命令行工具集；它是一个“一体化”的应用程序，提供了一个网页/图形界面。ntop 工具套件是免费下载的。在这个免费级别上，它通过论坛和“尽力而为”的邮件列表享有“社区支持”。

**互联网级别知识系统**（**SILK**）是最古老的流量收集工具之一，但它仍然支持所有较新的协议。它由 CERT 的网络态势感知组开发，文档和下载托管在这里：[`tools.netsa.cert.org/silk/`](https://tools.netsa.cert.org/silk/)。SILK 是一个免费工具，没有商业提供。

说到这一点，这个领域还有哪些商业产品？

### 商业产品

几乎每个拥有商业 NMS 的供应商都会有一个流量收集模块与该 NMS 相配套。然而，当你深入研究他们的文档时，几乎所有的供应商都只建议你在与 SNMP 和 syslog 功能相同的服务器上部署流量收集。正如我们之前讨论的，随着流量数据量的增长和数据保留时间的增加，流量收集服务往往会压倒已经繁忙的系统。此外，由于大多数流量收集服务对数据库的依赖性，通常会看到人们不得不定期清除数据，作为修复破损的流量收集服务器的“当所有其他故障排除失败时”的步骤。这些因素往往会迅速导致 NetFlow 或其相关服务在大多数组织中被移至自己的服务器和数据库。

话虽如此，在商业产品中，你经常会看到更多关于应用程序“外观和感觉”的工作。例如，当为 NetFlow 添加设备接口时，接口名称通常会从接口的`description`值中读取，并且图表的最大带宽将最初从接口的吞吐量值或路由器的“带宽”度量（如果设置）中设置。图表通常会包括应用程序名称和工作站名称，甚至用户 ID。图表还将从一开始就深入到目标端口值和数据速率，因为那通常是你想要最终到达的地方。总的来说，大多数商业产品往往更容易设置，无论是在初始应用程序还是在添加设备时。

# 总结

在这一点上，你应该意识到可以从各种系统的日志中收集到大量有用的数据，以及如何使用命令行工具来“挖掘”这些数据，以找到可以帮助你解决特定问题的信息。日志警报的使用也应该是熟悉的领域，允许你在问题的早期阶段主动发送警报。

然后，介绍了 Dshield 项目。我们欢迎你的参与，但即使你不贡献数据，它也可以成为一个快速的“互联网天气报告”的宝贵资源，以及有助于定义“互联网气候”的趋势，就恶意流量（按端口和协议）而言。

你现在应该熟悉 SNMP 的工作原理，以及如何使用基于 SNMP 的 NMS 来管理网络设备甚至 Linux 或 Windows 服务器的性能指标。我们在示例中使用了 LibreNMS，但几乎任何你可能使用的 NMS 的方法甚至实现都会非常相似。

在更高级别上，你应该对 NetFlow 协议非常熟悉，包括在网络设备和 Linux 收集器上配置它。在本章中，我们使用 NetFlow 作为侦探工具，对网络流量进行高级取证，以找到可疑的流量，最终找到恶意数据外泄事件。

在下一章中，我们将探讨入侵防范系统（IPS），这将建立在本书的几章材料基础上，以寻找并经常阻止恶意网络活动。

# 问题

在我们结束时，这里有一些问题供你测试对本章材料的了解。你可以在*附录*的*评估*部分找到答案：

1.  为什么启用 SNMP 的读写社区访问是一个坏主意？

1.  使用 Syslog 的风险是什么？

1.  NetFlow 也是一个明文协议。这会带来什么风险？

# 进一步阅读

有关本章内容的更多信息，请参阅以下资源：

+   处理 Syslog 数据的方法：

+   [`isc.sans.edu/diary/Syslog+Skeet+Shooting+-+Targetting+Real+Problems+in+Event+Logs/19449`](https://isc.sans.edu/diary/Syslog+Skeet+Shooting+-+Targetting+Real+Problems+in+Event+Logs/19449)

+   [`isc.sans.edu/forums/diary/Finding+the+Clowns+on+the+Syslog+Carousel/18373/`](https://isc.sans.edu/forums/diary/Finding+the+Clowns+on+the+Syslog+Carousel/18373/)

+   Swatch 手册：

+   [`manpages.ubuntu.com/manpages/bionic/man1/swatchdog.1p.html`](http://manpages.ubuntu.com/manpages/bionic/man1/swatchdog.1p.html)

+   [`linux.die.net/man/1/swatch`](https://linux.die.net/man/1/swatch)

+   Swatch 主页：

+   [`github.com/ToddAtkins/swatchdog`](https://github.com/ToddAtkins/swatchdog)

+   [`sourceforge.net/projects/swatch/`](https://sourceforge.net/projects/swatch/)

+   各种正则表达式备忘单：

+   [`www.rexegg.com/regex-quickstart.html`](https://www.rexegg.com/regex-quickstart.html)

+   [`developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions/Cheatsheet`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions/Cheatsheet)

+   [`www.sans.org/security-resources/posters/dfir/hex-regex-forensics-cheat-sheet-345`](https://www.sans.org/security-resources/posters/dfir/hex-regex-forensics-cheat-sheet-345)

+   在线正则表达式“构建器”：

+   [`regexr.com/`](https://regexr.com/)

+   https://gchq.github.io/CyberChef/#recipe=Regular_expression('User%20defined','',true,true,false,false,false,false,'Highlight%20matches')&input=Ig

+   出口过滤器：[`isc.sans.edu/forums/diary/Egress+Filtering+What+do+we+have+a+bird+problem/18379/`](https://isc.sans.edu/forums/diary/Egress+Filtering+What+do+we+have+a+bird+problem/18379/)

+   相关的 RFC：

+   **Syslog**：[`datatracker.ietf.org/doc/html/rfc5424`](https://datatracker.ietf.org/doc/html/rfc5424)

+   **SNMP**：

1.  [`datatracker.ietf.org/doc/html/rfc3411`](https://datatracker.ietf.org/doc/html/rfc3411)

1.  [`datatracker.ietf.org/doc/html/rfc3412`](https://datatracker.ietf.org/doc/html/rfc3412)

1.  [`datatracker.ietf.org/doc/html/rfc3413`](https://datatracker.ietf.org/doc/html/rfc3413)

1.  [`datatracker.ietf.org/doc/html/rfc3415`](https://datatracker.ietf.org/doc/html/rfc3415)

1.  [`datatracker.ietf.org/doc/html/rfc3416`](https://datatracker.ietf.org/doc/html/rfc3416)

1.  [`datatracker.ietf.org/doc/html/rfc3417`](https://datatracker.ietf.org/doc/html/rfc3417)

1.  [`datatracker.ietf.org/doc/html/rfc3418`](https://datatracker.ietf.org/doc/html/rfc3418)

+   **SNMP MIB II**：[`datatracker.ietf.org/doc/html/rfc1213`](https://datatracker.ietf.org/doc/html/rfc1213)

+   **SNMPv3**：

1.  [`datatracker.ietf.org/doc/html/rfc3414`](https://datatracker.ietf.org/doc/html/rfc3414)

1.  [`datatracker.ietf.org/doc/html/rfc6353`](https://datatracker.ietf.org/doc/html/rfc6353)

+   **NetFlow**：[`datatracker.ietf.org/doc/html/rfc3954.html`](https://datatracker.ietf.org/doc/html/rfc3954.html)

+   **sFlow**：[`datatracker.ietf.org/doc/html/rfc3176`](https://datatracker.ietf.org/doc/html/rfc3176)

+   **IPFIX**：[`datatracker.ietf.org/doc/html/rfc7011`](https://datatracker.ietf.org/doc/html/rfc7011)

+   各种供应商的**SNMP OID**：请查阅您的供应商文档；以下是您通常会看到的一些 OID。

## 常用的 SNMP OID

+   监控路由器 CPU：`1.3.6.1.4.1.9.2.1.58.0`

+   监控路由器内存：`1.3.6.1.4.1.9.9.48.1.1.1.6.1`

+   `1.3.6.1.2.1.1`

+   接口：`1.3.6.1.2.1.2`

+   IP：`1.3.6.1.2.1.4`

+   内存：`1.3.6.1.2.1.4.1.9.9.48`

+   CPU：`1.3.6.1.2.1.4.1.9.9.109`

+   防火墙：`1.3.6.1.2.1.4.1.9.9.147`

+   缓冲区：`1.3.6.1.2.1.4.1.9.9.147.1.2.2.1`

+   连接：`1.3.6.1.2.1.4.1.9.9.147.1.2.2.2`

+   SSL 统计：`1.3.6.1.4.1.3076.2.2.26`

+   IPSec 统计：`1.3.6.1.2.1.4.1.9.9.171`

+   远程访问统计：`1.3.6.1.2.1.4.1.9.9.392`

+   FIPS 统计：`1.3.6.1.2.1.4.1.9.9.999999`

+   PIX/ASA 防火墙中的活动连接：`1.3.6.1.4.1.9.9.147.1.2.2.2.1.5.40.7`

+   当前活动的 IPsec Phase-2 隧道总数：`1.3.6.1.4.1.9.9.171.1.3.1.1.0`

您将需要以下 MIB：

+   IF-MIB，RFC1213-MIB，CISCO-MEMORY-POOLMIB，CISCO-PROCESS-MIB，ENTITY-MIB，CISCO-SMI，CISCO-FIREWALL-MIB。ASA 还添加了 CISCO-IPSEC-FLOW-MONITOR-MIB，CISCO-FIPS-STAT-MIB 和 ALTIGA-SSL-STATS-MIB。

+   堆叠交换机的序列号：`1.3.6.1.2.1.47.1.1.1.1.11.1`

+   堆叠交换机的 IOS 版本：`1.3.6.1.2.1.47.1.1.1.1.9.1`

+   路由器上的 ARP 缓存：`1.3.6.1.2.1.3.1.1.2`

+   接口的最后状态更改：`1.3.6.1.2.1.2.2.1.9`。[接口编号]
