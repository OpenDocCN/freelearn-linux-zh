- en: Handling Hardware Interrupts
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 处理硬件中断
- en: 'In this chapter, we''ll focus on a really key aspect of writing a device driver:
    what hardware interrupts are and, more importantly, how exactly you, as a driver
    author, handle them. The fact is, a large percentage of peripherals (that you''re
    interested in writing a device driver for) indicate their need for immediate action
    via the OS or driver by asserting a hardware interrupt. This is, in effect, an
    electrical signal that ultimately alerts the processor''s control unit (typically,
    this alert must redirect control to the affected peripheral''s interrupt handler
    routine as it requires immediate attention).'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将重点关注编写设备驱动程序的一个非常关键的方面：硬件中断是什么，更重要的是，作为驱动程序作者，您如何处理它们。事实上，大部分（如果不是全部）您有兴趣为其编写设备驱动程序的外围设备通过断言硬件中断来指示它们需要立即采取行动。这实际上是一个电信号，最终会提醒处理器的控制单元（通常，这个警报必须将控制重定向到受影响的外围设备的中断处理程序，因为它需要立即处理）。
- en: 'To handle these kinds of interrupts, you need to understand some of the fundamentals
    of how they work; that is, how the OS handles them and, most importantly, how
    you as a driver author are expected to work with them. An additional layer of
    complexity is added by the fact that Linux, being a VM-based rich OS, requires
    and uses some abstraction in the way it works with interrupts. So, you will begin
    by learning about the (very) basic workflow regarding how to handle a hardware
    interrupt. Then, we will look at the topics that a driver author like yourself
    will be primarily interested in: how exactly to allocate an IRQ and write the
    code of the handler routine itself – there are some very specific dos and don''ts!
    We will then cover the motivation behind and the usage of the newer threaded interrupt
    model, enabling/disabling specific IRQs, viewing information about IRQ lines via
    proc, and what top and bottom halves are for and how to use them. We''ll finish
    this chapter by answering a few FAQs on interrupt handling.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理这些类型的中断，您需要了解它们的工作原理的一些基本知识；也就是说，操作系统如何处理它们，以及作为驱动程序作者的您应该如何与它们一起工作。Linux增加了一层复杂性，因为作为一个基于VM的丰富操作系统，它在处理中断时需要和使用一些抽象。因此，您将首先学习关于如何处理硬件中断的（非常）基本工作流程。然后，我们将看看像您这样的驱动程序作者主要感兴趣的主题：如何精确分配IRQ并编写处理程序代码本身
    - 有一些非常具体的要求和禁忌！然后，我们将介绍和使用较新的线程中断模型的动机，启用/禁用特定的IRQ，通过proc查看有关IRQ线的信息，以及上半部分和下半部分的用途以及如何使用它们。我们将通过回答一些关于中断处理的常见问题来结束本章。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Hardware interrupts and how the kernel handles them
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件中断以及内核如何处理它们
- en: Allocating the hardware IRQ
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分配硬件IRQ
- en: Implementing the interrupt handler routine
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现中断处理程序
- en: Working with the threaded interrupts model
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程中断模型
- en: Enabling and disabling IRQs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用和禁用IRQ
- en: Viewing all allocated interrupt (IRQ) lines
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看所有分配的中断（IRQ）线
- en: Understanding and using top and bottom halves
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解和使用上半部分和下半部分
- en: A few remaining FAQs answered
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答一些剩下的常见问题
- en: Let's get started!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter assumes that you''ve gone through the *Preface* section *To get
    the most out of this book* and have appropriately prepared a guest VM running
    Ubuntu 18.04 LTS (or a later stable release) and installed all the required packages.
    If not, I highly recommend you do this first. To get the most out of this book,
    I strongly recommend you first set up the workspace environment, including cloning
    this book''s GitHub repository for the code, and work on it in a hands-on fashion.
    The repository can be found here: [https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/ch4).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假设您已经阅读了*前言*部分*为了充分利用本书*，并且已经适当准备了运行Ubuntu 18.04 LTS（或更高版本稳定发布版）的虚拟机，并安装了所有必需的软件包。如果没有，我强烈建议您首先这样做。为了充分利用本书，我强烈建议您首先设置工作环境，包括克隆本书的GitHub存储库以获取代码，并以实际操作的方式进行工作。存储库可以在这里找到：[https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/ch4)。
- en: Hardware interrupts and how the kernel handles them
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 硬件中断以及内核如何处理它们
- en: Many, if not most, peripheral controllers use a hardware interrupt to inform
    the OS or device driver that some (usually urgent) action is required. Typical
    examples include network adapters (NICs), block devices (disks), USB devices,
    AV devices, **human interface devices** (**HIDs**) such as keyboards, mice, touchscreens,
    and video screens, clocks/timer chips, DMA controllers, and so on. The primary
    idea behind hardware interrupts is efficiency. Instead of continually polling
    the chip (on a battery-backed device, this can result in rapidly draining the
    battery!), the interrupt is a means to have the low-level software run only as
    and when required.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 许多，如果不是大多数，外围控制器使用硬件中断来通知操作系统或设备驱动程序需要一些（通常是紧急的）操作。典型的例子包括网络适配器（NIC）、块设备（磁盘）、USB设备、AV设备，人机接口设备（HID）如键盘、鼠标、触摸屏和视频屏幕，时钟/定时器芯片，DMA控制器等。硬件中断背后的主要思想是效率。与其不断轮询芯片（在备电设备上，这可能导致电池迅速耗尽！），中断是一种只在需要时才运行低级软件的手段。
- en: 'Here''s a quick hardware-level overview (without getting into too much detail):
    modern system motherboards will have an interrupt controller chip of some sort,
    which is often called the **[IO][A]PIC**, short for **IO-[Advanced] Programmable
    Interrupt Controller**, on x86 (the kernel documents for the x86 IO-APIC can be
    found at [https://www.kernel.org/doc/html/latest/x86/i386/IO-APIC.html#io-apic](https://www.kernel.org/doc/html/latest/x86/i386/IO-APIC.html#io-apic))
    or a **generic interrupt controller** (**GIC**) on ARM. The PIC (to keep it simple,
    we''ll just use the generic term PIC) has one line to the CPU''s interrupt pin.
    Onboard peripherals capable of asserting interrupts will have an IRQ line to the
    PIC.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个快速的硬件级概述（不涉及太多细节）：现代系统主板将具有某种中断控制器芯片，通常称为**[IO][A]PIC**，在x86上称为**IO-[Advanced]
    Programmable Interrupt Controller**（x86 IO-APIC的内核文档可在[https://www.kernel.org/doc/html/latest/x86/i386/IO-APIC.html#io-apic](https://www.kernel.org/doc/html/latest/x86/i386/IO-APIC.html#io-apic)找到），或者在ARM上称为**通用中断控制器**（**GIC**）。PIC（为了简单起见，我们将使用通用术语PIC）与CPU的中断引脚相连。能够断言中断的板载外围设备将具有到PIC的IRQ线。
- en: '**IRQ **is the common abbreviated term for **Interrupt ReQuest***; *it denotes
    the interrupt line (or lines) that''s allocated to a peripheral device.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**IRQ**是**Interrupt ReQuest**的常用缩写；它表示分配给外围设备的中断线（或线）。'
- en: 'Let''s say that the peripheral device in question is a network adapter (a NIC)
    and a network packet is received. The (highly simplified) flow is as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 假设所讨论的外围设备是网络适配器（NIC），并且接收到一个网络数据包。以下是（高度简化的）流程：
- en: The peripheral device (the NIC) now needs to emit (assert) a hardware interrupt;
    thus, it asserts its line on the PIC (low or high logic as required; all this
    is internal to the hardware).
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 外围设备（NIC）现在需要发出（断言）硬件中断；因此，它在PIC上断言其线（根据需要为低或高逻辑；所有这些都是硬件内部的）。
- en: The PIC, on seeing that a peripheral line has been asserted, saves the asserted
    line value in a register.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PIC在看到外围线被断言后，将断言的线值保存在寄存器中。
- en: The PIC then asserts the CPU's interrupt pin.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，PIC断言CPU的中断引脚。
- en: The control unit on the processor checks for the presence of hardware interrupts
    on every CPU after every single machine instruction runs. Thus, if a hardware
    interrupt occurs, it will certainly come to know about it almost immediately.
    The CPU will then raise a hardware interrupt (of course interrupts can be masked;
    we'll discuss this in more detail later in the *Enabling and disabling IRQs* section).
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理器上的控制单元在每个CPU上的每条机器指令运行后都会检查硬件中断的存在。因此，如果发生硬件中断，它几乎立即就会知道。然后，CPU将引发硬件中断（当然，中断可以被屏蔽；我们将在*启用和禁用IRQs*部分中更详细地讨论这一点）。
- en: The low-level (BSP/platform) code on the OS will be hooked into this and will
    react (this is often code that's at the assembly level); for example, on the ARM-32,
    the low-level C entry point for a hardware interrupt is `arch/arm/kernel/irq.c:asm_do_IRQ()`.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 操作系统上的低级（BSP/平台）代码将与此相连，并做出反应（通常是在汇编级别的代码）；例如，在ARM-32上，硬件中断的低级C入口点是`arch/arm/kernel/irq.c:asm_do_IRQ()`。
- en: From here, the OS executes code paths that ultimately invoke the registered
    interrupt handler routine(s) of the driver(s) this interrupt is to be serviced
    by. (Again, it's not our intention to focus on the hardware layer and even the
    arch-specific platform-level details of hardware interrupts in this chapter. I'd
    like to focus on what's of relevance to you as the driver author – how to handle
    them!).
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这里开始，操作系统执行代码路径，最终调用驱动程序的已注册中断处理程序例程，以便为该中断提供服务。（再次强调，我们不打算在本章节关注硬件层面，甚至不关注硬件中断的特定于架构的平台级细节。我想关注的是对驱动程序作者有关的内容
    - 如何处理它们！）。
- en: 'The hardware interrupt is literally the top priority on the Linux OS: it preempts
    whatever''s currently running – be it user or kernel-space code paths – in order
    to run. Having said that, later, we will see that on modern Linux kernels, it''s
    possible to employ a threaded interrupt model that changes things; a little patience
    please – we''ll get there!'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 硬件中断在Linux操作系统中是最高优先级的：它会抢占当前正在运行的任何内容 - 无论是用户空间还是内核空间的代码路径。话虽如此，稍后我们将看到，在现代Linux内核上，可以采用线程化中断模型来改变这一点；请稍作耐心
    - 我们会讲到的！
- en: Now, let's digress. We mentioned an example of a typical peripheral device,
    a network controller (or NIC), and have essentially said that it services packet
    transmission and reception (Tx/Rx) via hardware interrupts. This used to be true,
    but this isn't always the case with modern high-speed NICs (typically 10 Gbps
    and higher). Why? The answer is interesting: the extreme speed at which interrupts
    will literally interrupt the processor can cause the system to land in a problematic situation
    called **livelock**;a situation where it cannot cope with the extremely high interrupt
    demand! As with deadlocks (covered in [Chapter 6](f456f2ea-ca5f-4d0f-b9c0-55b9ae92f659.xhtml),
    *Kernel Synchronization – Part 1*), the system effectively tends to freeze or
    hang. So, what do we do regarding livelock? Most high-end modern NICs support
    a polled-mode of operation; modern OSes such as Linux have a network receive path
    infrastructure called **NAPI** (it's nothing to do with babies, mind you – it's short
    for **New API**) that allows the driver to switch between interrupt and polled
    mode based on demand and hence process network packets (on the receive path) more
    efficiently.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们离题一下。我们提到了一个典型外围设备的例子，即网络控制器（或NIC），并且基本上说它通过硬件中断来服务数据包的传输和接收（Tx/Rx）。这曾经是真的，但对于现代高速NIC（通常为10
    Gbps及更高速度）来说，情况并非总是如此。为什么？答案很有趣：中断以极快的速度打断处理器，可能导致系统陷入一个称为**活锁**的问题情况；即它无法应对极高的中断需求！与死锁一样（在[第6章](f456f2ea-ca5f-4d0f-b9c0-55b9ae92f659.xhtml)中介绍，*内核同步
    - 第1部分*），系统实际上会冻结或挂起。那么，对于活锁，我们该怎么办？大多数高端现代NIC支持轮询模式操作；现代操作系统（如Linux）具有名为**NAPI**的网络接收路径基础设施（请注意，这与婴儿无关
    - 它是**New API**的缩写），它允许驱动程序根据需求在中断和轮询模式之间切换，从而更有效地处理网络数据包（在接收路径上）。
- en: Now that we've introduced hardware interrupts, let's learn how you, as a driver
    author, can work with them. Most of the remaining sections in this chapter will
    deal with this. Let's start by learning how to allocate or register an IRQ line.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了硬件中断，让我们学习作为驱动程序作者如何与它们一起工作。本章剩下的大部分部分将涉及这一点。让我们首先学习如何分配或注册一个IRQ线。
- en: Allocating the hardware IRQ
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分配硬件IRQ
- en: Often, a key part of writing a device driver is really the work of trapping
    into and handling the hardware interrupt that the chip you're writing the driver
    for emits. How do you do this? The trouble is that the way that hardware interrupts
    are routed from the interrupt controller chip(s) to the CPU(s) varies widely;
    it is very platform-specific. The good news is that the Linux kernel provides
    an abstraction layer to abstract away all the hardware-level differences; it's
    referred to as the **generic interrupt (or IRQ) handling layer**. Essentially,
    it performs the required work under the hood and exposes APIs and data structures
    that are completely generic. Thus, at least theoretically, your code will work
    on any platform. This **generic IRQ layer** is what we, primarily as driver authors,
    shall be using, of course; all the APIs and helper routines we use fall into this
    category.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 编写设备驱动程序的一个关键部分通常是陷入和处理硬件中断，即您为其编写驱动程序的芯片发出的中断。你如何做到这一点？问题在于硬件中断从中断控制器芯片到CPU的路由方式差异很大；这是非常特定于平台的。好消息是，Linux内核提供了一个抽象层来抽象掉所有硬件级别的差异；它被称为**通用中断（或IRQ）处理层**。基本上，它在幕后执行所需的工作，并公开完全通用的API和数据结构。因此，至少在理论上，您的代码将在任何平台上运行。这个**通用IRQ层**就是我们作为驱动程序作者主要要使用的；当然，我们使用的所有API和辅助例程都属于这个类别。
- en: 'Recall that it''s really the core kernel that, at least initially, handles
    the interrupt (as we learned in the previous section). It then refers to an array
    of linked lists (a very common data structure on Linux; here, the index to the
    array is the IRQ number) to figure out the driver-level function(s) to invoke.
    (Without going into too much detail, the node on the lists is the IRQ descriptor
    structure; that is, `include/linux/interrupt.h:struct irqaction`.) But how do
    you get your driver''s interrupt handler function onto this list so that the kernel
    can invoke it when an interrupt from your device occurs? Ah, that''s the key: you
    register it with the kernel. Modern Linux provides at least four ways (APIs) via
    which you can register interest in an interrupt line, as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，至少最初，真正处理中断的是核心内核（正如我们在上一节中学到的）。然后，它会参考一个链表数组（这是Linux上非常常见的数据结构；这里，数组的索引是IRQ号）来找出要调用的驱动程序级函数。
    （不详细介绍，列表上的节点是IRQ描述符结构；即`include/linux/interrupt.h:struct irqaction`。）但是，如何将您的驱动程序的中断处理程序函数放入此列表中，以便内核在设备发生中断时调用它？啊，这就是关键：您要向内核注册它。现代Linux提供了至少四种（API）方式，通过这些方式您可以注册对中断线的兴趣，如下所示：
- en: '`request_irq()`'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`request_irq()`'
- en: '`devm_request_irq()`'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`devm_request_irq()`'
- en: '`request_threaded_irq()`'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`request_threaded_irq()`'
- en: '`devm_request_threaded_irq()` (recommended!)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`devm_request_threaded_irq()`（推荐！）'
- en: Let's tackle them one by one (there are additional routines that are slight
    variations of them). Along the way, we'll look at some code from a few drivers
    and learn how to work with threaded interrupts. There's a lot to learn and do;
    let's get on with it!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个解决它们（还有一些略有不同的其他例程）。在这过程中，我们将查看一些驱动程序的代码，并学习如何处理线程中断。有很多东西要学习和做；让我们开始吧！
- en: Allocating your interrupt handler with request_irq()
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`request_irq()`分配您的中断处理程序
- en: Just as we saw with I/O memory and I/O ports, the IRQ line(s) is considered
    a **resource** that the kernel is in charge of. The `request_irq()` kernel API
    can be thought of as the traditional means by which driver authors register their
    interest in an IRQ and allocate this resource to themselves, thus allowing the
    kernel to invoke their handler when the interrupt asynchronously  arrives.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在I/O内存和I/O端口中看到的那样，IRQ线被认为是内核负责的**资源**。`request_irq()`内核API可以被认为是驱动程序作者注册对IRQ的兴趣并将此资源分配给自己的传统方法，从而允许内核在中断异步到达时调用他们的处理程序。
- en: It might strike you that this discussion seems very analogous to user space
    **signal handling**. There, we call the `sigaction(2)` system call to register
    interest in a signal. When the signal (asynchronously) arrives, the kernel invokes
    the registered signal handler (user mode) routine!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会觉得这个讨论似乎与用户空间**信号处理**非常类似。在那里，我们调用`sigaction(2)`系统调用来注册对信号的兴趣。当信号（异步）到达时，内核调用注册的信号处理程序（用户模式）例程！
- en: There are some key differences here. First, a user space signal handler is not
    an interrupt; second, the user space signal handler runs purely in non-privileged
    user mode; in contrast, the kernel space interrupt handler of your driver runs (asynchronously)
    with kernel privileges and in an interrupted context!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些关键的区别。首先，用户空间信号处理程序不是中断；其次，用户空间信号处理程序纯粹在非特权用户模式下运行；相比之下，您的驱动程序的内核空间中断处理程序以（异步）内核特权和中断上下文运行！
- en: Furthermore, some signals are really the software side effect of a **processor
    exception** being raised; broadly speaking, the processor will raise a **fault,
    trap, or abort** when something illegal occurs and it has to "trap" (switch) to
    kernel space to handle it. A process or thread attempting to access an invalid
    page (or without sufficient permissions) causes the MMU to raise a fault or an
    abort; this leads to the OS fault handling code raising the `SIGSEGV` signal upon
    the process context (i.e. upon `current`)! However, raising an exception of some
    sort does *not* always imply there's a problem – a system call is nothing but
    a trap to the OS; that is, a programmed exception (via `syscall / SWI` on x86/ARM).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些信号实际上是**处理器异常**引发的软件副作用；广义上讲，当发生非法情况并且必须“捕获”（切换）到内核空间处理时，处理器将引发**故障、陷阱或中止**。尝试访问无效页面（或没有足够权限）的进程或线程会导致MMU引发故障或中止；这将导致操作系统故障处理代码在进程上下文（即`current`）上引发`SIGSEGV`信号！然而，引发某种异常并*不*总是意味着存在问题
    - 系统调用只是对操作系统的陷阱；也就是说，通过x86/ARM上的`syscall / SWI`进行编程异常（通过`syscall / SWI`）。
- en: 'The following comment (which has been partially reproduced in the following
    snippet) from the kernel source tells us more about what the `request[_threaded]_irq()` API
    does:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 内核源代码中的以下注释（在下面的片段中部分重现）告诉我们更多关于`request[_threaded]_irq()` API的信息：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Actually, `request_irq()` is merely a thin wrapper over the `request_threaded_irq()` API;
    we will discuss this API later. The signature of the `request_irq()` API is as
    follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，`request_irq()`只是`request_threaded_irq()` API的一个薄包装；我们将在后面讨论这个API。`request_irq()`
    API的签名如下：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Always include the `linux/interrupt.h` header file. Let''s examine each of
    the parameters to `request_irq()` one by one:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 始终包括`linux/interrupt.h`头文件。让我们逐个检查`request_irq()`的每个参数：
- en: '`int irq`: This is the IRQ line that you''re attempting to register or trap/hook
    into. This means that when this particular interrupt fires, your interrupt handler
    function (the second parameter, `handler_func`) is invoked. The question regarding
    `irq` is: how do I find out what the IRQ number is? We addressed this generic
    issue in [Chapter 3](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml), *Working with
    Hardware I/O Memory*, in the (really key) *Obtaining the device resources* section.
    To quickly reiterate, **an IRQ line is a resource**, which means it is obtained
    in the usual manner – on modern embedded systems, it''s obtained by parsing the **Device
    Tree** (**DT**); the older way was to hard code the values within board-specific
    source files (relax, you will see an example of querying the IRQ line via the
    DT in the *IRQ allocation – the modern way – the managed interrupt facility* section).
    On PC-type systems, you might have to resort to interrogating the bus that the
    device lives on (for cold devices). Here, the PCI bus (and friends) is very common.
    The kernel even provides PCI helper routines you can use to query resources from
    it, and thus find out the assigned IRQ line.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`int irq`：这是您尝试注册或陷阱/挂钩的IRQ线。这意味着当特定中断触发时，将调用您的中断处理程序函数（第二个参数`handler_func`）。关于`irq`的问题是：我如何找出IRQ号是多少？我们在[第3章](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml)中解决了这个通用问题，*使用硬件I/O内存*，在（真正关键的）*获取设备资源*部分。为了快速重申，**IRQ线是一种资源**，这意味着它是以通常的方式获得的
    - 在现代嵌入式系统上，它是通过解析**设备树**（**DT**）获得的；旧的方法是在特定于板的源文件中硬编码值（放心，您将看到通过DT查询IRQ线的示例在*IRQ分配
    - 现代方式 - 管理的中断设施*部分）。在PC类型系统上，您可能不得不诉诸于询问设备所在总线（对于冷设备）。在这里，PCI总线（和朋友们）非常常见。内核甚至提供了PCI辅助例程，您可以使用它来查询资源，并找出分配的IRQ线。'
- en: '`irq_handler_t (*handler_func)(int, void *)`: This parameter is a pointer to
    the interrupt handler function (in C, just providing the function''s name is sufficient).
    This, of course, is the code that will be asynchronously invoked when the hardware
    interrupt fires. Its job is to service the interrupt (more on this later). How
    does the kernel know where it is? Recall `struct irqaction`, which is the structure
    that''s populated by the `request_irq()` routine. One of its members is `handler`,
    and is set to this second parameter.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`irq_handler_t (*handler_func)(int, void *)`：这个参数是指向中断处理程序函数的指针（在C中，只提供函数的名称就足够了）。当硬件中断触发时，当然，这是将异步调用的代码。它的工作是为中断提供服务（稍后详细介绍）。内核如何知道它在哪里？回想一下`struct
    irqaction`，这是由`request_irq()`例程填充的结构。它的成员之一是`handler`，并设置为这个第二个参数。'
- en: '`unsigned long flags`: This, the third parameter to `request_irq()`, is a flag
    bitmask. When it''s set to zero, it implements its default behavior (we''ll discuss
    some key interrupt flags in the *Setting interrupt flags* section).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unsigned long flags`：这是`request_irq()`的第三个参数，是一个标志位掩码。当设置为零时，它实现其默认行为（我们将在*设置中断标志*部分讨论一些关键的中断标志）。'
- en: '`const char *name`: This is the name of the code/driver that owns the interrupt.
    Typically, this is set to the name of the device driver (this way, `/proc/interrupts` can
    show you the name of the driver that is using the interrupt; it''s the right-most
    column; details follow in the *Viewing all allocated interrupt (IRQ)* *lines*
    section.)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`const char *name`：这是拥有中断的代码/驱动程序的名称。通常，这设置为设备驱动程序的名称（这样，`/proc/interrupts`可以向您显示正在使用中断的驱动程序的名称；它是最右边的列；详细信息在*查看所有分配的中断（IRQ）*
    *线*部分后面）。'
- en: '`void *dev`: This, the fifth and last parameter to `request_irq()`, allows
    you to pass any data item you wish to (often called a cookie) to the interrupt
    handler routine, which is a common software technique. In the second parameter,
    you can see that the interrupt handler routine is of the `void *` type. This is
    where this parameter gets passed.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`void *dev`：这是`request_irq()`的第五个也是最后一个参数，允许您传递任何数据项（通常称为cookie）给中断处理程序例程，这是一种常见的软件技术。在第二个参数中，您可以看到中断处理程序例程是`void
    *`类型。这就是这个参数被传递的地方。'
- en: Most real-world drivers will have some kind of context or private data structure
    where they store all required information. Furthermore, this context structure
    is often embedded into the driver's device (often specialized by the subsystem
    or driver framework) structure. In fact, the kernel typically helps you do so;
    for example, network drivers use `alloc_etherdev()` to embed their data into `struct
    net_device`, platform drivers embed their data into the `platform_device.device.platform_data` member
    of `struct platform_device`, I2C client drivers employ the `i2c_set_clientdata()` helper
    to "set" their private/context data into the `i2c_client` structure, and so on.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数真实世界的驱动程序都会有一些上下文或私有数据结构，用于存储所有所需的信息。此外，这种上下文结构通常嵌入到驱动程序的设备（通常由子系统或驱动程序框架专门化）结构中。事实上，内核通常会帮助您这样做；例如，网络驱动程序使用`alloc_etherdev()`将它们的数据嵌入到`struct
    net_device`中，平台驱动程序将它们的数据嵌入到`struct platform_device`的`platform_device.device.platform_data`成员中，I2C客户端驱动程序使用`i2c_set_clientdata()`助手将它们的私有/上下文数据“设置”到`i2c_client`结构中，依此类推。
- en: Note that when you're using a *shared* interrupt (we'll explain this shortly),
    you *must *initialize this parameter to a non-NULL value (otherwise, how will `free_irq()` know
    which handler to free?). If you do not have a context structure or anything specific
    to pass along, passing the `THIS_MODULE` macro here will do the trick (assuming
    you're writing the driver using the loadable kernel module framework; it's the
    pointer to your kernel module's metadata structure; that is, `struct module`).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当您使用*共享*中断时（我们将很快解释这一点），您*必须*将此参数初始化为非NULL值（否则，`free_irq()`将如何知道要释放哪个处理程序？）。如果您没有上下文结构或任何特定的内容要传递，那么在这里传递`THIS_MODULE`宏就可以了（假设您正在使用可加载内核模块框架编写驱动程序；它是指向内核模块元数据结构的指针；也就是`struct
    module`）。
- en: The return value from `request_irq()` is an integer, as per the usual `0/-E`
    kernel convention (see the companion guide *Linux Kernel Programming -* *Chapter
    4*, *Writing Your First Kernel Module – LKMs Part 1*, the section *The 0/-E return
    convention*), it's `0` on success, and a negative `errno` value on failure. As
    the `__must_check` compiler attribute clearly specifies, you are certainly expected
    to check for the failure case (this is good programming practice in any case).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`request_irq()`的返回值是一个整数，按照通常的`0/-E`内核约定（请参阅配套指南*Linux内核编程 - 第4章，编写您的第一个内核模块
    - LKMs第1部分*，*0/-E返回约定*一节），成功时为`0`，失败时为负的`errno`值。正如`__must_check`编译器属性明确指出的那样，您肯定应该检查失败的情况（这在任何情况下都是良好的编程实践）。'
- en: '**Linux Driver Verification (LDV) project**: In the companion guide *Linux
    Kernel Programming,* *Chapter 1* *- Kernel Workspace Setup*, in the section *The
    LDV - Linux Driver Verification - project*, we mentioned that this project has
    useful "rules" with respect to various programming aspects of Linux modules (drivers,
    mostly) as well as the core kernel.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Linux驱动程序验证（LDV）项目**：在配套指南*Linux内核编程*，*第1章 - 内核工作空间设置*，*LDV - Linux驱动程序验证
    - 项目*一节中，我们提到该项目对Linux模块（主要是驱动程序）以及核心内核的各种编程方面有有用的“规则”。'
- en: With regard to our current topic, here's one of the rules, a negative one, implying
    that you *cannot *do this: "*Making no delay when probing for IRQs*" ([http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0037](http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0037)). This
    discussion really applies to x86[_64] systems. Here, in some circumstances, you
    might need to physically probe for the correct IRQ line number. For this purpose,
    the kernel provides an "autoprobe" facility via the `probe_irq_{on|off}()` APIs
    (`probe_irq_on()` returns a bitmask of potential IRQ lines that can be used).
    The thing is, a delay is required between the `probe_irq_on()` and `probe_irq_off()` APIs;
    not invoking this delay can cause issues. The LDV page mentioned previously covers
    this in some detail, so do take a look. The actual API used to perform the delay
    is typically `udelay()`. Worry not, we cover it (and several others) in detail
    in [Chapter 5](c7d2d826-9d8a-439f-b843-06fa72db36b9.xhtml), *Working with Kernel
    Timers, Threads, and Workqueues* in the section *Delaying for a given time in
    the kernel*.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们当前的主题，这里有一个规则，一个否定的规则，暗示着您*不能*这样做：“*探测IRQ时不进行延迟*”（[http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0037](http://linuxtesting.org/ldv/online?action=show_rule&rule_id=0037)）。这个讨论实际上适用于x86[_64]系统。在这里，在某些情况下，您可能需要物理探测正确的IRQ线路号。为此，内核通过`probe_irq_{on|off}()`
    API（`probe_irq_on()`返回可以使用的潜在IRQ线路的位掩码）提供了“自动探测”功能。问题是，在`probe_irq_on()`和`probe_irq_off()`
    API之间需要延迟；不调用此延迟可能会导致问题。前面提到的LDV页面详细介绍了这一点，所以请查看。用于执行延迟的实际API通常是`udelay()`。不用担心，我们在[第5章](c7d2d826-9d8a-439f-b843-06fa72db36b9.xhtml)，*使用内核定时器、线程和工作队列*的*为内核中的给定时间延迟*一节中详细介绍了它（以及其他几个）。
- en: Where in the driver's code should you call the `request_irq()` API (or its equivalent)?
    For pretty much all modern drivers that adhere to the modern **Linux Device Model** (**LDM**), the
    modern kernel framework for devices and drivers, the `probe()` method (this is
    a function, really) is the right place.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在驱动程序的代码中，您应该在哪里调用`request_irq()` API（或其等效物）？对于几乎所有遵循现代**Linux设备模型**（**LDM**）的现代驱动程序，即设备和驱动程序的现代内核框架，`probe()`方法（实际上是一个函数）是正确的地方。
- en: Freeing the IRQ line
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 释放IRQ线
- en: 'Conversely, when the driver is being unloaded or the device is being detached,
    the `remove()` (or `disconnect()`) method is the right place where you should
    call the converse routine – `free_irq()` – to free the IRQ line back to the kernel:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，当驱动程序被卸载或设备被分离时，`remove()`（或`disconnect()`）方法是您应该调用相反例程`free_irq()`的正确位置，以将IRQ线释放回内核：
- en: '[PRE2]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The first parameter to `free_irq()` is the IRQ line to free back to the kernel.
    The second parameter is, again, the same value that's passed to the interrupt
    handler (via the last parameter to `request_irq()`), so you must typically populate
    it with either the device structure pointer (which embeds your driver's context
    or private data structure) or the `THIS_MODULE` macro.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`free_irq()`的第一个参数是要释放回内核的IRQ线。第二个参数再次是传递给中断处理程序的相同值（通过`request_irq()`的最后一个参数），因此您通常必须使用设备结构指针（其中嵌入了驱动程序的上下文或私有数据结构）或`THIS_MODULE`宏来填充它。'
- en: The return value is the *device name* argument that you passed as the fourth
    parameter of the `request_irq()` routine (yes, it's a string) on success and `NULL` on
    failure.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 返回值是`request_irq()`例程的第四个参数（是的，它是一个字符串）成功时是*设备名称*参数，失败时是`NULL`。
- en: 'It''s important that you, as the driver author, take care to do the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 作为驱动程序作者，重要的是要注意执行以下操作：
- en: Disable the interrupt on the board before calling `free_irq()` when the IRQ
    line is being shared
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在共享IRQ线时，在调用`free_irq()`之前在板上禁用中断
- en: Call it from process context only
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅从进程上下文中调用
- en: Also, `free_irq()` will only return when any and all the executing interrupts
    for this IRQ line have completed.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`free_irq()`只有在此IRQ线的所有执行中断都完成时才会返回。
- en: 'Before we look at some code, we need to briefly cover two additional areas:
    interrupt flags and the notion of level/edge-triggered interrupts.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在查看一些代码之前，我们需要简要介绍另外两个领域：中断标志和电平/边沿触发中断的概念。
- en: Setting interrupt flags
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置中断标志
- en: 'When allocating an interrupt (IRQ line) with the `{devm_}request{_threaded}_irq()` APIs
    (we''ll cover the variants of `request_irq()` shortly), you can specify certain
    interrupt flags that will affect the interrupt line''s configuration and/or behavior.
    The parameter that''s responsible for this is `unsigned long flags` (as we mentioned
    in the *Allocating your interrupt handler with request_irq()* section). It''s
    important to realize it''s a bitmask; you can bitwise-OR several flags to get
    their combined effect. The flag values fall broadly into a few classes: flags
    to do with IRQ line sharing, interrupt threading, and suspend/resume behavior.
    They''re all in the `linux/interrupt.h` header in `IRQF_foo` format. The following
    are some of the most common ones:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用`{devm_}request{_threaded}_irq()`APIs（我们将很快介绍`request_irq()`的变体）分配中断（IRQ线）时，您可以指定某些中断标志，这些标志将影响中断线的配置和/或行为。负责此操作的参数是`unsigned
    long flags`（正如我们在*使用request_irq()分配中断处理程序*部分中提到的）。重要的是要意识到它是一个位掩码；您可以按位或多个标志以获得它们的组合效果。标志值大致分为几类：与IRQ线共享、中断线程和挂起/恢复行为有关的标志。它们都在`linux/interrupt.h`头文件中以`IRQF_foo`格式。以下是一些最常见的：
- en: '`IRQF_SHARED`: This allows you to share the IRQ line between several devices
    (required for devices on the PCI bus).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRQF_SHARED`：这允许您在多个设备之间共享IRQ线（对PCI总线上的设备是必需的）。'
- en: '`IRQF_ONESHOT`: The IRQ is not enabled after the hardirq handler finishes executing.
    This flag is typically used by threaded interrupts (covered in the *Working with
    the threaded interrupts model* section) to ensure that the IRQ remains disabled
    until the threaded handler completes.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IRQF_ONESHOT`：硬中断处理程序执行完成后不启用IRQ。此标志通常由线程中断（在*使用线程中断模型*部分中介绍）使用，以确保IRQ保持禁用，直到线程处理程序完成。'
- en: The `__IRQF_TIMER` flag is a special case. It's used to mark the interrupt as
    a timer interrupt. As seen in the companion guide *Linux Kernel Programming,*
    *Chapter 10*, *The CPU Scheduler - Part 1*, and *Chapter 11*, *The CPU Scheduler
    - Part 2*, when we looked at CPU scheduling, that the timer interrupt fires at
    periodic intervals and is responsible for implementing the kernel's timer/timeout
    mechanisms, scheduler-related housekeeping, and so on.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`__IRQF_TIMER`标志是一个特例。它用于将中断标记为定时器中断。正如在配套指南*Linux内核编程*，*第10章*，*CPU调度器-第1部分*和*第11章*，*CPU调度器-第2部分*中所看到的，当我们研究CPU调度时，定时器中断以周期性间隔触发，并负责实现内核的定时器/超时机制，调度器相关的日常工作等。'
- en: 'The timer interrupt flags are specified by this macro:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 定时器中断标志由此宏指定：
- en: '[PRE3]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In addition to specifying that it's marked as the timer interrupt (`__IRQF_TIMER`),
    the `IRQF_NO_SUSPEND` flag specifies that the interrupt remains enabled even when
    the system goes into a suspend state. Furthermore, the `IRQF_NO_THREAD` flag specifies
    that this interrupt cannot use the threaded model (we'll cover this in the *Working
    with the threaded interrupts model* section).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 除了指定它标记为定时器中断（`__IRQF_TIMER`）之外，`IRQF_NO_SUSPEND`标志指定即使系统进入挂起状态，中断仍保持启用。此外，`IRQF_NO_THREAD`标志指定此中断不能使用线程模型（我们将在*使用线程中断模型*部分中介绍）。
- en: There are several other interrupt flags we can use, including `IRQF_PROBE_SHARED`,  `IRQF_PERCPU`,
    `IRQF_NOBALANCING`, `IRQF_IRQPOLL`, `IRQF_FORCE_RESUME`, `IRQF_EARLY_RESUME`,
    and `IRQF_COND_SUSPEND`. We won't cover them explicitly here (take a look at the
    comment header briefly describing them in the `linux/interrupt.h` header file).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用几种其他中断标志，包括`IRQF_PROBE_SHARED`、`IRQF_PERCPU`、`IRQF_NOBALANCING`、`IRQF_IRQPOLL`、`IRQF_FORCE_RESUME`、`IRQF_EARLY_RESUME`和`IRQF_COND_SUSPEND`。我们不会在这里明确介绍它们（请看一下`linux/interrupt.h`头文件中简要描述它们的注释头）。
- en: Now, let's gain a brief understanding of what level- and edge-triggered interrupts
    are.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们简要了解一下电平触发和边沿触发中断。
- en: Understanding level- and edge-triggered interrupts – a brief note
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解电平触发和边沿触发中断-简要说明
- en: 'When a peripheral asserts an interrupt, the interrupt controller is triggered
    to latch this event. The electrical characteristics that it uses to trigger the
    hardware interrupt in the CPU fall into two broad categories:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当外围设备断言中断时，中断控制器被触发以锁存此事件。它用于触发CPU中的硬件中断的电气特性分为两大类：
- en: '**Level-triggered**: The interrupt is triggered when the level changes (from
    inactive to active or asserted); until it''s deasserted, the line remains in the
    asserted state. This happens even after your handler returns; if the line is still
    asserted, you will get the interrupt again.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**电平触发**：当电平发生变化（从非活动到活动或激活）时触发中断；直到去激活，该线保持激活状态。即使在处理程序返回后，如果线仍处于激活状态，您将再次收到中断。'
- en: '**Edge-triggered**: The interrupt triggers only once when the level changes
    from inactive to active.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**边沿触发**：当电平从非活动变为活动时，中断仅触发一次。'
- en: Additionally, the interrupt could be high or low triggered, on the rising or
    falling (clock) edge. The kernel allows this to be configured and specified via
    additional flags such as `IRQF_TRIGGER_NONE`, `IRQF_TRIGGER_RISING`, `IRQF_TRIGGER_FALLING`,
    `IRQF_TRIGGER_HIGH`, `IRQF_TRIGGER_LOW`, and so on. These low-level electrical
    characteristics of the peripheral chip are typically pre-configured within the
    BSP-level code or specified in the DT.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，中断可以是高触发或低触发，在上升或下降（时钟）边缘。内核允许通过附加标志（例如`IRQF_TRIGGER_NONE`，`IRQF_TRIGGER_RISING`，`IRQF_TRIGGER_FALLING`，`IRQF_TRIGGER_HIGH`，`IRQF_TRIGGER_LOW`等）进行配置和指定。这些外围芯片的低级电气特性通常在BSP级代码中预先配置或在DT中指定。
- en: Level-triggered interrupts force you to understand the interrupt source so that
    you can correctly deassert (or *ack*) it (in the case of a shared IRQ, after checking
    that it's for you). Typically, this is the first thing you must do when you're
    servicing it; otherwise, it will keep firing. For example, if the interrupt is
    triggered when a certain device register hits the value `0xff`, for example, then
    the driver must set the register to, say, `0x0` before deasserting it! This is
    easy to see but can be difficult to handle correctly.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 电平触发中断会迫使您了解中断源，以便您可以正确地去激活（或*ack*）它（在共享IRQ的情况下，在检查它是否属于您之后）。通常，这是您在服务它时必须做的第一件事；否则，它将继续触发。例如，如果当某个设备寄存器达到值`0xff`时触发中断，那么驱动程序必须在去激活之前将寄存器设置为`0x0`！这很容易理解，但正确处理可能会很困难。
- en: On the other hand, edge-triggered interrupts are easy to work with since no
    knowledge of the interrupt source is required, but they can also be easy to miss!
    In general, firmware designers use edge-triggered interrupts (though this isn't
    a rule). Again, these characteristics are really at the hardware/firmware boundary.
    You should study the datasheet and any allied documentation (such as Application
    Notes from the OEM) provided for the peripheral you're writing the driver for.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，边沿触发中断易于处理，因为不需要了解中断源，但也容易错过！一般来说，固件设计人员使用边沿触发中断（尽管这不是一个规则）。同样，这些特性实际上是在硬件/固件边界上。您应该研究为您编写驱动程序的外围设备提供的数据表和任何相关文档（例如OEM的应用说明）。
- en: You might by now realize that writing a device driver (well!) requires two distinct
    knowledge domains. First, you'll need to have a deep understanding of the hardware/firmware
    and how it works - it's **theory of operation** (**TOO**), its control/data planes,
    register banks, I/O memory, and so on. Second, you'll need to have a deep (enough)
    understanding of the OS (Linux) and its kernel/driver framework, how Linux works,
    memory management, scheduling, interrupt models, and so on. Also, you need to
    understand the modern LDM and kernel driver frameworks and how to go about debugging
    and profiling them. The better you get at these things, the better you'll be at
    writing the driver!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您可能已经意识到编写设备驱动程序（好！）需要两个不同的知识领域。首先，您需要深入了解硬件/固件及其工作原理，控制/数据平面，寄存器组，I/O内存等。其次，您需要对操作系统（Linux）及其内核/驱动程序框架有深入（足够）的了解，了解Linux的工作原理，内存管理，调度，中断模型等。此外，您需要了解现代LDM和内核驱动程序框架以及如何进行调试和分析。您在这些方面的能力越强，编写驱动程序的能力就越强！
- en: We'll learn how to find out what kind of triggering is being used in the *Viewing
    all allocated (IRQ) lines* section. Check out the *Further reading *section for
    more links concerning IRQ edge/level triggering.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习如何查找在*查看所有分配的（IRQ）线*部分中使用的触发类型。查看*更多关于IRQ边沿/电平触发的链接*部分以获取更多链接。
- en: Now, let's move on and look at something interesting. To help assimilate what
    you've learned so far, we'll look at some small snippets of code from a Linux
    network driver!
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续看一些有趣的东西。为了帮助消化到目前为止学到的东西，我们将看一些来自Linux网络驱动程序的小代码片段！
- en: Code view 1 – the IXGB network driver
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码视图1 - IXGB网络驱动程序
- en: 'It''s time to look at some code. Let''s take a look at some small portions
    of code for the Intel IXGB network adapter driver (which drives several Intel
    network adapters in the 82597EX series). Among the many available on the market,
    Intel has a product line called the **IXGB network adapter**. The controller is
    the Intel 82597EX; these are typically 10-gigabit ethernet adapters meant for
    servers (Intel''s product brief on this controller can be found at [https://www.intel.com/Assets/PDF/prodbrief/pro10GbE_LR_SA-DS.pdf](https://www.intel.com/Assets/PDF/prodbrief/pro10GbE_LR_SA-DS.pdf)):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候看一些代码了。让我们看一下英特尔IXGB网络适配器驱动程序的一些小代码片段（该驱动程序驱动着英特尔82597EX系列中的几个英特尔网络适配器）。在市场上有许多可用的产品，英特尔有一条名为**IXGB网络适配器**的产品线。控制器是英特尔82597EX；这些通常是用于服务器的10千兆以太网适配器（有关此控制器的英特尔产品简介可以在[https://www.intel.com/Assets/PDF/prodbrief/pro10GbE_LR_SA-DS.pdf](https://www.intel.com/Assets/PDF/prodbrief/pro10GbE_LR_SA-DS.pdf)找到）。
- en: '![](img/64a61ae6-eae6-494f-a160-2abc85728f77.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/64a61ae6-eae6-494f-a160-2abc85728f77.png)'
- en: Figure 4.1 – The Intel PRO/10GbE LR server adapter (IXGB, 82597EX) network adapter
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 - 英特尔PRO/10GbE LR服务器适配器（IXGB，82597EX）网络适配器
- en: 'First, let''s take a look at it invoking `request_irq()` to allocate the IRQ
    line:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下它调用`request_irq()`来分配IRQ线：
- en: '[PRE4]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In the preceding code snippet, you can see the driver invoking the `request_irq()` API
    to allocate this interrupt within the network driver''s `ixgb_up()` method. This
    method is invoked when the network interface is brought up (by networking utilities
    such as `ip(8)` or (older) `ifconfig(8)`). Let''s look at the parameters passed
    to `request_irq()` here, in turn:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，您可以看到驱动程序调用`request_irq()`API来在网络驱动程序的`ixgb_up()`方法中分配此中断。当网络接口被启动时（由网络实用程序如`ip(8)`或（较早的）`ifconfig(8)`调用），将调用此方法。让我们依次查看传递给`request_irq()`的参数：
- en: Here, the IRQ number – the first parameter – is queried from the `irq` member
    of the `pci_dev` structure (as this device lives on the PCI bus). The `pdev` structure
    pointer is within this driver's context (or private) metadata structure named `ixgb_adapter`.
    Its member is called `irq`.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里，IRQ号码-第一个参数-是从`pci_dev`结构的`irq`成员中查询的（因为此设备位于PCI总线上）。`pdev`结构指针在这个驱动程序的上下文（或私有）元数据结构中，名为`ixgb_adapter`。它的成员称为`irq`。
- en: The second parameter is the pointer to the interrupt handler routine (it's often
    referred to as the *hardirq handler*; we'll look at all this in a lot more detail
    later); here, it's the function named `ixgb_intr()`.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个参数是指向中断处理程序例程的指针（通常被称为*hardirq handler*；我们稍后将更详细地查看所有这些）；在这里，它是名为`ixgb_intr()`的函数。
- en: The third parameter is the `flags` bitmask. You can see that here the driver
    specifies that this interrupt is shared (via the `IRQF_SHARED` flag). It's part
    of the PCI specification for devices on this bus to share their interrupt lines.
    This implies that the driver will need to verify that the interrupt is really
    meant for it. It does this in the interrupt handler (it's usually very hardware-specific
    code, typically checking a given register for some expected value).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个参数是`flags`位掩码。您可以看到这里驱动程序指定此中断是共享的（通过`IRQF_SHARED`标志）。这是PCI规范的一部分，用于在该总线上的设备共享它们的中断线。这意味着驱动程序需要验证中断是否真的是为它而来的。它在中断处理程序中执行此操作（通常是非常特定于硬件的代码，通常检查给定寄存器的某个预期值）。
- en: The fourth parameter is the name of the driver handling this interrupt. It's
    obtained via the specialized `net_device` structure's `name` member (which has
    been registered to the kernel's net framework by  this driver calling `register_netdev()` in
    its probe method, `ixgb_probe()`).
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第四个参数是处理此中断的驱动程序的名称。它是通过专门的`net_device`结构的`name`成员获得的（该成员已经通过此驱动程序在其探测方法`ixgb_probe()`中调用`register_netdev()`注册到内核的网络框架中）。
- en: The fifth parameter is the value to pass along to the interrupt handler routine.
    As we mentioned previously, it's (again) the specialized `net_device` structure
    (which internally has the driver's context structure (`struct ixgb_adapter`) embedded
    within it!).
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第五个参数是传递给中断处理程序例程的值。正如我们之前提到的，它（再次）是专门的`net_device`结构（其中内部嵌入了驱动程序上下文结构（`struct
    ixgb_adapter`）！）。
- en: 'Conversely, when the network interface goes down, the `ixgb_down()` method
    is invoked by the kernel. When this happens, it disables NAPI and frees up the
    IRQ line with `free_irq()`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，当网络接口关闭时，内核会调用`ixgb_down()`方法。当这种情况发生时，它会禁用NAPI并使用`free_irq()`释放IRQ线。
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now that you've learned how to trap into a hardware interrupt via `request_irq()`,
    we need to understand some key points about writing the code of the interrupt
    handler routine itself, which is where the actual work of handling the interrupt
    is performed.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经学会了如何通过`request_irq()`陷入硬件中断，我们需要了解有关编写中断处理程序例程代码的一些关键要点，这就是处理中断的实际工作所在。
- en: Implementing the interrupt handler routine
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现中断处理程序例程
- en: 'Often, the interrupt is the hardware peripheral''s way of informing the system –
    the driver, really – that data is available and that it should pick it up. This
    is what typical drivers do: they grab the incoming data from the device buffers
    (or port, or whatever). Not just that, it''s also possible that there are user
    mode processes (or threads) that want this data. Thus, they have quite possibly
    opened the device file and have issued the `read(2)` (or equivalent) system call.
    This has them currently blocking (sleeping) upon this very event; that is, data
    arriving from the device.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，中断是硬件外围设备通知系统（实际上是驱动程序）数据已经可用并且应该接收的方式。这是典型驱动程序的操作：它们从设备缓冲区（或端口等）中获取传入的数据。不仅如此，还有可能有用户模式进程（或线程）需要这些数据。因此，他们很可能已经打开了设备文件并发出了`read(2)`（或等效）系统调用。这使得他们当前正在阻塞（睡眠），等待设备传来的数据。
- en: On detecting that data currently isn't available, the driver's *read* method
    typically puts the process context to sleep using one of the `wait_event*()` APIs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在检测到当前没有可用数据时，驱动程序的*read*方法通常会使用`wait_event*()`API之一将进程上下文置于睡眠状态。
- en: So, once your driver's interrupt handler has fetched the data into some kernel
    buffer, it typically awakens the sleeping readers. They now run through the driver's
    read method (in process context), pick up the data, and transfer it to the user
    space buffer as required.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一旦您的驱动程序的中断处理程序将数据获取到某个内核缓冲区中，它通常会唤醒正在睡眠的读取者。他们现在通过驱动程序的读取方法（在进程上下文中）运行，获取数据，并根据需要将其传输到用户空间缓冲区中。
- en: This section has been split into two broad parts. First, we'll learn what we
    can and cannot do in our interrupt handler. Then, we'll cover the mechanics of
    writing the code.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分分为两个主要部分。首先，我们将学习在我们的中断处理程序中可以做什么和不能做什么。然后，我们将介绍编写代码的机制。
- en: Interrupt context guidelines – what to do and what not to do
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 中断上下文指南-要做和不要做的事情
- en: 'The interrupt handler routine is your typical C code, with some caveats. A
    few key points regarding the design and implementation of your hardware interrupt
    handler are as follows:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 中断处理程序例程是您典型的C代码，但有一些注意事项。关于设计和实现硬件中断处理程序的一些关键点如下：
- en: '**The handler runs in an interrupt context, so do not block**: First and foremost,
    this code always runs in an interrupt context; that is, an atomic context. On
    a preemptible kernel, preemption is disabled, so there are some limitations regarding
    what it can and cannot do. In particular, it cannot do anything that directly
    or indirectly invokes the scheduler (`schedule()`)!'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理程序在中断上下文中运行，因此不要阻塞**：首先，这段代码始终在中断上下文中运行；也就是说，在原子上下文中。在可抢占的内核上，抢占被禁用，因此它有一些关于它可以做和不能做的限制。特别是，它不能做任何直接或间接调用调度器（`schedule()`）的事情！'
- en: 'In effect, you **cannot** do the following:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你**不能**做以下事情：
- en: Transfer data to and from kernel to user space as it might cause a page fault,
    which isn't allowed in an atomic context.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在内核和用户空间之间传输数据可能会导致页面错误，在原子上下文中是不允许的。
- en: Use the `GFP_KERNEL` flag in memory allocation. You must use the `GFP_ATOMIC`
    flag so that the allocation is non-blocking – it either succeeds or fails immediately.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在内存分配中使用`GFP_KERNEL`标志。你必须使用`GFP_ATOMIC`标志，以便分配是非阻塞的 - 它要么立即成功，要么立即失败。
- en: Invoke any API that's blocking (that, down the line, calls `schedule()`). In
    other words, it has to be purely non-blocking code paths. (We covered why in some
    detail in As seen in the companion guide *Linux Kernel Programming -* *Chapter
    8*, *Kernel Memory Allocation for Module Authors – Part 1*, in the *Never sleep
    in interrupt or atomic contexts* section).
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用任何会阻塞的API（最终调用`schedule()`）。换句话说，它必须是纯非阻塞的代码路径。（我们在伴随指南*Linux内核编程* - *第8章*，*模块作者的内核内存分配
    - 第1部分*的*永远不要在中断或原子上下文中休眠*部分中详细介绍了原因）。
- en: '**Interrupt masking**: By default, while your interrupt handler is running,
    **all** interrupts on the local CPU core where your handler is executing are masked
    (disabled), and the particular interrupt you''re handling is masked **across all
    cores**. Thus, your code is inherently reentrant-safe.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中断屏蔽**：默认情况下，当你的中断处理程序运行时，本地CPU核心上的**所有**中断都被屏蔽（禁用），你正在处理的特定中断在**所有核心**上都被屏蔽。因此，你的代码本质上是可重入安全的。'
- en: '**Keep it fast!:** You are writing code that will literally interrupt other
    processes – other "business" that the system was running before you rudely interrupted
    it; thus, you must do what''s required, as fast as is possible, and return, allowing
    the interrupted code path to continue. Important system software metrics include
    the worst-case interrupt length and the worst-case interrupt''s disabled time
    (we''ll cover some more on this in the *Measuring metrics and latency* section
    at the end of this chapter).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保持快速！**：你正在编写的代码会打断其他进程 - 在你粗鲁地打断它之前系统正在运行的其他“业务”；因此，你必须尽可能快地完成所需的工作，并返回，让被打断的代码路径继续。重要的系统软件指标包括最坏情况下的中断长度和最坏情况下的中断禁用时间（我们将在本章末尾的*测量指标和延迟*部分再详细介绍一些内容）。'
- en: These points are important enough to merit more detail, so we'll cover them
    more thoroughly in the following subsections.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这些要点非常重要，因此我们将在以下小节中更详细地介绍它们。
- en: Don't block – spotting possibly blocking code paths
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不要阻塞 - 发现可能会阻塞的代码路径
- en: 'This really boils down to the fact that when you''re in an interrupt or atomic
    context, don''t do anything that will call`schedule()`*. *Now, let''s look at
    what happens if our interrupt handler''s pseudocode looks like this:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上归结为这样一个事实，当你处于中断或原子上下文中时，不要做任何会调用`schedule()`的事情。现在，让我们看看如果我们的中断处理程序的伪代码如下会发生什么：
- en: '[PRE6]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Did you spot the big fat potential (though perhaps still subtle) bugs here?
    (Take a moment to spot them before moving on.)
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 你有没有发现这里存在潜在的大问题（尽管可能还很微妙）？（在继续之前花点时间发现它们。）
- en: First, the invocation of `kzalloc()` with the `GFP_KERNEL` flag might cause
    its kernel code to invoke `schedule()`! If it does, this will result in an "Oops,"
    which is a kernel bug. In typical production environments, this causes the kernel
    to panic (as the *sysctl* named `panic_on_oops` is typically set to `1` in production;
    doing `sysctl kernel.panic_on_oops` will show you the current setting). Next,
    the `copy_to_user()` invocation might result in a page fault and therefore necessitate
    a context switch, which will, of course, invoke `schedule()`; this is just not
    possible -again, a serious bug - in an atomic or interrupt context!
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用`GFP_KERNEL`标志调用`kzalloc()`可能会导致内核代码调用`schedule()`！如果是这样，这将导致“Oops”，这是一个内核错误。在典型的生产环境中，这会导致内核恐慌（因为*sysctl*命名为`panic_on_oops`通常在生产中设置为`1`；执行`sysctl
    kernel.panic_on_oops`将显示当前设置）。接下来，调用`copy_to_user()`可能导致页面错误，因此需要进行上下文切换，这当然会调用`schedule()`；这是不可能的
    - 再次，这是一个严重的错误 - 在原子或中断上下文中！
- en: 'So, more generically, let''s your interrupt handler calls a function, `a()`, with
    the call chain for `a()` being as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，更通用地说，让我们的中断处理程序调用一个名为`a()`的函数，`a()`的调用链如下：
- en: '[PRE7]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here, you can see that calling `a()` ultimately results in `schedule()` being
    called, which, as we just pointed out, will result in an "Oops", which is a kernel
    bug. So, the question here is, how do you, the driver developer, know that when
    you call `a()`, it results in `schedule()` being called? There are a few points
    you need to understand and leverage regarding this:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到调用`a()`最终会导致调用`schedule()`，正如我们刚刚指出的那样，这将导致“Oops”，这是一个内核错误。因此，问题是，作为驱动程序开发人员，当你调用`a()`时，你如何知道它会导致调用`schedule()`？关于这一点，你需要了解并利用一些要点：
- en: (As mentioned in the companion guide *Linux Kernel Programming -* *Chapter 8*,
    *Kernel Memory Allocation for Module Authors – Part 1*) One way you can find out in
    advance if your kernel code will ever enter an atomic or interrupt context is
    by looking at the kernel directly. When you're configuring the kernel (again, as
    seen in the companion guide *Linux Kernel Programming,* recall `make menuconfig` from *Linux
    Kernel Programming -* *Chapter 2*, *Building the 5.x Linux Kernel from Source
    – Part 1*), you can turn on a kernel config option that will help you spot exactly
    this circumstance. Take a look under the Kernel Hacking / Lock Debugging menu.
    There, you will find a Boolean tunable called Sleep inside atomic section checking.
    Turn it ON!
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （如在伴随指南*Linux内核编程*-*第8章* *模块作者的内核内存分配-第1部分*中提到）您可以通过直接查看内核来提前了解您的内核代码是否会进入原子或中断上下文。当您配置内核时（同样，如在伴随指南*Linux内核编程*中所见，回想一下`make
    menuconfig`来自*Linux内核编程*-*第2章* *从源代码构建5.x Linux内核-第1部分*），您可以打开一个内核配置选项，这将帮助您准确地发现这种情况。在Kernel
    Hacking / Lock Debugging菜单下查看。在那里，您会找到一个名为Sleep inside atomic section checking的布尔可调节项。将其打开！
- en: The config option is named `CONFIG_DEBUG_ATOMIC_SLEEP`; you can always grep
    your kernel's config file for it. As seen in the companion guide *Linux Kernel
    Programming -* *Chapter 5,* *Writing Your First Kernel Module - LKMs Part 2*,
    in the *Configuring a debug kernel *section, we specified that this option should
    be turned ON!
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 配置选项名为`CONFIG_DEBUG_ATOMIC_SLEEP`；您可以随时在内核的配置文件中使用grep进行搜索。如在伴随指南*Linux内核编程*-*第5章*
    *编写您的第一个内核模块-LKMs第2部分*中所见，在*配置调试内核*部分，我们指定应该打开此选项！
- en: Next (this is a bit pedantic, but it will help you!), make it a habit to look
    up the kernel documentation on the function in question (even better, briefly
    look up its code). The fact that it's a blocking call will usually be documented
    or specified in the comment header.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来（这有点迂腐，但会帮助您！），养成查看有关问题函数的内核文档的习惯（甚至更好的是，简要查看其代码）。它是一个阻塞调用的事实通常会在注释标题中有所记录或指定。
- en: 'The kernel has a helper macro called `might_sleep()`; it''s a useful debugging
    aid for just these situations! The following screenshot (from the kernel source, `include/linux/kernel.h`)
    explains it clearly:'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核有一个名为`might_sleep()`的辅助宏；它对这些情况非常有用的调试辅助工具！下面的屏幕截图（来自内核源码，`include/linux/kernel.h`）清楚地解释了它：
- en: '![](img/12db57d4-3c8a-457e-877b-6ed082d76051.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](img/12db57d4-3c8a-457e-877b-6ed082d76051.png)'
- en: Figure 4.2 – The comment for might_sleep() is helpful
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2-对might_sleep()的注释很有帮助
- en: Along the same lines, the kernel provides helper macros such as `might_resched()`, `cant_sleep()`, `non_block_start()`, `non_block_end()`,
    and so on.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，内核提供了一些辅助宏，如`might_resched()`、`cant_sleep()`、`non_block_start()`、`non_block_end()`等。
- en: Just to remind you, we mentioned pretty much the same thing - regarding not
    blocking within an atomic context - in the companion guide *Linux Kernel Programming,* *Chapter
    8,  Kernel Memory Allocation for Module Authors Part 1* in the *Dealing with the
    GFP flags* section (and elsewhere). Furthermore, we also showed you how the useful
    LDV project (mentioned back in companion guide *Linux Kernel Programming*, *Chapter
    1, Kernel Workspace Setup*, in the section *The LDV - Linux Driver Verification
    - project*) has caught and fixed several such violations within kernel and driver
    module code.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只是为了提醒您，我们在伴随指南*Linux内核编程*-*第8章* *模块作者的内核内存分配第1部分*的*处理GFP标志*部分（以及其他地方）中提到了几乎相同的事情-关于不在原子上下文中阻塞。此外，我们还向您展示了有用的LDV项目（在伴随指南*Linux内核编程*-*第1章*
    *内核工作空间设置*中提到，在*LDV-Linux驱动程序验证-项目*部分）如何捕获并修复了内核和驱动程序模块代码中的几个此类违规行为。
- en: At the beginning of this section, we mentioned that, often, sleeping user space readers
    block upon the arrival of data. Its arrival is typically signaled by the hardware
    interrupt. Then, your interrupt handler routine fetches the data into a kernel
    VAS buffer and wakes up the sleepers. Hey, isn't that disallowed? No – the `wake_up*()` APIs
    are non-blocking in nature. The thing you need to understand is that they only
    switch the process' (or thread's) state from asleep (`TASK_{UN}INTERRUPTIBLE`)
    to awake, ready to run (`TASK_RUNNING`). This does not invoke the scheduler; the
    kernel will do that at the next opportunity point (we discussed CPU scheduling
    in the companion guide *Linux Kernel Programming, **Chapter 10*, *The CPU Scheduler
    – Part 1*, and *Chapter 11*, *The CPU Scheduler – Part 2*).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的开头，我们提到，通常情况下，睡眠的用户空间读取器会在数据到达时阻塞。其到达通常由硬件中断信号。然后，您的中断处理程序例程将数据获取到内核VAS缓冲区并唤醒睡眠者。嘿，这是不允许的吗？不-`wake_up*()`
    API在性质上是非阻塞的。您需要理解的是，它们只会将进程（或线程）的状态从睡眠（`TASK_{UN}INTERRUPTIBLE`）切换到唤醒，准备运行（`TASK_RUNNING`）。这不会调用调度程序；内核将在下一个机会点进行调度（我们在伴随指南*Linux内核编程*-*第10章*
    *CPU调度程序-第1部分*和*第11章* *CPU调度程序-第2部分*中讨论了CPU调度）。
- en: Interrupt masking – the defaults and controlling it
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中断屏蔽-默认值和控制
- en: Recall that the interrupt controller chip (the PIC/GIC) will have a mask register.
    The OS can program it **to mask or block hardware interrupts** as required (of
    course, some interrupts may be unmaskable; the**non-maskable interrupt** (**NMI**)
    is a typical case that we  discuss later in this chapter).
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下中断控制器芯片（PIC/GIC）将具有屏蔽寄存器。操作系统可以根据需要对其进行编程**屏蔽或阻止硬件中断**（当然，某些中断可能是不可屏蔽的；**不可屏蔽中断**（**NMI**）是我们稍后在本章中讨论的典型情况）。
- en: It's important to realize, though, that keeping interrupts enabled (unmasked)
    as much as possible is a critical measure of OS quality!Why? If an interrupt(s)
    is blocked, the peripheral cannot be responded to and the system's performance
    lags or suffers as a result (merely pressing and releasing a keyboard key results
    in two hardware interrupts). You must keep interrupts enabled for as long as possible.
    Locking with the spinlock will cause interrupts and preemption to be disabled!
    Keep the critical section short (we'll cover locking in depth in the last two
    chapters of this book).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，重要的是要意识到，尽可能保持中断启用（未屏蔽）是操作系统质量的一个关键指标！为什么？如果中断被阻塞，外围设备无法响应，系统的性能会下降或受到影响（仅按下并释放键盘键会导致两个硬件中断）。您必须尽可能长时间地保持中断启用。使用自旋锁会导致中断和抢占被禁用！保持关键部分短暂（我们将在本书的最后两章中深入介绍锁定）。
- en: 'Next, when it comes to the default behavior on the Linux OS, when a hardware
    interrupt occurs and that interrupt isn''t masked (always the default), let''s
    say it''s IRQn (where *n* is the IRQ number), **the kernel ensures that while
    its interrupt (hardirq) handler executes, all interrupts on the local CPU core
    where the handler is executing are disabled and IRQn is disabled across all CPUs**.
    Thus, your handler code is inherently reentrant-safe. This is good as it means
    you never have to worry about the following:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，当涉及到Linux操作系统上的默认行为时，当硬件中断发生并且该中断未被屏蔽（通常是默认情况），假设它是IRQn（其中*n*是中断号），**内核确保在其中断（hardirq）处理程序执行时，所有在处理程序执行的本地CPU核心上的中断都被禁用，并且IRQn在所有CPU上都被禁用**。因此，您的处理程序代码本质上是可重入安全的。这很好，因为这意味着您永远不必担心以下问题：
- en: Masking interrupts yourself
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自己屏蔽中断
- en: When to run atomically, to completion and without interruption, on that CPU
    core
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 何时在该CPU核心上以原子方式完成且不被中断
- en: As we'll see later, a bottom-half can still be interrupted by a top-half, thus
    necessitating locking.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在后面看到的，底半部仍然可以被顶半部中断，因此需要锁定。
- en: While IRQn executes on, say, CPU core 1, other interrupts remain enabled (unmasked)
    on all CPU cores but core 1\. Thus, on multicore system hardware, interrupts can
    run in parallel on different CPU cores. This is fine as long as they don't step
    on each other's toes, with respect to global data! If they do, you'll have to
    employ locking, something we'll cover in detail in this book's last two chapters.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 当IRQn在CPU核心1上执行时，其他CPU核心上的中断仍然启用（未屏蔽）。因此，在多核系统硬件上，中断可以在不同的CPU核心上并行运行。只要它们不相互干扰全局数据，这是可以的！如果它们这样做，您将不得不使用锁定，这是我们将在本书的最后两章中详细介绍的内容。
- en: Furthermore, on Linux, **all interrupts are peers**, so there is no priority
    among them; in other words, they all run at the same priority. Provided it's unmasked,
    any hardware interrupt can interrupt the system at any point in time; an interrupt
    can even interrupt interrupts! However, they typically don't do the latter. This
    is because, as we have just learned, while an interrupt IRQn is running on a CPU
    core, all the interrupts on that core are disabled (masked) and IRQn is disabled
    globally (across all cores) until it completes; the exception is an NMI.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在Linux上，**所有中断都是对等的**，因此它们之间没有优先级；换句话说，它们都以相同的优先级运行。只要它未被屏蔽，任何硬件中断都可以在任何时间点中断系统；中断甚至可以中断中断！但它们通常不会这样做。这是因为，正如我们刚刚了解的，当中断IRQn在CPU核心上运行时，该核心上的所有中断都被禁用（屏蔽），并且IRQn在全局范围内（跨所有核心）被禁用，直到完成；例外是NMI。
- en: Keep it fast
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保持快速
- en: 'An interrupt is what is suggests: it interrupts normal work on the machine;
    it''s a bit of an annoyance that has to be tolerated. Context has to be saved,
    the handler has to be executed (along with bottom halves, which we will cover
    in the *Understanding and using top and bottom halves* section), and then context
    must be restored to whatever got interrupted. So, you get the idea: it''s a critical
    code path, so don''t plod along – **be fast and non-blocking!**'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 中断就是它所暗示的：它中断了机器上的正常工作；这是一个必须被容忍的烦恼。上下文必须被保存，处理程序必须被执行（连同底半部，我们将在*理解和使用顶半部和底半部*部分中介绍），然后必须将上下文恢复到被中断的状态。所以，你明白了：这是一个关键的代码路径，所以不要磕磕绊绊-**要快速和非阻塞！**
- en: 'It also brings up the question, how fast is fast? While the answer is, of course,
    platform-dependent, a heuristic is this: keep your interrupt processing as fast
    as is possible, **within tens of microseconds**. If it consistently exceeds 100
    microseconds, then the need for alternate strategies does come up. We''ll cover
    what you can do when this occurs later in the chapter.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 它还提出了一个问题，快有多快？虽然答案当然是依赖于平台的，但一个经验法则是：尽可能快地处理中断，**在几十微秒内**。如果它一直超过100微秒，那么确实需要考虑使用替代策略。我们将在本章后面介绍当发生这种情况时可以做什么。
- en: With regard to our simple `my_interrupt()` pseudocode snippet (shown in the
    *Don't block – spotting possibly blocking code paths* section), first, ask yourself,
    must I really allocate memory in a critical non-blocking needs-to-execute-fast
    code path such as an interrupt handler? Can you design the module/driver to allocate
    the memory earlier (and just use the pointer)?
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 关于我们简单的`my_interrupt()`伪代码片段（在*不要阻塞-发现可能阻塞的代码路径*部分中显示）,首先，问问自己，在关键的非阻塞需要快速执行的代码路径（例如中断处理程序）中，我真的需要分配内存吗？您是否可以设计模块/驱动程序以更早地分配内存（并且只使用指针）？
- en: Again, the reality is that, at times, quite a lot of work has to be done to
    correctly service the interrupt (network/block drivers are good examples). We
    shall cover some typical strategies we can use to deal with this shortly.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，现实情况是，有时需要做相当多的工作才能正确地处理中断（网络/块驱动程序是很好的例子）。我们将很快介绍一些我们可以用来处理这个问题的典型策略。
- en: Writing the interrupt handler routine itself
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写中断处理程序例程
- en: 'Now, let''s quickly learn the mechanical part of it. The signature of the hardware
    interrupt handler routine (often referred to as the **hardirq** routine) is as
    follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们快速学习它的机械部分。硬件中断处理程序例程（通常称为**hardirq**例程）的签名如下：
- en: '[PRE8]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The interrupt handler routine is invoked by the kernel''s generic IRQ layer
    when a hardware IRQ that your driver has registered interest in (via the `request_irq()` or
    friends APIs) is triggered. It receives two parameters:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的驱动程序注册了兴趣（通过`request_irq()`或友元API）的硬件IRQ被触发时，中断处理程序例程由内核的通用IRQ层调用。它接收两个参数：
- en: The first parameter is the IRQ line (an integer). Triggering this causes this
    handler to be invoked.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个参数是IRQ线（整数）。触发这个会调用处理程序。
- en: The second parameter is the value that was passed via the last parameter to `request_irq()`.
    As we mentioned previously, it's typically the driver's specialized device structure
    that embeds the driver context or private data. Because of this, its data type
    is the generic `void *`, allowing `request_irq()` to pass any type along, typecasting
    it appropriately in the handler routine and using it.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个参数是通过`request_irq()`的最后一个参数传递的值。正如我们之前提到的，它通常是驱动程序的专用设备结构，嵌入了驱动程序上下文或私有数据。因此，它的数据类型是通用的`void
    *`，允许`request_irq()`传递任何类型，适当地在处理程序例程中进行类型转换并使用它。
- en: The handler is regular C code, but with all the caveats we mentioned in the
    preceding section! Take care to follow those guidelines. Though the details are
    hardware-specific, typically, your interrupt handler's first responsibility is
    to clear the interrupt on the board, in effect, acknowledging it and telling the
    PIC as much. This is usually achieved by writing some specific bits into a specified hardware
    register on the board or controller; read the datasheet for your particular chip,
    chipset or hardware device to figure this out. Here, the `in_irq()` macro will
    return `true`, informing you that your code is currently in a hardirq context.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 处理程序是常规的C代码，但是有了我们在前一节中提到的所有注意事项！请务必遵循这些准则。虽然细节是硬件特定的，通常，您的中断处理程序的第一个责任是在板上清除中断，实际上是确认它并告诉PIC。这通常是通过向板上或控制器上的指定硬件寄存器写入一些特定位来实现的；阅读您特定芯片、芯片组或硬件设备的数据表以弄清楚这一点。在这里，`in_irq()`宏将返回`true`，通知您的代码当前处于hardirq上下文中。
- en: The rest of the work that's done by the handler is obviously very device-specific.
    For example, an input driver will want to scan the key code (or touchscreen coordinates
    or mouse key/movement or whatever) that was just pressed or released from some
    register or peripheral memory location and perhaps save it in some memory buffer.
    Alternatively, it might immediately pass it up the stack to a generic input layer
    above it. We won't try and delve into those details here. Again, the driver framework
    is what you need to understand for your driver type; this is beyond the scope
    of this book.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 处理程序所做的其余工作显然是非常特定于设备的。例如，输入驱动程序将希望扫描刚刚从某个寄存器或外围内存位置按下或释放的键码（或触摸屏坐标或鼠标键/移动等），并可能将其保存在某个内存缓冲区中。或者，它可能立即将其传递到其上面的通用输入层。我们不会在这里深入探讨这些细节。再次强调，驱动程序框架是您需要了解的驱动程序类型；这超出了本书的范围。
- en: 'What about the value to return from your hardirq handler? The `irqreturn_t` return
    value is an `enum` and looks as follows:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 那么从您的hardirq处理程序返回的值是什么？`irqreturn_t`返回值是一个`enum`，如下所示：
- en: '[PRE9]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding comment header clearly points out its meaning. Essentially, the
    generic IRQ framework insists that you return the `IRQ_HANDLED` value if your
    driver handled the interrupt. If the interrupt was not yours or you couldn't handle
    it, you should return the `IRQ_NONE` value. (This helps the kernel detect spurious
    interrupts as well. If you cannot figure out whether it's your interrupt, simply
    return `IRQ_HANDLED`.) We'll see how `IRQ_WAKE_THREAD` is used shortly.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的注释标题清楚地指出了它的含义。基本上，通用的IRQ框架坚持要求您返回`IRQ_HANDLED`值，如果您的驱动程序处理了中断。如果中断不是您的，或者您无法处理它，应该返回`IRQ_NONE`值。（这也有助于内核检测虚假中断。如果您无法确定它是否是您的中断，只需返回`IRQ_HANDLED`。）我们将很快看到`IRQ_WAKE_THREAD`是如何使用的。
- en: Now, let's look at some more code! In the next section, we'll check out the
    hardware interrupt handler code for two drivers (we came across these earlier
    in this and the previous chapter).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一些更多的代码！在下一节中，我们将检查两个驱动程序的硬件中断处理程序代码（我们在本章和上一章中都遇到过）。
- en: Code view 2 – the i8042 driver's interrupt handler
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码视图2 - i8042驱动程序的中断处理程序
- en: 'In the previous chapter, [Chapter 3](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml),
    *Working with Hardware I/O Memory*, in the *A PIO example – the i8042* section,
    we learned how the i8042 device driver uses some very simple helper routines to
    perform I/O (read/write) on the I/O ports of the i8042 chip (this is often the
    keyboard/mouse controller on x86 systems). The following code snippet shows some
    of the code for its hardware interrupt handler routine; you can clearly see it
    reading both the status and data registers:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，[第3章](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml)，*使用硬件I/O内存*，在*A PIO示例
    - i8042*部分，我们学习了i8042设备驱动程序如何使用一些非常简单的辅助程序在i8042芯片的I/O端口上执行I/O（读/写）（这通常是x86系统上的键盘/鼠标控制器）。以下代码片段显示了其硬件中断处理程序例程的一些代码；您可以清楚地看到它同时读取了状态寄存器和数据寄存器：
- en: '[PRE10]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Here, the `serio_interrupt()` call is how this driver passes on the data it
    read from the hardware to the upper "input" layer, which will process it further
    and ultimately have it ready for the user space process to consume. (Take a look
    at the *Questions *section at the end of this chapter; one of the exercises for
    you to try is writing a simple "key logger" device driver.)
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`serio_interrupt()`调用是这个驱动程序将从硬件读取的数据传递给上层的“输入”层，该层将进一步处理它，并最终使其准备好供用户空间进程使用。（在本章末尾的*问题*部分中看一下；您可以尝试的练习之一是编写一个简单的“键盘记录器”设备驱动程序。）
- en: Code view 3 – the IXGB network driver's interrupt handler
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码视图3 - IXGB网络驱动程序的中断处理程序
- en: 'Let''s take a look at another example. Here, we''re looking at the hardware
    interrupt handler of the Intel IXGB ethernet adapter''s device driver, which we
    mentioned earlier:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个例子。在这里，我们正在查看Intel IXGB以太网适配器的设备驱动程序的硬件中断处理程序，这是我们之前提到的：
- en: '[PRE11]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding code snippet, notice how the driver gains access to its private
    (or context) metadata structure (`struct ixgb_adapter`) from the `net_device` structure
    (the specialized structure for network devices) it receives as the second parameter;
    this is very typical. (Here, the `netdev_priv()` helper used to extract the driver's
    private structure from the generic `net_device` structure is somewhat analogous
    to the well-known `container_of()` helper macro. In fact, this helper is also
    often employed in similar situations.)
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，注意驱动程序如何从第二个参数接收的`net_device`结构（用于网络设备的专用结构）中获得对其私有（或上下文）元数据结构（`struct
    ixgb_adapter`）的访问权限；这是非常典型的。（在这里，`netdev_priv()`助手用于从通用的`net_device`结构中提取驱动程序的私有结构，类似于众所周知的`container_of()`助手宏。事实上，这个助手在类似的情况下也经常被使用。）
- en: 'Next, it performs a peripheral I/O memory read via the `IXGB_READ_REG()` macro (it''s
    using the MMIO approach – see the previous chapter for details on MMIO; `IXGB_READ_REG()` is
    a macro that invokes the `readl()` API we covered in the previous chapter – the
    older style routine for performing a 32-bit MMIO read). Don''t miss the key point
    here: this is how the driver determines whether the interrupt is meant for it,
    as, recall, it''s a shared interrupt! If it is meant for it (the likely case),
    it proceeds with its job; since this adapter supports NAPI, the driver now schedules
    polled NAPI reads to suck up network packets as they come in and sends them up
    the network protocol stack for further processing (well, it''s really not that simple;
    the actual memory transfer work will be performed over DMA).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，它通过`IXGB_READ_REG()`宏执行外围I/O内存读取（它使用MMIO方法，详情请参阅上一章关于MMIO的详细信息；`IXGB_READ_REG()`是一个调用我们在上一章中介绍的`readl()`API的宏，用于执行32位MMIO读取的旧风格例程）。不要错过这里的关键点：这是驱动程序确定中断是否适用于它的方式，因为它是一个共享中断！如果它适用于它（可能的情况），它将继续执行它的工作；由于此适配器支持NAPI，驱动程序现在安排轮询NAPI读取以吸收网络数据包并将其发送到网络协议栈进行进一步处理（实际上并不是那么简单；实际的内存传输工作将通过DMA执行）。
- en: 'Now, a diversion but an important one: you need to learn how to allocate the
    IRQ line the modern way – via the `devm_*` APIs. This is known as the managed
    approach.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，一个分歧但重要的问题：您需要学习如何以现代方式（通过`devm_*`API）分配IRQ线。这被称为托管方法。
- en: IRQ allocation – the modern way – the managed interrupt facility
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IRQ分配-现代方式-托管中断设施
- en: Many modern drivers employ the kernel's *devres* or managed APIs framework for
    various purposes. The managed APIs in modern Linux kernels give you the advantage
    of not having to worry about freeing up resources that you've allocated (we have
    covered a few of them already, including `devm_k{m,z}alloc()` and `devm_ioremap{_resource}()`).
    Of course, you must use them appropriately, typically in the probe method (or
    `init` code) of the driver.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 许多现代驱动程序使用内核的*devres*或托管API框架来实现各种目的。现代Linux内核中的托管API为您提供了一个优势，即无需担心释放已分配的资源（我们已经介绍了其中的一些，包括`devm_k{m,z}alloc()`和`devm_ioremap{_resource}()`）。当然，您必须适当地使用它们，通常是在驱动程序的探测方法（或`init`代码）中。
- en: 'It is recommended that, when writing drivers, you use this newer API style.
    Here, we''ll show how you to employ the `devm_request_irq()` API in order to allocate
    (register) your hardware interrupt. Its signature is as follows:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 建议在编写驱动程序时使用这种更新的API风格。在这里，我们将展示如何使用`devm_request_irq()`API来分配（注册）硬件中断。它的签名如下：
- en: '[PRE12]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The first parameter is the pointer to the `device` structure of the device (which,
    as we saw in [Chapter 1](239d8da6-0342-441a-823e-d3766f0d97b6.xhtml), *Writing
    a Simple misc Character Device Driver*, has to be obtained by registering to the
    appropriate kernel framework). The five remaining parameters are identical to
    `request_irq()`; we won't repeat them here. The whole point is that, once registered,
    you are freed from calling `free_irq()`; the kernel will automatically invoke
    it as required (on driver removal or device detachment). This greatly helps us
    developers avoid common and infamous leakage type bugs.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数是设备的`device`结构的指针（正如我们在[第1章](239d8da6-0342-441a-823e-d3766f0d97b6.xhtml)中看到的，*编写一个简单的misc字符设备驱动程序*，必须通过注册到适当的内核框架来获取）。剩下的五个参数与`request_irq()`相同；我们这里不再重复。整个重点是，一旦注册，您就不必调用`free_irq()`；内核将根据需要自动调用它（在驱动程序移除或设备分离时）。这极大地帮助我们开发人员避免常见和臭名昭著的泄漏类型错误。
- en: 'To help clarify its use, let''s quickly look at an example. The following is
    a bit of the code from the V4L TV tuner driver:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助澄清其用法，让我们快速看一个例子。以下是来自V4L电视调谐器驱动程序的一部分代码。
- en: '[PRE13]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As we saw in regard to getting the physical address for MMIO in [Chapter 3](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml),
    *Working with Hardware I/O Memory*, in the *Obtaining the device resources* section,
    here, the same driver employs the `platform_get_resource()` API to extract the IRQ
    number (specifying the type of resource as an IRQ line with `IORESOURCE_IRQ`).
    Once it has it, it issues the `devm_request_irq()` API to allocate or register
    the interrupt! As is therefore expected, a search for `free_irq()` in this driver
    yields no results.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[第3章](7399aaad-197a-4a1b-aa1a-edec3d4e3faa.xhtml)中关于获取MMIO的物理地址所看到的，*使用硬件I/O内存*，在*获取设备资源*部分，这里，相同的驱动程序使用`platform_get_resource()`API来提取IRQ号（将资源类型指定为带有`IORESOURCE_IRQ`的IRQ线）。一旦获得，它就会使用`devm_request_irq()`API来分配或注册中断！因此，可以预期在这个驱动程序中搜索`free_irq()`将不会得到任何结果。
- en: Next, we'll learn what a threaded interrupt is, how to work with one, and, more
    importantly, the *why* of it.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习什么是线程中断，如何处理线程中断，更重要的是它的原因。
- en: Working with the threaded interrupts model
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用线程中断模型
- en: As seen in the companion guide *Linux Kernel Programming -* *Chapter 11*, *The
    CPU Scheduler – Part 2*, in the *Converting mainline Linux into an RTOS* section,
    we covered the real-time patch for Linux (RTL), which allows you to patch, configure,
    build, and run Linux as an RTOS! If you're hazy on this, please refer back to
    this. We won't repeat the same information here.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在配套指南*Linux内核编程 - 第11章*，*CPU调度器 - 第2部分*，*将主线Linux转换为RTOS*部分中所看到的，我们介绍了Linux的实时补丁（RTL），它允许您对Linux进行补丁、配置、构建和运行为RTOS！如果您对此感到困惑，请回头查看。我们不会在这里重复相同的信息。
- en: The **Real-Time Linux**(**RTL**) project's work has been steadily back-ported
    into the mainline Linux kernel. One of the key changes wrought by RTL was merging
    the **threaded interrupts** feature into the mainline kernel. This occurred in
    kernel version 2.6.30 (June 2009). This technology does something that, at first
    glance, seems very weird: it "converts" the hardware interrupt handler into, essentially,
    a kernel thread.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**实时Linux（RTL）**项目的工作已经稳步地被回溯到主线Linux内核中。RTL带来的关键变化之一是将**线程中断**功能合并到主线内核中。这发生在内核版本2.6.30（2009年6月）。这项技术做了一些乍一看似乎非常奇怪的事情：它“转换”硬件中断处理程序，基本上成为一个内核线程。'
- en: As you will learn in the next chapter, a kernel thread is really very similar
    to a user mode thread – it runs independently, in the process context and has
    its own task structure (and thus its own PID, TGID, and so on), which means it
    can be scheduled; that is, when in the runnable state, it fights with other contender
    threads to run on a CPU core. The key difference is that a user mode thread always
    has two address spaces – the process VAS that it belongs to (user space) and the
    kernel VAS, which it switches to when it issues a system call. A kernel thread,
    on the other hand, runs purely in kernel space and has no view of the user space;
    it only sees the kernel VASthat it always executes in (technically, its `current-mm` value is
    always `NULL`!).
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您将在下一章中了解到的那样，内核线程与用户模式线程非常相似 - 它在进程上下文中独立运行，并且有自己的任务结构（因此有自己的PID、TGID等），这意味着它可以被调度；也就是说，在可运行状态时，它与其他竞争线程争夺CPU核心的运行。关键区别在于用户模式线程始终有两个地址空间
    - 它所属的进程VAS（用户空间）和它发出系统调用时切换到的内核VAS。另一方面，内核线程纯粹在内核空间中运行，并且没有用户空间的视图；它只看到它始终在其中执行的内核VAS（从技术上讲，它的`current-mm`值始终为`NULL`！）。
- en: 'So, how do you decide if you should use a threaded interrupt? We need to cover
    a few more topics before this becomes completely clear (for those of you who are
    impatient, here''s the short answer: use a threaded interrupt handler when (as
    a quick heuristic) the interrupt work takes over 100 microseconds; skip ahead
    to the *Hardirqs, tasklets, threaded handlers – what to use when* section and
    see the table there for a quick look).'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你如何决定是否应该使用线程中断？在这变得完全清晰之前，我们需要涵盖一些更多的话题（对于那些急切的人，这里是简短的答案：当中断工作需要超过100微秒时，使用线程中断处理程序作为一个快速的启发式方法；跳到*硬中断、任务、线程处理程序
    - 什么时候使用*部分并查看那里的表以快速查看）。
- en: Now, let's learn how to employ the threaded interrupt model by checking out
    the available APIs – both the regular and managed ones. Then, we'll learn how
    to use the managed version and how to employ it within a driver. After that, we'll
    look at its internal implementation and delve more into the why of it.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们通过查看可用的API（常规和托管的API）来学习如何使用线程中断模型。然后，我们将学习如何使用托管版本以及如何在驱动程序中使用它。之后，我们将查看其内部实现并更深入地探讨其中的原因。
- en: Employing the threaded interrupt model – the API
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用线程中断模型 - API
- en: 'In order to understand the threaded interrupt model''s inner workings, let''s
    take a look at the relevant APIs. We''ve already covered using the `request_irq()` API.
    Let''s look at its implementation:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解线程中断模型的内部工作原理，让我们来看看相关的API。我们已经介绍了如何使用`request_irq()`API。让我们看看它的实现：
- en: '[PRE14]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This API is merely a thin wrapper over the `request_threaded_irq()` API! Its
    signature is as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 这个API只是`request_threaded_irq()`API的一个薄包装！它的签名如下：
- en: '[PRE15]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The parameters, except for the third one, are identical to `request_irq()`.
    The following are a few key points to note:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 除了第三个参数外，其他参数与`request_irq()`是相同的。以下是一些要注意的关键点：
- en: '`irq_handler_t handler`: The second parameter is a pointer to the usual interrupt
    handler function. We now refer to it as the primary handler. If it''s null and `thread_fn` (the
    third parameter) is non-null, a default primary handler (of the kernel''s) is
    auto-installed (if you''re wondering about this default primary handler, we''ll
    cover it in more detail in the *Internally implementing the threaded interrupt* section).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`irq_handler_t handler`：第二个参数是指向通常的中断处理程序函数的指针。我们现在称它为主处理程序。如果它为空，而`thread_fn`（第三个参数）不为空，则会自动安装一个默认的主处理程序（如果您想了解这个默认的主处理程序，我们将在*内部实现线程中断*部分中更详细地介绍）。'
- en: '`irq_handler_t thread_fn`: The third parameter is a pointer to the threaded
    interrupt function; the API behavior depends on whether you pass this parameter
    as null or not:'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`irq_handler_t thread_fn`：第三个参数是指向线程中断函数的指针；API的行为取决于您是否将此参数传递为null：'
- en: If it's non-null, then the actual servicing of the interrupt is performed by
    this function. It runs within the context (process) of a dedicated kernel thread
    – it's a threaded interrupt!
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它不为空，则实际的中断服务由此函数执行。它在专用内核线程的上下文（进程）中运行 - 这就是线程中断！
- en: If it's null, which is the default when you call `request_irq()`, only the primary
    handler runs, and no kernel thread is created.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它为空，也就是在调用`request_irq()`时的默认情况下，只有主处理程序运行，不会创建内核线程。
- en: 'The primary handler if specified (second parameter), is run in what''s referred
    to as the **hardirq** or hard interrupt context (as was the case with `request_irq()`).
    If the primary handler is non-null, thenyou are expected to write it''s code and
    (minimally) do the following in it:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果指定了主处理程序（第二个参数），则在所谓的**硬中断**或**硬中断**上下文中运行（与`request_irq()`的情况一样）。如果主处理程序不为空，则您应该编写它的代码，并（最少）在其中执行以下操作：
- en: Verify the interrupt is for you; if it's not, return `IRQ_NONE`.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证中断是否为您服务; 如果不是，请返回`IRQ_NONE`。
- en: If it is for you, then you can clear and/or disable the interrupt on the board/device.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果是为您服务的，那么您可以在板/设备上清除和/或禁用中断。
- en: Return `IRQ_WAKE_THREAD`; this will cause the kernel to wake up the kernel thread
    representing your threaded interrupt handler. The name of the kernel thread will
    be in the format `irq/irq#-name`. This kernel thread will now internally invoke
    the `thread_fn()` function, where you perform the actual interrupt handling work.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回`IRQ_WAKE_THREAD`; 这将导致内核唤醒代表您的线程中断处理程序的内核线程。内核线程的名称将以`irq/irq#-name`的格式。现在，这个内核线程将在内部调用`thread_fn()`函数，您将在其中执行实际的中断处理工作。
- en: On the other hand, if the primary handler is null, then just your threaded handler
    – the function specified by the third parameter – will be automatically run **as
    a kernel thread** by the OS when the interrupt fires.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果主处理程序为空，那么当中断触发时，只会自动运行您的线程处理程序 - 第三个参数指定的函数**作为内核线程**。
- en: As with `request_irq()`, the return value from `request_threaded_irq()` is an
    integer, following the usual `0/-E` kernel convention: `0` on success and a negative
    `errno` value on failure. You are expected to check it.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 与`request_irq()`一样，`request_threaded_irq()`的返回值是一个整数，遵循通常的`0/-E`内核约定：成功返回`0`，失败返回负的`errno`值。您应该检查它。
- en: Employing the managed threaded interrupt model – the recommended way
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用托管线程中断模型-推荐的方式
- en: 'Again, using the managed API for allocating a threaded interrupt would be the
    recommended approach for a modern driver. The kernel provides the `devm_request_threaded_irq()` API
    for this very purpose:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '再次，对于现代驱动程序，使用托管API来分配线程中断将是推荐的方法。内核为此目的提供了`devm_request_threaded_irq()`API:'
- en: '[PRE16]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: All the parameters besides the first one, which is the pointer to the device
    structure, are the same as those for `request_threaded_irq()`. The key advantage
    of this is that you don't need to worry about freeing up the IRQ line. The kernel
    will auto-free it on device detach or driver removal, as we learned with `devm_request_irq()`. As
    with `request_threaded_irq()`, the return value from `devm_request_threaded_irq()` is
    an integer, following the usual `0/-E` kernel convention: `0` on success and a
    negative errno value on failure; you are expected to check it.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 除了第一个参数（指向设备结构的指针）之外的所有参数都与`request_threaded_irq()`的参数相同。这样做的关键优势在于，您无需担心释放IRQ线。内核将在设备分离或驱动程序移除时自动释放它，就像我们在`devm_request_irq()`中学到的那样。与`request_threaded_irq()`一样，`devm_request_threaded_irq()`的返回值是一个整数，遵循通常的`0/-E`内核约定：成功返回`0`，失败返回负的errno值;
    你应该检查它。
- en: Don't forget! Using the managed `devm_request_threaded_irq()` API is the modern
    recommended approach for allocating a threaded interrupt. However, note that it
    won't always be the right approach; see the *Constraints when using a threaded
    handler* section for more information.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记！使用托管`devm_request_threaded_irq()`API是分配线程中断的现代推荐方法。但是，请注意，这并不总是正确的方法; 有关更多信息，请参阅*使用线程处理程序时的约束*部分。
- en: 'The signature of the threaded interrupt handler function is identical to that
    for the hardirq interrupt handler:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '线程中断处理程序函数的签名与hardirq中断处理程序的签名相同:'
- en: '[PRE17]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The parameters have the same meaning as well.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 参数的含义也是相同的。
- en: 'Threaded interrupts often use the `IRQF_ONESHOT` interrupt flag; the kernel
    comment in `include/linux/interrupt.h` describes it best:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '线程中断通常使用`IRQF_ONESHOT`中断标志; `include/linux/interrupt.h`中的内核注释最好描述了它:'
- en: '[PRE18]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As a matter of fact, the kernel **insists that you use** the `IRQF_ONESHOT` flag
    when your driver is incorporating a threaded handler and the primary handler is
    the kernel default. Not using the `IRQF_ONESHOT` flag would be deadly when level-triggered
    interrupts are in play. To be safe, the kernel throws an error - when this flag
    isn't present in the `irqflags` bitmask parameter - even for edge-triggering.
    If you're curious, the code at `kernel/irq/manage.c:__setup_irq()` checks for
    just this (link: [https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/manage.c#L1486](https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/manage.c#L1486)).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '事实上，内核**坚持要求**在您的驱动程序包含线程处理程序并且主处理程序是内核默认值时使用`IRQF_ONESHOT`标志。当级联触发中断在起作用时，不使用`IRQF_ONESHOT`标志将是致命的。为了安全起见，内核会抛出一个错误-当`irqflags`位掩码参数中不存在这个标志时-即使是边缘触发。如果您感兴趣，`kernel/irq/manage.c:__setup_irq()`中的代码检查了这一点（链接:
    [https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/manage.c#L1486](https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/manage.c#L1486)）。'
- en: A kernel parameter called `threadirqs` exists that you can pass to the kernel
    command line (via the bootloader). This force threads all the interrupt handlers
    except those marked explicitly as `IRQF_NO_THREAD`*.* To find out more about this
    kernel parameter, go to [https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html](https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 存在一个名为`threadirqs`的内核参数，您可以将其传递给内核命令行（通过引导加载程序）。这会强制线程化所有中断处理程序，除了那些明确标记为`IRQF_NO_THREAD`的中断处理程序。要了解有关此内核参数的更多信息，请转到[https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html](https://www.kernel.org/doc/html/latest/admin-guide/kernel-parameters.html)。
- en: In the following subsection, we'll take a look at one of the Linux driver's
    STM32 microcontrollers. Here, we will focus on how interrupt allocation is done
    via the "managed" API that we just covered.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将看一下Linux驱动程序的STM32微控制器之一。在这里，我们将重点关注通过刚刚介绍的“托管”API进行中断分配的方式。
- en: Code view 4 – the STM32 F7 microcontroller's threaded interrupt handler
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码视图4 - STM32 F7微控制器的线程中断处理程序
- en: 'The STM32 F7 is part of a series of microcontrollers that have been manufactured
    by STMicroelectronics, based on the ARM-Cortex M7F core:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 'STM32 F7是由STMicroelectronics制造的一系列微控制器中的一部分，基于ARM-Cortex M7F核心:'
- en: '![](img/beaa7b0f-7523-4633-8ba4-0fcc9a157cb2.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](img/beaa7b0f-7523-4633-8ba4-0fcc9a157cb2.png)'
- en: Figure 4.3 – The STM32F103 microcontroller pinout with some I2C pins highlighted
    (see the lower left)
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 - 带有一些I2C引脚突出显示的STM32F103微控制器引脚布局（见左下角）
- en: 'Image Credit: The preceding image, which has been slightly added to by myself,
    has been taken from [https://www.electronicshub.org/wp-content/uploads/2020/02/STM32F103C8T6-Blue-Pill-Pin-Layout.gif](https://www.electronicshub.org/wp-content/uploads/2020/02/STM32F103C8T6-Blue-Pill-Pin-Layout.gif).
    Image by Rasmus Friis Kjekisen. This image falls under Creative Commons CC BY-SA
    1.0 ([https://creativecommons.org/licenses/by-sa/1.0/](https://creativecommons.org/licenses/by-sa/1.0/)).'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：前面的图片，我稍作修改后，来自[https://www.electronicshub.org/wp-content/uploads/2020/02/STM32F103C8T6-Blue-Pill-Pin-Layout.gif](https://www.electronicshub.org/wp-content/uploads/2020/02/STM32F103C8T6-Blue-Pill-Pin-Layout.gif)。图片由Rasmus
    Friis Kjekisen提供。此图片属于知识共享CC BY-SA 1.0许可证（[https://creativecommons.org/licenses/by-sa/1.0/](https://creativecommons.org/licenses/by-sa/1.0/)）。
- en: 'The Linux kernel supports the STM32 F7 via various drivers and DTS files. Here,
    we''ll take a look at a tiny bit of the code for the I2C bus driver (`drivers/i2c/busses/i2c-stm32f7.c`)
    for this microcontroller. It allocates two hardware interrupts:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核通过各种驱动程序和DTS文件支持STM32 F7。在这里，我们将看一小部分微控制器的I2C总线驱动程序（`drivers/i2c/busses/i2c-stm32f7.c`）的代码。它分配了两个硬件中断：
- en: The event IRQ line, via the `devm_request_threaded_irq()` API
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`devm_request_threaded_irq()`API的事件IRQ线
- en: The error IRQ line, via the `request_irq()` API
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`request_irq()`API的错误IRQ线
- en: 'The code that allocates the IRQ lines is, as expected, within its probe method:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 分配IRQ线的代码如预期地位于其`probe`方法中：
- en: '[PRE19]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Let's focus on the call to `devm_request_threaded_irq()`. The first parameter
    is the pointer to the device structure. Since this is a platform driver (registered
    via the `module_platform_driver` wrapper macro), its probe method receives the `struct
    platform_device *pdev` parameter; the `device` structure is extracted from it.
    The second parameter is the IRQ line to allocate. Again, as we've already seen,
    it's extracted via a helper routine. Here, this is the `platform_get_irq()` API.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们关注对`devm_request_threaded_irq()`的调用。第一个参数是指向设备结构的指针。由于这是一个平台驱动程序（通过`module_platform_driver`包装宏注册），其probe方法接收`struct
    platform_device *pdev`参数；设备结构从中提取。第二个参数是要分配的IRQ线。同样，如我们已经看到的，它是通过辅助例程提取的。在这里，这是`platform_get_irq()`API。
- en: The third parameter specifies the primary handler; that is the hardirq. Since
    it's non-null, this routine will be invoked when the IRQ is triggered. It performs
    hardware-specific verification on the device and the I2C transfer, and if all
    is okay, it returns the `IRQ_WAKE_THREAD` value. This awakens the threaded interrupt routine,
    the fourth parameter, and the function `stm32f7_i2c_isr_event_thread()` runs as
    a kernel thread in process context! The `irqflags` parameter, which is set to `IRQF_ONESHOT`,
    is typical with threaded handlers; it specifies that the IRQ line remains disabled
    until the threaded handler completes (not just the hardirq). The threaded handler
    routine does its work and returns `IRQ_HANDLED` when it's finished.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个参数指定了主处理程序；也就是硬中断。由于它不为空，当IRQ被触发时将调用此例程。它对设备和I2C传输进行硬件特定的验证，如果一切正常，它将返回`IRQ_WAKE_THREAD`值。这会唤醒线程中断例程，第四个参数，函数`stm32f7_i2c_isr_event_thread()`将作为内核线程在进程上下文中运行！`irqflags`参数被设置为`IRQF_ONESHOT`，这在线程处理程序中很典型；它指定IRQ线保持禁用，直到线程处理程序完成（不仅仅是硬中断）。线程处理程序例程完成其工作并在完成时返回`IRQ_HANDLED`。
- en: Since the error IRQ line is allocated via the `devm_request_irq()` API, and
    because we have already covered how to use this API (refer to the *IRQ allocation
    – the modern way – the managed interrupt facility* section), we won't repeat any
    information regarding it here.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 由于错误的IRQ线是通过`devm_request_irq()`API分配的，并且因为我们已经介绍了如何使用这个API（请参阅*IRQ allocation
    – the modern way – the managed interrupt facility*部分），我们不会在这里重复任何关于它的信息。
- en: Now, let's look at how the kernel internally implements the threaded interrupt
    model.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看内核是如何内部实现线程中断模型的。
- en: Internally implementing the threaded interrupt
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内部实现线程中断
- en: As we mentioned previously, if the primary handler is null and the thread function
    is non-null, the kernel uses a default primary handler. The function is called `irq_default_primary_handler()` and all
    it does is return the `IRQ_WAKE_THREAD` value, thus waking up (and making schedulable)
    the kernel thread.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，如果主处理程序为空并且线程函数非空，内核将使用默认的主处理程序。该函数被称为`irq_default_primary_handler()`，它的作用是返回`IRQ_WAKE_THREAD`值，从而唤醒（并使可调度）内核线程。
- en: 'Furthermore, the actual kernel thread that runs your `thread_fn` routine is
    created within the code of the `request_threaded_irq()` API. The call graph (as
    of version 5.4.0 of the Linux kernel) is as follows:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，运行您的`thread_fn`例程的实际内核线程是在`request_threaded_irq()`API的代码中创建的。调用图（截至Linux内核5.4.0版本）如下：
- en: '[PRE20]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The invocation of the `kthread_create()` API is as follows. Here, you can clearly
    see how the format of the new kernel thread''s name will be in `irq/irq#-name`
    format:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 调用`kthread_create()`API如下。在这里，您可以清楚地看到新内核线程的名称格式将采用`irq/irq#-name`格式：
- en: '[PRE21]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here (we don't show the code), the new kernel thread is programmed to be set
    to the `SCHED_FIFO` scheduling policy and the `MAX_USER_RT_PRIO/2` real-time scheduling
    priority, which typically has a value of `50` (the `SCHED_FIFO` range is from `1` to `99`,
    and `MAX_USER_RT_PRIO` is `100`). We'll cover why this is important in the *Why
    use threaded interrupts?* section. If you're unsure about the thread scheduling
    policy and its priority, please refer to the companion guide *Linux Kernel Programming
    -* *Chapter 10*, *The CPU Scheduler – Part 1*, the *The POSIX scheduling policies*
    section.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里（我们不显示代码），新的内核线程被设置为`SCHED_FIFO`调度策略和`MAX_USER_RT_PRIO/2`实时调度优先级，通常为`50`（`SCHED_FIFO`范围为`1`到`99`，`MAX_USER_RT_PRIO`为`100`）。我们将在*为什么使用线程中断？*部分介绍这一点。如果您对线程调度策略及其优先级不确定，请参阅配套指南*Linux
    Kernel Programming -* *第10章*，*CPU Scheduler – Part 1*，*The POSIX scheduling policies*部分。
- en: The kernel manages this kernel thread representing the threaded interrupt handler
    in its entirety. As we've already seen, it creates it on IRQ allocation via the `[devm_]request_threaded_irq()` API;
    then, the kernel thread simply sleeps. It is awoken on demand by the kernel, whenever
    the allocated IRQ is triggered; the kernel will destroy it when `free_irq()` is
    invoked. Don't worry about the details at the moment; we'll cover kernel threads and
    other interesting topics in the next chapter.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 内核完全管理代表线程中断处理程序的内核线程。正如我们已经看到的，它通过`[devm_]request_threaded_irq()`API在IRQ分配时创建它；然后，内核线程简单地休眠。内核会在需要时唤醒它，每当分配的IRQ被触发时；当调用`free_irq()`时，内核将销毁它。目前不要担心细节；我们将在下一章中介绍内核线程和其他有趣的主题。
- en: So far, although you have learned how to use the threaded interrupt model, it's
    not been clearly explained why (and when)you should. The next section will cover
    this in detail.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，虽然您已经学会了如何使用线程中断模型，但尚未清楚地解释了为什么（以及何时）应该使用。下一节将详细介绍这一点。
- en: Why use threaded interrupts?
  id: totrans-238
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要使用线程中断？
- en: 'A key question that''s usually asked is, why should I use threaded interrupts
    at all when the regular hardirq-type interrupt exists? The complete answer is
    a bit elaborate; the following are the primary reasons why:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 通常会问的一个关键问题是，当常规的hardirq类型中断存在时，为什么要使用线程中断？完整的答案有点复杂；以下是主要原因：
- en: To really make it real time.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真正使其实时。
- en: It eliminates/reduces softirq bottlenecks. Since the threaded handler actually
    runs its code in process context, it's not considered to be as critical a code
    path as a hardirq handler; hence, you can take a little longer with interrupt
    handling.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它消除/减少了softirq瓶颈。由于线程处理程序实际上在进程上下文中运行其代码，因此它不被认为是与hardirq处理程序一样关键的代码路径；因此，您可以在中断处理时花费更长的时间。
- en: While a hardirq executes IRQn, that IRQ line is disabled on all the cores across
    the system. If it takes a while to execute to completion (of course, you should
    design it so that it doesn't), then the system's response can significantly drop;
    on the other hand, while a threaded handler executes, the hardware IRQ line is enabled by
    default. This is good for performance and responsiveness. (Note that there will
    be many cases where the driver will not want this behavior; that is, it will want
    IRQ to be disabled while it processes it. To do that, specify the `IRQF_ONSEHOT` flag.)
  id: totrans-242
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当hardirq执行IRQn时，系统中所有核心上的IRQ线都被禁用。如果执行时间较长（当然，您应该设计它不这样做），那么系统的响应可能会显着下降；另一方面，当线程处理程序执行时，默认情况下硬件IRQ线是启用的。这对性能和响应性是有利的。（请注意，有许多情况下驱动程序不希望出现这种行为；也就是说，它希望在处理中断时禁用IRQ。要做到这一点，请指定`IRQF_ONESHOT`标志。）
- en: In a nutshell, as a quick rule of thumb, **when the interrupt handling consistently
    takes over 100 microseconds, use the threaded interrupt model** (see the table
    in *Hardirqs, tasklets, threaded handlers – what to use when* section).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，作为一个快速的经验法则，**当中断处理一直超过100微秒时，使用线程中断模型**（参见*Hardirqs，tasklets，threaded
    handlers-何时使用*部分中的表）。
- en: In the following subsections, we will expand on these points.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的小节中，我们将扩展这些观点。
- en: Threaded interrupts – to really make it real time
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 线程中断-真正实时
- en: This is a key point and requires some explanation.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个关键点，需要一些解释。
- en: 'Prioritization on the standard Linux OS goes from highest to lowest priority
    as follows (we''ll suffix each bullet point with the *context* it runs in; it
    will be either process or interrupt. If you''re unclear on this point, it''s very
    important you understand this; do refer to the companion guide *Linux Kernel Programming
    - **Chapter 6*, *Kernel Internals Essentials – Processes and Threads*, the *Understanding
    Process and Interrupt Contexts* section, for more information):'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 标准Linux OS上的优先级从最高到最低依次如下（我们将每个项目后缀为它运行的*context*；它将是进程或中断。如果您对此不清楚，那么您理解这一点非常重要；请参考配套指南*Linux
    Kernel Programming - **第6章*，*内核内部要点-进程和线程*，*理解进程和中断上下文*部分，以获取更多信息）：
- en: '**Hardware interrupts**: These preempt anything and everything. The hardirq handler
    runs atomically (to completion, without interruption) on the CPU; `context:interrupt`.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 硬件中断：这些会抢占任何东西。hardirq处理程序在CPU上原子地运行（完成，不中断）；`context:interrupt`。
- en: '**Real-time threads** (the `SCHED_FIFO` or `SCHED_RR` scheduling policy), both
    kernel and user space, with positive real-time priority (`rtprio`); `context:process`:'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实时线程（`SCHED_FIFO`或`SCHED_RR`调度策略），内核空间和用户空间都具有正实时优先级（`rtprio`）；`context:process`：
- en: A kernel thread at the same realtime priority (`current-rtprio`) gets a slight
    priority bump over a user space thread at the same realtime priority.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在相同的实时优先级（`current-rtprio`）下，内核线程会比相同实时优先级的用户空间线程稍微提高优先级。
- en: '**Processor exceptions**: This includes system calls (they''re really synchronous
    exceptions; for example, `syscall` on the x86, `SWI` on ARM), page faults, protection
    faults, and so on; `context:process`*.*'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理器异常：这包括系统调用（它们实际上是同步异常；例如，在x86上是`syscall`，在ARM上是`SWI`），页错误，保护错误等；`context:process`。
- en: '**User mode threads**: They use the `SCHED_OTHER` scheduling policy by default
    with an `rtprio` of `0`; `context:process`*.*'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户模式线程：它们默认使用`SCHED_OTHER`调度策略，`rtprio`为`0`；`context:process`。
- en: 'The following diagram shows relative prioritization on Linux (this diagram
    is a bit simplistic; a more refined diagram is seen later via *Figure 4.10* and
    *Figure 4.11*):'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了Linux上的相对优先级（这个图表有点简单；稍后会通过*图4.10*和*图4.11*看到更精细的图表）：
- en: '![](img/9decdc81-d105-45f1-8e71-a471632f4fc5.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9decdc81-d105-45f1-8e71-a471632f4fc5.png)'
- en: Figure 4.4 – Relative prioritization on the standard Linux OS
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4-标准Linux OS上的相对优先级
- en: Let's say you are working on a real-time multithreaded application. Of the dozens
    of threads that are alive within the process, three of them (let's call them threads
    A, B, and C for simplicity) are considered to be critical "real-time" threads.
    Accordingly, you have the app grant them a scheduling policy of `SCHED_FIFO` and
    real-time priorities of 30, 45, and 60 to threads A, B, and C, respectively (if
    you're unclear on these points, please refer to the companion guide *Linux Kernel
    Programming - Chapter 10*, *The CPU Scheduler - Part 1*, and *Chapter 11*, *The
    CPU Scheduler - Part 2*, on CPU scheduling). Since it's a real-time app, the maximum
    time that it can take these threads to complete their work is curtailed. In other
    words, a *deadline exists; *for our example scenario, let's say that the **worst-case deadline** for
    thread B to complete its work is 12 milliseconds.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您正在开发一个实时多线程应用程序。在进程中有数十个活动线程，其中三个（我们简单地称它们为A、B和C）被认为是关键的“实时”线程。因此，您让应用程序授予它们`SCHED_FIFO`调度策略和分别为30、45和60的实时优先级（如果您对这些内容不清楚，请参考配套指南*Linux内核编程-第10章*，*CPU调度器-第1部分*和*第11章*，*CPU调度器-第2部分*，关于CPU调度）。由于这是一个实时应用程序，这些线程完成工作的最长时间是有限的。换句话说，存在一个*截止日期*；在我们的示例场景中，假设线程B完成工作的*最坏情况截止日期*是12毫秒。
- en: Now, in terms of relative priorities, how will this work? For simplicity, let's
    say that the system has a single CPU core. Now, another thread, X (running with
    the scheduling policy `SCHED_OTHER` and with a real-time priority of `0`, which
    is the default scheduling policy/priority value), is currently executing code
    on the CPU. However, if the "event" that any of your real-time threads is waiting
    upon occurs, it will preempt the currently executing thread and run. This is what's
    expected; recall that the fundamental rule for real-time scheduling is very simple: *the
    highest priority runnable thread must be the thread that's running*. Okay; that's
    good. Now, we need to consider hardware interrupts. A hardware interrupt, as we've
    seen, has the highest priority. This means it will preempt anything and everything,
    including your (so-called) real-time thread (see the preceding diagram)!
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，就相对优先级而言，这将如何运作？为简单起见，假设系统有一个单CPU核心。现在，另一个线程X（使用`SCHED_OTHER`调度策略，并且实时优先级为`0`，这是默认的调度策略/优先级值）当前正在CPU上执行代码。但是，如果任何您的实时线程正在等待的“事件”发生，它将抢占当前正在执行的线程并运行。这是预期的；请记住，实时调度的基本规则非常简单：*最高优先级的可运行线程必须是正在运行的线程*。好的。现在，我们需要考虑硬件中断。正如我们所见，硬件中断具有最高优先级。这意味着它将抢占任何东西，包括您的（所谓的）实时线程（请参见前面的图表）！
- en: Let's say that interrupt processing takes 200 microseconds; on a rich OS such
    as Linux, this isn't considered too bad. However, in this situation, five hardware
    interrupts will consume 1 millisecond; what if the device becomes busy (many incoming
    data packets, for example) and emits, say, 20 hardware interruptsin a continuous
    stream? This will certainly be given priority and will consume (at least) 4 milliseconds!
    Your real-time thread(s) will definitely be preempted while interrupt processing
    runs and will be unable to gain the CPU it needs until it's far too late! The
    (12 ms) deadline will have long expired and the system will fail (if yours is
    a true real-time app, this could be catastrophic).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 假设中断处理需要200微秒；在像Linux这样的强大操作系统上，这并不算太糟糕。然而，在这种情况下，五个硬件中断将消耗1毫秒；如果设备变得繁忙（例如有大量传入数据包），并且连续发出20个硬件中断，会怎么样？这肯定会被优先考虑，并且会消耗（至少）4毫秒！您的实时线程肯定会在中断处理运行时被抢占，并且无法获得它所需的CPU，直到为时已晚！（12毫秒）截止日期早已过期，系统将失败（如果您的应用程序是真正的实时应用程序，这可能是灾难性的）。
- en: 'The following diagram represents this scenario conceptually (for conciseness
    and clarity, we have only shown one of our user space `SCHED_FIFO` real-time threads;
    that is, thread B at `rtprio` 45):'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表以概念上表示了这种情况（为简洁和清晰起见，我们只显示了一个我们的用户空间`SCHED_FIFO`实时线程；即`rtprio`为45的线程B）：
- en: '![](img/2d7f4c41-b170-4c4c-b628-2b63b473f6ff.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2d7f4c41-b170-4c4c-b628-2b63b473f6ff.png)'
- en: 'Figure 4.5: The hardirq model – a user mode RT SCHED_FIFO thread interrupted
    by a hardware interrupt flood; deadline missed'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5：硬中断模型-用户模式RT SCHED_FIFO线程被硬件中断洪水打断；截止日期未能满足
- en: Real-time thread B is depicted as running from time `t0` (on the x-axis; the
    y-axis represents the real-time priority; thread B's `rtprio` is 45); it has 12
    ms (a hard deadline) to complete its work. However, let's say that after 6 ms
    have elapsed (at time `t1`), a hardware interrupt fires.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 实时线程B被描述为从时间`t0`（x轴上）开始运行；y轴表示实时优先级；线程B的`rtprio`为45；它有12毫秒（硬截止日期）来完成工作。然而，假设经过6毫秒（在时间`t1`）后，发生了一个硬件中断。
- en: 'In *Figure 4.5*, we haven''t shown the low-level interrupt setup code that
    executes. Now a hardware interrupt firing at time `t1` results in the interrupt
    handler being invoked; that is, the hardirq (shown as the big black vertical double-arrow
    in the preceding diagram). Obviously, the hardware interrupt preempts thread B.
    Now, let''s say it takes 200 microseconds to execute; that''s not much, but what
    if a flood of interrupts (say 20 of them, thus eating up 4 ms) arrives! This is
    depicted in the preceding diagram: the interrupts continue at a rapid rate until
    time `t2`; only after they all complete will context be restored. Thus, the scheduling
    code runs and (let''s say) context switches back to thread B, giving it the processor
    (we take, on a modern Intel CPU, a conservative context switching time of 50 microseconds:
    [https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html](https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html)).
    However, soon after, at time `t3`, the hardware interrupt fires once more, preempting
    B again. This can go on indefinitely; the RT thread will eventually run (when
    the interrupt storm is complete) but may or may not meet its deadline! This is
    the main issue.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图4.5*中，我们没有显示执行低级中断设置代码。现在，在时间`t1`触发硬件中断导致中断处理程序被调用；也就是说，hardirq（在前面的图中显示为大黑色垂直双箭头）。显然，硬件中断会抢占线程B。现在，假设它需要200微秒来执行；这不多，但是如果出现一连串的中断（比如20个，因此占用了4毫秒）会怎么样！这在前面的图中有所描述：中断以快速的速度持续到时间`t2`；只有在它们全部完成后，上下文才会被恢复。因此，调度代码运行并且（假设）上下文切换回线程B，将其给予处理器（在现代英特尔CPU上，我们采取保守的上下文切换时间为50微秒：[https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html](https://blog.tsunanet.net/2010/11/how-long-does-it-take-to-make-context.html)）。然而，不久之后，在时间`t3`，硬件中断再次触发，再次抢占B。这可能会无限期地继续下去；RT线程最终会运行（当中断风暴完成时），但可能会或可能不会满足其截止日期！这是主要问题。
- en: The problem that was described in the preceding paragraph doesn't go away by
    simply raising the real-time priority of your user mode threads; the hardirq hardware
    interrupts will still always preempt them, regardless of their priority.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 前面段落中描述的问题并不能通过简单提高用户模式线程的实时优先级来解决；硬件中断仍然会始终抢占它们，无论它们的优先级如何。
- en: 'By backporting the **threaded interrupt** from the RTL project to mainline
    Linux, we can **solve** this problem. How? Think about it: with the *threaded
    interrupt* model, the majority of the interrupt handling work is now performed
    by a `SCHED_FIFO` kernel thread running with a real-time priority of `50`. So,
    simply design your user space applications to have, where essential, `SCHED_FIFO`
    RT threads with real-time priorities **higher than `50`**. **This will ensure
    that they run in preference to the hardware interrupt handler!**'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将RTL项目中的**线程化中断**从主线Linux移植，我们可以**解决**这个问题。如何？想一想：使用*线程化中断*模型，现在大部分中断处理工作是由一个以实时优先级`50`运行的`SCHED_FIFO`内核线程执行的。因此，只需设计您的用户空间应用程序，在必要时具有`SCHED_FIFO`
    RT线程，其实时优先级**高于`50`**。**这将确保它们优先于硬件中断处理程序运行！**
- en: The key idea here is that a user mode thread under the `SCHED_FIFO` policy and
    a real-time priority 50, can, in effect, preempt the (threaded) hardware interrupt! Quite
    a thing indeed.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的关键思想是，一个处于`SCHED_FIFO`策略下，实时优先级为50的用户模式线程，实际上可以抢占（线程化的）硬件中断！确实是一件了不起的事情。
- en: 'So, for our example scenario, let''s now assume we''re using threaded interrupts.
    Next, tweak the user space multithreaded app''s design: assign our three real-time
    threads a policy of `SCHED_FIFO` and real-time priorities of 60, 65, and 70\.
    The following diagram conceptually depicts this scenario (for clarity, we have
    only shown one of our user space `SCHED_FIFO` threads, thread B, this time at
    `rtprio` of `65`):'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于我们的示例场景，现在假设我们正在使用线程化中断。接下来，调整用户空间多线程应用程序的设计：将我们的三个实时线程分配为`SCHED_FIFO`策略，并且实时优先级分别为60、65和70。以下图概念上描述了这种情况（为了清晰起见，我们只显示了我们的用户空间`SCHED_FIFO`线程之一，线程B，这次的`rtprio`为`65`）：
- en: '![](img/9e8f7bd2-2822-44d8-b5f9-1a0c30c5b1f9.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9e8f7bd2-2822-44d8-b5f9-1a0c30c5b1f9.png)'
- en: Figure 4.6 – Threaded interrupt model – a user mode RT SCHED_FIFO rtprio 50
    thread can preempt the threaded interrupt; deadline achieved
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6-线程化中断模型-一个用户模式RT SCHED_FIFO rtprio 50线程可以抢占线程化中断；达到截止日期
- en: In the preceding diagram, RT thread B is now at the `SCHED_FIFO` scheduling
    policy with an `rtprio` of `65`. It has up to 12 ms to complete (reach its deadline).
    Again, say it executes for 6 ms (`t0` to `t1`); at time `t1`, a hardware interrupt
    fires. Here, the low-level setup code and the (kernel default or driver's) hardirq
    handler will execute immediately, preempting anything on the processor. However,
    the hardirq or primary handler takes a very short time to execute (a few microseconds
    at the most). This is, as we have already discussed, the primary handler that
    is now executing; it will do the bare minimum work required before returning the
    `IRQ_WAKE_THREAD` value, which will have the kernel wake up the kernel thread
    representing the threaded handler. However – and this is the key – the threaded
    interrupt, which is `SCHED_FIFO` with a priority of `50`, is now competing with
    other runnable threads for the CPU resource. Since thread B is a `SCHED_FIFO` real-time
    thread with an rtprio of `65`, **it will beat the threaded handler to the CPU
    and will run instead!**
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图中，RT线程B现在处于`SCHED_FIFO`调度策略，`rtprio`为`65`。它最多有12毫秒的时间来完成（达到它的截止日期）。同样，假设它执行了6毫秒（从`t0`到`t1`）；在时间`t1`，硬件中断触发。在这里，低级设置代码和（内核默认或驱动程序的）hardirq处理程序将立即执行，抢占处理器上的任何东西。然而，hardirq或主处理程序执行的时间非常短（最多几微秒）。这是，正如我们已经讨论过的，现在正在执行的主处理程序；它将在返回`IRQ_WAKE_THREAD`值之前执行所需的最低限度的工作，这将使内核唤醒代表线程处理程序的内核线程。然而-这是关键-线程中断，它是`SCHED_FIFO`，优先级为`50`，现在正在与其他可运行的线程竞争CPU资源。由于线程B是一个`SCHED_FIFO`实时线程，其rtprio为`65`，**它将击败线程处理程序到CPU并且会运行！**
- en: 'To summarize, in the preceding diagram, the following is happening:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，在前面的图中，正在发生以下情况：
- en: 'Time `t0` to `t1`: the user mode RT thread (`SCHED_FIFO`, `rtprio 65`) is executing
    its code (for 6 ms)'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间`t0`到`t1`：用户模式RT线程（`SCHED_FIFO`，`rtprio 65`）正在执行其代码（持续6毫秒）
- en: At time `t1`, the thin gray bar represents the hardirq low-level setup/BSP code.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在时间`t1`，细灰色条代表hardirq低级设置/BSP代码。
- en: The thin black double-arrow vertical line represents the primary hardirq handler
    (both the above take just a few microseconds to complete).
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 细黑色双箭头垂直线代表主要的hardirq处理程序（上面两者只需几微秒即可完成）。
- en: The blue color bar is the scheduling code.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝色条是调度代码。
- en: The purple bar (at `t3` + 50 us) represents the threaded interrupt handler running
    at rtprio `50`.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 紫色条（在`t3` + 50微秒处）代表以rtprio `50`运行的线程中断处理程序。
- en: The upshot of all this is that thread B completes its work well within its deadline
    (here, as an example, it's met its deadline in just over 10 ms).
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些的要点是，B线程在其截止日期内完成了其工作（在这里，例如，它在10毫秒多一点的时间内满足了其截止日期）。
- en: Unless time constraints are extremely critical, using the threaded interrupt
    model to handle your device's interrupts works very well for most devices and
    drivers. At the time of writing, the devices that tend to remain within the traditional
    top/bottom half approach (covered in detail in the *Understanding and using top
    and bottom halves* section) are typically high-performance network, block, and
    (some) multimedia devices.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 除非时间限制非常关键，否则使用线程中断模型来处理设备的中断对大多数设备和驱动程序都非常有效。在撰写本文时，倾向于保持传统的上/下半部分方法（在*理解和使用上半部分和下半部分*部分中有详细介绍）的设备通常是高性能网络、块和（一些）多媒体设备。
- en: Constraints when using a threaded handler
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用线程处理程序时的约束
- en: 'One last thing regarding threaded handlers: the kernel won''t blindly allow
    you to use a threaded handler for any IRQ; it honors some constraints. At the
    time of registering your thread handler (via the `[devm_]request_threaded_irq()`
    APIs), it performs several validity checks, one of which we''ve mentioned already: `IRQF_ONESHOT` must
    be present for a threaded handler.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 关于线程处理程序的最后一件事：内核不会盲目地允许您为任何IRQ使用线程处理程序；它遵守一些约束。在注册线程处理程序时（通过`[devm_]request_threaded_irq()`API），它执行几个有效性检查，其中我们已经提到了一个：`IRQF_ONESHOT`必须存在于线程处理程序中。
- en: 'It also depends on the actual IRQ line; for example, I once tried using a threaded
    handler for IRQ `1` on x86 (it''s typically the i8042 keyboard/mouse controller
    chip''s interrupt line). It failed, with the kernel showing the following:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 它还取决于实际的IRQ线路；例如，我曾经尝试在x86上使用线程处理程序处理IRQ `1`（通常是i8042键盘/鼠标控制器芯片的中断线）。它失败了，内核显示如下：
- en: '[PRE22]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: So, from the preceding output, we can see that the i8042 will only accept the `0x80` bitmask
    for the IRQ flags, whereas I passed a value of `0x2080`; a little checking will
    show that the `0x2000` flag is indeed the `IRQF_ONESHOT` flag; apparently, this
    causes a mismatch and isn't allowed. Not only that, but notice who flagged the
    error – it was the kernel's generic IRQ layer (`genirq`) checking things under
    the hood. (Note that this kind of error checking isn't restricted to threaded
    interrupts.)
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从前面的输出中，我们可以看到i8042只接受`0x80`的IRQ标志位掩码，而我传递了一个值为`0x2080`；稍微检查一下就会发现`0x2000`标志确实是`IRQF_ONESHOT`标志；显然，这会导致不匹配并且不被允许。不仅如此，还要注意谁标记了错误-是内核的通用IRQ层（`genirq`）在幕后检查事情。
    （请注意，这种错误检查不仅限于线程中断。）
- en: Also, certain critical devices will find that using threaded handlers will actually
    slow them down; this is pretty typical for modern NICs, block devices, and some
    multimedia devices. They typically use the hardirq top half and tasklet/softirq
    bottom half mechanisms (this will be explained in the *Understanding and using
    top and bottom halves* section).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，某些关键设备将发现使用线程处理程序实际上会减慢它们的速度；这对于现代NIC、块设备和一些多媒体设备非常典型。它们通常使用hardirq上半部分和tasklet/softirq下半部分机制（这将在*理解和使用上半部分和下半部分*部分中解释）。
- en: Working with either hardirq or threaded handlers
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用hardirq或线程处理程序
- en: 'Before we conclude this section, there''s one more interesting point to take
    into consideration: the kernel provides an IRQ allocation API that, based on certain
    circumstances, will either set up your interrupt handler as a traditional hardirq
    handler or as a threaded handler. This API is called `request_any_context_irq()`;
    note that it''s exported as GPL-only though. Its signature is as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束本节之前，还有一个有趣的要考虑的问题：内核提供了一个IRQ分配API，根据某些情况，将设置您的中断处理程序作为传统的hardirq处理程序或线程处理程序。此API称为`request_any_context_irq()`；请注意，它仅作为GPL导出。其签名如下：
- en: '[PRE23]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The parameters are identical to that of `request_irq()`. When invoked, this
    routine will decide whether the interrupt handler function – the  `handler` parameter –
    will run in an atomic hardirq context or in a sleep-capable process context, that
    of a kernel thread – in other words, as a threaded handler. How will you know
    which context `handler()` will run in? The return value let''s you know based
    on the context that `handler()` will run in:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 参数与`request_irq()`相同。当调用时，此例程将决定中断处理程序函数（`handler`参数）将在原子hardirq上下文中运行还是在可睡眠的进程上下文中运行，即内核线程的上下文，换句话说，作为线程处理程序。您如何知道`handler()`将在哪个上下文中运行？返回值让您知道基于`handler()`将在其中运行的上下文：
- en: If it's going to run in a hardirq context, it returns a value of `IRQC_IS_HARDIRQ`.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它将在hardirq上下文中运行，则返回值为`IRQC_IS_HARDIRQ`。
- en: If it's going to run in a process/threaded context, it returns a value of `IRQC_IS_NESTED`.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果它将在进程/线程上下文中运行，则返回值为`IRQC_IS_NESTED`。
- en: A negative `errno` will be returned on failure (you're expected to check this).
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 失败时将返回负的`errno`（您应该检查这一点）。
- en: What does this really imply, though? Essentially, there are controllers that
    are on slow buses (I2C is a great example); they spawn off handlers that use so-called
    "nested" interrupts, which really means that the handler isn't atomic in nature.
    It might invoke functions that sleep (again, I2C functions are a good example
    of this), and thus are required to be preemptible. Using the `request_any_context_irq()`
    API ensures that if this is the case, the underlying generic IRQ code detects
    it and gives you an appropriate handling interface. The GPIO-driven matrix keypad
    driver is another example that makes use of this API (`drivers/input/keyboard/matrix_keypad.c`).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 但这实际上意味着什么呢？基本上，有些控制器位于慢总线上（I2C是一个很好的例子）；它们产生使用所谓的“嵌套”中断的处理程序，这实际上意味着处理程序的性质不是原子的。它可能调用会休眠的函数（再次，I2C函数就是一个很好的例子），因此需要是可抢占的。使用`request_any_context_irq()`
    API可以确保如果是这种情况，底层的通用IRQ代码会检测到并为您提供适当的处理接口。GPIO驱动的矩阵键盘驱动程序是另一个使用此API的例子（`drivers/input/keyboard/matrix_keypad.c`）。
- en: 'With this coverage, you now understand what threaded interrupts are and why
    they can be very useful. Now, let''s take a look at a shorter topic: how you,
    as the driver author, can selectively enable/disable IRQ lines.'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些覆盖，现在你知道了什么是线程中断，以及为什么它们非常有用。现在，让我们来看一个更短的话题：作为驱动程序作者，你如何有选择地启用/禁用IRQ线。
- en: Enabling and disabling IRQs
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启用和禁用IRQs
- en: 'Typically, it''s the core kernel (and/or arch-specific) code that handles low-level
    interrupt management. This includes doing things such as masking them as and when
    required. Nevertheless, some drivers, as well as the OS, require fine-grained
    control when enabling/disabling hardware interrupts. As your driver or module
    code runs with kernel privileges, the kernel provides (exported) helper routines
    that allow you to do exactly this:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '通常，核心内核（和/或特定于体系结构的）代码处理低级中断管理。这包括在需要时屏蔽它们。然而，一些驱动程序以及操作系统在启用/禁用硬件中断时需要细粒度的控制。由于您的驱动程序或模块代码以内核特权运行，内核提供了（导出的）辅助程序，允许您做到这一点： '
- en: '| **Brief comment** | **API or helper routine** |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| **简要评论** | **API或辅助程序** |'
- en: '| **Disable/enable all interrupts on the local processor** |  |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| **禁用/启用本地处理器上的所有中断** |  |'
- en: '| Unconditionally disables all interrupts on the local (current) processor
    core. | `local_irq_disable()` |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| 无条件地禁用当前处理器核心上的所有中断。 | `local_irq_disable()` |'
- en: '| Unconditionally enables all interrupts on the local (current) processor core.
    | `local_irq_enable()` |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 无条件地启用当前处理器核心上的所有中断。 | `local_irq_enable()` |'
- en: '| Saves the state (interrupt mask) of, and then disables all interrupts on 
    the local (current) processor core. The state is saved in the `flags` parameter
    that''s passed. | `local_irq_save(unsigned long flags);` |'
  id: totrans-300
  prefs: []
  type: TYPE_TB
  zh: '| 保存本地（当前）处理器核心上的所有中断的状态（中断掩码），然后禁用所有中断。状态保存在传递的`flags`参数中。 | `local_irq_save(unsigned
    long flags);` |'
- en: '| Restores the state (interrupt mask) that''s passed, thus enabling interrupts
    on the local (current) processor core as per the `flags` parameter. | `local_irq_restore(unsigned
    long flags);` |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 恢复传递的状态（中断掩码），从而根据`flags`参数在本地（当前）处理器核心上启用中断。 | `local_irq_restore(unsigned
    long flags);` |'
- en: '| **Disable/enable a specific IRQ line** |  |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| **禁用/启用特定的IRQ线** |  |'
- en: '| Disables IRQ line `irq`; will wait for – and synchronize – any pending interrupts
    (on that IRQ line) to complete before returning. | `​void disable_irq(unsigned
    int irq);` |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| 禁用IRQ线`irq`；将等待并同步任何待处理的中断（在该IRQ线上）完成后再返回。 | `void disable_irq(unsigned int
    irq);` |'
- en: '| Disables IRQ line `irq`; won''t wait for any pending interrupts (on that
    IRQ line) to complete (`nosync`). | `void disable_irq_nosync(unsigned int irq);`
    |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 禁用IRQ线`irq`；不会等待任何待处理的中断（在该IRQ线上）完成（`nosync`）。 | `void disable_irq_nosync(unsigned
    int irq);` |'
- en: '| Disables IRQ line `irq` and waits for the active hardirq handler to complete
    before returning. It returns `false` if any threaded handlers pertaining to this
    IRQ line are active (requires GPL). | `bool disable_hardirq(unsigned int irq);`
    |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| 禁用IRQ线`irq`并等待活动的hardirq处理程序完成后再返回。如果与此IRQ线相关的任何线程处理程序处于活动状态（需要GPL），则返回`false`。
    | `bool disable_hardirq(unsigned int irq);` |'
- en: '| Enables IRQ line `irq`; undoes the effect of one call to `disable_irq()`.
    | `​void enable_irq(unsigned int irq);` |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| 启用IRQ线`irq`；撤消对`disable_irq()`的一次调用的影响。 | `void enable_irq(unsigned int irq);`
    |'
- en: The `local_irq_disable() / local_irq_enable()` helpers are designed to disable/enable all
    interrupts (except NMI) on the local or current processor core.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '`local_irq_disable() / local_irq_enable()`助手旨在禁用/启用当前处理器核心上的所有中断（除NMI）。'
- en: The implementation on x86[_64] of `local_irq_disable()`/`local_irq_enable()` is
    done via the (in)famous `cli`/`sti` pair of machine instructions; in the bad old
    days, these used to disable/enable interrupts across the system, on all CPUs. Now,
    they work on a per-CPU basis.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '`local_irq_disable()`/`local_irq_enable()`在x86[_64]上的实现是通过（臭名昭著的）`cli`/`sti`一对机器指令来完成的；在过去的坏日子里，这些指令会在整个系统上禁用/启用中断，作用于所有CPU。现在，它们在每个CPU上都可以工作。'
- en: The `disable_{hard}irq*()`/`enable_irq()` helpers are designed to selectively
    disable/enable a particular IRQ line and to be called as a pair. A few of the
    aforementioned routines can be called from an interrupt context, though this should
    be done with care! it's just safer to ensure you call them from process context.
    The "with care" statement is there because several of these helpers work by internally
    invoking non-blocking routines, such as `cpu_relax()`, that wait by repeatedly
    running some machine instructions on the processor. (`cpu_relax()` is a good example
    of this "needs to be used with care" case as it works by calling the `nop` machine
    instruction in an infinite loop; the loop is exited when any hardware interrupt
    fires, which is exactly what we're waiting for! Now, waiting for a while when
    in the interrupt context is considered a wrong thing to do; hence the "with care"
    statement.) The kernel commit for `disable_hardirq()` (link: [https://github.com/torvalds/linux/commit/02cea3958664723a5d2236f0f0058de97c7e4693](https://github.com/torvalds/linux/commit/02cea3958664723a5d2236f0f0058de97c7e4693))
    explains that it's there to be used in situations where, *like netpoll, there
    is a need to disable an interrupt from an atomic context*.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '`disable_{hard}irq*()`/`enable_irq()`辅助程序旨在选择性地禁用/启用特定的IRQ线，并作为一对调用。前面提到的一些例程可以从中断上下文中调用，尽管这应该谨慎进行！最好确保您从进程上下文中调用它们。之所以说“谨慎”，是因为其中几个辅助程序通过内部调用非阻塞例程（例如`cpu_relax()`）来工作，该例程通过在处理器上重复运行一些机器指令来等待。
    （`cpu_relax()`是这种“需要谨慎使用”的情况的一个很好的例子，因为它通过在无限循环中调用`nop`机器指令来工作；当任何硬件中断触发时，循环将退出，这正是我们在等待的！现在，在中断上下文中等待一段时间被认为是错误的；因此有了“谨慎”这一说法。）`disable_hardirq()`的内核提交（链接：[https://github.com/torvalds/linux/commit/02cea3958664723a5d2236f0f0058de97c7e4693](https://github.com/torvalds/linux/commit/02cea3958664723a5d2236f0f0058de97c7e4693)）解释了它是用于在需要从原子上下文中禁用中断的情况下，*比如netpoll*。'
- en: When disabling an interrupt, take care to ensure you're not holding (have locked)
    any shared resource that the handler might use. This will result in a (self) deadlock!
    (Locking and its many scenarios will be explained in a lot more detail in the
    last two chapters of this book.)
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在禁用中断时，要注意确保您没有持有（已锁定）处理程序可能使用的任何共享资源。这将导致（自身）死锁！（锁定及其许多场景将在本书的最后两章中详细解释。）
- en: The NMI
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NMI
- en: All the preceding APIs and helpers work on all hardware interrupts except for
    the **non-maskable interrupt** (**NMI**)***. ***The NMI is an arch-specific interrupt
    and is used to implement stuff such as hardware watchdogs and debug features (for
    example, an unconditional kernel stack dump for all cores; we'll show an example
    of this very shortly). Also, NMI interrupt lines cannot be shared.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 所有先前的API和辅助程序都适用于所有硬件中断，除了**不可屏蔽中断**（NMI）。NMI是特定于体系结构的中断，用于实现诸如硬件看门狗和调试功能（例如，所有核心的无条件内核堆栈转储；我们将很快展示一个例子）。此外，NMI中断线不能共享。
- en: A quick example of exploiting the NMI can be shown with the kernel's so-called
    **magic SysRq** facility. To see the keyboard hotkeys that are assigned for magic
    SysRq, you must invoke or trigger it by typing in the `[Alt][SysRq][letter]` key
    combination.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过内核的所谓的**魔术SysRq**设施来快速展示利用NMI的一个例子。要查看为魔术SysRq分配的键盘热键，您必须通过输入`[Alt][SysRq][letter]`键组合来调用或触发它。
- en: 'magic SysRq triggering: Instead of getting your fingers all twisted typing `[Alt][SysRq][letter]`,
    there''s an easier – and more importantly non-interactive – way to do so: just
    echo the relevant letter to a proc pseudofile (as root, of course): `echo letter/proc/sysrq-trigger`.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 魔术SysRq触发：与其让手指扭曲输入`[Alt][SysRq][letter]`，不如使用更简单的方法 - 更重要的是非交互式的方法：只需将相关字母作为根用户回显到`proc`伪文件中：`echo
    letter/proc/sysrq-trigger`。
- en: 'But which letter do we need to type in? The following output shows a quick
    way you can find out. This is a kind of quick-help for magic SysRq (I did this
    on my Raspberry Pi 3B+):'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们需要输入哪个字母呢？以下输出显示了您可以找到的一种快速方法。这是魔术SysRq的快速帮助（我在我的Raspberry Pi 3B+上执行了这个操作）：
- en: '[PRE24]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The one we're currently interested in is shown in bold – the letter `l` (that's
    a lowercase L) – `show-backtrace-all-active-cpus(l)`. Once triggered, it literally
    does as promised – it shows a stack backtrace of the kernel-mode stack on all
    active CPUs! (This can be a useful debugging aid as you will see what each CPU
    core is running right now.) How? It does this by sending an NMI to them; that
    is, to all CPU cores! This is one way we can see exactly what the CPUs are up
    to at the very moment the command was triggered! This could be very useful when
    something is hanging the system.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们目前感兴趣的是粗体显示的 - 字母`l`（小写L） - `show-backtrace-all-active-cpus（l）`。一旦触发，它确实如约
    - 它显示所有活动CPU上内核模式堆栈的堆栈回溯！（这可以作为一个有用的调试辅助工具，因为您将看到每个CPU核心当前正在运行的内容。）如何？它通过向它们发送NMI来实现这一点；也就是说，向所有CPU核心发送NMI！这是我们可以看到在命令被触发的那一刻CPU正在做什么的一种方式！当系统出现问题时，这可能非常有用。
- en: 'Here, `echo l /proc/sysrq-trigger` (as root) does the trick! The following
    partial screenshot shows the output:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`echo l /proc/sysrq-trigger`（作为根用户）就可以了！以下是部分屏幕截图显示的输出：
- en: '![](img/79f72a3d-c1fa-4bc9-9d0d-a6c26353cfed.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](img/79f72a3d-c1fa-4bc9-9d0d-a6c26353cfed.png)'
- en: Figure 4.7 – The output when the NMI is sent to all CPUs, showing the kernel
    stack backtrace on each of them
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 - 发送NMI到所有CPU时的输出，显示每个CPU的内核堆栈回溯
- en: In the preceding screenshot, you can see that `bash` PID 633 is running on CPU `0` and
    that the kernel thread, `swapper/1`, is running on CPU `1` (the kernel stack for
    each can be seen; read it in a bottom-up fashion).
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，您可以看到`bash` PID 633正在CPU `0`上运行，内核线程`swapper/1`正在CPU `1`上运行（可以看到每个的内核堆栈；以自下而上的方式阅读）。
- en: 'The magic SysRq facility''s code can be found at `drivers/tty/sysrq.c`; it''s
    interesting to browse through. The following is the approximate call graph for
    what happens on the x86 when the magic SysRq `l` is triggered:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在`drivers/tty/sysrq.c`找到魔术SysRq设施的代码；浏览一下会很有趣。以下是在x86上触发魔术SysRq `l`时发生的近似调用图：
- en: '[PRE25]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The last function actually becomes the generic (not arch-specific) code at `lib/nmi_backtrace.c:nmi_trigger_cpumask_backtrace()`. The
    code here triggers the CPU backtrace by sending an NMI to each CPU. This is achieved
    via the `nmi_cpu_backtrace()` function. This function, in turn, displays the information
    we saw in the preceding screenshot by invoking the `show_regs()` or `dump_stack()` routines,
    which ultimately become arch-specific code to dump the CPU registers, as well
    as the kernel-mode stack. The code is also intelligent enough to not attempt to
    show a backtrace on those CPU cores that are in a low power (idle) state.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '最后一个函数实际上成为了通用的（非特定于架构）代码，位于`lib/nmi_backtrace.c:nmi_trigger_cpumask_backtrace()`。这里的代码通过向每个CPU发送NMI来触发CPU回溯。这是通过`nmi_cpu_backtrace()`函数实现的。这个函数反过来通过调用`show_regs()`或`dump_stack()`例程显示了我们在前面的屏幕截图中看到的信息，这些例程最终成为了特定于架构的代码，用于转储CPU寄存器以及内核模式堆栈。该代码还足够智能，不会尝试在处于低功耗（空闲）状态的CPU核心上显示回溯。 '
- en: 'Again, things are not always simple in the real world; see this article by
    Steven Rostedt on the complex issues people have faced with the x86 NMI and how
    they''ve been addressed: *The x86 NMI iret problem*, March 2012: [https://lwn.net/Articles/484932/](https://lwn.net/Articles/484932/).'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实世界中，事情并不总是简单的；请参阅Steven Rostedt在x86 NMI上所面临的复杂问题以及它们是如何解决的这篇文章：*x86 NMI iret问题*，2012年3月：[https://lwn.net/Articles/484932/](https://lwn.net/Articles/484932/)。
- en: So far, we haven't actually seen the kernel view of allocated IRQ lines; the
    interface is, quite naturally, via the `procfs` filesystem; let's delve into it.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们实际上还没有看到分配的IRQ线的内核视图；接口自然是通过`procfs`文件系统；让我们深入研究一下。
- en: Viewing all allocated interrupt (IRQ) lines
  id: totrans-327
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 查看所有分配的中断（IRQ）线
- en: 'Now that you have understood sufficient details about IRQs and interrupt handling,
    we can (finally!) leverage the kernel''s `proc`filesystem so that we can peek
    at the currently allocated IRQs. We can do this by reading the content of the `/proc/interrupts` pseudofile.
    We''ll show a couple of screenshots: the first (*Figure 4.8*) shows the IRQ status
    – the number of interrupts serviced per CPU per I/O device – on my Raspberry Pi
    ZeroW, while the second (*Figure 4.9*) shows this on our "usual" x86_64 Ubuntu
    18.04 VM:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了关于IRQ和中断处理的足够细节，我们可以（终于！）利用内核的`proc`文件系统，以便我们可以窥视当前分配的IRQ。我们可以通过读取`/proc/interrupts`伪文件的内容来做到这一点。我们将展示一些屏幕截图：第一个（*图4.8*）显示了在我的Raspberry
    Pi ZeroW上每个CPU每个I/O设备服务的中断数量的IRQ状态，而第二个（*图4.9*）显示了我们“通常”的x86_64 Ubuntu 18.04 VM上的情况：
- en: '![](img/97cb838d-8a47-42f0-81ed-e47551ee8883.png)'
  id: totrans-329
  prefs: []
  type: TYPE_IMG
  zh: '![](img/97cb838d-8a47-42f0-81ed-e47551ee8883.png)'
- en: Figure 4.8 – IRQ status on a Raspberry Pi ZeroW
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 - Raspberry Pi ZeroW上的IRQ状态
- en: 'In the preceding `/proc/interrupts` output, one line (or record) is emitted
    for each IRQ line on the system. Let''s interpret each column of the output:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的`/proc/interrupts`输出中，系统上的每个IRQ线（或记录）都会发出一行。让我们解释一下输出的每一列：
- en: The first column is the IRQ number that's been allocated.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一列是已分配的IRQ号码。
- en: The second column (onward) shows the number of hardirqs that have been serviced
    by each CPU core (from system startup until now). The number represents the number
    of times the interrupt handler ran on that CPU core (the number of columns varies,
    depending on the number of active cores that are handling IRQs on the system).
    In the preceding screenshot, the Raspberry Pi Zero has only one CPU core, whereas
    our x86_64 VM has two (virtualized) CPU cores that interrupts are distributed
    over and handled (more on this in the *Load balancing interrupts and IRQ affinity* section).
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二列（以后）显示了每个CPU核心已服务的硬中断数（从系统启动到现在）。该数字表示中断处理程序在该CPU核心上运行的次数（列数因正在处理系统上的IRQ的活动核心数而变化）。在前面的屏幕截图中，Raspberry
    Pi Zero只有一个CPU核心，而我们的x86_64 VM有两个（虚拟化的）CPU核心，中断分布和处理在这些核心上进行（在*负载平衡中断和IRQ亲和力*部分中有更多信息）。
- en: The third (or later) column shows the interrupt controller chip. On x86 (the
    fourth column in *Figure 4.9*), the name IO-APIC means that the interrupt controller
    is an enhanced one that's used on multicore systems to distribute interrupts to
    various cores or CPU groups (on high-end systems, multiple IO-APICs may be in
    play).
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三（或更后面）列显示了中断控制器芯片。在x86（*图4.9*中的第四列），IO-APIC表示中断控制器是一种增强型中断控制器，用于在多核系统上将中断分发到各个核心或CPU组（在高端系统上，可能会使用多个IO-APIC）。
- en: The column after that displays the type of interrupt triggering that's being
    used; that is, level or edge triggering (we discussed this in the *Understanding
    level- and edge-triggered interrupts* section). Here, `Edge`tells us that the
    IRQ is edge-triggered. The number that's prefixed to it (for example, `35 Edge` in
    the preceding screenshot) is very system-dependent. It often represents the interrupt
    source (that the kernel maps to an IRQ line; many embedded device drivers often
    use GPIO pins to serve as interrupt sources). It's best not to attempt to interpret
    it (unless you actually know how to) and just rely on the IRQ number instead (the
    first column).
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 之后的列显示了正在使用的中断触发类型；即，电平触发或边沿触发（我们在*理解电平触发和边沿触发中断*部分中讨论过这一点）。在这里，`Edge`告诉我们IRQ是边沿触发的。它前面的数字（例如，在前面的屏幕截图中的`35
    Edge`）非常依赖于系统。它通常代表中断源（内核将其映射到IRQ线；许多嵌入式设备驱动程序通常使用GPIO引脚作为中断源）。最好不要尝试解释它（除非您确实知道如何），而只依赖于IRQ号码（第一列）。
- en: The last column on the right states the current owner of the IRQ line. Typically,
    this is the name of the device driver or kernel component (that allocated this
    IRQ line via one of the `*request_*irq()` APIs).
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右侧的最后一列显示了IRQ线的当前所有者。通常，这是设备驱动程序或内核组件的名称（通过`*request_*irq()`API之一分配了此IRQ线）。
- en: '![](img/4cfcd782-9fe7-4648-85a6-d1d1df254a38.png)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4cfcd782-9fe7-4648-85a6-d1d1df254a38.png)'
- en: Figure 4.9 – IRQ status on an x86_64 Ubuntu 18.04 VM (truncated screenshot)
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.9 - x86_64 Ubuntu 18.04 VM上的IRQ状态（截断屏幕截图）
- en: From the 2.6.24 kernel, for x86 and AMD64 systems (or x86_64), even non-device
    (I/O) interrupts (system interrupts) are displayed here, such as the NMI, **local
    timer interrupt** (**LOC**), PMI, IWI, and so on. You can see in *Figure 4.9*,
    the last line displays `IWI`, which is the **Inter-Work Interrupt**.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 从2.6.24内核开始，对于x86和AMD64系统（或x86_64），即使是非设备（I/O）中断（系统中断）也会显示在这里，例如NMI，**本地定时器中断**（**LOC**），PMI，IWI等。您可以在*图4.9*中看到，最后一行显示了`IWI`，这是**Inter-Work
    Interrupt**。
- en: 'The kernel procfs code that displays the preceding output of `/proc/interrupts` –
    that is, its `show`method – can be found at `kernel/irq/proc.c:show_interrupts()`
    (link: [https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/proc.c#L438](https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/proc.c#L438)).
    First, it prints the header line, then emits a one-line "record" for each IRQ
    line. The statistics are mainly obtained from within the metadata structure for
    each IRQ line – `struct irq_desc`; within each IRQ, it loops over every processor
    core (via the `for_each_online_cpu()` helper routine), printing the number of
    hardirqs that have been served for each of them. Finally (last column), it prints
    the "owner" of the IRQ line via the `name` member of `struct irqaction`. The arch-specific
    interrupts for the x86 (such as the `NMI`, `LOC`, `PMI`, and `IWI` IRQs) are displayed
    via the code at `arch/x86/kernel/irq.c:arch_show_interrupts()`.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 显示`/proc/interrupts`的前述输出的内核procfs代码 - 即其`show`方法 - 可以在`kernel/irq/proc.c:show_interrupts()`（链接：[https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/proc.c#L438](https://elixir.bootlin.com/linux/v5.4/source/kernel/irq/proc.c#L438)）中找到。首先，它打印标题行，然后为每个IRQ行发出一行“记录”。统计数据主要来自每个IRQ行的元数据结构
    - `struct irq_desc`；在每个IRQ中，它通过`for_each_online_cpu()`辅助例程循环遍历每个处理器核心，打印为每个处理器核心服务的hardirqs数量。最后（最后一列），它通过`struct
    irqaction`的`name`成员打印IRQ行的“所有者”。 x86的特定于体系结构的中断（例如`NMI`，`LOC`，`PMI`和`IWI` IRQ）通过`arch/x86/kernel/irq.c:arch_show_interrupts()`中的代码显示。
- en: On the x86, IRQ `0` is always the **timer interrupt**. In the companion guide
    *Linux Kernel Programming -* *Chapter 10*, *The CPU Scheduler - Part 1*, we learned
    that, in theory, the timer interrupt fires `HZ` times per second. In practice,
    for efficiency, this has now been replaced with a per-CPU periodic **high-resolution
    timer** (**HRT**); it shows up as the IRQ named **LOC** (for **LOCal**) for timer
    interrupts in `/proc/interrupts`.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在x86上，IRQ 0始终是**定时器中断**。在伴随指南*Linux Kernel Programming -* *第10章* *CPU调度器 - 第1部分*中，我们了解到，理论上，定时器中断每秒触发`HZ`次。实际上，为了效率，现在已经用每个CPU的周期性**高分辨率定时器**（**HRT**）替换；它显示为名为**LOC**（用于`/proc/interrupts`中的定时器中断的**LOCal**）的IRQ。
- en: 'This actually explains why the number of hardware timer interrupts under the `timer` row
    is very low; check this out (on an x86_64 guest with four (virtual) CPUs):'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上解释了为什么`timer`行下的硬件定时器中断数量非常低；看看这个（在一个带有四个（虚拟）CPU的x86_64客户端上）：
- en: '`$ egrep "timer|LOC" /proc/interrupts ; sleep 1 ; egrep "timer|LOC" /proc/interrupts`'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: $ egrep "timer|LOC" /proc/interrupts ; sleep 1 ; egrep "timer|LOC" /proc/interrupts
- en: '`  0:         33          0          0          0   IO-APIC   2-edge      timer`'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: '` 0:       33          0          0          0  IO-APIC   2-edge      timer`'
- en: '`LOC:      11038      11809      10058       8848   Local timer interrupts`'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '`LOC:      11038      11809      10058       8848  Local timer interrupts`'
- en: '`  0:         33          0          0          0   IO-APIC   2-edge      timer`'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '` 0:       33          0          0          0  IO-APIC   2-edge      timer`'
- en: '`LOC:      11104      11844      10086       8889   Local timer interrupts`'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '`LOC:      11104      11844      10086       8889  Local timer interrupts`'
- en: '`$` Notice how IRQ `0` doesn''t increment but the `LOC` IRQ does indeed (per
    CPU core).'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '`$`请注意IRQ 0不增加，但`LOC` IRQ确实增加（每个CPU核心）。'
- en: The `/proc/stat` pseudofile also provides some information on utilizing servicing
    interrupts on a per-CPU basis and the number of interrupts that can be serviced
    (please refer to the man page on `proc(5)` for more details).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`/proc/stat`伪文件还提供了有关每个CPU基础上利用服务中断和可以服务的中断数量的一些信息（有关更多详细信息，请参阅`proc(5)`的手册页）。'
- en: Softirqs, as explained in detail in the *Understanding and using top and bottom
    halves* section, can be viewed via `/proc/softirqs`; more on this later.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 如*理解和使用上半部和下半部*部分详细解释的那样，softirqs可以通过`/proc/softirqs`查看；稍后会详细介绍。
- en: 'With that, you''ve learned how to view the allocated IRQ lines. However, one
    major aspect of interrupt handling remains: understanding the so-called top-half/bottom-half
    dichotomies, why they exist, and how to work with them. We''ll look at this in
    the next section.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，您已经学会了如何查看分配的IRQ行。但是，中断处理的一个主要方面仍然存在：理解所谓的上半部/下半部二分法，为什么它们存在以及如何与它们一起工作。我们将在下一节中讨论这个问题。
- en: Understanding and using top and bottom halves
  id: totrans-352
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解和使用上半部和下半部
- en: 'Much emphasis has been put on the fact that your interrupt handler must complete
    its work quickly (as explained in the *Keep it fast* section and elsewhere). Having
    said that, a practical issue does crop up. Let''s consider this scenario: you
    have allocated IRQn and have written the interrupt handler function to handle
    this interrupt when it arrives. As you may recall, the function we''re talking
    about here, commonly referred to as the **hardirq** or **ISR (Interrupt Service
    Routine)** or primary handler, is the second parameter to the `request_{threaded}_irq()` API, the
    third parameter to the `devm_request_irq()` API, and the fourth parameter to the `devm_request_threaded_irq()` API.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 已经非常强调了您的中断处理程序必须**快速**完成其工作（如*保持快速*部分和其他地方所解释的）。话虽如此，实际上确实出现了一个实际问题。让我们考虑这种情况：您已经分配了IRQn并编写了中断处理程序函数来处理此中断。正如您可能记得的那样，我们在这里谈论的函数，通常称为**hardirq**或**ISR（中断服务例程）**或主处理程序，是`request_{threaded}_irq()`API的第二个参数，`devm_request_irq()`API的第三个参数，以及`devm_request_threaded_irq()`API的第四个参数。
- en: 'As we mentioned previously, there''s a quick heuristic to follow: if your hardirq routine''s
    processing consistently exceeds 100 microseconds, then you will need to use alternate
    strategies. Let''s say that your handler finishes well within this time; in this
    case, there''s no issue at all! But what if it does require more time? Perhaps
    the low-level specification for the peripheral entails that you do a number of
    things when the interrupt arrives (say there are 10 items to complete). You correctly
    write the code to do so, but it pretty much always exceeds the time limit (100
    microseconds as a thumb rule)! So, what do you do? On the one hand, there are
    these kernel folks yelling at you to finish fast; on the other, the low-level
    spec for the peripheral demands that you follow several key steps in order to
    correctly handle the interrupt! (Talk about being on the horns of a dilemma!)'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，有一个快速的启发式法则要遵循：如果你的`hardirq`例程的处理一直超过100微秒，那么你需要使用替代策略。假设你的处理程序在这个时间内完成得很好；在这种情况下，就没有问题了！但如果它确实需要更多的时间呢？也许外设的低级规范要求在中断到达时你要做一些事情（比如有10个项目要完成）。你正确地编写了代码来做到这一点，但它几乎总是超过了时间限制（100微秒作为一个经验法则）！那么，你该怎么办？一方面，有这些内核人员对你大声呼喊要**快点完成**；另一方面，外设的低级规范要求你按照几个关键步骤正确处理中断！（谈论处于两难境地！）
- en: 'As we hinted at earlier, there are two broad strategies that are followed in
    cases like these:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前暗示的，这些情况下有两种广泛的策略。
- en: Employ a thread interrupt to handle the majority of the work; considered the
    modern approach.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线程中断来处理大部分工作；被认为是现代的方法。
- en: Use a "bottom half" routine to handle the majority of the work; the traditional
    approach.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用“底半部”例程来处理大部分工作；传统的方法。
- en: 'We covered the conceptual understanding, practical usage and the *why* of threaded
    interrupts in detail in the *Working with the threaded interrupts model* section.
    In the top-bottom-half model, this is the approach:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在“使用线程中断模型”部分详细介绍了线程中断的概念理解、实际用法和*为什么*。
- en: 'The so-called **top half** is the function that is initially invoked when the
    hardware interrupt is triggered. This is thus familiar to you - it''s nothing
    but the **hardirq**, ISR, or primary handler routine that you registered via one
    of the `*request_*irq()` APIs (just for clarity: via one of these APIs: `request_irq()`
    / `devm_request_irq()` / `request_threaded_irq()` / `devm_request_threaded_irq()`.)'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所谓的**顶半部**是在硬件中断触发时最初调用的函数。这对你来说是很熟悉的 - 它只是通过`*request_*irq()`API之一注册的**hardirq**、ISR或主处理程序例程（为了清楚起见：通过这些API之一：`request_irq()`
    / `devm_request_irq()` / `request_threaded_irq()` / `devm_request_threaded_irq()`）。
- en: We also register a so-called **bottom half** routine to perform the majority
    of the interrupt handling work.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们还注册了一个所谓的**底半部**例程来执行大部分中断处理工作。
- en: 'In other words, interrupt handling is **split into two halves** – top and bottom.
    However, this isn''t really a pleasing way to describe it (as the English word half makes
    you intuitively think that the routines are of approximately the same size); the
    reality is more like this:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，中断处理被**分成两半** - 顶部和底部。然而，这并不是一个令人愉快的描述方式（因为英语单词“half”让你直觉地认为例程的大小大致相同）；实际情况更像是这样：
- en: The top half performs the bare minimum work required (typically, acknowledging
    the interrupt, perhaps turning it off on the board for the duration of the top
    half, and then performing any (minimal) hardware-specific work including receiving/sending
    some data as is required from/to the device).
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 顶半部执行所需的最低限度的工作（通常是确认中断，也许在顶半部的持续时间内关闭板上的中断，然后执行任何（最小的）硬件特定工作，包括根据需要从/向设备接收/发送一些数据）。
- en: The bottom half routine carries out the majority of the interrupt handling work.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 底半部例程执行大部分中断处理工作。
- en: 'So, what is the bottom half? It''s just a C function that''s appropriately
    registered with the kernel. The actual registration API you should use depends
    on the *type* of bottom half you intend to use. There are three types:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，什么是底半部？它只是一个适当注册到内核的C函数。你应该使用的实际注册API取决于你打算使用的**底半部的类型**。有三种类型：
- en: The old **bottom-half** mechanism, which is now deprecated; it's abbreviated
    as **BH** (you can pretty much ignore it).
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旧的**底半部**机制，现在已经被弃用；它被缩写为**BH**（你基本上可以忽略它）。
- en: 'The modern recommended (if you''re using this top-bottom-half technology in
    the first place) mechanism: the **tasklet**.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代推荐的（如果你一开始就使用了这种上下半部技术）机制：**tasklet**。
- en: 'The underlying kernel mechanism: the **softirq**.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 底层内核机制：**softirq**。
- en: You will come to see that the tasklet is actually built upon a kernel softirq.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现tasklet实际上是建立在内核softirq之上的。
- en: 'Here''s the thing: the top half – the hardirq handler that we''ve been working
    with until now – does, as we mentioned previously, the bare minimum work; it then
    "schedules" its bottom half and exits (returns). The word schedule here does not
    mean it calls `schedule()`, as that would be ridiculous (we''re in an interrupt
    context, after all!); it''s just the word that''s used to describe the fact. The
    kernel will guarantee that the bottom half runs as soon as possible once the top
    half completes; in particular, no user or kernel thread will ever preempt it.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 事实是：顶半部 - 我们一直在使用的`hardirq`处理程序 - 像我们之前提到的那样，只做最低限度的工作；然后“调度”它的底半部并退出（返回）。这里的“调度”并不意味着它调用`schedule()`，因为那太荒谬了（毕竟我们处于中断上下文中！）；这只是用来描述这个事实的词。内核将保证一旦顶半部完成，底半部将尽快运行；特别是，没有用户或内核线程会抢占它。
- en: 'Hang on a second, though: even if we do all this – splitting the handler into
    two halves and have them collectively execute the work – then how have we saved
    any time? That was the original intent, after all. Won''t it take an even longer
    time to complete now with the overhead of invoking two functions as opposed to
    one? Ah, this brings us to a really key point: **the top half (hardirq) always
    runs with all interrupts disabled (masked) on the current CPU and the IRQ it''s
    handling disabled (masked) across all CPUs, but the bottom half handler runs with
    all interrupts enabled.**'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，等一下：即使我们做了这一切 - 将处理程序分成两个部分并让它们共同执行工作 - 那么我们节省了什么时间呢？毕竟，这原本就是最初的意图。现在执行完毕会不会花更长的时间，因为要调用两个函数而不是一个函数的开销呢？啊，这带我们来到一个非常关键的观点：**上半部分（硬中断）始终在当前CPU上以所有中断被禁用（屏蔽）的状态运行，并且它正在处理的IRQ在所有CPU上都被禁用（屏蔽）的状态下运行，但下半部分处理程序在所有中断被启用的状态下运行。**
- en: 'Note that the bottom half is still very much running in an atomic or interrupt
    context! So, the same caveats that apply to the hardirq (top half) handler also
    apply to the bottom-half handler:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，下半部分仍然在原子或中断上下文中运行！因此，适用于硬中断（上半部分）处理程序的相同注意事项也适用于下半部分处理程序：
- en: You cannot transfer data (to or from user kernel spaces).
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不能传输数据（到或从用户内核空间）。
- en: You can only allocate memory (if you really must) with the `GFP_ATOMIC` flag.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你只能使用`GFP_ATOMIC`标志分配内存（如果你真的必须）。
- en: You cannot, ever, directly or indirectly, call `schedule()`.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不能直接或间接调用`schedule()`。
- en: 'This bottom-half handling is a subset of what''s known as the kernel''s *deferred
    functionality* prowess; the kernel has several of these deferred functionality mechanisms:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 这个下半部分处理是所谓的内核*延迟功能*的一个子集；内核有几种这样的延迟功能机制：
- en: Workqueues (based on kernel threads); `context:process`
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作队列（基于内核线程）；`context:process`
- en: Bottom half/tasklet (based on softirqs); `context:interrupt`
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 下半部分/任务let（基于softirqs）；`context:interrupt`
- en: Softirqs; `context:interrupt`
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Softirqs；`context:interrupt`
- en: kernel timers; `context:interrupt`
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核定时器；`context:interrupt`
- en: We will cover kernel timers and workqueues in [Chapter 5](c7d2d826-9d8a-439f-b843-06fa72db36b9.xhtml), *Working
    with Kernel Timers, Threads, and Workqueues.*
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第5章](c7d2d826-9d8a-439f-b843-06fa72db36b9.xhtml)中介绍内核定时器和工作队列，*使用内核定时器、线程和工作队列*。
- en: All these mechanisms allows the kernel (or driver) to specify that some work
    must be carried out later (it's deferred), when it is safe to do so.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些机制都允许内核（或驱动程序）指定一些工作必须在以后进行（它是延迟的），在安全时才能执行。
- en: 'At this point, you should be able to understand that the threaded interrupt
    mechanism we''ve already discussed is somewhat akin to a deferred functionality
    mechanism. This is considered the modern approach to use; again, though its performance
    is acceptable for most peripherals, a few device classes – typically network/block/multimedia
    – might still require the traditional top-bottom-half mechanisms to provide high
    enough performance. Also, we emphasize yet again: both top and bottom halves always
    run in an atomic (interrupt) context, whereas threaded handlers actually run in
    process context; you can view this as an advantage or disadvantage. The fact is
    that although the threaded handler is technically within the process context,
    it''s really best to perform fast non-blocking operations within it.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 到这一点，你应该能够理解我们已经讨论过的线程中断机制在某种程度上类似于延迟功能机制。这被认为是现代的使用方法；尽管对于大多数外围设备来说性能是可以接受的，但一些设备类别
    - 通常是网络/块/多媒体 - 仍可能需要传统的上半部分和下半部分机制来提供足够高的性能。此外，我们再次强调：上半部分和下半部分始终在原子（中断）上下文中运行，而线程处理程序实际上在进程上下文中运行；你可以将这视为优势或劣势。事实上，尽管线程处理程序在技术上处于进程上下文中，但最好在其中执行快速的非阻塞操作。
- en: Specifying and using a tasklet
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指定和使用任务let
- en: A key difference between a tasklet and the kernel's softirq mechanism is that
    tasklets are simply easier to work with, making them a good choice for your typical
    driver. Of course, if you can use a threaded handler instead, just do that; later,
    we'll show a table that will help you decide what to use and when. One of the
    key things that makes tasklets easier to use is the fact that (on an SMP system)
    a particular tasklet will never run in parallel with itself; in other words, a
    given tasklet will run on exactly one CPU at a time (making it non-concurrent,
    or serialized, with respect to itself).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 任务let和内核的softirq机制之间的一个关键区别是，任务let更容易使用，这使它成为典型驱动程序的不错选择。当然，如果可以使用线程处理程序，那就直接使用；稍后，我们将展示一张表，帮助你决定何时使用何种方法。任务let更容易使用的一个关键因素是（在SMP系统上）特定的任务let永远不会并行运行；换句话说，给定的任务let将一次只在一个CPU上运行（使其与自身不并发，或串行化）。
- en: 'The header comment in `linux/interrupt.h` gives us some important properties
    of the tasklet as well:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '`linux/interrupt.h`中的头部注释给出了任务let的一些重要属性：'
- en: '[PRE26]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: We'll show the `tasklet_schedule()` function shortly. The last point in the
    preceding comment block will be covered in the last two chapters of this book.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将很快展示`tasklet_schedule()`函数。前面评论块中的最后一点将在本书的最后两章中涵盖。
- en: So, how can we use a tasklet? First, we have to set it up with the `tasklet_init()`
    API; then, we have to schedule it for execution. Let's learn how to do this.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何使用任务let呢？首先，我们必须使用`tasklet_init()`API进行设置；然后，我们必须安排它执行。让我们学习如何做到这一点。
- en: Initializing the tasklet
  id: totrans-389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 初始化任务let
- en: 'The `tasklet_init()` function initializes a tasklet; its signature is as follows:'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '`tasklet_init()`函数初始化一个任务let；其签名如下：'
- en: '[PRE27]'
  id: totrans-391
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s check out its parameters:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查它的参数：
- en: '`struct tasklet_struct *t`: This structure is the metadata representing the
    tasklet. As you already know, a pointer, by itself, has no memory! Remember to
    allocate memory to the data structure and then pass the pointer here.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`struct tasklet_struct *t`：这个结构是表示任务let的元数据。正如你已经知道的，一个指针本身没有内存！记得为数据结构分配内存，然后将指针传递到这里。'
- en: '`void (*func)(unsigned long)`: This is the tasklet function itself – **the
    "bottom half"** that runs once the hardirq completes; this bottom half function
    performs the majority of the interrupt handling process.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`void (*func)(unsigned long)`：这就是tasklet函数本身 - **“底半部分”**，一旦硬中断完成就会运行；这个底半部分函数执行大部分中断处理过程。'
- en: '`unsigned long data`: Any data item you wish to pass along to the tasklet routine
    (a cookie).'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`unsigned long data`：任何你希望传递给tasklet例程的数据项（一个cookie）。'
- en: Where should this initialization work be performed? Typically, this is done
    within the driver's *probe* (or `init`) function. So, now that it's been initialized
    and is ready to go, how do we invoke it? Let's find out.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 这个初始化工作应该在哪里执行？通常，这是在驱动程序的*probe*（或`init`）函数中完成的。所以，现在它已经初始化并准备就绪，我们该如何调用它呢？让我们找出来。
- en: Running the tasklet
  id: totrans-397
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行tasklet
- en: 'The tasklet is the bottom half. Thus, in the top half, which is your hardirq handler
    routine, the last thing you should do before returning is "schedule" your tasklet
    to execute:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: Tasklet是底半部分。因此，在顶半部分，也就是你的硬中断处理程序例程中，你应该在返回之前做的最后一件事是“安排”你的tasklet执行：
- en: '[PRE28]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Simply pass the pointer to your (initialized) tasklet structure to the `tasklet_schedule()`
    API; the kernel will handle the rest. What does the kernel do? It schedules this
    tasklet to execute; practically speaking, your tasklet's function code is guaranteed
    to run before control returns to the task that was interrupted in the first place
    (be it a user or kernel thread). More details can be found in the *Understanding
    how the kernel runs softirqs* section.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 只需将指向你（初始化的）tasklet结构的指针传递给`tasklet_schedule()` API；内核会处理剩下的事情。内核做了什么？它安排这个tasklet执行；实际上，你的tasklet函数代码保证在控制返回到首先被中断的任务之前运行（无论是用户还是内核线程）。更多细节可以在*理解内核如何运行softirqs*部分找到。
- en: 'Regarding the tasklet, there are a few things you need to be clear about:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 关于tasklet，有一些事情你需要明确：
- en: The tasklet executes its code in an interrupt (atomic) context; it's actually
    a softirq context. So, remember, all the restrictions that apply to top halves
    apply here too! (Check out the *Interrupt context guidelines – what to do and
    what not to do* section for detailed information on restrictions)
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tasklet在中断（原子）上下文中执行它的代码；实际上它是一个softirq上下文。所以，请记住，所有适用于顶半部分的限制在这里也适用！（查看*中断上下文指南
    - 做什么和不做什么*部分，了解有关限制的详细信息）
- en: 'Synchronization (on an SMP box):'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同步（在SMP框架上）：
- en: A given tasklet will never run in parallel with itself.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定的tasklet永远不会与自身并行运行。
- en: Different tasklets *can *run in parallel on different CPU cores.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的tasklet *可以*在不同的CPU核心上并行运行。
- en: Your tasklet can itself be interrupted by a hardirq, including your own IRQ!
    This is because tasklets, by default, run with all interrupts enabled on the local
    core, and, of course, hardirq's are the very top priority on the system
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的tasklet本身可能会被硬中断打断，包括你自己的IRQ！这是因为tasklet默认情况下在本地核心上以所有中断启用的状态运行，当然，硬中断在系统上是最高优先级的。
- en: Locking implications really do matter – we'll cover these areas in detail in
    the last two chapters of this book (particularly when we cover *spinlocks*).
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 锁定影响真的很重要 - 我们将在本书的最后两章中详细介绍这些领域（特别是当我们涵盖*自旋锁*时）。
- en: 'Some (generic driver) sample code is as follows (for clarity, we''ve avoided
    showing any error paths):'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 一些（通用驱动程序）示例代码如下（为了清晰起见，我们避免显示任何错误路径）：
- en: '[PRE29]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: In the preceding code snippet, we declared a global pointer, `ts`, to `struct
    tasklet_struct`; in the `init`code of the driver, we registered the driver as
    belonging to the `misc`kernel framework. Next, we allocated RAM to the tasklet
    structure (via the useful `devm_kzalloc()` API). Next, we initialized the tasklet
    via the `tasklet_init()` API. Notice that we specified the function name (second
    parameter) and simply passed `0` as the third parameter, which is the cookie to
    pass along (many real drivers pass their context/private data structure pointer
    here). We then allocated an IRQ line (via the `devm_request_irq()` API).
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码片段中，我们声明了一个全局指针`ts`，指向`struct tasklet_struct`；在驱动程序的`init`代码中，我们将驱动程序注册为属于`misc`内核框架。接下来，我们通过有用的`devm_kzalloc()`
    API为tasklet结构分配了RAM。然后，我们通过`tasklet_init()` API初始化了tasklet。请注意，我们指定了函数名（第二个参数），并简单地传递了`0`作为第三个参数，这是要传递的cookie（许多真实的驱动程序在这里传递它们的上下文/私有数据结构指针）。然后，我们通过`devm_request_irq()`
    API分配了一个IRQ线。
- en: 'Let''s continue looking at the code of this generic driver:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续看一下这个通用驱动程序的代码：
- en: '[PRE30]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the preceding code, let's imagine we did whatever minimal work was required
    in our top half (the `my_hardirq_handler()` function). We then primed our tasklet
    so that it can run by invoking the `tasklet_schedule()` API. You'll find that
    the tasklet will run almost immediately after the hardirq (in the preceding code,
    the tasklet function is called `mydrv_tasklet()`). In the tasklet, you are expected
    to perform the majority of the interrupt processing work. Within it, we called
    our macro `PRINT_CTX()`; as you will see in the *Fully figuring out the context*
    section, it prints various details regarding our current context, which is helpful
    for debugging/learning (you'll find it shows, among other things, that we're currently
    running in interrupt context).
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码中，让我们想象我们在顶半部分（`my_hardirq_handler()`函数）中做了所需的最小工作。然后我们启动了我们的tasklet，以便通过调用`tasklet_schedule()`
    API来运行。你会发现tasklet几乎会在硬中断之后立即运行（在前面的代码中，tasklet函数被称为`mydrv_tasklet()`）。在tasklet中，你应该执行大部分中断处理工作。在其中，我们调用了我们的宏`PRINT_CTX()`；正如你将在*完全弄清上下文*部分中看到的，它打印了关于我们当前上下文的各种细节，这对于调试/学习很有帮助（你会发现它显示了，除其他事项外，我们当前正在中断上下文中运行）。
- en: Instead of the `tasklet_schedule()` API, you can use an alternate routine, via
    the `tasklet_hi_schedule()` API. This internally makes the tasklet become the
    *highest priority softirq* (softirq priority `0`)! (More information can be found
    in the *Understanding the kernel softirq mechanism* section.) Note that this is
    almost never done; the default (softirq) priority that a tasklet enjoys is usually
    more than sufficient. Setting it to the `hi` level is really only meant for extreme
    cases; avoid it as far as is possible.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`tasklet_schedule()`API，你可以通过`tasklet_hi_schedule()`API使用一个替代例程。这在内部使tasklet成为*最高优先级的softirq*（softirq优先级`0`）！（更多信息可以在*理解内核softirq机制*部分找到。）请注意，这几乎从不会发生；tasklet享有的默认（softirq）优先级通常是足够的。将其设置为`hi`级别实际上只是为极端情况而设计的；尽可能避免它。
- en: On version 5.4.0 Linux, there *are* 70-odd instances of the `tasklet_hi_schedule()`
    function being used by drivers. The drivers are typically high-performance network
    drivers – a few GPU, crypto, USB, and mmc drivers, as well as a few other drivers.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux 5.4.0版本中，有70多个实例使用了`tasklet_hi_schedule()`函数。这些驱动程序通常是高性能网络驱动程序-一些GPU、加密、USB和mmc驱动程序，以及其他一些驱动程序。
- en: When it comes to tasklets, the kernel keeps evolving. Recent (as the time of
    writing, July 2020) patches by *Kees Cook* and others are looking to modernize
    the tasklet routine (callback). For more information regarding this, please go
    to [https://www.openwall.com/lists/kernel-hardening/2020/07/16/1](https://www.openwall.com/lists/kernel-hardening/2020/07/16/1).
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到tasklets时，内核不断发展。最近（截至2020年7月）由*Kees Cook*和其他人提出的补丁旨在现代化tasklet例程（回调）。有关更多信息，请访问[https://www.openwall.com/lists/kernel-hardening/2020/07/16/1](https://www.openwall.com/lists/kernel-hardening/2020/07/16/1)。
- en: Understanding the kernel softirq mechanism
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解内核softirq机制
- en: 'At this point, you understand that the bottom half, the tasklet, is a deferred
    functionality mechanism that, while running, doesn''t mask interrupts. They''re
    designed to allow you to get the best of both worlds: they allow the driver to
    do fairly lengthy interrupt processing if the situation demands it *and* do it
    in a deferred safe manner while simultaneously allowing the business of the system
    (via hardware interrupts) to continue.'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，你了解到底部的一半，tasklet，是一个延迟功能机制，而运行时不会屏蔽中断。它们被设计成让你同时获得最好的两个世界：如果情况需要，它们允许驱动程序进行相当长时间的中断处理*并且*以延迟安全的方式进行，同时允许系统的业务（通过硬件中断）继续进行。
- en: 'You''ve already learned how to use the tasklet – it''s a great example of a
    deferred functionality mechanism. But how are they internally implemented? The
    kernel implements tasklets via an underlying facility called the **softirq** (or
    **software-interrupt**) mechanism*.* Though on the surface they''re analogous
    to the threaded interrupt we saw earlier, it''s really very different in many
    important ways. The following characteristics of softirqs will help you understand
    them:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经学会了如何使用tasklet-它是延迟功能机制的一个很好的例子。但它们是如何内部实现的呢？内核通过一个称为**softirq**（或**软件中断**）机制的基础设施来实现tasklets。虽然在表面上它们类似于我们之前看到的线程中断，但在许多重要方面它们实际上是非常不同的。下面softirqs的特征将帮助你理解它们：
- en: Softirqs are a pure internal kernel deferred functionality mechanism in the
    sense that they are statically assigned at kernel compile time (they're all hard-coded
    into the kernel); you cannot dynamically create a new softirq.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Softirqs是一个纯粹的内核延迟功能机制，因为它们在内核编译时静态分配（它们都是硬编码到内核中的）；你不能动态创建一个新的softirq。
- en: 'The kernel (as of version 5.4) provides a total of 10 discrete softirqs:'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核（截至5.4版本）提供了总共10个离散的softirqs：
- en: Each softirq is designed to serve a particular need, usually associated with
    a very particular hardware interrupt or kernel activity. (The exceptions here
    are perhaps the soft IRQs reserved for the generic tasklet: `HI_SOFTIRQ`  and `TASKLET_SOFTIRQ`.)
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个softirq都设计为满足特定的需求，通常与特定的硬件中断或内核活动相关联。（这里的例外可能是保留给通用tasklet的soft IRQs：`HI_SOFTIRQ`和`TASKLET_SOFTIRQ`。）
- en: These 10 softirqs have a priority ordering (and will be consumed in that order).
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这10个softirqs有一个优先级排序（并且将按照该顺序被消耗）。
- en: The tasklet is, in fact, a thin abstraction on top of a particular softirq (`TASKLET_SOFTIRQ`),
    one of the 10 available. The tasklet is the only one that can be registered, run,
    and deregistered at will, making it an ideal choice for many device drivers.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务是，实际上，一个薄的抽象在一个特定的softirq（`TASKLET_SOFTIRQ`）之上，其中有10个可用的。任务是唯一一个可以随意注册、运行和注销的，这使它成为许多设备驱动程序的理想选择。
- en: Softirqs run in interrupt – softirq – context; the `in_softirq()` macro returns
    `true` here, implying you are in a softirq (or tasklet) context.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Softirqs在中断-softirq-上下文中运行；`in_softirq()`宏在这里返回`true`，意味着你在softirq（或tasklet）上下文中。
- en: All softirq servicing is considered a high priority on the system. Next to the
    hardware interrupt (the `hardirq/ISR/primary` handler), the softirq has the highest
    priority on the system. Pending softirqs are consumed by the kernel *before *the
    process context that was interrupted in the first place is restored.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有softirq服务都被认为是系统上的高优先级。在硬件中断（`hardirq/ISR/primary`处理程序）之后，softirq在系统上具有最高优先级。未决的softirqs在内核恢复首先中断的进程上下文之前被消耗。
- en: 'The following diagram is a superset of our earlier depiction of priorities
    on standard Linux; this one includes softirqs (within which is the tasklet):'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是我们之前对标准Linux优先级的描述的超集；这个包括softirqs（其中包括tasklet）：
- en: '![](img/cdb5a54d-d4ea-4ac3-b64f-cba27cd50639.png)'
  id: totrans-428
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cdb5a54d-d4ea-4ac3-b64f-cba27cd50639.png)'
- en: Figure 4.10 – Relative priorities on standard Linux, showing softirqs as well
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.10-标准Linux上的相对优先级，显示softirqs
- en: So, yes, as you can see, softirqs are a very high-priority mechanism on Linux;
    there are 10 distinct ones at differing priorities. What they are, and what they're
    meant for, will be covered in the next subsection.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，是的，正如你所看到的，softirqs是Linux上一个非常高优先级的机制；有10个不同的优先级。它们是什么，以及它们的用途，将在下一小节中介绍。
- en: Available softirqs and what they are for
  id: totrans-431
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可用的softirqs及其用途
- en: 'The work that''s carried out by a given softirq is statically compiled into
    the kernel image (it''s fixed). This coupling of the softirq and the action it
    takes (in effect, the code it runs, via the `action` function pointer) is done
    via the following code:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 由给定softirq执行的工作被静态编译到内核映像中（它是固定的）。通过以下代码完成了softirq和它采取的行动（实际上是通过`action`函数指针运行的代码）的耦合：
- en: '[PRE31]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following diagram is a conceptual representation of the available softirqs
    and their priority level on Linux (as of kernel version 5.4), with `0` being the
    highest and `9` the lowest softirq priority level:'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表是Linux上可用的softirqs及其优先级级别的概念表示（截至内核版本5.4），其中`0`为最高，`9`为最低的softirq优先级级别：
- en: '![](img/f4db6866-2a3b-414f-b0e2-88a2e21c1dfa.png)'
  id: totrans-435
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f4db6866-2a3b-414f-b0e2-88a2e21c1dfa.png)'
- en: Figure 4.11 – The 10 softirqs on Linux in order of priority (0:highest, 9:lowest)
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.11 - Linux上的10个softirq按优先级顺序排列（0：最高，9：最低）
- en: 'The following table sums up the individual kernel''s softirqs in order of their
    priority (`0`: `HI_SOFTIRQ` being the highest priority one), along with the action
    or vector, its functionality, and a comment mentioning what its use case is:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格总结了各个内核的softirq按其优先级的顺序（`0`：`HI_SOFTIRQ`为最高优先级），以及其功能、用途的动作或向量和注释：
- en: '| **Softirq#** | **Softirq** | **Comment (what it''s used for/does)** | **"action"
    or "vector" function** |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| **Softirq#** | **Softirq** | **注释（用途/功能）** | **“action”或“vector”函数** |'
- en: '| `0` | `HI_SOFTIRQ` | **Hi-tasklet**: The highest priority softirq; used when
    `tasklet_hi_schedule()` is invoked. It is not recommended for the majority of
    use cases. Use the regular tasklet instead (softirq #`6`). | `tasklet_hi_action()`
    |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| `0` | `HI_SOFTIRQ` | **Hi-tasklet**：最高优先级的softirq；在调用`tasklet_hi_schedule()`时使用。不建议大多数用例使用。请改用常规tasklet（softirq
    #`6`）。 | `tasklet_hi_action()` |'
- en: '| `1` | `TIMER_SOFTIRQ` | **Timer**: The timer interrupt''s bottom half runs
    expired timers along with other "housekeeping" tasks (including the scheduler
    CPU `runqueue` + `vruntime` updates, increments of the well-known `jiffies_64` variable,
    and so on). | `run_timer_softirq()` |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| `1` | `TIMER_SOFTIRQ` | **Timer**：定时器中断的底半部分运行已过期的定时器以及其他“日常”任务（包括调度器CPU
    `runqueue` + `vruntime`更新，增加已知的`jiffies_64`变量等）。 | `run_timer_softirq()` |'
- en: '| `2` | `NET_TX_SOFTIRQ` | **Net**: Network stack transmit path bottom half
    (qdisc). | `net_tx_action()` |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| `2` | `NET_TX_SOFTIRQ` | **Net**：网络堆栈传输路径底部（qdisc）。 | `net_tx_action()` |'
- en: '| `3` | `NET_RX_SOFTIRQ` | **Net**: Network stack receive path bottom half
    (NAPI polling). | `net_rx_action()` |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| `3` | `NET_RX_SOFTIRQ` | **Net**：网络堆栈接收路径底部（NAPI轮询）。 | `net_rx_action()`
    |'
- en: '| `4` | `BLOCK_SOFTIRQ` | **Block**: Block processing (complete the I/O op;
    invokes the complete function of block MQ, `blk_mq_ops`). | `blk_done_softirq()`
    |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
  zh: '| `4` | `BLOCK_SOFTIRQ` | **Block**：块处理（完成I/O操作；调用块MQ的`complete`函数，`blk_mq_ops`）。
    | `blk_done_softirq()` |'
- en: '| `5` | `IRQ_POLL_SOFTIRQ` | **irqpoll**: Implements the kernel''s block layer
    polled IRQ mode (equivalent to the network layer''s NAPI processing). | `irq_poll_softirq()`
    |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
  zh: '| `5` | `IRQ_POLL_SOFTIRQ` | **irqpoll**：实现内核的块层轮询中断模式（相当于网络层的NAPI处理）。 | `irq_poll_softirq()`
    |'
- en: '| `6` | `TASKLET_SOFTIRQ` | **Regular tasklet**: Implements the tasklet bottom-half
    mechanism, the only dynamic (flexible) softirq: can be registered, used, and deregistered
    by drivers as required. | `tasklet_action()` |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
  zh: '| `6` | `TASKLET_SOFTIRQ` | **常规tasklet**：实现tasklet底部机制，唯一的动态（灵活）softirq：可以由驱动程序根据需要注册、使用和注销。
    | `tasklet_action()` |'
- en: '| `7` | `SCHED_SOFTIRQ` | **sched**: Used for periodic load balancing by the
    CFS scheduler on SMP; migrates tasks to other runqueues if required. | `run_rebalance_domains()`
    |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
  zh: '| `7` | `SCHED_SOFTIRQ` | **sched**：由SMP上的CFS调度器用于周期性负载平衡；如果需要，将任务迁移到其他运行队列。
    | `run_rebalance_domains()` |'
- en: '| `8` | `HRTIMER_SOFTIRQ` | **HRT**: Used for **high-resolution timers** (**HRT**).
    It was removed in version 4.2 and reentered the kernel in a better form in version
    4.16. | `hrtimer_run_softirq()` |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
  zh: '| `8` | `HRTIMER_SOFTIRQ` | **HRT**：用于**高分辨率定时器**（**HRT**）。在4.2版本中被移除，并在4.16版本中以更好的形式重新进入内核。
    | `hrtimer_run_softirq()` |'
- en: '| `9` | `RCU_SOFTIRQ` | **RCU**: Performs **read copy update** (**RCU**) processing,
    a form of lock-free technology used within the core kernel. | `rcu_core_si() /
    rcu_process_callbacks()` |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
  zh: '| `9` | `RCU_SOFTIRQ` | **RCU**：执行**读复制更新**（**RCU**）处理，一种在核心内核中使用的无锁技术。 | `rcu_core_si()
    / rcu_process_callbacks()` |'
- en: It's interesting; the network and block stacks are very high priority code paths
    (as is the timer interrupt), so their code must run as soon as possible. Thus,
    they have explicit softirqs that service these critical code paths.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣；网络和块堆栈是非常高优先级的代码路径（定时器中断也是），因此它们的代码必须尽快运行。因此，它们有明确的softirqs来服务这些关键代码路径。
- en: 'Can we see the softirqs that have been fired off so far? Of course, very much
    like how we can view hardirqs (via its `proc/interrupts` pseudofile). We have
    the `/proc/softirqs` pseudofile for tracking softirqs. Here''s a sample screenshot
    from my native (four-core) x86_64 Ubuntu system:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能看到迄今为止已经触发的softirqs吗？当然，就像我们可以查看硬中断一样（通过其`proc/interrupts`伪文件）。我们有`/proc/softirqs`伪文件来跟踪softirqs。这是我本地（四核）x86_64
    Ubuntu系统的一个示例截图：
- en: '![](img/3f611395-ef6b-492d-8729-18ac25cb5dd6.png)'
  id: totrans-451
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3f611395-ef6b-492d-8729-18ac25cb5dd6.png)'
- en: Figure 4.12 – Output of /proc/softirqs on a native x86_64 system with 4 CPU
    cores
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.12 - 本地x86_64系统上/proc/softirqs的输出，有4个CPU核心
- en: Just like with `/proc/interrupts`, the numbers shown in the preceding screenshot
    depict the number of times a particular softirq occurred on a particular CPU core
    from system startup. In addition, FYI, the powerful `crash` tool has a useful
    command, `irq`, that shows information regarding interrupts; `irq -b` displays
    the defined softirqs on that kernel.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`/proc/interrupts`一样，前面截图中显示的数字表示从系统启动以来在特定CPU核心上发生特定softirq的次数。另外，值得一提的是，强大的`crash`工具有一个有用的命令，`irq`，显示关于中断的信息；`irq
    -b`显示内核上定义的softirqs。
- en: Understanding how the kernel runs softirqs
  id: totrans-454
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解内核如何运行softirqs
- en: 'The following is the (approximate) call graph that''s used on x86 when a hardware
    interrupt is triggered:'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在x86触发硬件中断时使用的（近似）调用图：
- en: '[PRE32]'
  id: totrans-456
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Some of the preceding code paths are arch-dependent. Note that the "marking
    the context as an interrupt" context is really an artifact. The kernel is marked
    as having entered this context in the `entering_irq()` function and as having
    left it once `exiting_irq()` returns (on x86). But hang on! The `exiting_irq()` inline
    function invokes the `kernel/softirq.c:irq_exit()` function ([https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L403)[L403](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L403)).
    It''s within this routine that the kernel processes, and consumes, all pending
    softirqs. The basic call graph (from `do_softirq()` onward) is as follows:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的一些代码路径是与体系结构相关的。请注意，“标记上下文为中断”上下文实际上是一个人为的产物。内核被标记为进入这个上下文在`entering_irq()`函数中，并且一旦`exiting_irq()`返回（在x86上），它就被标记为离开。但是等等！`exiting_irq()`内联函数调用`kernel/softirq.c:irq_exit()`函数（[https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L403)[L403](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L403)）。在这个例程中，内核处理并消耗所有待处理的softirq。从`do_softirq()`开始的基本调用图如下：
- en: '[PRE33]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The real work happens in the internal `__do_softirq()` routine ([https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L249](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L249)).
    It's here that any pending softirqs are consumed in priority order. Notice that
    softirq processing is done before context is restored to the interrupted task.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 真正的工作发生在内部的`__do_softirq()`例程中（[https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L249](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L249)）。在这里，任何待处理的softirq按优先级顺序被消耗。请注意，在上下文恢复到中断任务之前，softirq处理是在之前完成的。
- en: Now, let's briefly focus on some of the internal details of tasklet execution,
    followed by how to use *ksoftirqd* kernel threads to offload softirq work.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们简要关注一些tasklet执行的内部细节，然后是如何使用ksoftirqd内核线程来卸载softirq工作。
- en: Running tasklets
  id: totrans-461
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 运行tasklets
- en: 'A word on the internals of tasklet invocation: we understand that the tasklet
    softirq runs via `tasklet_schedule()`. This API ends up invoking the kernel''s
    internal `__tasklet_schedule_common()` function ([https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L471](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L471)),
    which internally calls `raise_softirq_irqoff(softirq_nr)` ([https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L423](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L423)).
    This raises the `softirq_nr` softirq; for a regular tasklet, this value is `TASKLET_SOFTIRQ`,
    whereas when the tasklet is scheduled via the `tasklet_hi_schedule()` API, is
    value is `HI_SOFTIRQ`, the highest priority softirq! Use it rarely, if ever.'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 关于tasklet调用的内部工作：我们知道tasklet softirq通过`tasklet_schedule()`运行。这个API最终会调用内核的内部`__tasklet_schedule_common()`函数（[https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L471](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L471)），它内部调用`raise_softirq_irqoff(softirq_nr)`（[https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L423](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L423)）。这会触发`softirq_nr`
    softirq；对于常规tasklet，这个值是`TASKLET_SOFTIRQ`，而当通过`tasklet_hi_schedule()`API调度tasklet时，这个值是`HI_SOFTIRQ`，最高优先级的softirq！很少使用，如果有的话。
- en: We now know that the "schedule" functionality has set up the softirq; here,
    the actual execution takes place when the softirqs at that priority level (`0`
    or `6` here) actually run. The function that runs softirqs is called `do_softirq()`;
    for the regular tasklet, it ends up calling the `tasklet_action()` softirq vector (as
    shown in the preceding table); this calls `tasklet_action_common()` ([https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L501](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L501)), which
    (after some list setup) enables hardware interrupts (via a `local_irq_enable()`)
    and then loops over the per CPU tasklet list, consuming (running) the tasklet
    function(s) on it. Did you notice that pretty much all the functions mentioned
    here are arch-independent? - a good thing.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在知道，“schedule”功能已经设置了softirq；在这里，实际的执行发生在softirq在该优先级级别（这里是`0`或`6`）实际运行时。运行softirq的函数称为`do_softirq()`；对于常规的tasklet，它最终会调用`tasklet_action()`
    softirq向量（如前表所示）；这将调用`tasklet_action_common()`（[https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L501](https://elixir.bootlin.com/linux/v5.4/source/kernel/softirq.c#L501)），然后（经过一些列表设置）启用硬件中断（通过`local_irq_enable()`），然后循环遍历每个CPU的tasklet列表，运行其中的tasklet函数。你注意到这里提到的几乎所有函数都是与体系结构无关的吗？-
    这是一件好事。
- en: Employing the ksoftirqd kernel threads
  id: totrans-464
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用ksoftirqd内核线程
- en: 'Softirqs can impose an enormous load on the system when there is a flood of
    them waiting to be processed. This has been repeatedly seen in the network (and
    to some extent, block) layers, leading to the development of polled mode IRQ handling;
    it''s called NAPI for the network (receive) path and simply interrupt-poll handling for
    the block layer. But what if, even with polled mode handling, the softirq flood
    persists? The kernel has one more trick up its sleeve: if softirq processing exceeds
    2 milliseconds, the kernel offloads the pending softirq work onto per-CPU kernel
    threads named `ksoftirqd/n` (where `n` represents the CPU number, starting from `0`).
    A benefit of this approach is that because kernel threads must compete with other
    threads for CPU resources, user space doesn''t end up getting completely starved
    of CPU (which could happen with pure hardirq/softirq load).'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 当有大量softirq等待处理时，softirq会对系统施加巨大负载。这在网络（以及在某种程度上，块）层中反复出现，导致了轮询模式IRQ处理的开发；对于网络（接收）路径，称为NAPI，对于块层，称为中断轮询处理。但是，即使使用了轮询模式处理，softirq洪水仍然持续存在怎么办？内核还有一个更加巧妙的方法：如果softirq处理超过2毫秒，内核会将待处理的softirq工作卸载到每个CPU内核线程上，命名为`ksoftirqd/n`（其中`n`表示CPU编号，从`0`开始）。这种方法的好处是，因为内核线程必须与其他线程竞争CPU资源，用户空间不会完全被耗尽CPU（这可能会发生在纯硬中断/软中断负载中）。
- en: 'This sounds like a good solution, but the real world begs to differ. In February
    2019, a series of patches to set up softirq vector fine-grained masking looked
    promising but ultimately seem to have fizzled out (do read the very interesting
    details provided in the *Further reading *section). The following email from Linus
    Torvalds clarifies the real problem nicely ([https://lore.kernel.org/lkml/CAHk-=wgOZuGZaVOOiC=drG6ykVkOGk8RRXZ_CrPBMXHKjTg0dg@mail.gmail.com/#t](https://lore.kernel.org/lkml/CAHk-=wgOZuGZaVOOiC=drG6ykVkOGk8RRXZ_CrPBMXHKjTg0dg@mail.gmail.com/#t)):'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来像是一个好的解决方案，但现实世界并不这么认为。2019年2月，一系列设置软中断向量细粒度屏蔽的补丁看起来很有希望，但最终似乎已经消失了（请阅读*进一步阅读*部分提供的非常有趣的细节）。Linus
    Torvalds的以下电子邮件很好地澄清了真正的问题（[https://lore.kernel.org/lkml/CAHk-=wgOZuGZaVOOiC=drG6ykVkOGk8RRXZ_CrPBMXHKjTg0dg@mail.gmail.com/#t](https://lore.kernel.org/lkml/CAHk-=wgOZuGZaVOOiC=drG6ykVkOGk8RRXZ_CrPBMXHKjTg0dg@mail.gmail.com/#t)）：
- en: '[PRE34]'
  id: totrans-467
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: The last part of the statement hits the nail on the head.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 陈述的最后部分正中要害。
- en: 'So, this begs the question: can we *measure* hardirq/softirq instances and
    latencies? We cover this in the section *Measuring metrics and latency*.'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，问题是：我们能够*测量*硬中断/软中断实例和延迟吗？我们将在*测量指标和延迟*部分进行介绍。
- en: Softirqs and concurrency
  id: totrans-470
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 软中断和并发
- en: 'As we learned with regard to tasklets, a number of points with regard to *concurrency*
    must be understood with respect to softirqs:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们在任务let方面学到的那样，必须了解关于*并发*的一些要点，关于软中断：
- en: As noted with tasklets (on SMP), a tasklet will never run in parallel with itself;
    this is a feature that makes it easier to use. This isn't true of softirqs: the
    same softirq vector can indeed run in parallel with itself on another CPU! Thus,
    the softirq vector code has to be especially careful with the use of locking (and
    deadlock avoidance).
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如在任务let（在SMP上）中指出的，任务let永远不会与自身并行运行；这是一个使其更容易使用的特性。这对软中断并不成立：同一个软中断向量确实可以在另一个CPU上与自身并行运行！因此，软中断向量代码在使用锁定（和避免死锁）时必须特别小心。
- en: A softirq can always be interrupted by a hardirq, including the IRQ that caused
    it to be raised (this is because, as with tasklets, softirqs run with all interrupts
    enabled on the local core).
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软中断总是可以被硬中断中断，包括引发它被提出的IRQ（这是因为，与任务let一样，软中断在本地核心上以所有中断启用运行）。
- en: A softirq cannot preempt another currently executing softirq, even though they
    have priority levels; they are consumed in priority order.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个软中断不能抢占另一个当前正在执行的软中断，即使它们有优先级；它们按优先顺序消耗。
- en: The reality is that the kernel provides APIs such as `spin_lock_bh()`, which
    allow you to disable softirq processing while the lock is held. This is required
    to prevent deadlock when both the hardirq and the softirq handlers are working
    on shared data. The locking implications really do matter. We'll cover this in
    detail in the last two chapters of this book.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事实上，内核提供了诸如`spin_lock_bh()`这样的API，允许您在持有锁时禁用软中断处理。这是为了防止当硬中断和软中断处理程序都在处理共享数据时发生死锁。锁定的影响确实很重要。我们将在本书的最后两章中详细介绍这一点。
- en: Hardirqs, tasklets, and threaded handlers – what to use when
  id: totrans-476
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬中断、任务let和线程处理程序——在何时使用
- en: As you already know, the hardirq code is meant to do the bare minimum setup
    and interrupt handling, leaving the majority of the interrupt processing to be
    performed in a safe manner via the deferred functionality mechanisms we've been
    talking about, the tasklet and/or softirq. This 'bottom half' as well as deferred
    functionality handling is carried out in priority order – first, the softirq kernel
    timers, then tasklets (both of these are just special cases of the underlying
    softirq mechanism), then threaded interrupts, and finally workqueues (the latter
    two use underlying kernel threads).
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您已经知道的，硬中断代码旨在进行最少的设置和中断处理，将大部分中断处理留给通过我们一直在谈论的安全方式执行的延迟功能机制，即任务let和/或软中断。这个“下半部分”以及延迟功能处理按优先顺序进行——首先是软中断内核定时器，然后是任务let（这两者只是基础软中断机制的特殊情况），然后是线程中断，最后是工作队列（后两者使用基础内核线程）。
- en: So, the big question is, when you're writing your driver, which one of these
    should you use? Should you use a deferred mechanism at all? It really depends
    on the **amount of time ****your complete interrupt processing takes** to complete.
    If your complete interrupt processing can be consistently completed within a few
    microseconds, then just use the top-half hardirq; nothing else is required.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，重要的问题是，在编写驱动程序时，您应该使用这些中的哪一个？是否根本应该使用延迟机制？这实际上取决于**您的完整中断处理所需的时间**。如果您的完整中断处理可以在几微秒内始终完成，那么只需使用上半部分硬中断；不需要其他。
- en: 'But what if this isn''t the case? Take a look at the following table; the first
    column specifies the total time it takes for complete interrupt processing, while
    the other columns provide a few suggestions regarding its use plus pros and cons:'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果情况并非如此呢？看一下下表；第一列指定了完成中断处理所需的总时间，而其他列提供了一些建议以及利弊：
- en: '| **Time: If hardware interrupt handling  consistently requires** | **What
    to do** | **Pros/cons** |'
  id: totrans-480
  prefs: []
  type: TYPE_TB
  zh: '| **时间：如果硬件中断处理** **需要一致** | **该怎么办** | **利/弊** |'
- en: '| <= 10 microseconds | Use only the hardirq (top half); nothing else is required.
    | Best case; not typical. |'
  id: totrans-481
  prefs: []
  type: TYPE_TB
  zh: '| <= 10 微秒 | 仅使用硬中断（上半部分）；不需要其他。 | 最佳情况；不太典型。 |'
- en: '| Between 10 and 100 microseconds | Either only hardirq or both hardirq and
    a tasklet (softirq). | Run stress tests/workloads to see if a tasklet is really
    required. Its usage is mildly discouraged in favor of threaded handlers or workqueues.
    |'
  id: totrans-482
  prefs: []
  type: TYPE_TB
  zh: '| 10到100微秒之间 | 仅使用硬中断或硬中断和任务let（软中断）。 | 运行压力测试/工作负载，看看是否真的需要任务let。在使用上，它略有不鼓励，而更倾向于线程处理程序或工作队列。'
- en: '| 100 microseconds, non-critical device | Use a primary handler (hardirq);
    that is, either your own handler function (if hardware-specific work is required)
    or simply use the kernel default and a *threaded* handler. Alternatively, if acceptable,
    simply use a *workqueue* (covered in the next chapter). | This avoids softirq
    processing, which helps reduce system latencies but can result in slightly slower
    handling. This is because the threaded handler competes for CPU time with other
    threads. Workqueues are also based on kernel threads and have similar characteristics.
    |'
  id: totrans-483
  prefs: []
  type: TYPE_TB
  zh: '| 100微秒，非关键设备 | 使用主处理程序（hardirq）；也就是说，要么使用自己的处理程序函数（如果需要特定于硬件的工作），要么简单地使用内核默认值和*线程化*处理程序。或者，如果可以接受，只需使用*工作队列*（在下一章中介绍）。|
    这避免了softirq处理，有助于减少系统延迟，但可能导致处理速度稍慢。这是因为线程化处理程序与其他线程竞争CPU时间。工作队列也是基于内核线程并具有类似特性。|'
- en: '| 100 microseconds, critical device (typically network, block, and some multimedia
    devices) | Use a primary handler (hardirq/top half) and a tasklet (bottom half).
    | It prioritizes the device over everything when a flood of interrupts arrive.
    This is also a downside as this can cause "livelock" issues and long latencies
    with a softirq "flood"! Test and ascertain. |'
  id: totrans-484
  prefs: []
  type: TYPE_TB
  zh: '| 100微秒，关键设备（通常是网络、块和一些多媒体设备） | 使用主处理程序（hardirq/top half）和一个tasklet（bottom
    half）。| 当大量中断到达时，它优先处理设备。这也是一个缺点，因为这可能导致"活锁"问题和软中断的长延迟！测试并确定。'
- en: '| 100 microseconds, extremely critical work/device | Use a primary handler
    (hardirq/top half) and a hi-tasklet or (possibly) your own (new!) softirq. | This
    is a rather extreme, unlikely case; to add your own softirq you will need to change
    the internal (GPL-ed) kernel code. This makes it high maintenance (unless your
    core kernel changes + driver is contributed upstream!). |'
  id: totrans-485
  prefs: []
  type: TYPE_TB
  zh: '| 100微秒，极其关键的工作/设备 | 使用主处理程序（hardirq/top half）和一个hi-tasklet或（可能）自己的（新！）softirq。|
    这是一个相当极端的，不太可能的情况；要添加自己的softirq，您需要更改内部（GPL许可的）内核代码。这使得它需要高维护（除非您的核心内核更改+驱动程序被贡献上游！）。'
- en: The time in microseconds in the first column is, of course, debatable, arch-and-board-dependent,
    and can (and will) change over time. The suggested value of 100 microseconds as
    a baseline is merely a heuristic.
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 第一列中的微秒时间当然是有争议的，取决于架构和板卡，并且随着时间的推移可能会发生变化。100微秒作为基线的建议值仅仅是一种启发式方法。
- en: 'As we''ve already mentioned, softirq processing itself should complete within
    a few hundred microseconds; a flood of unprocessed softirqs can again lead to
    a livelock situation. The kernel mitigates (or de-risks) this in two broad ways:'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经提到的，softirq处理本身应该在几百微秒内完成；大量未处理的softirq可能再次导致活锁情况。内核通过两种方式来减轻（或降低）这种情况：
- en: Threaded interrupts or workqueues (both based on kernel threads)
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线程化中断或工作队列（都基于内核线程）
- en: Invoking the `ksoftirqd/n` kernel threads to take over softirq processing
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用`ksoftirqd/n`内核线程来接管softirq处理。
- en: The preceding cases run in process context, thus alleviating the issue of starving
    genuine (user space) threads that require the CPU via the scheduler (as the kernel
    threads themselves have to compete for the CPU resources).
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的情况在*进程*上下文中运行，因此减轻了通过调度程序使真正（用户空间）线程饥饿的问题（因为内核线程本身必须竞争CPU资源）。
- en: With regard to the last row of the preceding table, the only way to create a
    new softirq is to actually dive into the kernel code and modify it. By this, we
    mean modifying the (GPL licensed) kernel code base. In terms of embedded projects,
    modifying the kernel source is not uncommon. However, adding softirqs is considered
    (very) uncommon and not a great idea at all since latencies may already be high
    without more softirq processing to contend with! This hasn't happened for many
    years now.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 关于前表的最后一行，创建新的softirq的唯一方法是实际进入内核代码并对其进行修改。这意味着修改（GPL许可的）内核代码库。在嵌入式项目方面，修改内核源代码并不罕见。然而，添加softirq被认为是（非常）罕见的，而且根本不是一个好主意，因为延迟可能已经很高，而不需要更多的softirq处理！这已经很多年没有发生了。
- en: In terms of real time and determinism, in the companion guide *Linux Kernel
    Programming,* *Chapter 11*, *The CPU Scheduler – Part 2*, in the *Viewing the
    results* section, we mentioned that the *jitter* (the time variance) in interrupt
    processing on a microprocessor running standard Linux is on the order of +/- 10
    microseconds. With the RTL kernel, it's a lot better, yet not a hundred percent
    deterministic. So, can you be completely deterministic with interrupt handling
    on Linux? Well, one interesting approach is to use – if enabled and possible – **FIQs**,
    the so-called *fast interrupt* mechanism that some processors, notably ARM, provide.
    They work outside the Linux kernel's scope, which is precisely why writing an
    FIQ interrupt handler would eliminate any kernel-induced jitter. Take a look at
    this article for more information: [https://bootlin.com/blog/fiq-handlers-in-the-arm-linux-kernel/](https://bootlin.com/blog/fiq-handlers-in-the-arm-linux-kernel/).
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 在实时性和确定性方面，在伴随指南*Linux内核编程*的*第11章* *CPU调度器-第2部分*中，在*查看结果*部分，我们提到在运行标准Linux的微处理器上，中断处理的*抖动*（时间变化）大约为+/-
    10微秒。使用RTL内核会好很多，但并非百分之百确定性。那么，在Linux上处理中断时可以完全确定吗？一个有趣的方法是使用-如果启用并且可能-**FIQs**，即一些处理器（尤其是ARM）提供的所谓*快速中断*机制。它们在Linux内核范围之外工作，这正是为什么编写FIQ中断处理程序会消除任何内核引起的抖动。点击此处查看更多信息：[https://bootlin.com/blog/fiq-handlers-in-the-arm-linux-kernel/](https://bootlin.com/blog/fiq-handlers-in-the-arm-linux-kernel/)。
- en: 'Finally, it may be worth mentioning that (at the time of writing) a good amount
    of rethinking is going on here: the opinion of some kernel developers is that
    the whole top-half bottom-half mechanism isn''t required anymore. However, the
    fact is that this mechanism is deeply embedded into the kernel fabric, making
    it non-trivial to remove.'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，可能值得一提的是（在撰写本文时）这里正在进行大量的反思：一些内核开发人员的观点是，整个上半部分下半部分机制不再需要。然而，事实是这种机制已经深深嵌入到内核结构中，使得它不容易移除。
- en: Fully figuring out the context
  id: totrans-494
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完全弄清上下文
- en: The *Interrupt context guidelines – what to do and what not to do* section made
    this clear: when you're in any kind of interrupt (or atomic) context, do not invoke
    any possibly blocking APIs (that end up calling `schedule()`)*;* this really boils
    down to a few key points (as we saw). One is that you should not make any kernel
    to user space (or vice versa) data transfers; another, if you must allocate memory,
    do so with the `GFP_ATOMIC` flag.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: '*中断上下文指南 - 要做什么和不要做什么*部分明确指出：当您处于任何类型的中断（或原子）上下文中时，不要调用任何可能会阻塞的API（最终调用`schedule()`）；这实际上归结为几个关键点（正如我们所看到的）。其中一个是您不应进行任何内核到用户空间（或反之）的数据传输；另一个是，如果必须分配内存，请使用`GFP_ATOMIC`标志。'
- en: 'This, of course, begs the question: **how do I know if my driver (or module)
    code is currently running in process or interrupt (atomic) context?** Furthermore,
    if it''s running in interrupt context, is it in a top or bottom half? The short
    answer to all this is that the kernel provides several macros that you can use
    to figure this out. These macros are defined in the `linux/preempt.h` header.
    Instead of unnecessarily duplicating information, we''ll show the relevant kernel
    comment header here; it clearly names and describes these macros:'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这引出了一个问题：**我怎么知道我的驱动程序（或模块）代码当前是在进程还是中断（原子）上下文中运行？**此外，如果它在中断上下文中运行，它是在顶半部还是底半部？对所有这些的简短回答是内核提供了几个宏，您可以使用这些宏来弄清楚这一点。这些宏在`linux/preempt.h`头文件中定义。我们将在这里显示相关的内核注释头，而不是不必要地重复信息；它清楚地命名和描述了这些宏：
- en: '[PRE35]'
  id: totrans-497
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We covered a subset of this topic in the companion guide *Linux Kernel Programming,* *Chapter
    6*, *Kernel Internals Essentials – Processes and Threads*, under the *Determining
    the context* section.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在配套指南*Linux Kernel Programming*的*第6章* *Kernel Internals Essentials – Processes
    and Threads*的*确定上下文*部分中涵盖了这个主题的一个子集。
- en: 'So, it''s quite simple; in our `convenient.h` header ([https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/blob/main/convenient.h](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/blob/main/convenient.h)),
    we define a convenience macro called `PRINT_CTX()` that, when invoked, will print
    the current context to the kernel log. The message is very deliberately formatted.
    The following is an example of the typical output it emits when invoked:'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，很简单；在我们的`convenient.h`头文件中（[https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/blob/main/convenient.h](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/blob/main/convenient.h)），我们定义了一个方便的宏`PRINT_CTX()`，当调用时，将当前上下文打印到内核日志中。这条消息被非常有意地格式化。以下是调用时发出的典型输出的示例：
- en: '[PRE36]'
  id: totrans-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'At first, the format might look strange to you. However, I have simply followed
    the kernel''s Ftrace (latency) output format to show the context (with the exception
    of the `DURATION` column; we don''t have it here). The Ftrace output format is
    well supported and understood by developers and kernel users. The following output
    shows you how to interpret it:'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，这种格式可能对您来说看起来很奇怪。但是，我只是遵循内核的`Ftrace（延迟）输出`格式来显示上下文（除了`DURATION`列；我们这里没有）。`Ftrace`输出格式得到了开发人员和内核用户的良好支持和理解。以下输出向您展示了如何解释它：
- en: '[PRE37]'
  id: totrans-502
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'This can be very useful as it can help you understand and thus debug difficult
    situations! You get to see not only what was running (its name and PID, as well
    as on which CPU core), but also four interesting columns (highlighted in bold
    (`.N.0`)). The preceding ASCII art view of these four columns is in fact identical
    to what Ftraceitself generates. Let''s interpret these four columns (in our example
    here, it''s the value `.N.0`):'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能非常有用，因为它可以帮助您理解并因此调试困难的情况！您不仅可以看到正在运行的内容（其名称和PID，以及在哪个CPU核心上），还可以看到四个有趣的列（用粗体突出显示（`.N.0`））。这四列的ASCII艺术视图实际上与`Ftrace`本身生成的完全相同。让我们解释一下这四列（在我们的示例中，它的值是`.N.0`）：
- en: '**Column 1**: The IRQ state. It displays `.` if interrupts are enabled (usually
    the case) and `d` if disabled.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列1**：中断状态。如果中断已启用（通常情况下），则显示`.`，如果已禁用，则显示`d`。'
- en: '**Column 2**: The `TIF_NEED_RESCHED` bit state. If `1`, the kernel will invoke `schedule()` at
    the next opportunity point (return from syscall or return from interrupt, whichever
    comes first). It displays `N` if set and `.` if cleared.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列2**：`TIF_NEED_RESCHED`位状态。如果为`1`，内核将在下一个机会点调用`schedule()`（从系统调用返回或从中断返回，以先到者为准）。如果设置，则显示`N`，如果清除，则显示`.`。'
- en: '**Column 3**: If we''re in an interrupt context, we can employ more macros
    to check whether we''re in a hardirq (top half) or softirq (bottom half) context.
    It displays this as follows:'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列3**：如果我们处于中断上下文中，我们可以使用更多的宏来检查我们是否处于硬中断（顶半部）或软中断（底半部）上下文。它显示如下：'
- en: '`.`: Process (task) context'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.`：进程（任务）上下文'
- en: 'Interrupt / atomic context:'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中断/原子上下文：
- en: '`h`: Hardirq is running'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`h`：硬中断正在运行'
- en: '`H`: Hardirq occurred inside a softirq (that is, a hardirq occurred while a
    softirq was executing, interrupting it)'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`H`：在软中断内发生了硬中断（也就是说，在软中断执行时发生了硬中断，打断了它）'
- en: '`s`: Softirq (or tasklet) context'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s`：Softirq（或tasklet）上下文'
- en: '**Column 4**: An integer value (derived from a bitmask) called `preempt_depth`.
    Essentially, it''s incremented every time a lock is taken and decremented on every
    unlock. So, if it''s positive, it implies the code is within a critical or atomic
    section.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**列4**：称为`preempt_depth`的整数值（来自位掩码）。基本上，每次获取锁时它都会增加，每次解锁时都会减少。因此，如果它是正数，那么意味着代码在关键或原子部分中。'
- en: 'The following is (part of) our code implementation for the `convenient.h:PRINT_CTX()` macro (carefully
    study the code and do use the macro in your code to understand it):'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们的`convenient.h:PRINT_CTX()`宏的代码实现（仔细研究代码，并在您的代码中使用该宏来理解它的用法）的一部分：
- en: '[PRE38]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: It basically pivots on the `if` condition and checks whether the code is in
    a process (or task) context or not via the `in_task()` macro, and thus in an interrupt
    (or atomic) context.
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 它基本上围绕`if`条件进行旋转，并通过`in_task()`宏检查代码是否处于进程（或任务）上下文中，从而处于中断（或原子）上下文中。
- en: You might have come across the `in_interrupt()` macro being used in situations
    like this. If it returns `true`, your code is within an interrupt context, while
    if it returns `false`, it isn't. However, the recommendation for modern code is
    to *not* rely on this macro (and `in_softirq()`) due to the fact that bottom-half
    disabling can interfere with its correct working). Hence, we use `in_task()` instead.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经在这样的情况下使用`in_interrupt()`宏。如果它返回`true`，则您的代码在中断上下文中，而如果返回`false`，则不在。然而，对于现代代码的建议是*不*依赖于这个宏（和`in_softirq()`），因为底半部禁用可能会干扰其正确工作。因此，我们使用`in_task()`代替。
- en: 'Let''s continue looking at the code for the `PRINT_CTX()` macro:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续查看`PRINT_CTX()`宏的代码：
- en: '[PRE39]'
  id: totrans-518
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: If the `PRINTCTX_SHOWHDR` variable is set to `1`, it prints a header line; it's `0` by
    default. This is where the macro emits the (debug-level) printk (via `pr_debug()`),
    which shows the context information in Ftrace (latency) format, as seen in the
    preceding snippet.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`PRINTCTX_SHOWHDR`变量设置为`1`，它会打印一个标题行；默认情况下为`0`。这是宏发出（调试级别的）printk（通过`pr_debug()`）的地方，它以Ftrace（延迟）格式显示上下文信息，就像前面的片段中看到的那样。
- en: Viewing the context – examples
  id: totrans-520
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看上下文 - 示例
- en: 'As an example, in our `ch1/miscdrv_rdwr` misc driver code (and several others,
    in fact), we used this very macro (`PRINT_CTX()`) to display the context. Here''s
    some sample output from when our simple `rdwr_drv_secret` app read the "secret
    message" from the driver (for clarity, I removed the `dmesg` timestamps):'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在我们的`ch1/miscdrv_rdwr`杂项驱动程序代码（实际上还有其他几个），我们使用了这个宏（`PRINT_CTX()`）来显示上下文。以下是我们的简单`rdwr_drv_secret`应用程序从驱动程序中读取“秘密消息”时的一些示例输出（为了清晰起见，我删除了`dmesg`的时间戳）：
- en: '[PRE40]'
  id: totrans-522
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The header line shows how to interpret the output. (In fact, this header line
    is off by default. I temporarily changed the value of the `PRINTCTX_SHOWHDR` variable to `1` to
    show it here.)
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 标题行显示如何解释输出。（实际上，默认情况下这个标题行是关闭的。我暂时将`PRINTCTX_SHOWHDR`变量的值更改为`1`，以便在这里显示它。）
- en: 'The following is another example from an (out of tree) driver while running
    the code of a (bottom-half) tasklet (we covered tasklets in the *Understanding
    and using top and bottom halves* section):'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是另一个示例，来自一个（非内核）驱动程序，当运行（底半部）任务时的代码（我们在“理解和使用顶半部和底半部”部分中介绍了任务）：
- en: '[PRE41]'
  id: totrans-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let''s interpret the preceding output in more detail; from left to right:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地解释前面的输出；从左到右：
- en: '`000)`: The tasklet ran on CPU core `0`.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`000)`：任务在CPU核心`0`上运行。'
- en: The task that was interrupted by this is the `gnome-terminal*-*` process with
    PID `3075`. Actually, it was probably interrupted by the hardirq that fired before
    this tasklet ran, and will only resume execution – best case scenario – once the
    tasklet's done.
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 被中断的任务是PID为`3075`的`gnome-terminal*-*`进程。实际上，它可能是在这个任务完成之前被触发的硬中断打断的，并且只有在任务完成后才会恢复执行，最好的情况下。
- en: 'We can infer the following from the preceding four-column output (the `.Ns1`
    part):'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以从前面的四列输出（`.Ns1`部分）推断出以下内容：
- en: '`.`: All interrupts (on the local core, core `#0`) are enabled.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`.`：所有中断（在本地核心，核心`#0`）都已启用。'
- en: '`N`: The `TIF_NEED_RESCHED` bit is set (implying that the scheduler code will
    run when the next scheduling "opportunity point" is hit; realize that it will
    very likely be run (in process context) by the `gnome-terminal-` thread).'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`N`：`TIF_NEED_RESCHED`位被设置（意味着调度器代码将在下一个调度“机会点”被触发时运行；意识到它很可能会被（在进程上下文中）`gnome-terminal-`线程运行）。'
- en: '`s`: The tasklet is an interrupt – more precisely, a softirq – context (to
    be precise, it''s the `TASKLET_SOFTIRQ` softirq); an atomic context; this is expected
    - we''re running a tasklet!'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s`：任务是一个中断 - 更确切地说，是一个软中断上下文（确切地说，是`TASKLET_SOFTIRQ`软中断）；一个原子上下文；这是预期的 - 我们正在运行一个任务！'
- en: '`1`: the value of `preempt_depth` is `1`; this implies a (spin)lock is currently
    being held (again, this  implies that we''re currently in an atomic context).'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`：`preempt_depth`的值为`1`；这意味着当前正在持有（自旋）锁（再次，这意味着我们当前处于原子上下文中）。'
- en: The driver function running in the tasklet context was called `mydrv_tasklet()`.
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任务上下文中运行的驱动程序函数被称为`mydrv_tasklet()`。
- en: Often, when viewing a capture like this, in interrupt context, the interrupted
    task shows up as the `swapper/n` kernel thread (where `n` is the CPU core's number).
    This typically implies that the `swapper/n`kernel thread was interrupted by the
    hardirq, further implying that the interrupt triggered while that CPU was in an
    idle state (since the `swapper/n` threads only run then), which is a pretty common
    occurrence on a lightly loaded system.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在中断上下文中查看这样的捕获时，被中断的任务会显示为`swapper/n`内核线程（其中`n`是CPU核心的编号）。这通常意味着`swapper/n`内核线程被硬中断打断，进一步意味着在该CPU处于空闲状态时触发了中断（因为`swapper/n`线程只在这时运行），这在轻负载系统上是一个相当常见的情况。
- en: How Linux prioritizes activities
  id: totrans-536
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linux如何优先处理活动
- en: 'Now that you have learned about so many areas across the gamut, we can zoom
    out and see how the Linux kernel prioritizes things. The following (conceptual)
    diagram - a superset of earlier similar diagrams - neatly sums this up:'
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经了解了跨全范围的许多领域，我们可以放大看看Linux内核如何优先处理事情。以下（概念性）图表 - 之前类似图表的超集 - 很好地总结了这一点：
- en: '![](img/afcdef0b-492c-4afe-989d-e62aa5e74277.png)'
  id: totrans-538
  prefs: []
  type: TYPE_IMG
  zh: '![](img/afcdef0b-492c-4afe-989d-e62aa5e74277.png)'
- en: Figure 4.13 – Relative priorities across the full stack - user, kernel process
    context, and kernel interrupt contexts
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.13 - 用户、内核进程上下文和内核中断上下文之间的相对优先级
- en: This diagram is pretty self-explanatory, so please study it carefully.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图表非常直观，所以请仔细研究它。
- en: In this lengthy section, you have learned about interrupt handling via both
    the top-half and bottom-half mechanisms, the reasons for them in the first place,
    and how they are organized and to be used by drivers. You now understand that
    all bottom-half mechanisms are internally implemented via softirqs; the tasklet
    is the primary bottom-half mechanism that you, as a driver author, have easy access
    to use. This, of course, does not imply you must use them – if you can get away
    with simply using a top-half only, or, even better, just a threaded handler, then
    that's great. The *Hardirqs, tasklets, and threaded handlers – what to use when* section
    covered these considerations in detail.
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一长篇章节中，您已经了解了通过上半部和下半部机制处理中断的原因以及它们的组织和驱动程序的使用方式。您现在了解到所有的下半部机制都是通过softirqs进行内部实现的；tasklet是您作为驱动程序作者可以轻松访问的主要下半部机制。当然，这并不意味着您必须使用它们-如果您可以仅使用上半部，甚至更好的是只使用一个线程处理程序，那就太好了。*Hardirqs、tasklets和线程处理程序-在何时使用*部分详细介绍了这些考虑因素。
- en: With that, we're almost done! However, some miscellaneous areas still need to
    be traversed. Let's take a look by jumping into it via the familiar *FAQ* format!
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: 几个常见问题已经回答完毕！然而，还有一些杂项领域需要探讨。让我们通过熟悉的*FAQ*格式来看看！
- en: A few remaining FAQs answered
  id: totrans-543
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回答了一些剩下的常见问题
- en: 'Here are a few FAQs with regard to hardware interrupts and how they are handled.
    We haven''t touched on these areas yet:'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是关于硬件中断及其处理方式的一些常见问题。我们还没有涉及这些领域：
- en: On a multicore system, are all hardware interrupts routed to one CPU? If not,
    how are they load balanced? Can I change this?
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多核系统上，所有硬件中断都路由到一个CPU吗？如果不是，它们如何进行负载平衡？我可以改变这个吗？
- en: Does the kernel maintain a separate IRQ stack?
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核是否维护一个单独的IRQ堆栈？
- en: How can I obtain metrics on interrupts? Can I measure interrupt latency?
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我如何获得关于中断的指标？我能测量中断延迟吗？
- en: The idea here is to provide brief answers; we encourage you to dig deeper and
    try things out for yourself! At the risk of repetition, remember, the *empirical
    approach is best!*
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的想法是提供简短的答案；我们鼓励您深入挖掘并自己尝试！重复一遍，记住，*经验法则是最好的！*
- en: Load balancing interrupts and IRQ affinity
  id: totrans-549
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 负载均衡中断和IRQ亲和性
- en: 'First off, on a multicore (SMP) system, the way that hardware interrupts are
    routed to CPU cores tends to be very board and interrupt controller-specific.
    Having said that, the generic IRQ layer on Linux provides a very useful abstraction:
    it allows for (and implements) interrupt load balancing so that no CPUs (of set
    of CPUs) gets overloaded. There''s even frontend utilities, `irqbalance(1)` and `irqbalance-ui(1)`,
    that allow the admin (or root user) to perform IRQ balancing (`irqbalance-ui` is
    a `ncurses` frontend to `irqbalance`).'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在多核（SMP）系统上，硬件中断路由到CPU核心的方式往往是与板和中断控制器特定的。话虽如此，Linux上的通用IRQ层提供了一个非常有用的抽象：它允许（并实现）中断负载平衡，以便不会有CPU（一组CPU）过载。甚至还有前端实用程序`irqbalance(1)`和`irqbalance-ui(1)`，允许管理员（或root用户）执行IRQ平衡（`irqbalance-ui`是`irqbalance`的`ncurses`前端）。
- en: Can you change the interrupts that have been sent to a processor core(s)? Yes,
    via the `/proc/irq/IRQ/smp_affinity` pseudofile! It's a bitmask specifying the
    CPUs that this IRQ is allowed to be routed to. **The trouble is** that the default
    setting is to always allow all CPU cores to handle the interrupt by default. For
    example, on a system with eight cores, the value of `smp_affinity` for IRQ lines
    will be `0xff` (which is binary `1111 1111`). Why is this a problem? **CPU caching**.
    In a nutshell, if multiple cores handle the same interrupt, the caches get trashed
    and hence many cache invalidations may occur (to keep memory coherent with the
    CPU caches), leading to all kinds of performance headaches; this is especially
    true on high-end systems with dozens of cores and multiple NICs.
  id: totrans-551
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以更改已发送到处理器核心的中断吗？是的，通过`/proc/irq/IRQ/smp_affinity`伪文件！这是一个指定允许将此IRQ路由到的CPU的位掩码。**问题是**默认设置总是允许所有CPU核心处理中断。例如，在一个有八个核心的系统上，IRQ线的`smp_affinity`值将是`0xff`（二进制为`1111
    1111`）。为什么这是个问题？**CPU缓存**。简而言之，如果多个核心处理相同的中断，缓存会被破坏，因此可能会发生许多缓存失效（以保持内存与CPU缓存的一致性），导致各种性能问题；这在具有数十个核心和多个NIC的高端系统上尤其如此。
- en: We cover more on CPU caching issues in [Chapter 7](14cf1232-dfd5-428a-9c0b-30bcd84651b9.xhtml),  *Kernel
    Synchronization - Part 2* in the section *Cache effects and false sharing*.
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第7章](14cf1232-dfd5-428a-9c0b-30bcd84651b9.xhtml)中更多地涵盖了CPU缓存问题，*内核同步-第2部分*中的*缓存效应和伪共享*部分。
- en: It's recommended that you keep a single important IRQ line (such as the Ethernet
    interrupt) affined to a particular CPU core (or at most, to a physical core that
    is hyperthreaded). Not only that, but keeping the related network application
    processes and threads affined to the same core will (probably) result in better
    performance (we covered process/thread CPU affinity in the companion guide *Linux
    Kernel Programming -* *Chapter 11*, *The CPU Scheduler - Part 2* , in the *Understanding,
    querying, and setting the CPU affinity mask* section).
  id: totrans-553
  prefs: []
  type: TYPE_NORMAL
  zh: 建议您将单个重要的IRQ线（例如以太网中断）与特定的CPU核心（或者至多与一个支持超线程的物理核心）关联起来。不仅如此，将相关的网络应用程序进程和线程关联到同一个核心可能会带来更好的性能（我们在配套指南*Linux内核编程*-*第11章*-*CPU调度器-第2部分*的*理解、查询和设置CPU亲和性掩码*部分中介绍了进程/线程CPU亲和性）。
- en: 'Let''s go over a couple more points:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再讨论几个要点：
- en: The output of `/proc/interrupts` will reflect the IRQ affinity (and IRQ balancing)
    and allow you to see exactly how many interrupts have been routed to which CPU
    core on the system. (We covered interpreting its output in detail in the section
    *Viewing all allocated interrupt (IRQ) lines*.)
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/proc/interrupts`的输出将反映IRQ亲和性（和IRQ平衡），并允许您准确地看到系统上已经路由到哪个CPU核心的中断数量（我们在*查看所有分配的中断（IRQ）线*部分详细介绍了如何解释其输出）。'
- en: The `irqbalance` service can actually cause issues as it reverts the IRQ affinity
    settings to defaults upon startup ([https://unix.stackexchange.com/questions/68812/making-a-irq-smp-affinity-change-permanent](https://unix.stackexchange.com/questions/68812/making-a-irq-smp-affinity-change-permanent));
    you might want to disable it if you're carefully tweaking the settings (possibly
    at boot via an `rc.local` or equivalent `systemd` script.) The newer versions
    of `irqbalance`allow you to ban IRQ lines and won't (re)set them.
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`irqbalance`服务实际上可能会导致问题，因为它会在启动时将IRQ亲和性设置恢复为默认值（[https://unix.stackexchange.com/questions/68812/making-a-irq-smp-affinity-change-permanent](https://unix.stackexchange.com/questions/68812/making-a-irq-smp-affinity-change-permanent)）；如果您仔细调整设置，可能需要禁用它（可能通过`rc.local`或等效的`systemd`脚本在启动时）。较新版本的`irqbalance`允许您禁止IRQ线并且不会（重新）设置它们。'
- en: Does the kernel maintain separate IRQ stacks?
  id: totrans-557
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内核是否维护单独的IRQ堆栈？
- en: 'In the companion guide *Linux Kernel Programming* in *Chapter 6*, *Kernel Internals
    and Essentials – Processes and Threads*, in the *Organizing process, threads,
    and their stacks – user and **kernel space* section, we covered some key points:
    every single user space thread has two stacks: a user space stack and a kernel
    space stack. When the thread runs in non-privileged user space, it makes use of
    the user mode stack, while when it switches to privileged kernel space (via a
    system call or exception), it works with its kernel-mode stack (refer back to
    *Figure 6.3* in the companion guide *Linux Kernel Programming*). Next, the kernel-mode
    stack is very limited and fixed in size – it''s only 2 or 4 pages long (depending
    on whether your arch is 32- or 64-bit, respectively)!'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第6章*的*Linux内核编程*伴随指南中，*内核内部和基本要点-进程和线程*，在*组织进程、线程及其堆栈-用户和内核空间*部分，我们涵盖了一些关键点：每个用户空间线程都有两个堆栈：一个用户空间堆栈和一个内核空间堆栈。当线程在非特权用户空间运行时，它使用用户模式堆栈，而当它切换到特权内核空间（通过系统调用或异常）时，它使用内核模式堆栈（参考*Linux内核编程*伴随指南中的*图6.3*）。接下来，内核模式堆栈非常有限且大小固定-它只有2或4页长（取决于您的架构是32位还是64位）！
- en: So, imagine your driver code's (let's say, the `ioctl()` method) is running
    within a deeply nested code path. This implies that the kernel-mode stack for
    that process context is already pretty loaded up with metadata – the stack frames
    for each of those functions it's been invoking. Now, a hardware interrupt arrives!
    This, ultimately, is also code that must run and thus requires a stack. We could
    have it simply use the existing kernel-mode stack that's already in play, *but*
    this greatly increases the chances of stack overflow (given that we're deeply
    nested and the stack is small). A stack overflow within the kernel is disastrous
    as the system will simply hang/die with no real clues as to the root cause (well,
    the `CONFIG_VMAP_STACK` kernel config was introduced for mitigating precisely
    this kind of thing and is set by default on x86_64).
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，想象一下，您的驱动程序代码（比如说，`ioctl()`方法）正在一个深度嵌套的代码路径中运行。这意味着该进程上下文的内核模式堆栈已经装满了元数据-它正在调用的每个函数的堆栈帧。现在，硬件中断到达了！这也是必须运行的代码，因此需要一个堆栈。我们可以让它简单地使用已经在使用中的内核模式堆栈，*但*这会大大增加堆栈溢出的机会（因为我们嵌套很深并且堆栈很小）。内核中的堆栈溢出是灾难性的，因为系统将会无法启动/死机，而没有真正的线索指出根本原因（好吧，`CONFIG_VMAP_STACK`内核配置是为了减轻这种情况而引入的，并且在x86_64上默认设置）。
- en: So, long story short, on pretty much all modern architectures, the kernel allocates
    a *separate kernel space stack per CPU *for hardware interrupt handling. This
    is known as the **IRQ stack**. When a hardware interrupt arrives, the stack location
    (via the appropriate CPU stack pointer register) is switched to the IRQ stack
    of the CPU the interrupt is being processed on (and it's restored on IRQ exit).Some
    arch's (PPC) have a kernel config called `CONFIG_IRQSTACKS` to enable IRQ stacks.
    The size of the IRQ stack is fixed as the value is arch-dependent. On the x86_64,
    it's 4 pages long (16 KB, with a typical 4K page size).
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 长话短说，在几乎所有现代架构上，内核为硬件中断处理分配了*每个CPU一个单独的内核空间堆栈*。这被称为**IRQ堆栈**。当硬件中断到达时，堆栈位置（通过适当的CPU堆栈指针寄存器）被切换到正在处理中断的CPU的IRQ堆栈上（并在中断退出时恢复）。一些架构（PPC）有一个名为`CONFIG_IRQSTACKS`的内核配置来启用IRQ堆栈。IRQ堆栈的大小是固定的，其值取决于架构。在x86_64上，它有4页长（16
    KB，典型的4K页面大小）。
- en: Measuring metrics and latency
  id: totrans-561
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测量指标和延迟
- en: We have already discussed, to an extent, what latencies (delays) are and how
    to measure scheduling latency in the companion guide *Linux Kernel Programming
    -* *Chapter 11*, *The CPU Scheduler – Part 2*, under the *Latency and its measurement*
    section. Here, we'll look at more aspects of system latencies and their measurement.
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在*Linux内核编程*伴随指南的*第11章*，*CPU调度器-第2部分*，*延迟及其测量*部分，讨论了延迟是什么以及如何测量调度延迟。在这里，我们将看一下系统延迟及其测量的更多方面。
- en: As you already know, `procfs`is a rich source of information; we've already
    seen that both the number of hardirqs and softirqs that are generated per CPU
    core can be viewed via the `/proc/interrupts` and `/proc/softirqs` (pseudo) files.
    Similar information is available via `/proc/stat`.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您已经知道的，`procfs`是一个丰富的信息源；我们已经看到每个CPU核心生成的硬中断和软中断的数量可以通过`/proc/interrupts`和`/proc/softirqs`（伪）文件查看。类似的信息也可以通过`/proc/stat`获得。
- en: Measuring interrupts with [e]BPF
  id: totrans-564
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用[e]BPF测量中断
- en: In the companion guide *Linux Kernel Programming* - *Chapter 1*, *Kernel Workspace
    Setup*, in the* Modern tracing and performance analysis with [e]BPF* section,
    we pointed out how the modern approach to tracing, performance measurement, and
    analysis on (recent 4.x) Linux is [**e]BPF**, the **enhanced Berkeley Packet Filter**
    (just called BPF as well). Among the plethora of tools it stocks ([https://github.com/iovisor/bcc#tools](https://github.com/iovisor/bcc#tools)),
    two suit our immediate purpose of tracing, measuring, and analyzing interrupts
    (both hardirqs and softirqs). (The tools are named `toolname-bpfcc` on Ubuntu,
    where `toolname` is the name of the tool in question, such as `hardirqs-bpfcc` and `softirqs-bpfcc`).
    These tools dynamically trace interrupts (at the time of writing, they're not
    based on kernel tracepoints yet). You will require root access to run these [e]BPF
    tools.
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: 在配套指南*Linux Kernel Programming* - *Chapter 1*，*Kernel Workspace Setup*，在*Modern
    tracing and performance analysis with [e]BPF*部分，我们指出了在（最新的4.x）Linux上进行跟踪、性能测量和分析的现代方法是[e]BPF，即**增强型伯克利数据包过滤器**（也称为BPF）。在其库存的众多工具中（[https://github.com/iovisor/bcc#tools](https://github.com/iovisor/bcc#tools)），有两个适合我们的即时目的，即跟踪、测量和分析中断（硬中断和软中断）。
    （在Ubuntu上，这些工具的名称为`toolname-bpfcc`，其中`toolname`是所讨论工具的名称，例如`hardirqs-bpfcc`和`softirqs-bpfcc`）。这些工具动态跟踪中断（在撰写本文时，它们尚未基于内核跟踪点）。您需要root访问权限来运行这些[e]BPF工具。
- en: 'Important: You can install the BCC tools for your regular host Linux distro
    by reading the installation instructions here: [https://github.com/iovisor/bcc/blob/master/INSTALL.md](https://github.com/iovisor/bcc/blob/master/INSTALL.md).
    Why not do this on our guest Linux VM? You can do this when you''re running a
    distro kernel (such as an Ubuntu- or Fedora-supplied kernel). The reason you can
    do this is because the installation of the BCC toolset includes (and depends on)
    the installation of the `linux-headers-$(uname -r)` package; this `linux-headers`
    package exists only for distro kernels (and not for our custom 5.4 kernel, which
    you might be running on the guest).'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示：您可以通过阅读[https://github.com/iovisor/bcc/blob/master/INSTALL.md](https://github.com/iovisor/bcc/blob/master/INSTALL.md)的安装说明，在您的常规主机Linux发行版上安装BCC工具。为什么不在我们的Linux虚拟机上进行呢？当您运行发行版内核（例如Ubuntu或Fedora提供的内核）时，您可以这样做。您之所以可以这样做，是因为BCC工具集的安装包括（并依赖于）`linux-headers-$(uname
    -r)`软件包的安装；这个`linux-headers`软件包仅适用于发行版内核（而不适用于您可能在虚拟机上运行的自定义5.4内核）。
- en: Measuring time servicing individual hardirqs
  id: totrans-567
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测量服务各个硬中断的时间
- en: 'The `hardirqs[-bpfcc]` tool displays the total time spent servicing hardirqs
    (hardware interrupts). The following screenshot shows us running the `hardirqs-bpfcc` tool.
    Here, you can see the total time that was spent servicing hardirqs every 1 second
    (first parameter) for 3 seconds (second parameter):'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: '`hardirqs[-bpfcc]`工具显示了服务硬中断（硬件中断）的总时间。以下截图显示了我们运行`hardirqs-bpfcc`工具。在这里，您可以看到每秒服务硬中断的总时间（第一个参数）持续3秒（第二个参数）：'
- en: '![](img/0ca71735-eed0-4f33-b301-8e25289d116e.png)'
  id: totrans-569
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0ca71735-eed0-4f33-b301-8e25289d116e.png)'
- en: Figure 4.14 – hardirqs-bpfcc showing the time that was spent servicing hardirqs every
    1 second for 3 seconds
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.14 - hardirqs-bpfcc显示了每秒服务硬中断的时间，持续3秒
- en: 'The following screenshot shows us using the same tool to generate a histogram of
    hard IRQ time distribution (via the `-d` switch):'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了我们使用相同的工具生成硬中断时间分布的直方图（通过`-d`开关）：
- en: '![](img/1e6624d8-5cb1-4b22-b1e4-9471f204f17f.png)'
  id: totrans-572
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1e6624d8-5cb1-4b22-b1e4-9471f204f17f.png)'
- en: Figure 14.15 – hardirqs-bpfcc -d showing a histogram
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.15 - hardirqs-bpfcc -d显示直方图
- en: Notice how the majority of the network hardirqs (`iwlwifi`, 48 of them) take
    just between 4 to 7 microseconds to complete, though a few (three of them) take
    between 16 and 31 usecs.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 注意大多数网络硬中断（`iwlwifi`，48个）只需要4到7微秒完成，尽管其中一些（三个）需要16到31微秒。
- en: You can find more examples of how to use the `hardirqs[-bpfcc]` tool at [https://github.com/iovisor/bcc/blob/master/tools/hardirqs_example.txt](https://github.com/iovisor/bcc/blob/master/tools/hardirqs_example.txt).
    Looking up its man page would also be beneficial.
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[https://github.com/iovisor/bcc/blob/master/tools/hardirqs_example.txt](https://github.com/iovisor/bcc/blob/master/tools/hardirqs_example.txt)找到更多使用`hardirqs[-bpfcc]`工具的示例。查阅其手册页也会有益处。
- en: Measuring time servicing individual softirqs
  id: totrans-576
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 测量服务各个软中断的时间
- en: Similar to what we did previously with hardirqs, we will now employ the `softirqs[-bpfcc]` tool.
    It displays the total time spent servicing softirqs (software interrupts). Again, you
    will require root access to run these [e]BPF tools.
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前对硬中断的操作类似，我们现在将使用`softirqs[-bpfcc]`工具。它显示了服务软中断（软件中断）的总时间。同样，您需要root访问权限来运行这些[e]BPF工具。
- en: 'First, let''s place our system (native x86_64 running Ubuntu) under some stress
    (here, it''s performing network downloads, network uploads, and disk activity).
    The following screenshot shows us running the `softirqs-bpfcc` tool, which provides
    information about the total time spent servicing softirqs every 1 second (first parameter)
    forever (no second parameter):'
  id: totrans-578
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们让我们的系统（运行Ubuntu的本机x86_64）承受一些压力（在这里，它正在进行网络下载、网络上传和磁盘活动）。以下截图显示了我们运行`softirqs-bpfcc`工具，该工具提供了有关每秒服务软中断的总时间的信息（第一个参数）永久（没有第二个参数）：
- en: '![](img/6fc84cbc-b454-4a8b-b35e-3026f896669c.png)'
  id: totrans-579
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6fc84cbc-b454-4a8b-b35e-3026f896669c.png)'
- en: Figure 4.16 – softirqs-bpfcc displaying the time that was spent servicing softirqs
    every 1 second (under some I/O stress)
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.16 - softirqs-bpfcc显示了在一些I/O压力下每秒服务软中断的时间
- en: Notice how the tasklet softirq also comes into play.
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`tasklet`软中断也起作用。
- en: 'Let''s look at another example of using the same tool to generate a histogram of
    soft IRQ time distribution (via the `-d` switch, again with the system under some
    I/O – network and disk – stress). The following screenshot shows the output we
    get after running the `sudo softirqs-bpfcc -d` command:'
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个使用相同工具生成软中断时间分布的直方图的示例（再次使用系统在一些I/O - 网络和磁盘 - 压力下，通过`-d`开关）。以下截图显示了运行`sudo
    softirqs-bpfcc -d`命令后得到的输出：
- en: '![](img/6b7e1cc9-c1bc-44d0-ba29-6f4b6604a7f8.png)'
  id: totrans-583
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6b7e1cc9-c1bc-44d0-ba29-6f4b6604a7f8.png)'
- en: Figure 4.17 – softirqs-bpfcc -d showing a histogram (under some I/O stress)
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.17 - softirqs-bpfcc -d显示了一个直方图（在一些I/O压力下）
- en: Again, within this small sample set, the majority of `NET_RX_SOFTIRQ` instances
    have taken just between 4 and 7 microseconds, whereas the majority of `BLOCK_SOFTIRQ` instances
    have taken between 16 and 31 microseconds to complete.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在这个小样本集中，大多数`NET_RX_SOFTIRQ`实例只花费了4到7微秒，而大多数`BLOCK_SOFTIRQ`实例花费了16到31微秒来完成。
- en: These [e]BPF tools have man pages as well (again, with examples). I recommend
    that you install these [e]BPF on a native Linux system (see the companion guide
    *Linux Kernel Programming -* *Chapter 1*, *Kernel Workspace Setup*, the *Modern
    tracing and performance analysis with [e]BPF* section). Take a look and try out
    the tools for yourself.
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: 这些[e]BPF工具也有手册页（包括示例）。我建议你在本地Linux系统上安装这些[e]BPF（参见伴随指南*Linux内核编程*的*第1章*，*内核工作空间设置*，*使用[e]BPF进行现代跟踪和性能分析*部分）。看一看，尝试一下这些工具。
- en: Using Ftrace to get a handle on system latencies
  id: totrans-587
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用Ftrace来掌握系统延迟
- en: Linux has a very powerful tracing engine built into the kernel itself called
    **Ftrace***.* Just as you can trace system calls via the (oh so useful) `strace(1)` (and
    library APIs via `ltrace(1)`) utility in user space, you can also trace pretty
    much every function running in kernel space via Ftrace.Ftrace, though, is much more
    than simply a function tracer – it's a framework, a linchpin of the kernel's underlying
    tracing infrastructure.
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: Linux内核本身内置了一个非常强大的跟踪引擎，称为**Ftrace**。就像你可以通过（非常有用的）`strace(1)`（以及`ltrace(1)`）在用户空间跟踪系统调用和库API一样，你也可以通过Ftrace跟踪几乎在内核空间中运行的每个函数。不过，Ftrace不仅仅是一个函数跟踪器
    - 它是一个框架，是内核底层跟踪基础设施的关键。
- en: Steven Rostedt is the original author of Ftrace. His paper entitled *Finding
    Origins of Latencies Using Ftrace* is a very good read. You can find it here: [https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf](https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf).
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: Steven Rostedt是Ftrace的原始作者。他的论文*使用Ftrace找到延迟的起源*非常值得一读。你可以在这里找到：[https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf](https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf)。
- en: In this section, we don't intend to cover how to use Ftrace in an in-depth manner
    as it's really not part of the subject matter here. Learning to use Ftrace isn't
    difficult, and is a valuable weapon in your kernel debug armory! If you're unfamiliar
    with it, please go through the links we've provided on Ftrace in the *Further
    reading *section at the end of this chapter.
  id: totrans-590
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们不打算深入介绍如何使用Ftrace，因为这并不是本主题的一部分。学习使用Ftrace并不困难，而且是你内核调试工具中的一件宝贵武器！如果你对此不熟悉，请阅读本章末尾的*进一步阅读*部分中我们提供的有关Ftrace的链接。
- en: '**Latency** is the delay between the time when something is supposed to happen
    and when it actually does happen (the tongue in cheek difference between theory
    and practice). System latencies in an OS can be the underlying cause of performance
    issues. Among them are interrupt and scheduling latencies. But what''s the actual
    cause of these latencies? Borrowing from Steve Rostedt''s paper (mentioned previously),
    four *events *cause these latencies:'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: '**延迟**是某事应该发生和实际发生之间的延迟（理论和实践之间的玩笑差异）。操作系统中的系统延迟可能是性能问题的潜在原因。其中包括中断和调度延迟。但是这些延迟的实际原因是什么？借鉴史蒂夫·罗斯特德之前提到的论文，有四个*事件*导致这些延迟：'
- en: '**Interrupts disabled**: If IRQs are off, interrupts cannot be serviced until
    they''re turned on (here, we shall focus on measuring this one.)'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中断禁用**：如果中断关闭，中断在打开之前无法被服务（在这里，我们将专注于测量这个）。'
- en: '**Preemption disabled**: If this is the case, a thread that has been woken
    up cannot run until preemption is enabled.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**抢占禁用**：如果是这种情况，被唤醒的线程在抢占被启用之前无法运行。'
- en: '**Scheduling latency**: The delay between a thread being scheduled to run and
    it actually running on a core (we covered measuring this in the companion guide
    *Linux Kernel Programming -* *Chapter 11, The CPU Scheduler - Part 2* in the section
    *Latency and its measurement*.)'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调度延迟**：线程被调度运行和实际在核心上运行之间的延迟（我们在伴随指南*Linux内核编程*的*第11章，CPU调度器-第2部分*的*延迟及其测量*部分中介绍了如何测量这个延迟）。'
- en: '**Interrupt inversion**: When an interrupt runs in preference to a task that
    has higher priority (similar to priority inversion, this can happen in hard real-time;
    of course, as you learned, this is exactly why threaded handlers are key).'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中断倒置**：当中断优先于具有更高优先级的任务运行时发生的延迟（类似于优先级倒置，这可能发生在硬实时系统中；当然，正如你所学到的，这正是为什么线程处理程序至关重要）。'
- en: Ftrace can record all but the last one. Here, we shall focus on learning how
    to leverage Ftrace to find (or sample, really) the worst-case time for which hardware
    interrupts are disabled. This is referred to as `irqsoff` latency tracing. Let's
    go!
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: Ftrace可以记录除最后一个之外的所有事件。在这里，我们将专注于学习如何利用Ftrace找到（或者说采样）硬件中断被禁用的最坏情况时间。这被称为`irqsoff`延迟跟踪。让我们开始吧！
- en: Finding the interrupts disabled worst-case time latency with Ftrace
  id: totrans-597
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用Ftrace找到中断禁用的最坏情况时间延迟
- en: 'Ftrace has a number of plugins (or tracers) that it works with. First, you
    need to ensure that the `irqsoff` latency tracer (or plugin of Ftrace) is actually
    enabled within the kernel. You can check this in two different ways:'
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: Ftrace有许多插件（或跟踪器）可以使用。首先，你需要确保内核中实际启用了`irqsoff`延迟跟踪器（或Ftrace的插件）。你可以通过两种不同的方式来检查：
- en: Check the kernel config file (`grep` for `CONFIG_IRQSOFF_TRACER` within it).
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查内核配置文件（在其中使用`grep`查找`CONFIG_IRQSOFF_TRACER`）。
- en: Check the available tracers (or plugins) via Ftrace infrastructure.
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Ftrace基础设施检查可用的跟踪器（或插件）。
- en: 'We''ll go with the latter option here:'
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将选择后一种选项：
- en: '[PRE42]'
  id: totrans-602
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: In the preceding output, the `irqsoff` tracer – the one we require – is missing!
    This is usually the case and implies that you will have to configure the kernel
    (turning it on) and (re)build your custom 5.4 kernel. (This will be provided as
    an exercise in the *Questions* section at the end of this chapter.) We also recommend
    that you install a very useful frontend to Ftrace known as the `trace-cmd(1)` utility
    (we mentioned this utility in the companion guide *Linux Kernel Programming* - *Chapter
    1*, *Kernel Workspace Setup *and used it in *Chapter 11, The CPU Scheduler - Part
    2* in the section *Visualizing with trace-cmd*).
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们需要的`irqsoff`跟踪器缺失！这通常是情况，并意味着您需要配置内核（打开它）并（重新）构建您的自定义5.4内核。（这将作为本章末尾的*问题*部分的练习提供。）我们还建议您安装一个非常有用的Ftrace前端工具，称为`trace-cmd(1)`实用程序（我们在配套指南*Linux内核编程*的*第1章*“内核工作空间设置”中提到了这个实用程序，并在*第11章，CPU调度器-第2部分*的*使用trace-cmd进行可视化*部分中使用了它）。
- en: 'Lockdep can cause issues here: if enabled, it''s really best to disable the
    kernel''s lockdep feature when you''re performing latency tracing (it could add
    too much overhead). We''ll discuss lockdep in some detail in [Chapter 7](14cf1232-dfd5-428a-9c0b-30bcd84651b9.xhtml),
    *Kernel Synchronization - Part 2*.'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: Lockdep在这里可能会引起问题：如果启用了，最好在执行延迟跟踪时禁用内核的lockdep功能（它可能会增加太多开销）。我们将在第7章“内核同步-第2部分”中详细讨论lockdep。
- en: 'Once you have `CONFIG_IRQSOFF_TRACER` enabled (and `trace-cmd` installed),
    follow these steps to let Ftrace''s latency tracer figure out the **worst-case
    *interrupts-off* latency**. Needless to say, these steps must be carried out as
    root:'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启用了`CONFIG_IRQSOFF_TRACER`（并安装了`trace-cmd`），请按照以下步骤让Ftrace的延迟跟踪器找出**最坏情况的*中断关闭*延迟**。毋庸置疑，这些步骤必须以root身份执行：
- en: 'Get yourself a root shell (you will need root privileges to do this):'
  id: totrans-606
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取root shell（您需要root权限来执行此操作）：
- en: '[PRE43]'
  id: totrans-607
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Reset the Ftrace framework (this can be done with the `trace-cmd(1)` frontend
    to Ftrace):'
  id: totrans-608
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重置Ftrace框架（可以使用`trace-cmd(1)`前端来完成）：
- en: '[PRE44]'
  id: totrans-609
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Change directories to the one for ftrace:'
  id: totrans-610
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到ftrace的目录：
- en: '[PRE45]'
  id: totrans-611
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: It's can usually be found here. If you have the `debugfs` pseudo filesystem
    mounted under a different directory, then please `cd` there (and to the `tracing` directory under
    it).
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: 通常可以在这里找到。如果您在不同目录下挂载了`debugfs`伪文件系统，请转到那里（并进入其中的`tracing`目录）。
- en: Turn off all tracing using `echo 0 tracing_on` (ensure you leave a space between
    the `0` and the > symbol).
  id: totrans-613
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`echo 0 tracing_on`关闭所有跟踪（确保在`0`和`>`符号之间留有空格）。
- en: 'Set the `irqsoff` tracer as the current tracer:'
  id: totrans-614
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`irqsoff`跟踪器设置为当前跟踪器：
- en: '[PRE46]'
  id: totrans-615
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Now, turn tracing on:'
  id: totrans-616
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，打开跟踪：
- en: '[PRE47]'
  id: totrans-617
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The following output shows the worst-case `irqsoff latency` (this is typically
    shown in microseconds; worry not, we''ll show a sample run shortly):'
  id: totrans-618
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下输出显示了最坏情况的`irqsoff延迟`（通常以微秒显示；不用担心，我们很快会展示一个示例运行）：
- en: '[PRE48]'
  id: totrans-619
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Fetch and read the full report. All Ftrace output is held within the `trace` pseudofile:'
  id: totrans-620
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取并阅读完整报告。所有Ftrace输出都保存在`trace`伪文件中：
- en: '[PRE49]'
  id: totrans-621
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Reset the Ftrace framework:'
  id: totrans-622
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重置Ftrace框架：
- en: '[PRE50]'
  id: totrans-623
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The output we obtain will look like this:'
  id: totrans-624
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得的输出将如下所示：
- en: '[PRE51]'
  id: totrans-625
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Here, the worst-case `irqsoff` latency turned out to be 234 microseconds (experienced
    while the `sshd` task with PID 25311 was executing), implying that hardware interrupts
    were off for this period of time. For your convenience, I have provided a simple
    wrapper Bash script (`ch4/irqsoff_latency_ftrc.sh`) that does the same job.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，最坏情况的`irqsoff`延迟为234微秒（在执行`sshd`任务的PID 25311时经历），这意味着硬件中断在此期间关闭。为了方便起见，我提供了一个简单的Bash脚本包装器（`ch4/irqsoff_latency_ftrc.sh`），可以完成相同的工作。
- en: Now, we will mention a few other useful tools you can use to measure system
    latencies.
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将提到一些其他有用的工具，您可以用来测量系统延迟。
- en: Other tools
  id: totrans-628
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他工具
- en: 'The following are a few tools worth mentioning with regard to capturing and
    analyzing system latencies (and more):'
  id: totrans-629
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些有关捕获和分析系统延迟（以及更多内容）的工具值得一提：
- en: You can learn how to set up and use the powerful **Linux Tracing Toolkit – next
    generation** (**LTTng**) toolset to record traces of the system in action. I highly
    recommend using the superb **Trace Compass** GUI to analyze it. In fact, in the
    companion guide *Linux Kernel Programming -* *Chapter 1*, *Kernel Workspace Setup*,
    in the *Linux Tracing Toolkit next generation (LTTng)* section,we showed an interesting
    screenshot (*Figure 1.9*) of the Trace Compass GUI being used to display and analyze
    IRQ lines 1 and 130 (the interrupt lines for the i8042 and Wi-Fi chipset on my
    native x86_64 system, respectively).
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以学习如何设置和使用强大的**Linux跟踪工具-下一代**（LTTng）工具集来记录系统运行时的跟踪。我强烈推荐使用出色的**Trace Compass**
    GUI来进行分析。实际上，在配套指南*Linux内核编程-第1章*“内核工作空间设置”中的*Linux跟踪工具下一代（LTTng）*部分，我们展示了Trace
    Compass GUI用于显示和分析IRQ线1和130的有趣截图（分别是我的本机x86_64系统上i8042和Wi-Fi芯片的中断线）。
- en: You can also try using the `latencytop` tool to determine which kernel ops what
    user space threads are blocking on. You will have to turn on `CONFIG_LATENCYTOP` in
    the kernel config to do this.
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您还可以尝试使用`latencytop`工具来确定用户空间线程阻塞的内核操作。要执行此操作，您需要在内核配置中打开`CONFIG_LATENCYTOP`。
- en: Besides latency metrics, you can use `dstat(1)`, `mpstat(1)`, `watch(1)`, and
    so on to gain a "top"-like view of interrupts ([https://unix.stackexchange.com/questions/8699/is-there-a-utility-that-interprets-proc-interrupts-data-in-time](https://unix.stackexchange.com/questions/8699/is-there-a-utility-that-interprets-proc-interrupts-data-in-time)).
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了延迟度量，您还可以使用`dstat(1)`、`mpstat(1)`、`watch(1)`等工具来获得类似“top”的中断视图（[https://unix.stackexchange.com/questions/8699/is-there-a-utility-that-interprets-proc-interrupts-data-in-time](https://unix.stackexchange.com/questions/8699/is-there-a-utility-that-interprets-proc-interrupts-data-in-time)）。
- en: With that, we've completed this section and this chapter.
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们已经完成了本节和本章。
- en: Summary
  id: totrans-634
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congratulations! This chapter has been long but worthwhile. You will have learned
    a lot regarding how to work with hardware interrupts. We started by briefly looking
    at how the OS handles interrupts before learning how you, as a driver author,
    must work with them. To do so you learned how to, via several methods, allocate
    IRQ lines (and free them) and implement the hardware interrupt routine. Here,
    several limitations and caveats, essentially boiling down to the fact that it's
    an atomic activity, were discussed. The hows and whys of the "threaded interrupt"
    model were then covered; it's often regarded as the modern recommended way to
    handle interrupts. After that, we understood and learned how to work with hardirqs/softirqs
    and top/bottom halves. Finally, we covered, in typical FAQ style, information
    which taught you about load balancing interrupts, IRQ stacks, and how to employ
    some useful frameworks and tools that can measure interrupt metrics and latencies.
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！这一章很长，但很值得。你将学到很多关于如何处理硬件中断的知识。我们首先简要地了解了操作系统如何处理中断，然后学习了作为驱动程序作者，你必须如何处理它们。为此，你学会了通过几种方法分配IRQ线（和释放它们）并实现硬件中断例程。在这里，讨论了几个限制和注意事项，基本上归结为这是一个原子活动。然后，我们讨论了“线程中断”模型的方法和原因；它通常被认为是处理中断的现代推荐方式。之后，我们了解并学习了如何处理硬中断/软中断和顶部/底部。最后，我们以典型的FAQ风格，介绍了关于负载均衡中断、IRQ堆栈以及如何使用一些有用的框架和工具来测量中断指标和延迟的信息。
- en: All of this is essential knowledge when it comes to engineering a well-written
    driver that must work with hardware interrupts!
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些对于工程一个良好编写的必须与硬件中断一起工作的驱动程序来说都是必要的知识！
- en: 'The next chapter covers the areas of working with time: delays and timeouts
    within the kernel space, creating and managing kernel threads, and using kernel
    workqueues. I suggest that you diligently work on this chapter''s exercises, browse
    the numerous resources in the *Further reading* section, and then take a break
    (hey, all work and no play makes Jack a dull boy, right!?) before diving back
    in! See you there!'
  id: totrans-637
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章涵盖了与时间相关的工作领域：内核空间内的延迟和超时，创建和管理内核线程，以及使用内核工作队列。我建议你努力完成本章的练习，浏览*进一步阅读*部分的众多资源，然后休息一下（嘿，只工作不玩耍，聪明的孩子也变傻！）再继续深入！到时见！
- en: Questions
  id: totrans-638
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: On an x86 system (a VM is fine), show that while the number of timer interrupts
    (IRQ `0`) remains the same, another periodic system interrupt is actually continually
    incrementing (hence keeping track of time on a per-CPU basis).
  id: totrans-639
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在x86系统上（虚拟机也可以），显示定时器中断（IRQ `0`）的数量保持不变，另一个周期性系统中断实际上是不断增加的（因此在每个CPU上跟踪时间）。
- en: '*Hint:* use a `proc`pseudo-file associated with interrupts.'
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示：* 使用与中断相关的`proc`伪文件。'
- en: '***keylogger_simple ; native x86 only  [use only for ethical hacking; may not
    work on a VM]***'
  id: totrans-641
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '***keylogger_simple；仅限本机x86 [仅用于道德黑客攻击；可能无法在虚拟机上运行]***'
- en: (A bit more advanced) Write a simple keyboard logger driver using the "misc"
    kernel framework. Trap it inside the i8042's IRQ 1 in order to "trap" it inside
    the keyboard press/release and read the key scancode. Use a `kfifo` data structure
    to hold the keyboard scancode in kernel space memory. Have a user mode process
    (or thread) periodically read the data items from your driver's `kfifo` into a
    user space buffer and write them into a log file. Write an app (or use another
    thread) to interpret the keyboard keys.
  id: totrans-642
  prefs: []
  type: TYPE_NORMAL
  zh: （稍微高级一点）使用“misc”内核框架编写一个简单的键盘记录器驱动程序。将其陷入i8042的IRQ 1中，以便在键盘按下/释放时“捕获”它并读取键盘扫描码。使用`kfifo`数据结构将键盘扫描码保存在内核空间内存中。有一个用户模式进程（或线程）定期从驱动程序的`kfifo`中读取数据项到用户空间缓冲区，并将其写入日志文件。编写一个应用程序（或使用另一个线程）来解释键盘按键。
- en: '*Tips:*'
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示：*'
- en: Can you ensure that it runs only on x86 (as it should)? Yes; use `#ifdef CONFIG_X86` at
    the very beginning of your code!
  id: totrans-644
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能确保它只在x86上运行（正如它应该的那样）吗？可以；在你的代码开头使用`#ifdef CONFIG_X86`！
- en: Can you ensure that it runs only on a native system and not within a VM? Yes,
    you can use the `virt-what` script within a wrapper script to load up the driver;
    only perform `insmod` (or `modprobe`) if you're not on a VM.
  id: totrans-645
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你能确保它只在本机系统上运行，而不是在虚拟机中吗？是的，你可以在包装脚本中使用`virt-what`脚本来加载驱动程序；只有在不在虚拟机上时才执行`insmod`（或`modprobe`）。
- en: Writing a driver is actually a difficult (and quite unnecessary!) way to implement
    a key logger (here, you're just doing so as a learning exercise so that you know
    how to work with hardware interrupts within a device driver). It's really simpler
    and better to work at higher level abstractions – basically, by querying the kernel's
    `events` layer for keystrokes. A simple way you can do this is by using an event
    monitoring and capture tool – `evtest(1)` is great! (run it as root; [https://www.kernel.org/doc/html/latest/input/input_uapi.html](https://www.kernel.org/doc/html/latest/input/input_uapi.html)).
  id: totrans-646
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写驱动程序实际上是实现按键记录器的一种困难（而且相当不必要！）的方式（在这里，你只是为了学习而这样做，以便了解如何在设备驱动程序中处理硬件中断）。在更高级别的抽象层上工作实际上更简单更好
    - 基本上是通过查询内核的`events`层来获取按键。你可以通过使用事件监视和捕获工具`evtest(1)`来实现这一点（以root身份运行；[https://www.kernel.org/doc/html/latest/input/input_uapi.html](https://www.kernel.org/doc/html/latest/input/input_uapi.html)）。
- en: '*                  References for this assignment:*'
  id: totrans-647
  prefs: []
  type: TYPE_NORMAL
  zh: '*此任务的参考资料：*'
- en: '*Using the kernel kfifo*: [https://elixir.bootlin.com/linux/latest/source/samples/kfifo/bytestream-example.c](https://elixir.bootlin.com/linux/latest/source/samples/kfifo/bytestream-example.c)'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用内核kfifo*：[https://elixir.bootlin.com/linux/latest/source/samples/kfifo/bytestream-example.c](https://elixir.bootlin.com/linux/latest/source/samples/kfifo/bytestream-example.c)'
- en: '*US keyboard map and interpretation*: [http://www.philipstorr.id.au/pcbook/book3/scancode.htm](http://www.philipstorr.id.au/pcbook/book3/scancode.htm); [http://www.osdever.net/bkerndev/Docs/keyboard.htm](http://www.osdever.net/bkerndev/Docs/keyboard.htm)'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*美国键盘映射和解释*：[http://www.philipstorr.id.au/pcbook/book3/scancode.htm](http://www.philipstorr.id.au/pcbook/book3/scancode.htm)；[http://www.osdever.net/bkerndev/Docs/keyboard.htm](http://www.osdever.net/bkerndev/Docs/keyboard.htm)'
- en: 'The kernel provides "deferred functionality" mechanisms often called ______; 
    they''re deliberately designed to get the best of both worlds: (i) ____________ and
    (ii) ______.'
  id: totrans-650
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内核提供了通常称为______的“延迟功能”机制；它们被故意设计为兼顾最佳的两个方面：（i）__________和（ii）__________。
- en: Top halves; run the hardirq as soon as possible; immediately restore the interrupted
    context after that.
  id: totrans-651
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顶半部分；尽快运行hardirq；然后立即恢复中断上下文。
- en: Bottom halves; to allow the driver author to do fairly lengthy interrupt processing
    if the situation demands it. Do this in a deferred, safe manner while allowing
    the business of the system to continue.
  id: totrans-652
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 底半部分；如果情况需要，允许驱动程序作者进行相当长时间的中断处理。在延迟的、安全的方式下进行，同时允许系统的业务继续进行。
- en: Better half; do more work in the interrupt context so that you don't have to
    pay for it later.
  id: totrans-653
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更好的一半；在中断上下文中做更多的工作，这样你就不必以后付出代价。
- en: Bottom halves; run interrupt code with interrupts disabled and let it run for
    a long time.
  id: totrans-654
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 底半部分；在禁用中断的情况下运行中断代码，并让其运行很长时间。
- en: Use a code browsing tool (`cscope(1)` is a good choice) to find drivers that
    are using the `tasklet_hi_schedule()` API.
  id: totrans-655
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用代码浏览工具（`cscope(1)`是一个不错的选择）来查找使用`tasklet_hi_schedule()`API的驱动程序。
- en: Use the Ftrace `irqsoff` latency tracer plugin to find the maximum time for
    which interrupts have been turned off.
  id: totrans-656
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Ftrace `irqsoff`延迟跟踪器插件来查找中断被关闭的最长时间。
- en: '*Tip*:This will involve using the `irqsoff`plugin (`CONFIG_IRQSOFF_TRACER`);
    if it''s not turned on by default, you will have to configure the kernel so that
    it includes it (and other tracers as required; you can find them under `make menuconfig : Kernel
    Hacking / Tracers`). Then, you must build the kernel and turn off it.'
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示*：这将涉及使用`irqsoff`插件（`CONFIG_IRQSOFF_TRACER`）；如果默认情况下没有打开，您将需要配置内核以包含它（以及其他所需的跟踪器；您可以在`make
    menuconfig：Kernel Hacking / Tracers`下找到它们）。然后，您必须构建内核并关闭它。'
- en: '*Tip*:When measuring things such as system latencies (interrupts-off, interrupts-and-preemption-off,
    scheduling latency), it''s best to disable `lockdep`.'
  id: totrans-658
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示*：在测量诸如系统延迟（关闭中断，关闭中断和抢占，调度延迟）等事物时，最好禁用`lockdep`。'
- en: '*Reference:* *Finding Origins of Latencies Using Ftrace*, Steven Rostedt, RedHat: [https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf](https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf).'
  id: totrans-659
  prefs: []
  type: TYPE_NORMAL
  zh: '*参考：* *使用Ftrace查找延迟的起源*，Steven Rostedt，RedHat：[https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf](https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf)。'
- en: Solutions to some of the preceding questions could be found at [https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn).
  id: totrans-660
  prefs: []
  type: TYPE_NORMAL
  zh: 一些先前问题的解决方案可以在[https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn](https://github.com/PacktPublishing/Linux-Kernel-Programming-Part-2/tree/main/solutions_to_assgn)找到。
- en: Further reading
  id: totrans-661
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Kernel documentation: *Linux generic IRQ handling*: [https://www.kernel.org/doc/html/latest/core-api/genericirq.html#linux-generic-irq-handling](https://www.kernel.org/doc/html/latest/core-api/genericirq.html#linux-generic-irq-handling)'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核文档：*Linux通用IRQ处理*：[https://www.kernel.org/doc/html/latest/core-api/genericirq.html#linux-generic-irq-handling](https://www.kernel.org/doc/html/latest/core-api/genericirq.html#linux-generic-irq-handling)
- en: LWN kernel index on interrupts: [https://lwn.net/Kernel/Index/#Interrupts](https://lwn.net/Kernel/Index/#Interrupts)
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LWN内核中断索引：[https://lwn.net/Kernel/Index/#Interrupts](https://lwn.net/Kernel/Index/#Interrupts)
- en: 'Interrupt triggering at the level/edge:'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在级别/边缘触发的中断：
- en: '*Edge Triggered versus Level Triggered interrupts*, Mar ''13: [http://venkateshabbarapu.blogspot.com/2013/03/edge-triggered-vs-level-triggered.html](http://venkateshabbarapu.blogspot.com/2013/03/edge-triggered-vs-level-triggered.html)'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*边沿触发与电平触发中断*，''13年3月：[http://venkateshabbarapu.blogspot.com/2013/03/edge-triggered-vs-level-triggered.html](http://venkateshabbarapu.blogspot.com/2013/03/edge-triggered-vs-level-triggered.html)'
- en: '*Level-triggered versus Edge-triggered Interrupts*, Nov ''08: [https://www.garystringham.com/level-triggered-vs-edge-triggered-interrupts/](https://www.garystringham.com/level-triggered-vs-edge-triggered-interrupts/)'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*电平触发与边沿触发中断*，''08年11月：[https://www.garystringham.com/level-triggered-vs-edge-triggered-interrupts/](https://www.garystringham.com/level-triggered-vs-edge-triggered-interrupts/)'
- en: '*How do I disable non-maskable interrupts programmatically?*: [https://stackoverflow.com/questions/55394608/how-do-i-disable-non-maskable-interrupts-programmatically](https://stackoverflow.com/questions/55394608/how-do-i-disable-non-maskable-interrupts-programmatically)'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*如何以编程方式禁用不可屏蔽中断？*：[https://stackoverflow.com/questions/55394608/how-do-i-disable-non-maskable-interrupts-programmatically](https://stackoverflow.com/questions/55394608/how-do-i-disable-non-maskable-interrupts-programmatically)'
- en: '*Threadable NAPI polling, softirqs, and proper fixes*, Jon Corbet, May 2016,
    LWN: [https://lwn.net/Articles/687617/](https://lwn.net/Articles/687617/)'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可线程化的NAPI轮询，softirqs和适当的修复*，Jon Corbet，2016年5月，LWN：[https://lwn.net/Articles/687617/](https://lwn.net/Articles/687617/)'
- en: 'Possible future directions: softirq vector fine-grained masking:'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可能的未来方向：软中断向量细粒度屏蔽：
- en: '*Per-vector software-interrupt masking*, Jon Corbet, Feb 2019, LWN: [https://lwn.net/Articles/779738/](https://lwn.net/Articles/779738/)'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*每向量软中断屏蔽*，Jon Corbet，2019年2月，LWN：[https://lwn.net/Articles/779738/](https://lwn.net/Articles/779738/)'
- en: '*Soft-interruptible softirqs (or per vector masking)*, Frederic Weisbecker,
    SuSe: [https://linuxplumbersconf.org/event/4/contributions/420/attachments/375/609/lpc_softirq.pdf](https://linuxplumbersconf.org/event/4/contributions/420/attachments/375/609/lpc_softirq.pdf)'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*软中断可中断（或每向量屏蔽）*，Frederic Weisbecker，SuSe：[https://linuxplumbersconf.org/event/4/contributions/420/attachments/375/609/lpc_softirq.pdf](https://linuxplumbersconf.org/event/4/contributions/420/attachments/375/609/lpc_softirq.pdf)'
- en: 'IRQ balancing and affinity:'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IRQ平衡和亲和性：
- en: '*IRQ Balancing*, ntop project: [https://www.ntop.org/pf_ring/irq-balancing/](https://www.ntop.org/pf_ring/irq-balancing/)'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*IRQ平衡*，ntop项目：[https://www.ntop.org/pf_ring/irq-balancing/](https://www.ntop.org/pf_ring/irq-balancing/)'
- en: '*Setting interrupt affinity systems*, RHEL8: [https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance#setting-interrupt-affinity-systems_configuring-an-operating-system-to-optimize-cpu-utilization](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and-managing-system-status-and-performance#setting-interrupt-affinity-systems_configuring-an-operating-system-to-optimize-cpu-utilization)'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设置中断亲和性系统*，RHEL8：[https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and_managing-system-status-and-performance#setting-interrupt-affinity-systems_configuring-an-operating-system-to-optimize-cpu-utilization](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/monitoring_and_managing_system_status_and_performance/configuring-an-operating-system-to-optimize-cpu-utilization_monitoring-and_managing-system-status-and-performance#setting-interrupt-affinity-systems_configuring-an-operating-system-to-optimize-cpu-utilization)'
- en: 'The modern approach to performance measurement and analysis with eBPF:'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现代性能测量和分析的eBPF方法：
- en: '*Linux bcc/eBPF tracing tools*, Brendan Gregg: [https://github.com/iovisor/bcc#tools](https://github.com/iovisor/bcc#tools)'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Linux bcc/eBPF跟踪工具*，Brendan Gregg：[https://github.com/iovisor/bcc#tools](https://github.com/iovisor/bcc#tools)'
- en: '*bcc Tutorial*: [https://github.com/iovisor/bcc/blob/master/docs/tutorial.md#bcc-tutorial](https://github.com/iovisor/bcc/blob/master/docs/tutorial.md#bcc-tutorial)'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*bcc教程*：[https://github.com/iovisor/bcc/blob/master/docs/tutorial.md#bcc-tutorial](https://github.com/iovisor/bcc/blob/master/docs/tutorial.md#bcc-tutorial)'
- en: 'Ftrace:'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ftrace：
- en: 'Kernel doc: *ftrace – Function Tracer*: [https://www.kernel.org/doc/Documentation/trace/ftrace.txt](https://www.kernel.org/doc/Documentation/trace/ftrace.txt)'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内核文档：*ftrace-函数跟踪器*：[https://www.kernel.org/doc/Documentation/trace/ftrace.txt](https://www.kernel.org/doc/Documentation/trace/ftrace.txt)
- en: The following is a collection of links to articles on Ftrace on LWN (some of
    which are mentioned here): [https://lwn.net/Kernel/Index/#Ftrace](https://lwn.net/Kernel/Index/#Ftrace)
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下是有关LWN上Ftrace文章的链接集合（其中一些在此处提到）：[https://lwn.net/Kernel/Index/#Ftrace](https://lwn.net/Kernel/Index/#Ftrace)
- en: '*Debugging the kernel using ftrace - part 1*, Steven Rostedt, LWN, Dec 2009: [https://lwn.net/Articles/365835/](https://lwn.net/Articles/365835/)'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用ftrace调试内核-第1部分*，Steven Rostedt，LWN，2009年12月：[https://lwn.net/Articles/365835/](https://lwn.net/Articles/365835/)'
- en: '*Secrets of the ftrace function tracer*, Steven Rostedt, LWN, Jan 2010: [https://lwn.net/Articles/370423/](https://lwn.net/Articles/370423/)'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ftrace函数跟踪器的秘密*，Steven Rostedt，LWN，2010年1月：[https://lwn.net/Articles/370423/](https://lwn.net/Articles/370423/)'
- en: '*trace-cmd: a frontend for ftrace*, Steven Rostedt, LWN, Oct 2010: [https://lwn.net/Articles/410200/](https://lwn.net/Articles/410200/)'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*trace-cmd：ftrace的前端*，Steven Rostedt，LWN，2010年10月：[https://lwn.net/Articles/410200/](https://lwn.net/Articles/410200/)'
- en: '*Finding Origins of Latencies Using Ftrace*, Steven Rostedt, Oct 2011: [https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf](https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf)'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用Ftrace查找延迟的起源*，Steven Rostedt，2011年10月：[https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf](https://static.lwn.net/images/conf/rtlws11/papers/proc/p02.pdf)'
- en: '*LWN Kernel index on* *Latency*: [https://lwn.net/Kernel/Index/#Latency](https://lwn.net/Kernel/Index/#Latency)'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*LWN上有关* *延迟*的内核索引：[https://lwn.net/Kernel/Index/#Latency](https://lwn.net/Kernel/Index/#Latency)'
